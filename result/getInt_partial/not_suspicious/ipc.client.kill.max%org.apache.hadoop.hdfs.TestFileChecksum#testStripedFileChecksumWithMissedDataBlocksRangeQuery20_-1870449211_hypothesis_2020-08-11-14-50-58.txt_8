reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566607223-172.17.0.14-1597157506822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32849,DS-052c3131-89a0-466b-b3d2-c312a0089df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-c0888ad4-efcd-42b5-be7e-152242de5525,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-4078d1a2-d570-43fe-8b9e-662696bb5299,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-c390fce5-a412-4b8c-9d02-643a70ab3277,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-c4a8d011-d743-44c3-975b-c54a4ebf6ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-65fb9253-e1de-4b72-8f16-0982834a3548,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-70342eb3-4dc5-41d4-ac67-0d125e23c98b,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-a7f24845-6682-4988-9bf5-ca412f24e7e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566607223-172.17.0.14-1597157506822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32849,DS-052c3131-89a0-466b-b3d2-c312a0089df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-c0888ad4-efcd-42b5-be7e-152242de5525,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-4078d1a2-d570-43fe-8b9e-662696bb5299,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-c390fce5-a412-4b8c-9d02-643a70ab3277,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-c4a8d011-d743-44c3-975b-c54a4ebf6ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-65fb9253-e1de-4b72-8f16-0982834a3548,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-70342eb3-4dc5-41d4-ac67-0d125e23c98b,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-a7f24845-6682-4988-9bf5-ca412f24e7e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939338869-172.17.0.14-1597157727712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-0acd37b4-c7d3-4f78-8851-520b0a339345,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-cdfadc45-642c-40fe-b358-b6160daa9525,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-0fa4e683-57bb-45f4-a1bd-ef1a1b39cc13,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-22d48111-a210-432b-bfb7-b92b21547b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-c887ceb7-c173-4f8c-8a38-f5bef67835d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-39a7152b-5e9c-4d79-9a2f-869d001cfa11,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-d1867753-8f04-4f4a-b4e3-20f56d7a2431,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-14397e78-f43b-4885-b625-2b4c1134e46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1939338869-172.17.0.14-1597157727712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46781,DS-0acd37b4-c7d3-4f78-8851-520b0a339345,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-cdfadc45-642c-40fe-b358-b6160daa9525,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-0fa4e683-57bb-45f4-a1bd-ef1a1b39cc13,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-22d48111-a210-432b-bfb7-b92b21547b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-c887ceb7-c173-4f8c-8a38-f5bef67835d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42388,DS-39a7152b-5e9c-4d79-9a2f-869d001cfa11,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-d1867753-8f04-4f4a-b4e3-20f56d7a2431,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-14397e78-f43b-4885-b625-2b4c1134e46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286389247-172.17.0.14-1597158105244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-0db8151c-4bc6-42d3-8428-bf3cc983bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-3d286aa2-889d-4ec3-86d0-0ec4535f07d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-67f484c7-c05a-4bab-8c0d-5caddf034364,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-71b7d27e-a2a2-47c2-825a-d417519f6729,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-7b5d5f0e-5814-4094-8d46-494f1a12d9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-b1bf2b70-53f2-49de-a0ce-6d97156f5585,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-3cc3c1f1-9e2c-4ee9-97ad-1c33e153f332,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-554d8094-54d5-4a10-87a1-c44d86bc853a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286389247-172.17.0.14-1597158105244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-0db8151c-4bc6-42d3-8428-bf3cc983bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-3d286aa2-889d-4ec3-86d0-0ec4535f07d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-67f484c7-c05a-4bab-8c0d-5caddf034364,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-71b7d27e-a2a2-47c2-825a-d417519f6729,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-7b5d5f0e-5814-4094-8d46-494f1a12d9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-b1bf2b70-53f2-49de-a0ce-6d97156f5585,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-3cc3c1f1-9e2c-4ee9-97ad-1c33e153f332,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-554d8094-54d5-4a10-87a1-c44d86bc853a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797010969-172.17.0.14-1597158136007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33711,DS-2f97b2fc-7799-4d77-a0a9-6bf0cf8796f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-ea01734c-b37b-4ab8-8658-557410f82d16,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-c69f93d1-40d1-40a2-9ca5-eb6c3cf39b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-0f8e10a7-b33e-4dd8-98c2-f128f99c4440,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-20308cbe-3d26-4c54-833a-e17d225f2712,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-c0a642e4-f642-404d-ac38-28c1db186426,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-63571d84-6980-49ff-98fd-d6e2df8a12a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-e0443c8b-2f82-4e4e-b7a2-8343f3f21b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797010969-172.17.0.14-1597158136007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33711,DS-2f97b2fc-7799-4d77-a0a9-6bf0cf8796f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41392,DS-ea01734c-b37b-4ab8-8658-557410f82d16,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-c69f93d1-40d1-40a2-9ca5-eb6c3cf39b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-0f8e10a7-b33e-4dd8-98c2-f128f99c4440,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-20308cbe-3d26-4c54-833a-e17d225f2712,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-c0a642e4-f642-404d-ac38-28c1db186426,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-63571d84-6980-49ff-98fd-d6e2df8a12a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-e0443c8b-2f82-4e4e-b7a2-8343f3f21b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685565579-172.17.0.14-1597158209867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-93ea37c3-14e7-41ff-93ed-02de99255b52,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-ed768c9e-a740-4020-bacc-794ca4fe4db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-0ebed94b-4714-465b-82b1-0ea43dd0e2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-c311f44d-7577-42f8-a525-1bdfc9fc1189,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-b487bbd8-972f-4219-9113-bd8141408785,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-0b4e7dee-04ac-4f8e-9ae2-937ea1bfd071,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-19d01a65-d17c-4be8-9ee4-162ca8015287,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-88aed3ec-2bd2-46b1-a290-fd5e4e3eb49e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685565579-172.17.0.14-1597158209867:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-93ea37c3-14e7-41ff-93ed-02de99255b52,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-ed768c9e-a740-4020-bacc-794ca4fe4db9,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-0ebed94b-4714-465b-82b1-0ea43dd0e2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-c311f44d-7577-42f8-a525-1bdfc9fc1189,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-b487bbd8-972f-4219-9113-bd8141408785,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-0b4e7dee-04ac-4f8e-9ae2-937ea1bfd071,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-19d01a65-d17c-4be8-9ee4-162ca8015287,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-88aed3ec-2bd2-46b1-a290-fd5e4e3eb49e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068740739-172.17.0.14-1597158843015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-57e1037f-152d-4e7d-8221-651481586be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-086882b0-e747-4af9-92f5-214d47a41358,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-e9c2850d-c537-4e61-bebe-e0b63567043d,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-359a35c0-e75b-4cfd-9266-08bc07d066f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-15a9d113-7c5a-4cc5-97fd-c3ecfb1b4fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-2c0b292e-2284-4849-af54-3e4ad0f75025,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-f0e17bb1-d8e0-4e87-820e-646f7cd10ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-9925d8d3-83f5-4cab-b264-815aa4feb4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068740739-172.17.0.14-1597158843015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43205,DS-57e1037f-152d-4e7d-8221-651481586be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-086882b0-e747-4af9-92f5-214d47a41358,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-e9c2850d-c537-4e61-bebe-e0b63567043d,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-359a35c0-e75b-4cfd-9266-08bc07d066f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-15a9d113-7c5a-4cc5-97fd-c3ecfb1b4fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-2c0b292e-2284-4849-af54-3e4ad0f75025,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-f0e17bb1-d8e0-4e87-820e-646f7cd10ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-9925d8d3-83f5-4cab-b264-815aa4feb4ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831736693-172.17.0.14-1597158873258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34366,DS-8e375aea-f847-41fa-97a3-d98fcb5bf4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-034e5748-2873-421d-a382-a22532221a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-f805ffa5-4932-4966-99dd-9048f4a450ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-5c3c1ce0-b1dc-4f37-949b-fc6dc14f7a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-1f785173-f266-4f53-b4d1-adad3139e263,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-bec53720-1cb3-4035-bc90-75c8c387d86e,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-c5baec9c-b60f-42ac-b704-9fcc2163dd28,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-2cda9a50-67f3-4689-8345-9588303ee092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831736693-172.17.0.14-1597158873258:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34366,DS-8e375aea-f847-41fa-97a3-d98fcb5bf4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-034e5748-2873-421d-a382-a22532221a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-f805ffa5-4932-4966-99dd-9048f4a450ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-5c3c1ce0-b1dc-4f37-949b-fc6dc14f7a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-1f785173-f266-4f53-b4d1-adad3139e263,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-bec53720-1cb3-4035-bc90-75c8c387d86e,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-c5baec9c-b60f-42ac-b704-9fcc2163dd28,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-2cda9a50-67f3-4689-8345-9588303ee092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626114631-172.17.0.14-1597158960024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-ca4e40f8-2c8e-4f81-8c09-53476ac299b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-dc675864-13d4-4acd-98fb-efcf267ee3af,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-181ffc0e-3fb8-4052-8e17-1b0f46ff6770,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-7285ea27-9ddf-4413-9f63-93f46f959ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-38fac15f-2ba4-4e8a-9d3b-98f0e46e705f,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-c31ba0de-7e57-4f7c-9011-aa6c8ee762f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-418d2d91-0680-4063-80eb-e9c23de23b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-5aa555c6-b7cd-41a8-b98e-3904663a9998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626114631-172.17.0.14-1597158960024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-ca4e40f8-2c8e-4f81-8c09-53476ac299b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-dc675864-13d4-4acd-98fb-efcf267ee3af,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-181ffc0e-3fb8-4052-8e17-1b0f46ff6770,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-7285ea27-9ddf-4413-9f63-93f46f959ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-38fac15f-2ba4-4e8a-9d3b-98f0e46e705f,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-c31ba0de-7e57-4f7c-9011-aa6c8ee762f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-418d2d91-0680-4063-80eb-e9c23de23b79,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-5aa555c6-b7cd-41a8-b98e-3904663a9998,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577475082-172.17.0.14-1597159307372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-6538b283-d5ac-423a-8d73-bd862098edd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-ca5c7c94-5e2c-467d-8c83-d1302c1f1c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-98fbb217-ed34-4957-b59b-e6d0cb324b08,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-e8da1525-f800-4d84-91c1-2629dbe05310,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-a658da65-efc8-4d87-aa15-b76414d0953a,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-b233bcea-7ed4-4307-a442-506f8281fcda,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-f4b691ef-64b2-41c2-93e8-09ccb24c0efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-6bdde834-ff4c-4eca-b463-4290df90f925,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577475082-172.17.0.14-1597159307372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-6538b283-d5ac-423a-8d73-bd862098edd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-ca5c7c94-5e2c-467d-8c83-d1302c1f1c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-98fbb217-ed34-4957-b59b-e6d0cb324b08,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-e8da1525-f800-4d84-91c1-2629dbe05310,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-a658da65-efc8-4d87-aa15-b76414d0953a,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-b233bcea-7ed4-4307-a442-506f8281fcda,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-f4b691ef-64b2-41c2-93e8-09ccb24c0efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-6bdde834-ff4c-4eca-b463-4290df90f925,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234700161-172.17.0.14-1597159665047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-d5a0f331-e760-4bc2-b4b5-4b6e0f64c307,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-052f2d80-ff26-4bb4-bfef-5a78812153e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-8ab27cb4-fed9-4c69-9eab-1859c49c32a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-3660e14c-4c61-4fa1-9498-cb9fe272991c,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-64586c75-00ee-4096-83ee-8a029e0ee633,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-4b2b295f-771e-4045-aa98-594dee379fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-2acd515f-4453-4c90-bb7c-1e452997f088,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-1113fcf0-0c42-44a2-b043-af9e8d59f6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234700161-172.17.0.14-1597159665047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41748,DS-d5a0f331-e760-4bc2-b4b5-4b6e0f64c307,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-052f2d80-ff26-4bb4-bfef-5a78812153e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-8ab27cb4-fed9-4c69-9eab-1859c49c32a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-3660e14c-4c61-4fa1-9498-cb9fe272991c,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-64586c75-00ee-4096-83ee-8a029e0ee633,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-4b2b295f-771e-4045-aa98-594dee379fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-2acd515f-4453-4c90-bb7c-1e452997f088,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-1113fcf0-0c42-44a2-b043-af9e8d59f6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843129942-172.17.0.14-1597160191580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-6a8dbdcd-428d-4047-aa76-3a7dd2a277af,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-743f94a8-449e-46b8-87b6-38b4449962d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-cde0bc83-cbb6-49da-866a-42ee7427c470,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-378e6f3d-ad3b-4b23-a333-16de9b19f707,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-f155f6e9-68bd-4e89-9be8-6ccebaf8b7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-74dcb14e-ebc6-422d-ab4e-e68cc1113c65,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-5a357ee1-ae91-4f91-898d-912309696e00,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-5ee1ab48-2017-4c33-afe6-e3b325900d94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843129942-172.17.0.14-1597160191580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-6a8dbdcd-428d-4047-aa76-3a7dd2a277af,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-743f94a8-449e-46b8-87b6-38b4449962d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-cde0bc83-cbb6-49da-866a-42ee7427c470,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-378e6f3d-ad3b-4b23-a333-16de9b19f707,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-f155f6e9-68bd-4e89-9be8-6ccebaf8b7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-74dcb14e-ebc6-422d-ab4e-e68cc1113c65,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-5a357ee1-ae91-4f91-898d-912309696e00,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-5ee1ab48-2017-4c33-afe6-e3b325900d94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912847564-172.17.0.14-1597160483555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-8b057767-269c-4dff-9ae4-42016d888bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-0d329430-a854-4a2a-82c6-70e4da8e93d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4a7d5125-b958-47b9-8c45-56b6b04d7256,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-1f1998ee-cb38-48e5-982c-34acd8d59cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-c505c693-ff74-4987-9aff-6dfdc68296ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-54482c46-375b-4c78-8f6a-be506bb2e73d,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-3dbf6863-cd54-4b29-8b78-db9640c5e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-db6154f7-baf7-4834-b95a-4d53c988e6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912847564-172.17.0.14-1597160483555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-8b057767-269c-4dff-9ae4-42016d888bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-0d329430-a854-4a2a-82c6-70e4da8e93d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4a7d5125-b958-47b9-8c45-56b6b04d7256,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-1f1998ee-cb38-48e5-982c-34acd8d59cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-c505c693-ff74-4987-9aff-6dfdc68296ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-54482c46-375b-4c78-8f6a-be506bb2e73d,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-3dbf6863-cd54-4b29-8b78-db9640c5e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-db6154f7-baf7-4834-b95a-4d53c988e6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150127986-172.17.0.14-1597160976750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42474,DS-cde428ea-cae7-4295-b14a-85fa8825259d,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-90116cc9-1f9a-4292-89dd-ec5ca870391d,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-44494c18-730a-4953-88dd-8b8df6ce4ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-3e266d06-0b81-4c54-ac05-4a659e14a886,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-4e8fdb41-663b-496a-9b6f-4bcbe11c5f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-3f0cfde7-d1cb-4679-a5f4-78203f6c954d,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-078bfed5-b93b-48c3-9bc5-e8f65df2adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-79dccfdc-46dc-4470-b936-5a3451d7a120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1150127986-172.17.0.14-1597160976750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42474,DS-cde428ea-cae7-4295-b14a-85fa8825259d,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-90116cc9-1f9a-4292-89dd-ec5ca870391d,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-44494c18-730a-4953-88dd-8b8df6ce4ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:40940,DS-3e266d06-0b81-4c54-ac05-4a659e14a886,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-4e8fdb41-663b-496a-9b6f-4bcbe11c5f88,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-3f0cfde7-d1cb-4679-a5f4-78203f6c954d,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-078bfed5-b93b-48c3-9bc5-e8f65df2adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43566,DS-79dccfdc-46dc-4470-b936-5a3451d7a120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934026441-172.17.0.14-1597161008393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34958,DS-02972ecf-8476-413e-b939-bf8be96a9f66,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-2aaa487e-90e6-4b9e-8e9c-73e3c0dc762e,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-2cc0b03d-587d-4de2-bf91-8b3fcb05b6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-c3d76459-bb29-4080-be96-ace714c75222,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-88b24fd7-1de5-45f2-b6c3-3b59c7c9c645,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-4303e46b-b2e1-4ab4-9fb9-46cecc274135,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-29cd621b-1ee4-40aa-a9f5-95aefe9a9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-2c7166c9-79ec-43b4-8f27-abb16a6b397d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934026441-172.17.0.14-1597161008393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34958,DS-02972ecf-8476-413e-b939-bf8be96a9f66,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-2aaa487e-90e6-4b9e-8e9c-73e3c0dc762e,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-2cc0b03d-587d-4de2-bf91-8b3fcb05b6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-c3d76459-bb29-4080-be96-ace714c75222,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-88b24fd7-1de5-45f2-b6c3-3b59c7c9c645,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-4303e46b-b2e1-4ab4-9fb9-46cecc274135,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-29cd621b-1ee4-40aa-a9f5-95aefe9a9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-2c7166c9-79ec-43b4-8f27-abb16a6b397d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572617911-172.17.0.14-1597161101575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44004,DS-d7be6274-eea9-48c3-9d30-4a39f6b240ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-a12c6f7e-9745-4c9b-acba-73ba99bb8fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-c34efd7d-8a48-422d-b97b-1b40d79514b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-007447f7-e0b5-4c91-96d6-e369883ea225,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-281f0840-12d3-429b-a153-bc5da18b8781,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-a346e85e-03f9-4612-9963-25540fd550a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-434b90c6-f8cb-4cef-930a-174e69a22ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-6629cd04-887a-4e9f-b25a-35828cb7178c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572617911-172.17.0.14-1597161101575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44004,DS-d7be6274-eea9-48c3-9d30-4a39f6b240ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-a12c6f7e-9745-4c9b-acba-73ba99bb8fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-c34efd7d-8a48-422d-b97b-1b40d79514b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-007447f7-e0b5-4c91-96d6-e369883ea225,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-281f0840-12d3-429b-a153-bc5da18b8781,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-a346e85e-03f9-4612-9963-25540fd550a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-434b90c6-f8cb-4cef-930a-174e69a22ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-6629cd04-887a-4e9f-b25a-35828cb7178c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523129904-172.17.0.14-1597161981332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45726,DS-71cc878f-a464-4b02-82e8-a5b5be968bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-ff51fca9-27da-418f-97a0-b860e7ffaae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-d59e294e-b4fc-4324-b99d-485915113f69,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-dc6edeaf-b588-41cd-b206-af92dc1c65fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-e63f4e4d-8812-4567-9aea-4f68d2252479,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-a341a554-f0e9-4c7e-b73b-f49d1140ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-ad082444-ae1f-4ce5-966f-66a6d1f1c41b,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-fae66987-054a-4487-8a8e-2af9c7907473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523129904-172.17.0.14-1597161981332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45726,DS-71cc878f-a464-4b02-82e8-a5b5be968bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-ff51fca9-27da-418f-97a0-b860e7ffaae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-d59e294e-b4fc-4324-b99d-485915113f69,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-dc6edeaf-b588-41cd-b206-af92dc1c65fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-e63f4e4d-8812-4567-9aea-4f68d2252479,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-a341a554-f0e9-4c7e-b73b-f49d1140ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-ad082444-ae1f-4ce5-966f-66a6d1f1c41b,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-fae66987-054a-4487-8a8e-2af9c7907473,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718772045-172.17.0.14-1597162278362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39384,DS-4e1689a9-167a-4ccf-86ff-c70666538b61,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-a1e64f16-b742-40cd-b51f-4d2a1c01bbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-f030c8c8-b257-404d-9435-133c03208b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-f9d6b3e8-9712-42eb-8900-0f5d917f560c,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-93fe42b6-4264-403e-b060-79360c64be36,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-cf1531ed-7237-46c1-a82c-4975fab703e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-d00e0caf-07d4-4f60-82ac-a9177f789024,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-45ac941d-07f0-49ec-bcc3-0c802accbf0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1718772045-172.17.0.14-1597162278362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39384,DS-4e1689a9-167a-4ccf-86ff-c70666538b61,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-a1e64f16-b742-40cd-b51f-4d2a1c01bbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-f030c8c8-b257-404d-9435-133c03208b83,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-f9d6b3e8-9712-42eb-8900-0f5d917f560c,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-93fe42b6-4264-403e-b060-79360c64be36,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-cf1531ed-7237-46c1-a82c-4975fab703e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-d00e0caf-07d4-4f60-82ac-a9177f789024,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-45ac941d-07f0-49ec-bcc3-0c802accbf0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574987666-172.17.0.14-1597162384194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-4bc31ca0-844a-4bd9-a22d-7bfab550486a,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-b6549e4e-0541-46ef-90c8-6389a5539421,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-d46f97c6-9bb8-462b-ad2c-d2ee4e55c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-93e09355-1a37-403f-be3e-83dbd342567e,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-f6704c5b-c7c0-4faa-a459-a61c4dc2cd91,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-13c94a91-684a-4fac-a01b-1e5fa08a36f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d5168856-aff0-4ee9-b293-09d92a92d9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-c1b80cd3-e118-4079-a669-c1e257184539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574987666-172.17.0.14-1597162384194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-4bc31ca0-844a-4bd9-a22d-7bfab550486a,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-b6549e4e-0541-46ef-90c8-6389a5539421,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-d46f97c6-9bb8-462b-ad2c-d2ee4e55c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-93e09355-1a37-403f-be3e-83dbd342567e,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-f6704c5b-c7c0-4faa-a459-a61c4dc2cd91,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-13c94a91-684a-4fac-a01b-1e5fa08a36f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d5168856-aff0-4ee9-b293-09d92a92d9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-c1b80cd3-e118-4079-a669-c1e257184539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 4971
