reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815246582-172.17.0.15-1597106689910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-5dd00c26-aed0-4919-a9d4-7f6c95be492e,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-2645d2cc-6fa4-4680-848a-1dbbc19433d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-4c5786ce-9e74-4e85-bb4b-02bf514d2efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-58cb80bb-b5d8-45ef-9b9d-2b526248553e,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-646d179a-a8fc-4127-957b-457af6e8aa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-6646676a-eb58-48df-a6c6-8827b2e5ab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-8dcecc6f-5b4a-44fc-bf1a-3f6158732d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-48fe7675-a233-4fb9-b74e-3d27fa05b394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-815246582-172.17.0.15-1597106689910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42349,DS-5dd00c26-aed0-4919-a9d4-7f6c95be492e,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-2645d2cc-6fa4-4680-848a-1dbbc19433d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-4c5786ce-9e74-4e85-bb4b-02bf514d2efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-58cb80bb-b5d8-45ef-9b9d-2b526248553e,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-646d179a-a8fc-4127-957b-457af6e8aa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-6646676a-eb58-48df-a6c6-8827b2e5ab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-8dcecc6f-5b4a-44fc-bf1a-3f6158732d35,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-48fe7675-a233-4fb9-b74e-3d27fa05b394,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270737637-172.17.0.15-1597107581183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-276d09cc-dc0e-46f8-b0a2-d50fae9002bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-7f96f150-ee3e-48de-b708-80a981f0bd59,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-b48fd587-659f-415f-b4d3-4762e32b7773,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-d0290da3-e782-4420-bf1c-b2a8059e5fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-73370990-921d-4086-8d0d-e3274f9fda49,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-3b2dac6b-aad8-4d70-a23b-62e33eba1771,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-4e3cc9db-e48e-4b41-a748-4771de96145f,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-e433124c-4439-402d-876e-ef89fbda5951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270737637-172.17.0.15-1597107581183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-276d09cc-dc0e-46f8-b0a2-d50fae9002bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-7f96f150-ee3e-48de-b708-80a981f0bd59,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-b48fd587-659f-415f-b4d3-4762e32b7773,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-d0290da3-e782-4420-bf1c-b2a8059e5fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-73370990-921d-4086-8d0d-e3274f9fda49,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-3b2dac6b-aad8-4d70-a23b-62e33eba1771,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-4e3cc9db-e48e-4b41-a748-4771de96145f,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-e433124c-4439-402d-876e-ef89fbda5951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359698630-172.17.0.15-1597108017179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-02ae1db9-b700-442b-87ef-1a1d151cf76e,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-b2fe86e9-4cef-4fce-bd3e-6cdfa67e18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-7463d01e-4645-4d08-a061-12954158adbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-e938b625-40b1-4de3-882d-bfad9fbb78fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-f32439ff-3357-4a1e-a2e1-a084e3cb18d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-ff3b0ac5-9538-4d64-8995-ecea552a2b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-af1bc279-c480-4de9-8235-ada5231b6404,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-3c261609-ebd8-4508-b49a-b8ee24ed19f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359698630-172.17.0.15-1597108017179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39059,DS-02ae1db9-b700-442b-87ef-1a1d151cf76e,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-b2fe86e9-4cef-4fce-bd3e-6cdfa67e18a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-7463d01e-4645-4d08-a061-12954158adbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-e938b625-40b1-4de3-882d-bfad9fbb78fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-f32439ff-3357-4a1e-a2e1-a084e3cb18d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-ff3b0ac5-9538-4d64-8995-ecea552a2b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-af1bc279-c480-4de9-8235-ada5231b6404,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-3c261609-ebd8-4508-b49a-b8ee24ed19f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484466993-172.17.0.15-1597108175619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42090,DS-fd12d478-53cb-48cf-81d1-138b884a1dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-da35db13-bf26-4587-a9d7-a10b9c0c9198,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-1d62caf7-0723-4166-8f51-a119e432da20,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-437a7baa-82c2-4b1e-8753-31886c261171,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-e920677e-4e7d-4064-8165-ec9b744cd957,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-9a04db76-2aea-4e2b-92c2-921614292536,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-b269140a-2533-487a-8ac3-d75e1351b04b,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-993050eb-d5bd-4cf3-be73-70b2220cfe3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-484466993-172.17.0.15-1597108175619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42090,DS-fd12d478-53cb-48cf-81d1-138b884a1dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35061,DS-da35db13-bf26-4587-a9d7-a10b9c0c9198,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-1d62caf7-0723-4166-8f51-a119e432da20,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-437a7baa-82c2-4b1e-8753-31886c261171,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-e920677e-4e7d-4064-8165-ec9b744cd957,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-9a04db76-2aea-4e2b-92c2-921614292536,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-b269140a-2533-487a-8ac3-d75e1351b04b,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-993050eb-d5bd-4cf3-be73-70b2220cfe3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651367309-172.17.0.15-1597108316317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-2408d7fa-8ba9-4ed7-a235-c93aa0796c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-759e623b-833a-4794-a940-d382e1f70b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-2ab545ea-6ff5-426a-90ea-2922b5305fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-52c59845-cbe1-4a87-aae7-51079a195a61,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-a4937008-30c8-4372-b75a-7ec44615acdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-b0ea2d45-923e-4017-aaed-c09b1b57d7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-f6f11b24-469e-4a84-9893-ce4cfbbcc87b,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-548b352b-4ba8-4c1d-8497-465ed2262b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651367309-172.17.0.15-1597108316317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46060,DS-2408d7fa-8ba9-4ed7-a235-c93aa0796c17,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-759e623b-833a-4794-a940-d382e1f70b28,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-2ab545ea-6ff5-426a-90ea-2922b5305fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-52c59845-cbe1-4a87-aae7-51079a195a61,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-a4937008-30c8-4372-b75a-7ec44615acdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-b0ea2d45-923e-4017-aaed-c09b1b57d7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-f6f11b24-469e-4a84-9893-ce4cfbbcc87b,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-548b352b-4ba8-4c1d-8497-465ed2262b7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370451179-172.17.0.15-1597108393381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-92083c9b-2b04-4e82-ba1a-3c6ac6c51de5,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-f8e4bd81-517b-4370-9b50-73a5873f0c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-f087666e-80f7-421e-807c-87a32a13ab33,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-49d88c94-ac64-4e7c-9424-187e9e99e734,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-1f9e6558-9023-486a-b87e-5660cfdcce78,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-d5d44463-f5bf-4b4f-86c4-e6e3629cac07,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-47285a08-8cc6-457f-9416-90ac4fca7c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-acc1c519-afb7-4c38-8062-04c51ea91346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370451179-172.17.0.15-1597108393381:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-92083c9b-2b04-4e82-ba1a-3c6ac6c51de5,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-f8e4bd81-517b-4370-9b50-73a5873f0c01,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-f087666e-80f7-421e-807c-87a32a13ab33,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-49d88c94-ac64-4e7c-9424-187e9e99e734,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-1f9e6558-9023-486a-b87e-5660cfdcce78,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-d5d44463-f5bf-4b4f-86c4-e6e3629cac07,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-47285a08-8cc6-457f-9416-90ac4fca7c02,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-acc1c519-afb7-4c38-8062-04c51ea91346,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154406898-172.17.0.15-1597109846592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-67ec989e-960d-4995-a86f-924bdc738679,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-9a3e5df4-a54d-488e-8b70-bdb66954e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-c1589be3-34b8-4d7b-9835-b1979e0bfb69,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-f480b757-3e60-4780-8101-96b429f03c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-dd576856-1e06-454e-8337-8ec513119998,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-40d279b9-9679-4bbd-a804-5355ff6de2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-eb82f074-3fc6-45f2-bab3-2823fc87e1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-2b28b8f6-d72f-4c52-9ca5-14e4e96463cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154406898-172.17.0.15-1597109846592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39883,DS-67ec989e-960d-4995-a86f-924bdc738679,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-9a3e5df4-a54d-488e-8b70-bdb66954e7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-c1589be3-34b8-4d7b-9835-b1979e0bfb69,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-f480b757-3e60-4780-8101-96b429f03c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-dd576856-1e06-454e-8337-8ec513119998,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-40d279b9-9679-4bbd-a804-5355ff6de2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-eb82f074-3fc6-45f2-bab3-2823fc87e1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-2b28b8f6-d72f-4c52-9ca5-14e4e96463cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974553627-172.17.0.15-1597109961235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-744ead43-05c5-4e6a-9375-cb69c7239f92,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-7e905940-768e-4b34-b0c5-b538246e0d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-23803e7f-2045-4b7c-bf2a-1f446874ec20,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-877d733f-a85a-4d3a-be4f-1b3dfe44e98f,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-430b130b-7924-4342-af7e-29eb38a8593d,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-6ba93003-e757-4e77-b2ac-8fd9da91bb84,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-db0ecfde-5acf-473a-b4ed-8d228364ad02,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0ff0de52-ab1e-4cf3-ad9a-b41e01fa306a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974553627-172.17.0.15-1597109961235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-744ead43-05c5-4e6a-9375-cb69c7239f92,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-7e905940-768e-4b34-b0c5-b538246e0d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-23803e7f-2045-4b7c-bf2a-1f446874ec20,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-877d733f-a85a-4d3a-be4f-1b3dfe44e98f,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-430b130b-7924-4342-af7e-29eb38a8593d,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-6ba93003-e757-4e77-b2ac-8fd9da91bb84,DISK], DatanodeInfoWithStorage[127.0.0.1:46155,DS-db0ecfde-5acf-473a-b4ed-8d228364ad02,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-0ff0de52-ab1e-4cf3-ad9a-b41e01fa306a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924329628-172.17.0.15-1597110198695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46718,DS-e215879c-d7e1-4469-b7b7-33c1a2e261d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-06ac3938-d88a-4f0f-9803-e2fb39469b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-85cbb372-4392-4e1f-9819-84ddc5c5cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-497c428e-f3b5-4c03-abbf-e0b151018498,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-6493ac1a-c937-4903-8dc6-9352ec1fd0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-d4a4df13-4814-4615-bd62-6bb7dee68e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-77ddb340-457f-4132-9d54-5b3e6b03cabf,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-b718a954-b0e8-4bde-bba8-2f3510dea9f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924329628-172.17.0.15-1597110198695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46718,DS-e215879c-d7e1-4469-b7b7-33c1a2e261d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-06ac3938-d88a-4f0f-9803-e2fb39469b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-85cbb372-4392-4e1f-9819-84ddc5c5cf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-497c428e-f3b5-4c03-abbf-e0b151018498,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-6493ac1a-c937-4903-8dc6-9352ec1fd0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-d4a4df13-4814-4615-bd62-6bb7dee68e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-77ddb340-457f-4132-9d54-5b3e6b03cabf,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-b718a954-b0e8-4bde-bba8-2f3510dea9f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836514484-172.17.0.15-1597110603569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-d7fb333f-ed08-4ab0-9e32-0f12e279af7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-3d6374a0-d3b6-4948-bef1-d664dffd4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-6e1d5196-bdba-48b2-a6a2-afee9b14e3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-f8fe2efc-8d63-450b-b686-54720f73ef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-f54064ba-b631-49f0-bc3e-a294b9979af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-70406dc7-d437-40af-bb62-b00dc404951c,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-d9c2ce31-4226-45cd-82f3-9124fcc5bd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-04067d5e-124b-456e-92c9-66bf6c4e5091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836514484-172.17.0.15-1597110603569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36759,DS-d7fb333f-ed08-4ab0-9e32-0f12e279af7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-3d6374a0-d3b6-4948-bef1-d664dffd4fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-6e1d5196-bdba-48b2-a6a2-afee9b14e3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-f8fe2efc-8d63-450b-b686-54720f73ef9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-f54064ba-b631-49f0-bc3e-a294b9979af7,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-70406dc7-d437-40af-bb62-b00dc404951c,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-d9c2ce31-4226-45cd-82f3-9124fcc5bd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-04067d5e-124b-456e-92c9-66bf6c4e5091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248972448-172.17.0.15-1597110723810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-b879fa6f-65ce-43c9-97e8-d56e36636921,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-a1cfc004-6469-4d0e-8667-7531d9170208,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-bb52a5cd-a546-44b5-8c9c-c0b0d2e3927a,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-f2bd455d-3585-4e47-8880-f5958f466ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-f4af6114-9211-451e-ae08-1c40793eb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-529012b0-7786-4501-88c2-9bc9d8c1baac,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-004e3aef-41bc-4b3e-86a8-2764f45d0ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-006ee847-bdb5-4453-ab8d-68eec563d9cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248972448-172.17.0.15-1597110723810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37238,DS-b879fa6f-65ce-43c9-97e8-d56e36636921,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-a1cfc004-6469-4d0e-8667-7531d9170208,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-bb52a5cd-a546-44b5-8c9c-c0b0d2e3927a,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-f2bd455d-3585-4e47-8880-f5958f466ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-f4af6114-9211-451e-ae08-1c40793eb4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-529012b0-7786-4501-88c2-9bc9d8c1baac,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-004e3aef-41bc-4b3e-86a8-2764f45d0ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-006ee847-bdb5-4453-ab8d-68eec563d9cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250843921-172.17.0.15-1597110759652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-ec922d11-c7f6-435e-b43f-14982b84ae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-5fa3bba9-31a2-4681-ba48-101068ee4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-24952056-8e57-4ca6-9b40-07f5a88eec48,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-24301f7b-9653-4aa3-af9f-e649899e8ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-044e357f-4af5-4b3c-a2df-2c20a0445921,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-92015eca-b9cd-4822-80ba-a90dbac5df62,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-f01ac6a6-50d8-4407-b333-2634fcbd9e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-cddbddfa-21f4-4fd4-a749-cf62932b7805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250843921-172.17.0.15-1597110759652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35138,DS-ec922d11-c7f6-435e-b43f-14982b84ae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-5fa3bba9-31a2-4681-ba48-101068ee4bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-24952056-8e57-4ca6-9b40-07f5a88eec48,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-24301f7b-9653-4aa3-af9f-e649899e8ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-044e357f-4af5-4b3c-a2df-2c20a0445921,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-92015eca-b9cd-4822-80ba-a90dbac5df62,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-f01ac6a6-50d8-4407-b333-2634fcbd9e36,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-cddbddfa-21f4-4fd4-a749-cf62932b7805,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 100
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404315936-172.17.0.15-1597111353104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-376b3ece-205b-4a41-bc81-50a1657705a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-0ad6d01a-4b62-48a0-94d6-a26cb1344de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-c47407dc-c474-4247-8b2f-df36bd5240e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-c31b8b02-1cf9-4300-b32e-e870be297413,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-c373fd48-e1c5-46e6-b6d4-90cacb88c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-8157e111-929e-4873-bee8-f5034dbe5cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-3b892c1e-fe96-45f8-a696-8f09f06645c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-948aad3b-2743-43dd-91d0-dc7224aa0dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1404315936-172.17.0.15-1597111353104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35819,DS-376b3ece-205b-4a41-bc81-50a1657705a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-0ad6d01a-4b62-48a0-94d6-a26cb1344de2,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-c47407dc-c474-4247-8b2f-df36bd5240e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-c31b8b02-1cf9-4300-b32e-e870be297413,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-c373fd48-e1c5-46e6-b6d4-90cacb88c5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-8157e111-929e-4873-bee8-f5034dbe5cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-3b892c1e-fe96-45f8-a696-8f09f06645c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-948aad3b-2743-43dd-91d0-dc7224aa0dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5108
