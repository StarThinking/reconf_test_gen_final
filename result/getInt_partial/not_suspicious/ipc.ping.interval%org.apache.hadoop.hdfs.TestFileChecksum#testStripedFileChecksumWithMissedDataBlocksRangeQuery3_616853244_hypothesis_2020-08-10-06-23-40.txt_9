reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691589473-172.17.0.10-1597041562039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38847,DS-6e2ebc48-ca67-4e2e-8baa-abf1eb4b408a,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-e9c38abb-d578-4372-9045-96befd69a9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-91e75e35-2876-445b-afbb-4ce12a0bf5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-c3c0fa99-620b-44a5-9c3e-7dc54341bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-5ff0b58e-c61f-4350-a84d-c1d2c1a42da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-eb62491e-4b91-4858-9ad9-e1fd66e3e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-367f59bc-df96-4f85-8474-51b6ef4d1e29,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-fd43e4f1-971a-4e5e-8013-e7d8a0887684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691589473-172.17.0.10-1597041562039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38847,DS-6e2ebc48-ca67-4e2e-8baa-abf1eb4b408a,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-e9c38abb-d578-4372-9045-96befd69a9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-91e75e35-2876-445b-afbb-4ce12a0bf5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-c3c0fa99-620b-44a5-9c3e-7dc54341bbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-5ff0b58e-c61f-4350-a84d-c1d2c1a42da9,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-eb62491e-4b91-4858-9ad9-e1fd66e3e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-367f59bc-df96-4f85-8474-51b6ef4d1e29,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-fd43e4f1-971a-4e5e-8013-e7d8a0887684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696817316-172.17.0.10-1597042614446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41375,DS-b4bed062-12a9-49cb-a4e3-eb01f57f8e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-7e1402eb-eb5a-4011-ab82-b234b42010aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-37f47d73-643a-4e51-899f-75bc501e0402,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-db996d64-b65b-4840-9c1e-506bd0f109af,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-e8a2c51c-9bfc-4afa-88e9-615e114dcd72,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-2b4628b2-af1c-47a9-804c-0ca8a314611e,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-1c53395d-0347-4ab3-b05b-9bb102f2096c,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-27cba327-0a6a-46f1-9eb8-eeab0b5bfaac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696817316-172.17.0.10-1597042614446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41375,DS-b4bed062-12a9-49cb-a4e3-eb01f57f8e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-7e1402eb-eb5a-4011-ab82-b234b42010aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-37f47d73-643a-4e51-899f-75bc501e0402,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-db996d64-b65b-4840-9c1e-506bd0f109af,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-e8a2c51c-9bfc-4afa-88e9-615e114dcd72,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-2b4628b2-af1c-47a9-804c-0ca8a314611e,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-1c53395d-0347-4ab3-b05b-9bb102f2096c,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-27cba327-0a6a-46f1-9eb8-eeab0b5bfaac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643425612-172.17.0.10-1597042757922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-c1c4bdc2-9631-473f-8dd0-77b2e740c1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-6eb477dd-09ae-4005-8386-737eb66f93f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-237bd874-a0ae-4649-ace6-21601344d5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-66083e87-e79f-4cef-8eee-9fd55e9863de,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-3a463ee3-8df2-45d1-9373-167ddac01cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-f93922ec-01f5-4944-a323-48afbed28bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-6aa5505d-dff7-476d-bb98-019ce4444837,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-67dd1476-3bc8-437e-9a1a-3437ffd0db4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643425612-172.17.0.10-1597042757922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-c1c4bdc2-9631-473f-8dd0-77b2e740c1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-6eb477dd-09ae-4005-8386-737eb66f93f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-237bd874-a0ae-4649-ace6-21601344d5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-66083e87-e79f-4cef-8eee-9fd55e9863de,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-3a463ee3-8df2-45d1-9373-167ddac01cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-f93922ec-01f5-4944-a323-48afbed28bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-6aa5505d-dff7-476d-bb98-019ce4444837,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-67dd1476-3bc8-437e-9a1a-3437ffd0db4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754068470-172.17.0.10-1597042902583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-c0f263ab-5cd5-4b99-9c63-a08089172887,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-df41f9ca-3ef5-48d9-aea6-baea92874219,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-7cf1fb0e-1fab-47e2-b21d-517a6c345633,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-f5789e73-d948-4730-8882-38d5147aea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-f41e84f7-8dc1-4fef-a3cb-44d3d78faa22,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-8262523e-bf07-41ec-901f-d6b5b8f0bd30,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-1a20e7d2-507f-46cd-837d-5c79f23b125f,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-0bd345d1-d3b7-4ef1-bb55-b876cb8b4b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-754068470-172.17.0.10-1597042902583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-c0f263ab-5cd5-4b99-9c63-a08089172887,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-df41f9ca-3ef5-48d9-aea6-baea92874219,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-7cf1fb0e-1fab-47e2-b21d-517a6c345633,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-f5789e73-d948-4730-8882-38d5147aea4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-f41e84f7-8dc1-4fef-a3cb-44d3d78faa22,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-8262523e-bf07-41ec-901f-d6b5b8f0bd30,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-1a20e7d2-507f-46cd-837d-5c79f23b125f,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-0bd345d1-d3b7-4ef1-bb55-b876cb8b4b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232011384-172.17.0.10-1597042995136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-92fe6520-790f-42a3-bb81-07e6d35c5198,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-2b2717f0-4b91-4832-aaa0-970851d332ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-aed3aeaf-23fb-454c-a145-fb048dc2ddde,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-f4b614c8-08cc-4377-9e0b-526992a3656d,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-bbc54ea2-2271-476a-8bd2-1a986adb6f48,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-0f6cc2d7-75f3-4721-ba08-0ccb8bb538a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-96409275-33c6-49ea-8f48-bbd55f163670,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-3f1dd9c2-b28f-4ed7-8bf4-2d1b1eca3241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-232011384-172.17.0.10-1597042995136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-92fe6520-790f-42a3-bb81-07e6d35c5198,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-2b2717f0-4b91-4832-aaa0-970851d332ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-aed3aeaf-23fb-454c-a145-fb048dc2ddde,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-f4b614c8-08cc-4377-9e0b-526992a3656d,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-bbc54ea2-2271-476a-8bd2-1a986adb6f48,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-0f6cc2d7-75f3-4721-ba08-0ccb8bb538a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-96409275-33c6-49ea-8f48-bbd55f163670,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-3f1dd9c2-b28f-4ed7-8bf4-2d1b1eca3241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124688238-172.17.0.10-1597043628095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-584dae8d-f637-41a2-a9a2-826ce193eef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-3cde4b77-69cf-43ff-849e-5bdbc972c1de,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-9e4796e7-4d0d-4913-a576-1ec721f32d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-d05781d5-333b-49e2-ba30-882b4954b5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-d5bfcf4e-7e76-47a5-b25f-7f76c5df0cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-efcc79b1-6927-4622-a5f2-9f751250684c,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-d16c7df5-4978-4c0c-b6a8-ad01ba36b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-afc58ec8-ac2f-4052-a827-f857b158b654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124688238-172.17.0.10-1597043628095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36598,DS-584dae8d-f637-41a2-a9a2-826ce193eef6,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-3cde4b77-69cf-43ff-849e-5bdbc972c1de,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-9e4796e7-4d0d-4913-a576-1ec721f32d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-d05781d5-333b-49e2-ba30-882b4954b5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-d5bfcf4e-7e76-47a5-b25f-7f76c5df0cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-efcc79b1-6927-4622-a5f2-9f751250684c,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-d16c7df5-4978-4c0c-b6a8-ad01ba36b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-afc58ec8-ac2f-4052-a827-f857b158b654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045927920-172.17.0.10-1597043764348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-510201c8-210b-4362-bd21-c0ea77e5710b,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-0292fd0e-9170-44b2-83d6-6e33f29ebc13,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-7ac472be-971a-49a8-beda-8307869f059e,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-221ad754-a416-405a-93c2-b59e18e0d6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-5fce9ee6-c468-4a21-9590-468f26cf6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-8a294cfb-99c7-44e1-bded-4b3a3c53407f,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-62298a13-428f-43bd-b2f4-cc5648f543ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-045b4451-8e60-4f36-b773-505979e86eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045927920-172.17.0.10-1597043764348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-510201c8-210b-4362-bd21-c0ea77e5710b,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-0292fd0e-9170-44b2-83d6-6e33f29ebc13,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-7ac472be-971a-49a8-beda-8307869f059e,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-221ad754-a416-405a-93c2-b59e18e0d6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-5fce9ee6-c468-4a21-9590-468f26cf6cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-8a294cfb-99c7-44e1-bded-4b3a3c53407f,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-62298a13-428f-43bd-b2f4-cc5648f543ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-045b4451-8e60-4f36-b773-505979e86eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685398486-172.17.0.10-1597043935346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-be5e5287-5a72-4517-a327-d1a322a80aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-94f16025-fe9a-4938-a487-57489e39a298,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-08ccd186-20cd-4b0c-b198-57dd61834b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-27e9a1b5-0846-4bc4-994f-893e849c4f01,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-f7aeb0f8-836f-4f36-982f-b7e1b43acd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-7913ac4b-f241-4bdb-9d35-e6babe808401,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-a888adf3-4dc4-43b0-8746-429b612946b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-8b368741-3dce-44f8-8125-067ab2561adc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-685398486-172.17.0.10-1597043935346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-be5e5287-5a72-4517-a327-d1a322a80aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-94f16025-fe9a-4938-a487-57489e39a298,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-08ccd186-20cd-4b0c-b198-57dd61834b66,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-27e9a1b5-0846-4bc4-994f-893e849c4f01,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-f7aeb0f8-836f-4f36-982f-b7e1b43acd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-7913ac4b-f241-4bdb-9d35-e6babe808401,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-a888adf3-4dc4-43b0-8746-429b612946b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-8b368741-3dce-44f8-8125-067ab2561adc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043669507-172.17.0.10-1597044202426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43012,DS-af059089-31ad-4fde-a200-d2b212398b87,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-9d2c751d-577c-471d-8803-db410811b5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-b4460dfe-6fd8-4df6-b9f1-46523377be53,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-42813b4f-5f81-4036-818e-f29d4dbd595e,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-8f2a6e3d-7c51-47cf-b74a-7123332efba9,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-00b2577d-266b-425d-af21-f36e81fd4b05,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-0a05ce9a-7ccf-4658-a5ae-67b48fa64483,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-7a3702e3-c200-42a6-a04a-51e26a090c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043669507-172.17.0.10-1597044202426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43012,DS-af059089-31ad-4fde-a200-d2b212398b87,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-9d2c751d-577c-471d-8803-db410811b5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-b4460dfe-6fd8-4df6-b9f1-46523377be53,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-42813b4f-5f81-4036-818e-f29d4dbd595e,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-8f2a6e3d-7c51-47cf-b74a-7123332efba9,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-00b2577d-266b-425d-af21-f36e81fd4b05,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-0a05ce9a-7ccf-4658-a5ae-67b48fa64483,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-7a3702e3-c200-42a6-a04a-51e26a090c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738186460-172.17.0.10-1597044249627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-2b59f4d7-2f96-4950-9fa3-a0401e4c9c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-3a0752dd-2477-431e-bd12-ea003243a9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-5293490d-a9c2-429e-8616-cbe4655b7d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-6b06f01b-2ce7-4260-a794-dea0954290e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-0424fdbd-ecf1-4548-b521-d4eee1cd7ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-414f1624-ebc8-416c-8d74-32ba65f148e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-4b86469b-7861-4d79-98e7-1f92648c6885,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-4f29aa95-946c-40ac-bcc7-e28eb9ff4781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738186460-172.17.0.10-1597044249627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-2b59f4d7-2f96-4950-9fa3-a0401e4c9c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-3a0752dd-2477-431e-bd12-ea003243a9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-5293490d-a9c2-429e-8616-cbe4655b7d21,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-6b06f01b-2ce7-4260-a794-dea0954290e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-0424fdbd-ecf1-4548-b521-d4eee1cd7ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-414f1624-ebc8-416c-8d74-32ba65f148e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-4b86469b-7861-4d79-98e7-1f92648c6885,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-4f29aa95-946c-40ac-bcc7-e28eb9ff4781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611544594-172.17.0.10-1597045243523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45594,DS-e238dc99-57f4-4169-904d-edf12a2f4928,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-6e5d6640-11ad-4b7f-bd77-3041c949a5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-0cdbca2a-2228-44d0-8412-39c37b04334a,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-4c9e5f2d-0e80-4ed6-b0a3-f13147f6add5,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7fb883c9-bfa5-4543-907c-59b112aba65b,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-f31a379a-3c1b-497f-881d-cf10d691283a,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-689f0d06-8aeb-4f08-a454-1049ece30340,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-648440e3-478e-490a-851c-15e18d2a8b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-611544594-172.17.0.10-1597045243523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45594,DS-e238dc99-57f4-4169-904d-edf12a2f4928,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-6e5d6640-11ad-4b7f-bd77-3041c949a5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-0cdbca2a-2228-44d0-8412-39c37b04334a,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-4c9e5f2d-0e80-4ed6-b0a3-f13147f6add5,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-7fb883c9-bfa5-4543-907c-59b112aba65b,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-f31a379a-3c1b-497f-881d-cf10d691283a,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-689f0d06-8aeb-4f08-a454-1049ece30340,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-648440e3-478e-490a-851c-15e18d2a8b8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047997856-172.17.0.10-1597045560682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46545,DS-8ad08922-f99b-4b44-ac63-f4a0fac6aa21,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-e7969f97-b89b-474b-b678-9f419b06b84a,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-d151927d-1b4e-42da-8fe0-eb9baffb6df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-c47dae22-bc57-480d-93a2-2b9f1af91142,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-14f3b277-1bef-4d38-9d6d-5e436d61529d,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-dcbc256e-f36d-41dc-a72c-04e0875fc7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-6f20236c-d0f5-4837-a92c-e05bd7295aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-1c7ade6b-f532-4989-97fa-6f45a6f10280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047997856-172.17.0.10-1597045560682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46545,DS-8ad08922-f99b-4b44-ac63-f4a0fac6aa21,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-e7969f97-b89b-474b-b678-9f419b06b84a,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-d151927d-1b4e-42da-8fe0-eb9baffb6df4,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-c47dae22-bc57-480d-93a2-2b9f1af91142,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-14f3b277-1bef-4d38-9d6d-5e436d61529d,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-dcbc256e-f36d-41dc-a72c-04e0875fc7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-6f20236c-d0f5-4837-a92c-e05bd7295aef,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-1c7ade6b-f532-4989-97fa-6f45a6f10280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709243284-172.17.0.10-1597046125322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-21ba39b9-06f0-4353-8932-96236d121336,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-b8744ed9-6599-4b3c-83e3-02b5c7275c74,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-aa40436e-0625-48e4-afb9-c2df2ef2e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-3b1c418e-ec72-49cf-bccb-c610b499ae41,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-010a7081-e1c6-4f5d-b3b8-04d7c6883d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-98cd066f-79cd-4921-9e4e-5d5c1885e890,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-78be6f0f-7256-4c25-aa5f-a1d5569bdc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-61d6a70e-0dc6-44be-a11a-707d0af00d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1709243284-172.17.0.10-1597046125322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-21ba39b9-06f0-4353-8932-96236d121336,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-b8744ed9-6599-4b3c-83e3-02b5c7275c74,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-aa40436e-0625-48e4-afb9-c2df2ef2e49b,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-3b1c418e-ec72-49cf-bccb-c610b499ae41,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-010a7081-e1c6-4f5d-b3b8-04d7c6883d95,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-98cd066f-79cd-4921-9e4e-5d5c1885e890,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-78be6f0f-7256-4c25-aa5f-a1d5569bdc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-61d6a70e-0dc6-44be-a11a-707d0af00d41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144289785-172.17.0.10-1597046632460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-79c717e4-b860-4180-921e-222356872175,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-35e1a4c9-55c6-4827-aaf9-37f55ac51448,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-23480b53-70f3-4c4d-9213-9e577cd8cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-795ce6b5-edee-44f3-a664-f32b505497ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-3226cfad-4ae1-4094-bcdc-f7f393595033,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-842be386-a667-4b6c-9b50-7ffe8f9ada27,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-6ed7d4aa-ac85-48b6-98e9-b4cb20e2e625,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-bffa8eca-c16a-48a7-8411-9417c5045010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144289785-172.17.0.10-1597046632460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34313,DS-79c717e4-b860-4180-921e-222356872175,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-35e1a4c9-55c6-4827-aaf9-37f55ac51448,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-23480b53-70f3-4c4d-9213-9e577cd8cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-795ce6b5-edee-44f3-a664-f32b505497ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-3226cfad-4ae1-4094-bcdc-f7f393595033,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-842be386-a667-4b6c-9b50-7ffe8f9ada27,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-6ed7d4aa-ac85-48b6-98e9-b4cb20e2e625,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-bffa8eca-c16a-48a7-8411-9417c5045010,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360558900-172.17.0.10-1597047266732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46797,DS-59426208-2963-42af-9e8c-cd32fae58c06,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-2021708d-232b-4a7b-8eb5-1cfe9a68de9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-29356484-312b-4f87-969e-35e67e6db918,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-10dfc852-8c64-4f36-8fce-3030f091fb80,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-e74873db-890e-4320-82fb-5ae4b96a27a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-3f308be5-aede-4faf-97dd-330c747df329,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-2e229145-020b-4904-93c3-016bc9411cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-08a5751c-5f1d-4164-942d-13a1b41ba44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360558900-172.17.0.10-1597047266732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46797,DS-59426208-2963-42af-9e8c-cd32fae58c06,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-2021708d-232b-4a7b-8eb5-1cfe9a68de9a,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-29356484-312b-4f87-969e-35e67e6db918,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-10dfc852-8c64-4f36-8fce-3030f091fb80,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-e74873db-890e-4320-82fb-5ae4b96a27a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37277,DS-3f308be5-aede-4faf-97dd-330c747df329,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-2e229145-020b-4904-93c3-016bc9411cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-08a5751c-5f1d-4164-942d-13a1b41ba44e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.ping.interval
component: hdfs:DataNode
v1: 1000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440553631-172.17.0.10-1597047320600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40280,DS-d051820d-f6c7-4048-81fb-22038ff71cde,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-3e112f5a-5aa8-4467-8dc6-733c93f4dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-36d636da-95d0-4200-a011-e90de7eef322,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-2ed416b5-cebb-4ab5-8ab6-9310bed67f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-62dd62e0-2f9b-4b2a-80ca-f8fedf59f646,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-8d96bc91-4be1-4092-ae85-fe6f05f4acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-ce2ee815-a8b4-467f-84c3-31eb01756b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-f1a54b2a-0544-4d3e-a3da-77b485c34312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440553631-172.17.0.10-1597047320600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40280,DS-d051820d-f6c7-4048-81fb-22038ff71cde,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-3e112f5a-5aa8-4467-8dc6-733c93f4dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-36d636da-95d0-4200-a011-e90de7eef322,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-2ed416b5-cebb-4ab5-8ab6-9310bed67f74,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-62dd62e0-2f9b-4b2a-80ca-f8fedf59f646,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-8d96bc91-4be1-4092-ae85-fe6f05f4acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-ce2ee815-a8b4-467f-84c3-31eb01756b74,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-f1a54b2a-0544-4d3e-a3da-77b485c34312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6727
