reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55524426-172.17.0.6-1597209437976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41524,DS-b293c732-5388-47b1-ac1b-dba19ca5b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-ef057f28-4fca-406d-a47d-034c4b328b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-1049ecb0-6a8c-4aa0-a801-a936c05f44c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-81f3a48d-b5cd-4926-8b6b-219898ca15bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-622c5cab-055e-4d94-935f-aaf973d7646a,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-bcf869cf-ec1e-4287-8323-7f28ccc9c062,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-fe63eb2e-1438-4102-bbe4-72b0cb45d246,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-d05b105a-0512-4dea-81d2-ad958ef7a0a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55524426-172.17.0.6-1597209437976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41524,DS-b293c732-5388-47b1-ac1b-dba19ca5b26d,DISK], DatanodeInfoWithStorage[127.0.0.1:33384,DS-ef057f28-4fca-406d-a47d-034c4b328b16,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-1049ecb0-6a8c-4aa0-a801-a936c05f44c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35013,DS-81f3a48d-b5cd-4926-8b6b-219898ca15bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-622c5cab-055e-4d94-935f-aaf973d7646a,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-bcf869cf-ec1e-4287-8323-7f28ccc9c062,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-fe63eb2e-1438-4102-bbe4-72b0cb45d246,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-d05b105a-0512-4dea-81d2-ad958ef7a0a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359839046-172.17.0.6-1597209545186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32813,DS-bf51f718-f994-42b7-b958-809858d34968,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-726fa831-3351-403e-8914-8a3304ac176c,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-a3830630-b1ae-406e-aa83-e6afe1becc07,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-f61ea205-78ee-485e-bfb5-e797ce51223d,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-dae85130-5e51-4acf-b892-fe7ecdf27271,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-8ea7fe9d-a97a-4c56-b22e-111588b2fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-6cef0538-fe58-4bb6-b8ba-0a665e3ca221,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-2d3c7426-b5e8-4d22-ac58-c958222ed2e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359839046-172.17.0.6-1597209545186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32813,DS-bf51f718-f994-42b7-b958-809858d34968,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-726fa831-3351-403e-8914-8a3304ac176c,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-a3830630-b1ae-406e-aa83-e6afe1becc07,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-f61ea205-78ee-485e-bfb5-e797ce51223d,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-dae85130-5e51-4acf-b892-fe7ecdf27271,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-8ea7fe9d-a97a-4c56-b22e-111588b2fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-6cef0538-fe58-4bb6-b8ba-0a665e3ca221,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-2d3c7426-b5e8-4d22-ac58-c958222ed2e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204655457-172.17.0.6-1597210233959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-a69e89ed-129c-499b-9fbb-553cac31a064,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-737f2e6b-2bad-4638-a4be-a9166a029b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-6cbfad7c-ff20-46e8-9ed5-bddaf5cbfa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-0a3952ca-f171-4e34-8186-857f68efd478,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-f2847eb8-95c2-4d57-b6f3-59aa680bae17,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-90945147-cd75-4150-ba6a-1344d3636198,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-5832c5a9-ff4d-4050-9185-522cf977cf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-1bbe5253-378f-42ba-8984-32a187fad53e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204655457-172.17.0.6-1597210233959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-a69e89ed-129c-499b-9fbb-553cac31a064,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-737f2e6b-2bad-4638-a4be-a9166a029b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-6cbfad7c-ff20-46e8-9ed5-bddaf5cbfa2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-0a3952ca-f171-4e34-8186-857f68efd478,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-f2847eb8-95c2-4d57-b6f3-59aa680bae17,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-90945147-cd75-4150-ba6a-1344d3636198,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-5832c5a9-ff4d-4050-9185-522cf977cf3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-1bbe5253-378f-42ba-8984-32a187fad53e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702911512-172.17.0.6-1597210865573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44273,DS-7d8fc731-f556-425f-a908-67c0210522e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-8823765a-9076-4933-b5e4-9de9729d707b,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-31a2c0db-06b4-4856-b38a-5be820f23ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-b878aea2-8d34-4d3b-9a93-eefdfd96c6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-f291f2ea-9aed-4b92-8ade-c3cd052585d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-cd942a07-5d35-433c-a788-7681bc08b3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-7e7945a6-40ce-405c-9134-8df730d09504,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-2eddefd8-f93d-4c67-b2f0-642659dd38c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702911512-172.17.0.6-1597210865573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44273,DS-7d8fc731-f556-425f-a908-67c0210522e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-8823765a-9076-4933-b5e4-9de9729d707b,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-31a2c0db-06b4-4856-b38a-5be820f23ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-b878aea2-8d34-4d3b-9a93-eefdfd96c6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-f291f2ea-9aed-4b92-8ade-c3cd052585d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-cd942a07-5d35-433c-a788-7681bc08b3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-7e7945a6-40ce-405c-9134-8df730d09504,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-2eddefd8-f93d-4c67-b2f0-642659dd38c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194338746-172.17.0.6-1597211022397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46504,DS-70e0f1fd-d3d3-4996-90a7-e43d2b7bafb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-a29f413f-db59-421e-b2ef-5a5d28c45ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-3ef9ee98-fb8f-44fd-9833-b8719bbe8754,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-73cb4575-54aa-4b5a-a98d-4b28a8bf44dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-848d4137-9daf-4cda-a725-8fde1b8ebabe,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-98867e48-04a0-4d55-bfa5-daaaa7f993bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-1877f6e7-0c71-42ad-a7ec-e675458d4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-f2309b3d-4424-4020-98d1-3ce5dd8ef23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194338746-172.17.0.6-1597211022397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46504,DS-70e0f1fd-d3d3-4996-90a7-e43d2b7bafb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-a29f413f-db59-421e-b2ef-5a5d28c45ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-3ef9ee98-fb8f-44fd-9833-b8719bbe8754,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-73cb4575-54aa-4b5a-a98d-4b28a8bf44dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-848d4137-9daf-4cda-a725-8fde1b8ebabe,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-98867e48-04a0-4d55-bfa5-daaaa7f993bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-1877f6e7-0c71-42ad-a7ec-e675458d4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-f2309b3d-4424-4020-98d1-3ce5dd8ef23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159559825-172.17.0.6-1597211587781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42206,DS-564e104e-d5d8-4a2f-bd0a-f2b7addbfc56,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-ba3cbc04-9e10-4ecc-a033-227731ef085b,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-1613a0ba-b149-4f20-a9cd-e0add82a887c,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-66f378e9-d182-4e8d-bd35-84f1d1b32369,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-a320112e-b574-4c22-ba5f-9d2221df2d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-e6b8d458-0aeb-4032-a13e-9e1f46d5b22e,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-d53ab36b-f963-4100-b6e8-0c753a9be8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-398cb4bf-1ca5-445b-8df9-486bfbeb8f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159559825-172.17.0.6-1597211587781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42206,DS-564e104e-d5d8-4a2f-bd0a-f2b7addbfc56,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-ba3cbc04-9e10-4ecc-a033-227731ef085b,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-1613a0ba-b149-4f20-a9cd-e0add82a887c,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-66f378e9-d182-4e8d-bd35-84f1d1b32369,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-a320112e-b574-4c22-ba5f-9d2221df2d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-e6b8d458-0aeb-4032-a13e-9e1f46d5b22e,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-d53ab36b-f963-4100-b6e8-0c753a9be8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-398cb4bf-1ca5-445b-8df9-486bfbeb8f7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121482474-172.17.0.6-1597211704122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-eb1e3810-22ef-45f0-88d7-96dd40cb8908,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-5b530c3a-565e-415b-8575-0a517b72d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-592a6b1a-2a25-43bc-87ae-9a00a231e418,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-394646b1-bf7d-460e-99e9-7b14e106b6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-8f9c99ef-3413-4d6f-8dff-14bfa6b3de0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-17999991-7ef1-4845-82c3-e4b101461b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-910abb21-b148-4c28-a7c5-0af8327c3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-90dbed1c-05b9-4757-b202-62d908a95d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1121482474-172.17.0.6-1597211704122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39612,DS-eb1e3810-22ef-45f0-88d7-96dd40cb8908,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-5b530c3a-565e-415b-8575-0a517b72d75d,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-592a6b1a-2a25-43bc-87ae-9a00a231e418,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-394646b1-bf7d-460e-99e9-7b14e106b6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-8f9c99ef-3413-4d6f-8dff-14bfa6b3de0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-17999991-7ef1-4845-82c3-e4b101461b77,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-910abb21-b148-4c28-a7c5-0af8327c3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-90dbed1c-05b9-4757-b202-62d908a95d17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791292732-172.17.0.6-1597211775100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-62460c99-3636-4733-8393-ada12624e211,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-213088c8-c8bd-45af-8641-1182da9f96f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-7ca0ad45-5071-48e9-9d99-4d4587a792b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-6ccf39dd-18b5-479d-9f3f-3d9970622a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-99174db6-a40c-4554-9adf-aea9d2473ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-25252aab-f875-438d-ad83-8260f1f069b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-c78e1298-c00c-4c71-9125-bb4f4a48eb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-685d1b61-5b3d-414e-af4e-191b7ec45131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-791292732-172.17.0.6-1597211775100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-62460c99-3636-4733-8393-ada12624e211,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-213088c8-c8bd-45af-8641-1182da9f96f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-7ca0ad45-5071-48e9-9d99-4d4587a792b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-6ccf39dd-18b5-479d-9f3f-3d9970622a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-99174db6-a40c-4554-9adf-aea9d2473ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-25252aab-f875-438d-ad83-8260f1f069b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-c78e1298-c00c-4c71-9125-bb4f4a48eb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-685d1b61-5b3d-414e-af4e-191b7ec45131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-725444241-172.17.0.6-1597212119904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33041,DS-4d843496-57bf-4395-83a4-b06c059dae14,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-71f667df-9183-466c-ae8d-463f5140486b,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-bbccf8a6-7234-444d-8ae7-9004d03804d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-49aa6792-9dd7-44ba-9b84-36ba9a8c34fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-c70fd925-7261-49da-b89d-3dae522ab8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-59fbaf77-eccc-41e4-8b62-585a393a7e27,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-9f403b87-d09b-4fdf-8acf-1f2ea258cf76,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-a658596f-991c-48cb-aa83-9b52720375e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-725444241-172.17.0.6-1597212119904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33041,DS-4d843496-57bf-4395-83a4-b06c059dae14,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-71f667df-9183-466c-ae8d-463f5140486b,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-bbccf8a6-7234-444d-8ae7-9004d03804d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-49aa6792-9dd7-44ba-9b84-36ba9a8c34fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-c70fd925-7261-49da-b89d-3dae522ab8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-59fbaf77-eccc-41e4-8b62-585a393a7e27,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-9f403b87-d09b-4fdf-8acf-1f2ea258cf76,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-a658596f-991c-48cb-aa83-9b52720375e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692088853-172.17.0.6-1597212261312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34192,DS-d37d0125-319e-4609-8a12-562b9875f94c,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-6f100095-c661-47b6-bd0b-97c5a2ec9052,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-c41ac559-71fa-4cc6-9ad0-6c978c30bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-d1e4edbf-b140-4810-8e95-3611ba1019b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-a9756c1b-1224-451e-bd1a-c7896689af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-585c1bea-e086-416e-b6d7-be64141aa3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-93f035df-4255-413b-ac53-5dfd8f81a884,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-8bdc2467-e780-4358-a706-dccbf3c63dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1692088853-172.17.0.6-1597212261312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34192,DS-d37d0125-319e-4609-8a12-562b9875f94c,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-6f100095-c661-47b6-bd0b-97c5a2ec9052,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-c41ac559-71fa-4cc6-9ad0-6c978c30bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-d1e4edbf-b140-4810-8e95-3611ba1019b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-a9756c1b-1224-451e-bd1a-c7896689af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-585c1bea-e086-416e-b6d7-be64141aa3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-93f035df-4255-413b-ac53-5dfd8f81a884,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-8bdc2467-e780-4358-a706-dccbf3c63dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014743140-172.17.0.6-1597212708817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-04d6a2d0-2097-4cf3-a234-8bb53e083bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-b71cda2c-2a31-4527-843e-1fef24f2511e,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-99abc9b3-59b6-4a40-b4ed-59c91b04f884,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-b6b85cce-639c-4f85-8eff-18a559b7e456,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-7cbc8ef8-077c-470d-8b84-8eb29658254f,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-00ea7790-5c0f-4e6e-857c-0fc4c87e3b25,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-f55d6712-6c16-48f2-b4a8-24e11eef84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-f7e8751a-4ffa-4131-9d9c-64700f11ab37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014743140-172.17.0.6-1597212708817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33676,DS-04d6a2d0-2097-4cf3-a234-8bb53e083bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-b71cda2c-2a31-4527-843e-1fef24f2511e,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-99abc9b3-59b6-4a40-b4ed-59c91b04f884,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-b6b85cce-639c-4f85-8eff-18a559b7e456,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-7cbc8ef8-077c-470d-8b84-8eb29658254f,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-00ea7790-5c0f-4e6e-857c-0fc4c87e3b25,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-f55d6712-6c16-48f2-b4a8-24e11eef84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38173,DS-f7e8751a-4ffa-4131-9d9c-64700f11ab37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269612638-172.17.0.6-1597212809875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33480,DS-d7779e52-e492-4ad0-9ade-4bd0ba860df3,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-5eb002cb-68b9-4816-a930-74a6bd7f3b13,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-fb3572c2-aec8-415a-94e2-f0e305a6d551,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-e3111a69-bd99-405d-9a26-90f3c9ec7c56,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-879291b2-a5ce-4515-8aae-b0990f4a56e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-cde866d4-6f7e-4a49-aab0-8eee86e5f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-77b2a067-4f94-4665-9dae-97beb1cf4d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-cbf0b1c1-d5ec-4799-a0b1-9f5c42f3d654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269612638-172.17.0.6-1597212809875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33480,DS-d7779e52-e492-4ad0-9ade-4bd0ba860df3,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-5eb002cb-68b9-4816-a930-74a6bd7f3b13,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-fb3572c2-aec8-415a-94e2-f0e305a6d551,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-e3111a69-bd99-405d-9a26-90f3c9ec7c56,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-879291b2-a5ce-4515-8aae-b0990f4a56e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-cde866d4-6f7e-4a49-aab0-8eee86e5f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-77b2a067-4f94-4665-9dae-97beb1cf4d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-cbf0b1c1-d5ec-4799-a0b1-9f5c42f3d654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701550679-172.17.0.6-1597212902773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-fb846aff-9140-4b9a-b64a-9ece0087f459,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-ea6208f8-e50a-4c17-8e02-20d9e45ca453,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-1410ce16-9198-4d2e-81e9-7c3caa02674d,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-0382aa9b-938d-445d-b0e3-51b68e0716c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-a959e6b5-3d82-4ce1-8cdc-b7a4c98757c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-8886779b-7330-4a68-862d-c25b0482fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-df0238f2-0029-4fb5-b65a-8f9cfd806b16,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-a310b4c2-a03d-4ed7-9051-89bfb392063d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-701550679-172.17.0.6-1597212902773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34140,DS-fb846aff-9140-4b9a-b64a-9ece0087f459,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-ea6208f8-e50a-4c17-8e02-20d9e45ca453,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-1410ce16-9198-4d2e-81e9-7c3caa02674d,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-0382aa9b-938d-445d-b0e3-51b68e0716c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-a959e6b5-3d82-4ce1-8cdc-b7a4c98757c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-8886779b-7330-4a68-862d-c25b0482fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-df0238f2-0029-4fb5-b65a-8f9cfd806b16,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-a310b4c2-a03d-4ed7-9051-89bfb392063d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881094393-172.17.0.6-1597213044493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-2b5c0359-e409-49fd-a448-82886512b4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-6a3fbd77-846e-4352-9ae4-539c012e9eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-0edc559e-cab8-4851-8f88-bc28be9bb5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-dd29ffad-fdb2-4520-a597-86b277f22f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-956a2f0f-eb63-4429-b974-fcce26d257ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-96b5e739-6927-4e2c-8051-3978af8e30d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-ade93a67-72b3-45fb-9deb-73f55a6d08dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-ba20901e-9412-467a-9e00-7d0c2fcb42ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881094393-172.17.0.6-1597213044493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-2b5c0359-e409-49fd-a448-82886512b4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-6a3fbd77-846e-4352-9ae4-539c012e9eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-0edc559e-cab8-4851-8f88-bc28be9bb5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-dd29ffad-fdb2-4520-a597-86b277f22f61,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-956a2f0f-eb63-4429-b974-fcce26d257ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-96b5e739-6927-4e2c-8051-3978af8e30d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-ade93a67-72b3-45fb-9deb-73f55a6d08dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-ba20901e-9412-467a-9e00-7d0c2fcb42ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:NameNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322423533-172.17.0.6-1597213535236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-e64c3aa4-e6b8-4c92-a69f-8a5ad46088d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-f6ddf6ab-8d8e-43b5-b34b-3f882d6ac9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-004df23b-4aea-4b2f-8d0a-46e6c799f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-403e4903-33fe-46a2-8830-a82bcf108b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-3d090ad0-c4ec-43bd-8232-86dfb7c98baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-8320f42c-210b-444a-9fbb-37eab9dc765f,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-fe8aae89-0f59-4d64-b4b3-6855fba7cae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-233ae3f5-ab9d-4ba2-8932-1ef0393d3561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322423533-172.17.0.6-1597213535236:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35648,DS-e64c3aa4-e6b8-4c92-a69f-8a5ad46088d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-f6ddf6ab-8d8e-43b5-b34b-3f882d6ac9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-004df23b-4aea-4b2f-8d0a-46e6c799f6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-403e4903-33fe-46a2-8830-a82bcf108b61,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-3d090ad0-c4ec-43bd-8232-86dfb7c98baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-8320f42c-210b-444a-9fbb-37eab9dc765f,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-fe8aae89-0f59-4d64-b4b3-6855fba7cae5,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-233ae3f5-ab9d-4ba2-8932-1ef0393d3561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5298
