reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935719410-172.17.0.13-1597147391982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-e1c19668-ebdb-42d4-9db6-46b111004722,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-c10f3b6f-82c8-4b43-8b0b-49fc4f1bb2db,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-1cfad8d1-8016-449d-b1fd-778bc242b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-ec72818d-8b37-4306-b17d-29fcfb79c1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-edb327d5-5ca9-4471-9a29-4026b1b8371f,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-4a013507-3f70-4498-be79-b6db41e60ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-8881c506-f2ae-49d9-90c8-4ab90eecaac2,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-cdce1081-9b55-49b6-8cb5-f79e384c9e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-935719410-172.17.0.13-1597147391982:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-e1c19668-ebdb-42d4-9db6-46b111004722,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-c10f3b6f-82c8-4b43-8b0b-49fc4f1bb2db,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-1cfad8d1-8016-449d-b1fd-778bc242b2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-ec72818d-8b37-4306-b17d-29fcfb79c1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-edb327d5-5ca9-4471-9a29-4026b1b8371f,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-4a013507-3f70-4498-be79-b6db41e60ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37985,DS-8881c506-f2ae-49d9-90c8-4ab90eecaac2,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-cdce1081-9b55-49b6-8cb5-f79e384c9e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538852989-172.17.0.13-1597147576357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-48deb6d8-aaa7-4974-9b0c-d2db184433e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-030a58dd-87eb-40f1-80c4-ddf20c5a921e,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-80eb3c53-0e0a-446d-81d5-b74e49fe2950,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-89164f9c-f750-4fcc-acfd-ce8880317ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-a728f683-c872-46a5-8491-99805f775af1,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-b51cdf9a-5566-4dc4-af8f-2c6cdb8c106f,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-2ba87f5f-755e-4837-bca5-30a461984f50,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-67c19416-7e60-45b7-8169-299d736be5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538852989-172.17.0.13-1597147576357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36061,DS-48deb6d8-aaa7-4974-9b0c-d2db184433e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-030a58dd-87eb-40f1-80c4-ddf20c5a921e,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-80eb3c53-0e0a-446d-81d5-b74e49fe2950,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-89164f9c-f750-4fcc-acfd-ce8880317ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-a728f683-c872-46a5-8491-99805f775af1,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-b51cdf9a-5566-4dc4-af8f-2c6cdb8c106f,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-2ba87f5f-755e-4837-bca5-30a461984f50,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-67c19416-7e60-45b7-8169-299d736be5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609775573-172.17.0.13-1597147754609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-08ba48f1-2f52-4515-a2a9-472db5d748af,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-61c91661-2659-4487-94d6-2c7d9446a1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-aaf6d8d8-953d-4be8-b39b-916cb1737f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-420c2970-ab4a-4335-a928-1b698045cc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-0c20504d-18ec-451e-ae54-3d6f08154511,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-d50c3d8d-67ef-4c3d-b2ab-d59a2ec82ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-473d6784-f2ff-4d10-a23b-5993dfa94587,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-9193517d-0789-469e-8b17-e00e3dc58e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1609775573-172.17.0.13-1597147754609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43592,DS-08ba48f1-2f52-4515-a2a9-472db5d748af,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-61c91661-2659-4487-94d6-2c7d9446a1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-aaf6d8d8-953d-4be8-b39b-916cb1737f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-420c2970-ab4a-4335-a928-1b698045cc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-0c20504d-18ec-451e-ae54-3d6f08154511,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-d50c3d8d-67ef-4c3d-b2ab-d59a2ec82ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37471,DS-473d6784-f2ff-4d10-a23b-5993dfa94587,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-9193517d-0789-469e-8b17-e00e3dc58e7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374744374-172.17.0.13-1597148023334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38176,DS-2942916f-798e-4868-bd6f-8f97dbc5eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-b23c16f2-8ae1-4b07-9a45-7a82314d6bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-df1f76df-5db7-4bec-bbb5-d8417ad5c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-f82e0451-d397-4d80-aaec-ae67fb7aa70c,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-990a74e2-129e-4d53-82cc-ed64b9b11731,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-7d691394-d9ed-4eb6-9b1b-dc3f8fb75756,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-bee93cb7-3902-4962-adfc-57e0e0040e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-baa10b40-9af3-487a-a401-f81a8479bf30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374744374-172.17.0.13-1597148023334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38176,DS-2942916f-798e-4868-bd6f-8f97dbc5eeda,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-b23c16f2-8ae1-4b07-9a45-7a82314d6bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-df1f76df-5db7-4bec-bbb5-d8417ad5c5d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-f82e0451-d397-4d80-aaec-ae67fb7aa70c,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-990a74e2-129e-4d53-82cc-ed64b9b11731,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-7d691394-d9ed-4eb6-9b1b-dc3f8fb75756,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-bee93cb7-3902-4962-adfc-57e0e0040e23,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-baa10b40-9af3-487a-a401-f81a8479bf30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348211705-172.17.0.13-1597148204451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-7a314e88-507d-4e8d-8e73-288d341c6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-d5672052-f107-4bcf-8877-243347436ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-2552d4fc-7993-4ff9-9901-d64c7b7c769a,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-d317ec19-eae3-49ba-a50d-e62866950e19,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-35153efd-7f2e-4d51-af84-8b5a7e246c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-9aa1d8d3-3548-4d17-b193-431ea5199fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-27aecf3d-0119-434e-9153-c93bf24ff579,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-075e5022-26bc-46e1-9804-d760eb2dd8b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348211705-172.17.0.13-1597148204451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-7a314e88-507d-4e8d-8e73-288d341c6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45092,DS-d5672052-f107-4bcf-8877-243347436ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-2552d4fc-7993-4ff9-9901-d64c7b7c769a,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-d317ec19-eae3-49ba-a50d-e62866950e19,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-35153efd-7f2e-4d51-af84-8b5a7e246c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-9aa1d8d3-3548-4d17-b193-431ea5199fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-27aecf3d-0119-434e-9153-c93bf24ff579,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-075e5022-26bc-46e1-9804-d760eb2dd8b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783098232-172.17.0.13-1597148657697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-e73d4c12-cee8-426f-82d8-dedcf0b1c82f,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-42f157e2-c44b-4411-88b4-add0f8109dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-6ecfcc87-39eb-415d-b17b-dbaf58bf2e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-31696f68-5264-4210-9c02-76fca2bd84e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-4d1568b0-4e08-40f4-a9f2-58aa76729d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-d3a40ba2-99d9-41d2-b7e1-58a4a8d09455,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-4e5fd491-6377-4474-89dd-109284eaa141,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-15d70d92-f1a7-4920-84ef-6dc5332e8493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783098232-172.17.0.13-1597148657697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-e73d4c12-cee8-426f-82d8-dedcf0b1c82f,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-42f157e2-c44b-4411-88b4-add0f8109dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-6ecfcc87-39eb-415d-b17b-dbaf58bf2e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-31696f68-5264-4210-9c02-76fca2bd84e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-4d1568b0-4e08-40f4-a9f2-58aa76729d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-d3a40ba2-99d9-41d2-b7e1-58a4a8d09455,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-4e5fd491-6377-4474-89dd-109284eaa141,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-15d70d92-f1a7-4920-84ef-6dc5332e8493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230977881-172.17.0.13-1597148706591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-e4573a1c-0da1-4d4f-9320-6911f815facd,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-b7fed306-7003-479a-9778-834e4e545cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-92181c44-5bd4-4220-bf6f-0f7b0106d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-de56527c-158b-47ef-8594-a1ea91a4b51e,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-b55c0aaf-f0d0-4513-ad96-b429f8bcb29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-d22ca5ff-ccc5-4e57-a8bb-1130691c19ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-92f5e338-8f01-45d8-8fa9-f7b3a526fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-492fa60b-8e8b-4797-ae71-71306c784bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230977881-172.17.0.13-1597148706591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39740,DS-e4573a1c-0da1-4d4f-9320-6911f815facd,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-b7fed306-7003-479a-9778-834e4e545cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-92181c44-5bd4-4220-bf6f-0f7b0106d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-de56527c-158b-47ef-8594-a1ea91a4b51e,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-b55c0aaf-f0d0-4513-ad96-b429f8bcb29e,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-d22ca5ff-ccc5-4e57-a8bb-1130691c19ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-92f5e338-8f01-45d8-8fa9-f7b3a526fd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-492fa60b-8e8b-4797-ae71-71306c784bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513975571-172.17.0.13-1597150507441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42843,DS-feb393d3-cbed-4378-bef0-531b4bf0a583,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-523e12b7-b2e2-451a-af26-534b958f4185,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-286179c9-d926-4adc-82af-cf2d02bd154d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-28fcb070-1b1d-414b-b848-4a9e764ea53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-bb13d0ae-8d34-44e0-ad24-2fc9475b079c,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-b78fb036-00ca-4c59-b1f0-849f18bc92c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-761e56fd-ee30-4d4a-a1b9-de61c79e851e,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-cbbc5a50-8f10-49c0-b1a5-0db722e3a0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513975571-172.17.0.13-1597150507441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42843,DS-feb393d3-cbed-4378-bef0-531b4bf0a583,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-523e12b7-b2e2-451a-af26-534b958f4185,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-286179c9-d926-4adc-82af-cf2d02bd154d,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-28fcb070-1b1d-414b-b848-4a9e764ea53d,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-bb13d0ae-8d34-44e0-ad24-2fc9475b079c,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-b78fb036-00ca-4c59-b1f0-849f18bc92c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-761e56fd-ee30-4d4a-a1b9-de61c79e851e,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-cbbc5a50-8f10-49c0-b1a5-0db722e3a0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574372343-172.17.0.13-1597150631746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45039,DS-6d9e9ec9-1d85-4560-bb0a-b0ad27b2efcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-8c7cf5c3-c5d1-4045-8da8-7c53d21ddc86,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-078c8ba5-29ea-4b6d-9cec-e80c306fd9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-d73a5ca8-7c78-401c-8cd4-a181ae381647,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-0e1486c0-48cc-4e4a-8a82-8568bddbf121,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-72ba7951-4ed9-485c-ac73-e2f0da7c61f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-4952dc3e-122a-448d-9bde-aab9cf1e4b10,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-555474f5-0020-4376-971b-5d77a48bc475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-574372343-172.17.0.13-1597150631746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45039,DS-6d9e9ec9-1d85-4560-bb0a-b0ad27b2efcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-8c7cf5c3-c5d1-4045-8da8-7c53d21ddc86,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-078c8ba5-29ea-4b6d-9cec-e80c306fd9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-d73a5ca8-7c78-401c-8cd4-a181ae381647,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-0e1486c0-48cc-4e4a-8a82-8568bddbf121,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-72ba7951-4ed9-485c-ac73-e2f0da7c61f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-4952dc3e-122a-448d-9bde-aab9cf1e4b10,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-555474f5-0020-4376-971b-5d77a48bc475,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901461041-172.17.0.13-1597150854805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-af1d30a0-4d0a-48bd-a26f-7b84acbcef36,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-b01f7df0-825e-4a71-8d6c-0d0ecd8429b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-bc1a8110-0ee1-4d39-a31e-f6fa0f960847,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-2377372d-c21f-4431-b79d-8a1425c37919,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-86cf2d82-5f02-4a7f-9c6a-d79455c8ad17,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-a72484e3-dd6e-44d0-928a-2282de0db195,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-2f9eba28-2d80-4453-bd35-38ce8048d33a,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-147781cf-0f7a-4cba-95b7-00c3f19e65d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901461041-172.17.0.13-1597150854805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-af1d30a0-4d0a-48bd-a26f-7b84acbcef36,DISK], DatanodeInfoWithStorage[127.0.0.1:34524,DS-b01f7df0-825e-4a71-8d6c-0d0ecd8429b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-bc1a8110-0ee1-4d39-a31e-f6fa0f960847,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-2377372d-c21f-4431-b79d-8a1425c37919,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-86cf2d82-5f02-4a7f-9c6a-d79455c8ad17,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-a72484e3-dd6e-44d0-928a-2282de0db195,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-2f9eba28-2d80-4453-bd35-38ce8048d33a,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-147781cf-0f7a-4cba-95b7-00c3f19e65d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222672079-172.17.0.13-1597151107693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41455,DS-40690ff6-5b15-429a-b015-881402f825d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-7fecd5d9-fa07-476a-b383-9e9bc57c5df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-58fd03e4-ff17-43f7-bb23-1807c5cc70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-2f9db4d7-70b8-4bcd-9653-632af86fa672,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-5c27435f-d844-4e5e-a493-391d2d0b4ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-82de3fb2-9235-4b8f-aa40-1f0050ebe9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-94e80b40-a762-47eb-b884-5f07f5e6f4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-68737a9b-fc9e-4e69-9309-471f3a8a3877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-222672079-172.17.0.13-1597151107693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41455,DS-40690ff6-5b15-429a-b015-881402f825d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-7fecd5d9-fa07-476a-b383-9e9bc57c5df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-58fd03e4-ff17-43f7-bb23-1807c5cc70aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-2f9db4d7-70b8-4bcd-9653-632af86fa672,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-5c27435f-d844-4e5e-a493-391d2d0b4ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-82de3fb2-9235-4b8f-aa40-1f0050ebe9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-94e80b40-a762-47eb-b884-5f07f5e6f4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-68737a9b-fc9e-4e69-9309-471f3a8a3877,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62312537-172.17.0.13-1597151728095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-9dc9921d-1f37-4ac2-a825-c0c3a0e54106,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-41daa9e1-31e5-4275-b3fc-ff35a649cef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-7cbade7a-4334-46c8-a4d3-5fa895b9c1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-446af66f-eb1d-477e-97b5-75645c129665,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-9c38496b-c379-4b70-8671-5179482ca46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-b494194b-1499-4781-9f89-ab132d734a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-928ea3f3-cf98-49fc-bda8-020bd636deee,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-7ee1932e-c609-4c6e-a1f2-0711de786e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-62312537-172.17.0.13-1597151728095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-9dc9921d-1f37-4ac2-a825-c0c3a0e54106,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-41daa9e1-31e5-4275-b3fc-ff35a649cef2,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-7cbade7a-4334-46c8-a4d3-5fa895b9c1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-446af66f-eb1d-477e-97b5-75645c129665,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-9c38496b-c379-4b70-8671-5179482ca46d,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-b494194b-1499-4781-9f89-ab132d734a08,DISK], DatanodeInfoWithStorage[127.0.0.1:35475,DS-928ea3f3-cf98-49fc-bda8-020bd636deee,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-7ee1932e-c609-4c6e-a1f2-0711de786e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362544391-172.17.0.13-1597151899030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-4a7c6c9b-e820-4932-af75-b97898ebf3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-7aadd13b-956e-4a88-ab00-b2f676fbd701,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-81ee8bbf-e991-401a-b036-e4855df955bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-81f393dc-ca41-43a8-ab09-3e363eb8fcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-4db4450b-d6bb-4a75-8eae-0c33163beb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-a60c4844-afea-4c4c-9ffb-a82ada05fc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-65f1ac38-eb30-4dfa-bba9-030154ba6742,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-bba54f06-4638-41b4-91cf-51bf8a0e1f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362544391-172.17.0.13-1597151899030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-4a7c6c9b-e820-4932-af75-b97898ebf3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-7aadd13b-956e-4a88-ab00-b2f676fbd701,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-81ee8bbf-e991-401a-b036-e4855df955bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-81f393dc-ca41-43a8-ab09-3e363eb8fcd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-4db4450b-d6bb-4a75-8eae-0c33163beb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-a60c4844-afea-4c4c-9ffb-a82ada05fc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-65f1ac38-eb30-4dfa-bba9-030154ba6742,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-bba54f06-4638-41b4-91cf-51bf8a0e1f06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789505272-172.17.0.13-1597152114604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-027625d7-63c5-4b52-8156-8e4aa4138f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-e007e823-2669-4df0-8f38-4c952cf876d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-44d69f4b-c4a3-4e00-9ebf-46d7bd56dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-0afa77f7-dbd3-4d03-bf50-aba7d4820276,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-e2bd6b27-b448-446d-90f7-a150c766b72e,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-145423f5-8c17-4e3e-a838-1bab8e6242f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-31d0601e-96df-42e1-b3e6-a0e8715c15c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-3023f45f-7d58-40dd-81fc-c017cc3a9e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789505272-172.17.0.13-1597152114604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36092,DS-027625d7-63c5-4b52-8156-8e4aa4138f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-e007e823-2669-4df0-8f38-4c952cf876d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-44d69f4b-c4a3-4e00-9ebf-46d7bd56dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-0afa77f7-dbd3-4d03-bf50-aba7d4820276,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-e2bd6b27-b448-446d-90f7-a150c766b72e,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-145423f5-8c17-4e3e-a838-1bab8e6242f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-31d0601e-96df-42e1-b3e6-a0e8715c15c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-3023f45f-7d58-40dd-81fc-c017cc3a9e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898653144-172.17.0.13-1597152516323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-6f718eb9-03bd-43ba-b0a2-7195d8c7a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-c1dba11f-6f49-4037-b119-239078a80b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-7b3a320b-70c4-484f-8a64-91ecea7bb9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-97c3b25a-5111-4502-9b49-2063bcf5d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-e02375bb-b222-4d30-a495-6555f514bb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-7ef6ab85-a9d6-4e9e-9ff8-88db132ed2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-983a9c06-7089-4115-8507-c7c60b4dd244,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-72eb2014-c3b3-4dde-b36b-856d7aabcc5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-898653144-172.17.0.13-1597152516323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-6f718eb9-03bd-43ba-b0a2-7195d8c7a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-c1dba11f-6f49-4037-b119-239078a80b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-7b3a320b-70c4-484f-8a64-91ecea7bb9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-97c3b25a-5111-4502-9b49-2063bcf5d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-e02375bb-b222-4d30-a495-6555f514bb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-7ef6ab85-a9d6-4e9e-9ff8-88db132ed2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-983a9c06-7089-4115-8507-c7c60b4dd244,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-72eb2014-c3b3-4dde-b36b-856d7aabcc5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149542669-172.17.0.13-1597152749615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46312,DS-2eab40fb-f6cb-40b8-a291-dedd8caa916e,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-30fd23bb-b422-4e2a-88e7-386c21ad7bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-3077b5ca-5b93-472d-942f-ebd7f1cb5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-adfc5077-1898-45a2-bc7c-4a23d8466df0,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-f38cb85b-ab4c-4d3d-8446-4b138f75da79,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-20e3c600-5b3e-4c8a-b325-34d71bce7a07,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-ac0dda02-c63c-4694-8efa-225e8b20a247,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-d312e5b8-9f65-4adf-91d6-1f0172f9d61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149542669-172.17.0.13-1597152749615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46312,DS-2eab40fb-f6cb-40b8-a291-dedd8caa916e,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-30fd23bb-b422-4e2a-88e7-386c21ad7bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-3077b5ca-5b93-472d-942f-ebd7f1cb5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-adfc5077-1898-45a2-bc7c-4a23d8466df0,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-f38cb85b-ab4c-4d3d-8446-4b138f75da79,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-20e3c600-5b3e-4c8a-b325-34d71bce7a07,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-ac0dda02-c63c-4694-8efa-225e8b20a247,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-d312e5b8-9f65-4adf-91d6-1f0172f9d61e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808939609-172.17.0.13-1597152964368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-91b10cde-18a5-49fa-a22f-cdce359d92d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-bda4411e-b777-40fa-9cd8-1f48000aa428,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-82afd88c-c365-4dbd-b7ed-634f8e398c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-f5b18e4d-680a-4544-9911-8de23706cc24,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-8d258cf0-e745-4333-aa96-e9b36e652459,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-3e764f75-8390-47b0-b27c-7a5ec5dedab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-61765aa1-c602-450c-9f48-b720bb2813cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-b3759967-b10d-4d66-97a1-c838f662371a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808939609-172.17.0.13-1597152964368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35615,DS-91b10cde-18a5-49fa-a22f-cdce359d92d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-bda4411e-b777-40fa-9cd8-1f48000aa428,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-82afd88c-c365-4dbd-b7ed-634f8e398c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-f5b18e4d-680a-4544-9911-8de23706cc24,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-8d258cf0-e745-4333-aa96-e9b36e652459,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-3e764f75-8390-47b0-b27c-7a5ec5dedab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-61765aa1-c602-450c-9f48-b720bb2813cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-b3759967-b10d-4d66-97a1-c838f662371a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051126188-172.17.0.13-1597153049954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-529766fb-8da7-4d45-8e51-d40163afc392,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-79facffb-c576-4639-81d2-9fb66d720053,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-7392c381-3fa6-48dd-b2f0-97cfd8b2e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-db3d073c-cd71-41dd-8f39-052ea894e481,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-26c1dd03-7dfa-42ca-a33b-26c8f018a9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-7127cb25-1f8e-4e62-b2b6-7ff8f51fdabb,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-b121aa69-c938-4d01-b445-b703ccd6bc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-adbe714d-6c7c-4a10-b450-e8a8553ac085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051126188-172.17.0.13-1597153049954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42747,DS-529766fb-8da7-4d45-8e51-d40163afc392,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-79facffb-c576-4639-81d2-9fb66d720053,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-7392c381-3fa6-48dd-b2f0-97cfd8b2e0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-db3d073c-cd71-41dd-8f39-052ea894e481,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-26c1dd03-7dfa-42ca-a33b-26c8f018a9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-7127cb25-1f8e-4e62-b2b6-7ff8f51fdabb,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-b121aa69-c938-4d01-b445-b703ccd6bc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-adbe714d-6c7c-4a10-b450-e8a8553ac085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914296437-172.17.0.13-1597153194229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-e3ca8547-6d99-4beb-a836-9f279dd7a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-5012b2be-b446-4186-b9ea-1cf5eb11d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-a72d3f39-e8ad-47c6-aea7-4a656aa48a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-8c095722-100d-42f7-bf4c-516436acc683,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-12c960bb-32b0-416f-930d-7dae69b56f54,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-81edf1a8-7082-44bc-8a5f-d31f63fb4e46,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-60d912c8-cc34-48b2-bda6-50ac7c16f3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-02771aa1-782f-49e1-9b2c-0f775adc5ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914296437-172.17.0.13-1597153194229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-e3ca8547-6d99-4beb-a836-9f279dd7a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45519,DS-5012b2be-b446-4186-b9ea-1cf5eb11d8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-a72d3f39-e8ad-47c6-aea7-4a656aa48a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-8c095722-100d-42f7-bf4c-516436acc683,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-12c960bb-32b0-416f-930d-7dae69b56f54,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-81edf1a8-7082-44bc-8a5f-d31f63fb4e46,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-60d912c8-cc34-48b2-bda6-50ac7c16f3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-02771aa1-782f-49e1-9b2c-0f775adc5ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6749
