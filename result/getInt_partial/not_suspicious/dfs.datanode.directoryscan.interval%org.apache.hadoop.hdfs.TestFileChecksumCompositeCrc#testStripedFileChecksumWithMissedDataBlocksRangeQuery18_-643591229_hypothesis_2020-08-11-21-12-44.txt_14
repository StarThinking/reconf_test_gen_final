reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784332460-172.17.0.5-1597180446675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44497,DS-45f71f9b-2ade-45cd-b494-79a8badc13ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-c0670bfb-58b6-4c30-b2be-fb0a283eb1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-abcf4673-4e12-46bb-8102-1e293a6e38a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-396c749b-dd07-4085-b704-40967e45c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-83d91830-f502-415a-87a1-7624e637fe10,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-14a43613-290c-4984-8f02-361067ebf4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-ef6dbf22-cae0-4ba5-803e-b79cb81eeaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-6edcc072-af5f-4ea5-906a-e469f83084c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1784332460-172.17.0.5-1597180446675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44497,DS-45f71f9b-2ade-45cd-b494-79a8badc13ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-c0670bfb-58b6-4c30-b2be-fb0a283eb1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-abcf4673-4e12-46bb-8102-1e293a6e38a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-396c749b-dd07-4085-b704-40967e45c0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-83d91830-f502-415a-87a1-7624e637fe10,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-14a43613-290c-4984-8f02-361067ebf4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-ef6dbf22-cae0-4ba5-803e-b79cb81eeaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-6edcc072-af5f-4ea5-906a-e469f83084c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405660172-172.17.0.5-1597180515266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41627,DS-da046c43-9210-4207-9574-e29db2ba83ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-a795065e-2aff-4961-ad90-51e7ef25c748,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-28f5d2b9-dc39-450a-b565-5ea2e06fd3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-651bbeea-2256-4bdd-8472-4b5676ba0a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-04af6d9c-4599-4b79-9413-ea8deccec90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-34c96027-4bbc-41b9-bcc8-3b9baf558401,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-9f5d16eb-5921-46b5-ae0c-b3579c739ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-daad1061-c88a-43f4-ae98-34878550c26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405660172-172.17.0.5-1597180515266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41627,DS-da046c43-9210-4207-9574-e29db2ba83ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-a795065e-2aff-4961-ad90-51e7ef25c748,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-28f5d2b9-dc39-450a-b565-5ea2e06fd3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-651bbeea-2256-4bdd-8472-4b5676ba0a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-04af6d9c-4599-4b79-9413-ea8deccec90d,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-34c96027-4bbc-41b9-bcc8-3b9baf558401,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-9f5d16eb-5921-46b5-ae0c-b3579c739ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-daad1061-c88a-43f4-ae98-34878550c26a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491910901-172.17.0.5-1597181260629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33716,DS-9e872b44-3b26-4e2c-9e96-86c7f51af7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-79bda6ef-15ec-4baa-a1e5-5b61fcf9fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-dcbec410-2926-43d6-8c3b-e2297e62ebba,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-49ea451e-e801-4aaa-9f56-51b5d8119367,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-a9924b7a-8f52-46a5-b5c2-b027932f48bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-8ea2c7bf-cdbe-4f3f-8743-e5571a35d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-c8d37fd6-8b54-4c6d-811a-b639e159af17,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-9e995b58-983c-47f7-9efe-4003fde120d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-491910901-172.17.0.5-1597181260629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33716,DS-9e872b44-3b26-4e2c-9e96-86c7f51af7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-79bda6ef-15ec-4baa-a1e5-5b61fcf9fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-dcbec410-2926-43d6-8c3b-e2297e62ebba,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-49ea451e-e801-4aaa-9f56-51b5d8119367,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-a9924b7a-8f52-46a5-b5c2-b027932f48bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-8ea2c7bf-cdbe-4f3f-8743-e5571a35d2be,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-c8d37fd6-8b54-4c6d-811a-b639e159af17,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-9e995b58-983c-47f7-9efe-4003fde120d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728595230-172.17.0.5-1597181471007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-43b8c6a8-4eaa-4709-8dc7-62945ea84fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-508a7415-77e8-47b5-8b87-159bec3c02f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-b8b13526-ddc1-433c-9c3e-c4beb78bb2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-4d2b32d5-5a5d-495f-84ee-87a609558b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-ca597ffb-84f8-4a86-92ec-79437ced39c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-eb7206d4-d075-41b1-9b7a-d7ada367ac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-d3923c43-53ac-49d4-afac-b6b04973d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-214cd687-23ce-46ef-b182-ddf3bed4024b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728595230-172.17.0.5-1597181471007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46087,DS-43b8c6a8-4eaa-4709-8dc7-62945ea84fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-508a7415-77e8-47b5-8b87-159bec3c02f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-b8b13526-ddc1-433c-9c3e-c4beb78bb2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-4d2b32d5-5a5d-495f-84ee-87a609558b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-ca597ffb-84f8-4a86-92ec-79437ced39c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-eb7206d4-d075-41b1-9b7a-d7ada367ac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-d3923c43-53ac-49d4-afac-b6b04973d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-214cd687-23ce-46ef-b182-ddf3bed4024b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884182421-172.17.0.5-1597181610728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44434,DS-14713be1-edf1-492f-9317-b18c35952fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-82a3edb9-76e8-4a70-9bc6-db7e9c9d557a,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-1f777ede-cc69-471f-be9c-8809d0ef14df,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-b44de042-7033-4989-b21a-0f734a3f592c,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-c8acc929-5372-4087-9c34-5aa4c3afa79d,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-04372636-23ad-4623-9c57-fac744007f53,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-a4660218-8a49-4137-817b-0da5b8f5c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-1cd87d30-59df-4c5c-9e80-716a6adf3556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1884182421-172.17.0.5-1597181610728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44434,DS-14713be1-edf1-492f-9317-b18c35952fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-82a3edb9-76e8-4a70-9bc6-db7e9c9d557a,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-1f777ede-cc69-471f-be9c-8809d0ef14df,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-b44de042-7033-4989-b21a-0f734a3f592c,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-c8acc929-5372-4087-9c34-5aa4c3afa79d,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-04372636-23ad-4623-9c57-fac744007f53,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-a4660218-8a49-4137-817b-0da5b8f5c3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-1cd87d30-59df-4c5c-9e80-716a6adf3556,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556003705-172.17.0.5-1597181756451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41320,DS-49de5825-6780-4533-9f2a-8ed52c94bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-cbaf20b2-a53c-4964-8ee5-511053de1b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-4ee6b723-57ca-448e-a7ea-9e196d5ff7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-fff4e804-155b-472a-89ef-00c289ed5a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8487130f-df60-4927-a345-6bb3955b6b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-b72f63c7-8a2f-47c7-9a26-853cc61c0f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-121d1a34-d01c-4faa-ab31-c51b80690e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-556a7910-7233-4810-865d-ad1beb33066a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556003705-172.17.0.5-1597181756451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41320,DS-49de5825-6780-4533-9f2a-8ed52c94bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-cbaf20b2-a53c-4964-8ee5-511053de1b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-4ee6b723-57ca-448e-a7ea-9e196d5ff7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-fff4e804-155b-472a-89ef-00c289ed5a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-8487130f-df60-4927-a345-6bb3955b6b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-b72f63c7-8a2f-47c7-9a26-853cc61c0f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-121d1a34-d01c-4faa-ab31-c51b80690e73,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-556a7910-7233-4810-865d-ad1beb33066a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752572884-172.17.0.5-1597181963675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-93310e06-7ccb-4402-b453-b7903c22298a,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-d69d9d76-6fe2-4941-87e7-7847d7659d77,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-161ab5d1-ca27-4a60-a447-f608798b495c,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-1004dcc4-1fcc-47b4-b064-e36edd4cdad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-0f879b33-3305-47f6-ba17-5eb8a466d4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-70b69eb6-f285-49bd-a2c3-eb64dda31051,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-e0c0d68a-ff5b-434e-8043-19ec8005a5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-ef8987f9-6abb-473a-9cea-5a47b5832029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752572884-172.17.0.5-1597181963675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-93310e06-7ccb-4402-b453-b7903c22298a,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-d69d9d76-6fe2-4941-87e7-7847d7659d77,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-161ab5d1-ca27-4a60-a447-f608798b495c,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-1004dcc4-1fcc-47b4-b064-e36edd4cdad9,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-0f879b33-3305-47f6-ba17-5eb8a466d4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-70b69eb6-f285-49bd-a2c3-eb64dda31051,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-e0c0d68a-ff5b-434e-8043-19ec8005a5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-ef8987f9-6abb-473a-9cea-5a47b5832029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768713923-172.17.0.5-1597182505434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-f6a6f52d-e038-4bf7-a491-ba74700e0f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-ac36ac6a-21f7-42e2-9959-93cdba0dbd68,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-5f7e8054-6c15-45c1-93f9-34e4bb915fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-35326089-3fcb-45b0-b6d1-13cb5281aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-b8faaaec-0613-49ff-bead-3a6058b5398f,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-41d90574-d8e0-4f11-bbd7-f5b25b0835ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-4e0c1e7a-ae27-4db3-a504-53e8a6630656,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-d1558ad1-f9a4-4baa-9017-779166fd4b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768713923-172.17.0.5-1597182505434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34576,DS-f6a6f52d-e038-4bf7-a491-ba74700e0f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-ac36ac6a-21f7-42e2-9959-93cdba0dbd68,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-5f7e8054-6c15-45c1-93f9-34e4bb915fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-35326089-3fcb-45b0-b6d1-13cb5281aeba,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-b8faaaec-0613-49ff-bead-3a6058b5398f,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-41d90574-d8e0-4f11-bbd7-f5b25b0835ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-4e0c1e7a-ae27-4db3-a504-53e8a6630656,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-d1558ad1-f9a4-4baa-9017-779166fd4b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587839862-172.17.0.5-1597182573014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36644,DS-e9d656c5-9b92-4a78-9aec-40de7eaebcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-b03e5ec6-31d7-48e3-a116-49f3639f09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-a48c9dc6-19a2-47cf-aa5d-8382b7b53b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-54a5839f-9d1d-4544-9d74-c53150071a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-41a05341-b2d2-454d-a519-488b2739abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-d383da4b-61ac-4544-8fa1-6fb97f5476f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-3dca25a1-a9df-4f7f-833c-cb58ea07968e,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-ed056d35-aaf9-4520-b4c3-debfb93edb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587839862-172.17.0.5-1597182573014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36644,DS-e9d656c5-9b92-4a78-9aec-40de7eaebcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-b03e5ec6-31d7-48e3-a116-49f3639f09c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-a48c9dc6-19a2-47cf-aa5d-8382b7b53b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-54a5839f-9d1d-4544-9d74-c53150071a15,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-41a05341-b2d2-454d-a519-488b2739abe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-d383da4b-61ac-4544-8fa1-6fb97f5476f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-3dca25a1-a9df-4f7f-833c-cb58ea07968e,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-ed056d35-aaf9-4520-b4c3-debfb93edb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1423123512-172.17.0.5-1597182855246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-c7ba941b-9be4-465b-9e1b-89a9f4b637a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-a82bf918-69a4-444b-94fb-b88604ffd710,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-dd8b319d-b0b9-4bf0-94d8-d3158666d41f,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-92df260c-9ef9-47d0-b580-5c701627038f,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-be575c8a-c698-4242-b8f9-29e0ffde93ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-1780bc92-01ec-4ddc-a6c9-c58fcf213950,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-0afd21e3-931d-4934-bb49-a1a9c63bba92,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-c4844a1e-93a5-4c3f-bea3-f41a25a57df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1423123512-172.17.0.5-1597182855246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-c7ba941b-9be4-465b-9e1b-89a9f4b637a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-a82bf918-69a4-444b-94fb-b88604ffd710,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-dd8b319d-b0b9-4bf0-94d8-d3158666d41f,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-92df260c-9ef9-47d0-b580-5c701627038f,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-be575c8a-c698-4242-b8f9-29e0ffde93ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-1780bc92-01ec-4ddc-a6c9-c58fcf213950,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-0afd21e3-931d-4934-bb49-a1a9c63bba92,DISK], DatanodeInfoWithStorage[127.0.0.1:46496,DS-c4844a1e-93a5-4c3f-bea3-f41a25a57df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720136955-172.17.0.5-1597183307356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36330,DS-869f9e8d-87af-4aee-a18e-9ba80ad2f770,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-2791f0a4-162c-4586-8477-aab1c288dfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-938d94b8-e1eb-4202-9430-8619c85a868c,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-5590b177-4ad0-4be7-b4e4-2f420f9018da,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-5e90bcbd-eb44-48d2-96fb-8294c785961f,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-b627642d-8d5c-44d5-9be8-4f4396a3e6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-18af4d2e-4ccc-4a34-b5aa-9797d04bcab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-fd1ec6dd-417f-463b-9657-08fcea56fced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720136955-172.17.0.5-1597183307356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36330,DS-869f9e8d-87af-4aee-a18e-9ba80ad2f770,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-2791f0a4-162c-4586-8477-aab1c288dfd1,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-938d94b8-e1eb-4202-9430-8619c85a868c,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-5590b177-4ad0-4be7-b4e4-2f420f9018da,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-5e90bcbd-eb44-48d2-96fb-8294c785961f,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-b627642d-8d5c-44d5-9be8-4f4396a3e6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-18af4d2e-4ccc-4a34-b5aa-9797d04bcab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-fd1ec6dd-417f-463b-9657-08fcea56fced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288312328-172.17.0.5-1597183633826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42047,DS-5edf1295-2965-47a1-a495-a2affc3af392,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-8212a0ff-10d0-492a-9e27-19da8d7725cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-bf36d383-8504-43d4-bba4-5dd4f7b9a311,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-6edda70a-62f2-4502-a177-912fc38f631d,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-276c4f63-f111-431c-aa52-d64906224f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-890fb2aa-c7c7-41f9-93f9-bb7d18e4b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-eee6a7b2-3ace-4162-93b9-0f9165746688,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-595b918b-bf89-4705-9908-f57f54c0a326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-288312328-172.17.0.5-1597183633826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42047,DS-5edf1295-2965-47a1-a495-a2affc3af392,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-8212a0ff-10d0-492a-9e27-19da8d7725cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-bf36d383-8504-43d4-bba4-5dd4f7b9a311,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-6edda70a-62f2-4502-a177-912fc38f631d,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-276c4f63-f111-431c-aa52-d64906224f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-890fb2aa-c7c7-41f9-93f9-bb7d18e4b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-eee6a7b2-3ace-4162-93b9-0f9165746688,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-595b918b-bf89-4705-9908-f57f54c0a326,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420964936-172.17.0.5-1597183858016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43021,DS-8a524457-af44-4fdf-b408-18ce62b7787b,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-947bd09c-e556-412d-b6e8-d9554ce08b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-0276037b-4792-4fe0-9650-fceeb9f2d11e,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-1ff87360-1240-4840-a49a-0572d75e383f,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-a6b89633-ed55-4536-b961-ec870aae514d,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-e56968fc-67bf-4821-b105-a6fadfd75830,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-fd69708a-fd8e-43ca-ba1f-fe55eda7ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-c1b7b67a-f100-4a99-955d-665aa90760bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1420964936-172.17.0.5-1597183858016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43021,DS-8a524457-af44-4fdf-b408-18ce62b7787b,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-947bd09c-e556-412d-b6e8-d9554ce08b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-0276037b-4792-4fe0-9650-fceeb9f2d11e,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-1ff87360-1240-4840-a49a-0572d75e383f,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-a6b89633-ed55-4536-b961-ec870aae514d,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-e56968fc-67bf-4821-b105-a6fadfd75830,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-fd69708a-fd8e-43ca-ba1f-fe55eda7ba2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-c1b7b67a-f100-4a99-955d-665aa90760bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009071778-172.17.0.5-1597184111434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37996,DS-09efe5e7-7664-4efc-b37a-3f6600c120b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-6f4cc048-2b9b-467b-ac3f-19496c3fda2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-e78954d0-7f98-49e2-b762-c6a31e069c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-8e597ace-d85a-4adb-aee5-40094ecdba55,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-dd4bb9f9-512c-4687-ab0c-a4df24999111,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-6ec1aa52-f5a8-489a-bb97-80d3fdcc35e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-e8c0b6b8-c762-48df-948a-7745842975f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-0db101be-2de7-4e8a-9618-91a4c4c11630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009071778-172.17.0.5-1597184111434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37996,DS-09efe5e7-7664-4efc-b37a-3f6600c120b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-6f4cc048-2b9b-467b-ac3f-19496c3fda2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-e78954d0-7f98-49e2-b762-c6a31e069c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-8e597ace-d85a-4adb-aee5-40094ecdba55,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-dd4bb9f9-512c-4687-ab0c-a4df24999111,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-6ec1aa52-f5a8-489a-bb97-80d3fdcc35e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-e8c0b6b8-c762-48df-948a-7745842975f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-0db101be-2de7-4e8a-9618-91a4c4c11630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540861957-172.17.0.5-1597184183379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-492aa275-43cd-44df-8a07-ea8153436bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-a6203e0a-d7aa-4dca-81ae-87452d27cbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-e71df173-df29-43e7-bd04-01b6ada14ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-fe97592a-70fb-496d-98ed-ae0221e803e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-f27d49cd-fb6e-499b-bcb3-72d092753325,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-82378734-cedf-44e6-9b1d-6e33b2f930db,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-63cd28a2-8d65-4d9f-a815-fbfd9fa4ecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-de76034c-955a-400d-b3fb-2ea0d1ced5c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540861957-172.17.0.5-1597184183379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43565,DS-492aa275-43cd-44df-8a07-ea8153436bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-a6203e0a-d7aa-4dca-81ae-87452d27cbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-e71df173-df29-43e7-bd04-01b6ada14ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-fe97592a-70fb-496d-98ed-ae0221e803e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-f27d49cd-fb6e-499b-bcb3-72d092753325,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-82378734-cedf-44e6-9b1d-6e33b2f930db,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-63cd28a2-8d65-4d9f-a815-fbfd9fa4ecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-de76034c-955a-400d-b3fb-2ea0d1ced5c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-609420346-172.17.0.5-1597184663279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-01f87513-726b-44be-853a-8ad622289321,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-dafed99c-0903-431d-b072-7516d1a8ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-969e24c4-c4c9-486c-88ae-113cf02b5a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-df673934-07c1-4758-b515-a3cc57f60503,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-bfbafef5-2807-4945-a68b-7d7d0b1cbdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-0ab902d8-2023-471e-b579-a3e083d6ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-39912838-642f-4918-8a36-697e3b6f19b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-d77d6153-15f1-48ac-a13b-4aee0da30272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-609420346-172.17.0.5-1597184663279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39782,DS-01f87513-726b-44be-853a-8ad622289321,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-dafed99c-0903-431d-b072-7516d1a8ffb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-969e24c4-c4c9-486c-88ae-113cf02b5a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-df673934-07c1-4758-b515-a3cc57f60503,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-bfbafef5-2807-4945-a68b-7d7d0b1cbdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-0ab902d8-2023-471e-b579-a3e083d6ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-39912838-642f-4918-8a36-697e3b6f19b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-d77d6153-15f1-48ac-a13b-4aee0da30272,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367667692-172.17.0.5-1597184734169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-aab14730-9dde-4bfb-ad9f-594738762fba,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-1dbc1ef8-c8c9-4af6-ac6f-5a19e47916b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-b620cfbd-e08c-4a10-8815-65c018cd1e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-7584bd11-8a71-4e94-8a0b-9e5a8ac21ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-c0a3b81f-c759-418b-a654-6906c3c17f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-564e934a-7042-466f-9baf-73c85c996586,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-70812ebd-9abd-4b9e-a487-8c90f93eb59b,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-a3d77515-b1d1-403e-a158-369f881b97bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1367667692-172.17.0.5-1597184734169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-aab14730-9dde-4bfb-ad9f-594738762fba,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-1dbc1ef8-c8c9-4af6-ac6f-5a19e47916b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-b620cfbd-e08c-4a10-8815-65c018cd1e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-7584bd11-8a71-4e94-8a0b-9e5a8ac21ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-c0a3b81f-c759-418b-a654-6906c3c17f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-564e934a-7042-466f-9baf-73c85c996586,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-70812ebd-9abd-4b9e-a487-8c90f93eb59b,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-a3d77515-b1d1-403e-a158-369f881b97bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375502594-172.17.0.5-1597184871801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43566,DS-b2f9b40b-1bb2-4f7b-baef-8367690f3044,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-6239275c-7a63-4b13-bc3a-301a12de182c,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-c886144c-6ff2-4920-afb1-e579706461e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-c0c9531c-c47e-4fa4-b1b8-7da7c4580a58,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-2481cbf5-f6ca-4db9-91ec-a5989c4d43dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-b6d238c6-3f9f-4bbc-902e-6f7b36d347f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-d4ce344b-d24e-46c5-b077-7f7632ca92b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-8417b6cf-bcd1-4b0a-8dd3-34c9d262f379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375502594-172.17.0.5-1597184871801:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43566,DS-b2f9b40b-1bb2-4f7b-baef-8367690f3044,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-6239275c-7a63-4b13-bc3a-301a12de182c,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-c886144c-6ff2-4920-afb1-e579706461e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-c0c9531c-c47e-4fa4-b1b8-7da7c4580a58,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-2481cbf5-f6ca-4db9-91ec-a5989c4d43dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-b6d238c6-3f9f-4bbc-902e-6f7b36d347f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-d4ce344b-d24e-46c5-b077-7f7632ca92b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-8417b6cf-bcd1-4b0a-8dd3-34c9d262f379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107441038-172.17.0.5-1597185115904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42748,DS-47778ed8-bad4-418e-a919-a8254400c796,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-702d3674-bf87-46c1-bc11-b53ec1ac7dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-9a436a1f-5ced-4a4d-87be-edce948a5c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-78dc3cd1-6c64-412a-a994-473f52073670,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-7d39c7e7-4332-4f7e-a501-056bb4b3eadb,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-156ec6af-47a8-49fb-9051-2b969ced7817,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-ba273056-f6d1-4ffb-9521-442eb0d463fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-92f8be50-88a3-4537-af62-5887e6d8f5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107441038-172.17.0.5-1597185115904:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42748,DS-47778ed8-bad4-418e-a919-a8254400c796,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-702d3674-bf87-46c1-bc11-b53ec1ac7dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-9a436a1f-5ced-4a4d-87be-edce948a5c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-78dc3cd1-6c64-412a-a994-473f52073670,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-7d39c7e7-4332-4f7e-a501-056bb4b3eadb,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-156ec6af-47a8-49fb-9051-2b969ced7817,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-ba273056-f6d1-4ffb-9521-442eb0d463fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-92f8be50-88a3-4537-af62-5887e6d8f5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.interval
component: hdfs:DataNode
v1: 21600
v2: 10s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205295041-172.17.0.5-1597185474850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-f2ec1e40-2336-41eb-83cc-4f9f8299adfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-f7cdb3cf-ae93-468f-9e23-0757d85e36cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-3dd8bbda-ea22-42c9-91be-89ba0727d71d,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-bbb95ab3-dc03-4c7a-96ea-1f5f8956992a,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-6bc73ff9-cbdf-4322-8328-1a52d6996ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-0895e22d-3e49-420b-bc04-72f420031f90,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-66470f96-a500-4ddd-a5ff-74c5a8c3339d,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-010f61e3-9b3a-418b-ba5a-1cd8f397f530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205295041-172.17.0.5-1597185474850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40678,DS-f2ec1e40-2336-41eb-83cc-4f9f8299adfb,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-f7cdb3cf-ae93-468f-9e23-0757d85e36cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-3dd8bbda-ea22-42c9-91be-89ba0727d71d,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-bbb95ab3-dc03-4c7a-96ea-1f5f8956992a,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-6bc73ff9-cbdf-4322-8328-1a52d6996ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-0895e22d-3e49-420b-bc04-72f420031f90,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-66470f96-a500-4ddd-a5ff-74c5a8c3339d,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-010f61e3-9b3a-418b-ba5a-1cd8f397f530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5233
