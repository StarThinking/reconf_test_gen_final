reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463390299-172.17.0.7-1597105203311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-31db12cd-0670-4159-87b9-e419fbbdf407,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-8bd35d05-d22b-476f-99dd-723df47a48ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-ed865998-dba1-4c76-833f-4eb63647e775,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-f71887ef-ce29-4774-bcec-d5370bdbd58e,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-43b6f617-2ce8-464f-b27d-ba993a0bef34,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-a5753686-6dbc-4b2d-83c3-1a6e1b1b0c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-2cc76afe-92ad-4bc7-8ff0-a48cc1ec99ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-215c0c22-e671-4894-826c-aab0b8bb80b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1463390299-172.17.0.7-1597105203311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-31db12cd-0670-4159-87b9-e419fbbdf407,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-8bd35d05-d22b-476f-99dd-723df47a48ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-ed865998-dba1-4c76-833f-4eb63647e775,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-f71887ef-ce29-4774-bcec-d5370bdbd58e,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-43b6f617-2ce8-464f-b27d-ba993a0bef34,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-a5753686-6dbc-4b2d-83c3-1a6e1b1b0c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-2cc76afe-92ad-4bc7-8ff0-a48cc1ec99ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-215c0c22-e671-4894-826c-aab0b8bb80b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453760457-172.17.0.7-1597105241806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-1d91bf96-df72-4400-a658-671bdeab6cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-2f1c0be7-3305-44b4-a7dd-093df81982b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-d9a4105a-1a7f-43cb-ada6-6bcb69848ace,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-70dc9bca-96dc-43a9-8ace-20c566ac4277,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-46ea6687-39e1-4685-9c12-32488856f222,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-3ebde0a4-ee42-4534-a7de-9d92fd5fd978,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-b01ebdf1-be2f-4156-b6ae-6f89333f7a92,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-cc8b58fd-0e74-493c-bf72-a090848abb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453760457-172.17.0.7-1597105241806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45662,DS-1d91bf96-df72-4400-a658-671bdeab6cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46159,DS-2f1c0be7-3305-44b4-a7dd-093df81982b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-d9a4105a-1a7f-43cb-ada6-6bcb69848ace,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-70dc9bca-96dc-43a9-8ace-20c566ac4277,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-46ea6687-39e1-4685-9c12-32488856f222,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-3ebde0a4-ee42-4534-a7de-9d92fd5fd978,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-b01ebdf1-be2f-4156-b6ae-6f89333f7a92,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-cc8b58fd-0e74-493c-bf72-a090848abb2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285356217-172.17.0.7-1597105611821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42507,DS-ac425428-d505-4af2-83cb-e435503026af,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-aea4ccf1-90eb-4cb1-ab5f-35ee2ebab2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-37faf0e4-036c-412f-b925-8c49eec883d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-ee408e7c-adc1-4f4d-8cbd-bae1adecbf57,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-a431fef8-63f6-4938-9c38-a1b85466d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-a3bc7cc8-554a-4a3d-a6b3-b324f9afdf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-8f8dfa36-6c7a-48ce-abf3-68bf4002fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-1fb6c84f-89ff-4ae2-b09c-c6f366418b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285356217-172.17.0.7-1597105611821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42507,DS-ac425428-d505-4af2-83cb-e435503026af,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-aea4ccf1-90eb-4cb1-ab5f-35ee2ebab2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-37faf0e4-036c-412f-b925-8c49eec883d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-ee408e7c-adc1-4f4d-8cbd-bae1adecbf57,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-a431fef8-63f6-4938-9c38-a1b85466d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-a3bc7cc8-554a-4a3d-a6b3-b324f9afdf3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-8f8dfa36-6c7a-48ce-abf3-68bf4002fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-1fb6c84f-89ff-4ae2-b09c-c6f366418b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131110374-172.17.0.7-1597105847998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-43e73cfc-6cde-44fb-be86-77af1a1de898,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-df541840-af95-4ade-91c0-c50a6c0e0e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-64105ff9-79dd-4682-989a-619ae82bd010,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-6ac02268-dd48-4285-bbcb-086bfff6c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-298d6f71-e350-456b-9e55-9e07316ee9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-9978f7d0-120f-4274-acc3-a2ea0039ec10,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-926d53f3-f517-4674-8a1c-5ae7c76f2b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-dbdfc929-d2d2-4018-ba31-07d342eb9160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131110374-172.17.0.7-1597105847998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-43e73cfc-6cde-44fb-be86-77af1a1de898,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-df541840-af95-4ade-91c0-c50a6c0e0e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-64105ff9-79dd-4682-989a-619ae82bd010,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-6ac02268-dd48-4285-bbcb-086bfff6c9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-298d6f71-e350-456b-9e55-9e07316ee9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-9978f7d0-120f-4274-acc3-a2ea0039ec10,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-926d53f3-f517-4674-8a1c-5ae7c76f2b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-dbdfc929-d2d2-4018-ba31-07d342eb9160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729583865-172.17.0.7-1597106842888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-2ce9a0f0-7ca5-4b1a-8b76-d1acda637499,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-56a66472-99ce-4a9b-8d7c-2fd36b84083b,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-cca361a4-fa62-4810-b0ff-9db08e0023df,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-1b484b13-3ef5-4061-9953-c3f44fae2df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-105b36d9-3d37-46fe-9ab8-ea2eb7cc5ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-2717ba40-a0a7-4430-bb94-c4afd1e2aa78,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-aedbe3a1-ad4a-4f4a-b66c-27892302dbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-168c19d8-1a6a-4032-929c-fc1df65d69d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729583865-172.17.0.7-1597106842888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45724,DS-2ce9a0f0-7ca5-4b1a-8b76-d1acda637499,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-56a66472-99ce-4a9b-8d7c-2fd36b84083b,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-cca361a4-fa62-4810-b0ff-9db08e0023df,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-1b484b13-3ef5-4061-9953-c3f44fae2df0,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-105b36d9-3d37-46fe-9ab8-ea2eb7cc5ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-2717ba40-a0a7-4430-bb94-c4afd1e2aa78,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-aedbe3a1-ad4a-4f4a-b66c-27892302dbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-168c19d8-1a6a-4032-929c-fc1df65d69d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774125611-172.17.0.7-1597107297297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35908,DS-1acda7a2-0d01-4a5e-8559-cfb274bbc464,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-47b27a8a-fa39-4397-8d80-f3bd0dc1b02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-c39ed355-7d8f-4519-8439-1b3d7211a298,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-217ca244-72e4-495a-a75c-29245cd89756,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-690c334a-250a-45b2-8e1e-9a0c347eab49,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-6af2574f-b8c3-4712-b2ab-e70cc9316fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-8757334a-38a3-4cba-b752-b5d4d28f769e,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-9156f914-c814-4bad-9e69-ceb0c8871a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774125611-172.17.0.7-1597107297297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35908,DS-1acda7a2-0d01-4a5e-8559-cfb274bbc464,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-47b27a8a-fa39-4397-8d80-f3bd0dc1b02c,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-c39ed355-7d8f-4519-8439-1b3d7211a298,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-217ca244-72e4-495a-a75c-29245cd89756,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-690c334a-250a-45b2-8e1e-9a0c347eab49,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-6af2574f-b8c3-4712-b2ab-e70cc9316fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-8757334a-38a3-4cba-b752-b5d4d28f769e,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-9156f914-c814-4bad-9e69-ceb0c8871a82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34268727-172.17.0.7-1597108547683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38212,DS-532bb5a4-884c-49a6-85dc-f3a52c4609a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-6cfbb3b7-3875-4337-b072-1a23806c073d,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-b824aeed-a6df-40c9-92a1-40fb1f5decf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-1a100ef0-b5d0-41a3-b9e8-b4a63b34dde1,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-71ac9e3e-f825-4675-96d1-fbb495c69821,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-62170af2-7371-4815-8a8e-0ac1a7c25919,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-20e0e5f4-7743-4e61-9588-ddec202100e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-2e283f2d-fa31-4799-afb8-5bed0ee90040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34268727-172.17.0.7-1597108547683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38212,DS-532bb5a4-884c-49a6-85dc-f3a52c4609a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-6cfbb3b7-3875-4337-b072-1a23806c073d,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-b824aeed-a6df-40c9-92a1-40fb1f5decf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-1a100ef0-b5d0-41a3-b9e8-b4a63b34dde1,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-71ac9e3e-f825-4675-96d1-fbb495c69821,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-62170af2-7371-4815-8a8e-0ac1a7c25919,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-20e0e5f4-7743-4e61-9588-ddec202100e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-2e283f2d-fa31-4799-afb8-5bed0ee90040,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89016602-172.17.0.7-1597109478842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-b03bd0a1-fa51-42b6-9c79-9eab22b4ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-06ce6376-7884-42dd-9570-9540f107bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-7ad492d9-3bc7-4655-863e-3a45f09b0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-3aaac8b8-4b7f-4af4-a055-96bc22c63e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-fdc1b002-13d8-425b-9815-06db4dbbf52f,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-a97e0208-f4eb-458b-a641-1f62af4a104e,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-f6ea8de8-67df-405f-8bee-4cf3cc2e75ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-10b30a9d-99eb-477f-a36d-8b593a54d58f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89016602-172.17.0.7-1597109478842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-b03bd0a1-fa51-42b6-9c79-9eab22b4ffd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-06ce6376-7884-42dd-9570-9540f107bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-7ad492d9-3bc7-4655-863e-3a45f09b0ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-3aaac8b8-4b7f-4af4-a055-96bc22c63e31,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-fdc1b002-13d8-425b-9815-06db4dbbf52f,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-a97e0208-f4eb-458b-a641-1f62af4a104e,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-f6ea8de8-67df-405f-8bee-4cf3cc2e75ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-10b30a9d-99eb-477f-a36d-8b593a54d58f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542366778-172.17.0.7-1597110202922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39251,DS-8cc84096-564b-4054-9091-666dd7016370,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-442fd8c2-b9f9-4b9e-9f73-ea044e658305,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-12b3fda2-31fb-4ac5-8176-573ab58801df,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-f6d0aa74-6722-4ff2-8ff4-0796606af96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-14445e45-6ac8-4ea4-b375-97594129c717,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-76bbb888-90ad-420d-b649-70d9339e3664,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-9915d8fc-1be4-44ab-8b64-e505d89cc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-8344c5b6-444b-4445-810b-aa64d217893e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542366778-172.17.0.7-1597110202922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39251,DS-8cc84096-564b-4054-9091-666dd7016370,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-442fd8c2-b9f9-4b9e-9f73-ea044e658305,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-12b3fda2-31fb-4ac5-8176-573ab58801df,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-f6d0aa74-6722-4ff2-8ff4-0796606af96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-14445e45-6ac8-4ea4-b375-97594129c717,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-76bbb888-90ad-420d-b649-70d9339e3664,DISK], DatanodeInfoWithStorage[127.0.0.1:35755,DS-9915d8fc-1be4-44ab-8b64-e505d89cc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-8344c5b6-444b-4445-810b-aa64d217893e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367689092-172.17.0.7-1597110576577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45842,DS-d83b2fe8-aa23-441a-b1b4-cd37446212e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-d447b908-a88f-4599-bf8a-8b0a146d1fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-b5cabf4f-4af6-4e77-b8fc-0f91939ea215,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-d27e41cf-cd9d-41e8-a684-25a17fd55349,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-1813e162-f0fb-468e-a877-10aecc99623b,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-2dfc2e00-6aac-4e07-bd65-47d7b027a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-686021fe-c2d0-4721-8380-18bda6a47189,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-f8cfd037-2651-4440-94d9-a41c7ec7b0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367689092-172.17.0.7-1597110576577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45842,DS-d83b2fe8-aa23-441a-b1b4-cd37446212e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43211,DS-d447b908-a88f-4599-bf8a-8b0a146d1fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33272,DS-b5cabf4f-4af6-4e77-b8fc-0f91939ea215,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-d27e41cf-cd9d-41e8-a684-25a17fd55349,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-1813e162-f0fb-468e-a877-10aecc99623b,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-2dfc2e00-6aac-4e07-bd65-47d7b027a69d,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-686021fe-c2d0-4721-8380-18bda6a47189,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-f8cfd037-2651-4440-94d9-a41c7ec7b0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812585032-172.17.0.7-1597110615516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42786,DS-6864c78f-654b-445d-b653-f50a32b027e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-07c4cd25-f932-444c-a6fb-6cf9655704f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-baddfb6e-603e-4020-b5f0-16f8aed89643,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-dc066db2-225e-4563-90d2-8a0ad39765d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-179f6468-57f1-486a-bfb8-e13fd2aff04a,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-ebfc92fa-4cf1-4518-9bff-e4982eea1997,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-e337ffcb-b8b7-47d6-9576-ca434bbe0b60,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-2aa00c19-e4ba-4d9e-8f59-a5f528ec2b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-812585032-172.17.0.7-1597110615516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42786,DS-6864c78f-654b-445d-b653-f50a32b027e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-07c4cd25-f932-444c-a6fb-6cf9655704f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-baddfb6e-603e-4020-b5f0-16f8aed89643,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-dc066db2-225e-4563-90d2-8a0ad39765d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-179f6468-57f1-486a-bfb8-e13fd2aff04a,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-ebfc92fa-4cf1-4518-9bff-e4982eea1997,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-e337ffcb-b8b7-47d6-9576-ca434bbe0b60,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-2aa00c19-e4ba-4d9e-8f59-a5f528ec2b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628675272-172.17.0.7-1597111379846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43218,DS-5f9c4ab6-7d9e-42d6-9e54-ee46decfb85d,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-ff29707f-2692-4968-91f1-0012bad7dfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-3556f940-de19-44e0-8ed4-90a9af3c59b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-e28b137f-f698-453a-aa52-81a8520714eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-a1feb47f-7a7f-48db-8c12-ae77e3fa82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-7a630131-cbee-4360-8043-c3fde42c0ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-9d194dfb-2ad7-4055-97aa-dc7361035a45,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-2024e880-4d6f-459e-92c1-9e9726661116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628675272-172.17.0.7-1597111379846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43218,DS-5f9c4ab6-7d9e-42d6-9e54-ee46decfb85d,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-ff29707f-2692-4968-91f1-0012bad7dfe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-3556f940-de19-44e0-8ed4-90a9af3c59b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-e28b137f-f698-453a-aa52-81a8520714eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-a1feb47f-7a7f-48db-8c12-ae77e3fa82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46163,DS-7a630131-cbee-4360-8043-c3fde42c0ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-9d194dfb-2ad7-4055-97aa-dc7361035a45,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-2024e880-4d6f-459e-92c1-9e9726661116,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6437
