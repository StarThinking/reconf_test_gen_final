reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590451716-172.17.0.15-1597111225049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-15952a13-e78f-4ae1-9f47-1ce005537f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-da2acdb7-8335-4704-9255-b85350b5862e,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-fcf7aadc-8536-4f3e-831f-4d73968601c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-5b6d7cb6-4726-481e-9839-d61cc88ea75b,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-0710b291-0a8c-470d-9a76-da5b14b0f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-5b6ad938-4d9a-4cd3-86f2-f8b625f1b00f,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-dcb40cf6-30cd-49a3-9d1f-dde149455b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-7bbbf836-f02a-4b05-a37c-900849c0e642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590451716-172.17.0.15-1597111225049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46743,DS-15952a13-e78f-4ae1-9f47-1ce005537f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-da2acdb7-8335-4704-9255-b85350b5862e,DISK], DatanodeInfoWithStorage[127.0.0.1:40702,DS-fcf7aadc-8536-4f3e-831f-4d73968601c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-5b6d7cb6-4726-481e-9839-d61cc88ea75b,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-0710b291-0a8c-470d-9a76-da5b14b0f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-5b6ad938-4d9a-4cd3-86f2-f8b625f1b00f,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-dcb40cf6-30cd-49a3-9d1f-dde149455b53,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-7bbbf836-f02a-4b05-a37c-900849c0e642,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429361321-172.17.0.15-1597111292673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37837,DS-a1424f0b-fe54-42ec-bf5a-3fb1f28167f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-22886895-298c-4b10-a53a-49a097897a86,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-1614a0ed-9d36-41b7-8a3e-cf65b96060e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-65bd7f53-7ba0-40c5-9908-308276da4393,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-10723eb9-8047-4822-91d8-e706b9f06bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-01daaee4-1a16-4eb5-89f5-865a05dfffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-95933300-4255-41d2-b852-a6a3a012f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-7b0123e5-25b1-4cd1-a3f2-c5106b865048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429361321-172.17.0.15-1597111292673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37837,DS-a1424f0b-fe54-42ec-bf5a-3fb1f28167f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-22886895-298c-4b10-a53a-49a097897a86,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-1614a0ed-9d36-41b7-8a3e-cf65b96060e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-65bd7f53-7ba0-40c5-9908-308276da4393,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-10723eb9-8047-4822-91d8-e706b9f06bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-01daaee4-1a16-4eb5-89f5-865a05dfffd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-95933300-4255-41d2-b852-a6a3a012f80b,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-7b0123e5-25b1-4cd1-a3f2-c5106b865048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53140283-172.17.0.15-1597111782186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42823,DS-8320e2c7-aded-46ee-a645-6695df62b95f,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-7a7c3766-7ea9-4692-9cab-413a5d45b921,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-0f03cd1d-e2e7-407f-a9fe-1042e4705631,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-a3af2c2a-0157-4f0d-ae41-c89273513004,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-dd0dba65-f46b-4a98-8b87-2da6bbd973ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-15c156d6-f02d-4d1e-9ff8-3addb2594090,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-5e1b8537-21b0-4e8f-9fa0-0442aeec5f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-4d341da6-e919-457b-859d-3d6ecbff783c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-53140283-172.17.0.15-1597111782186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42823,DS-8320e2c7-aded-46ee-a645-6695df62b95f,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-7a7c3766-7ea9-4692-9cab-413a5d45b921,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-0f03cd1d-e2e7-407f-a9fe-1042e4705631,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-a3af2c2a-0157-4f0d-ae41-c89273513004,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-dd0dba65-f46b-4a98-8b87-2da6bbd973ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-15c156d6-f02d-4d1e-9ff8-3addb2594090,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-5e1b8537-21b0-4e8f-9fa0-0442aeec5f01,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-4d341da6-e919-457b-859d-3d6ecbff783c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839525124-172.17.0.15-1597112509928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-a1b82eff-c718-4cac-b945-44b12c1bbb88,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-7f2d1c47-f21c-4ee3-9cf3-9c82a9ed60f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-01370b7b-60b4-4fd3-b1e6-30495e02f3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-4d025308-98d0-49bc-85e9-fb7b8cf354b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-d1fc914a-67bf-4b71-b0c2-a527b7f7f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-b645a0f9-98b8-4e9a-8916-9c5d3de17971,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-f9d5bd7e-d24b-424a-81d6-386a6e2e1a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-d9df731d-0ecb-4d15-9ef0-fb97a2ef794a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839525124-172.17.0.15-1597112509928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-a1b82eff-c718-4cac-b945-44b12c1bbb88,DISK], DatanodeInfoWithStorage[127.0.0.1:45750,DS-7f2d1c47-f21c-4ee3-9cf3-9c82a9ed60f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-01370b7b-60b4-4fd3-b1e6-30495e02f3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-4d025308-98d0-49bc-85e9-fb7b8cf354b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-d1fc914a-67bf-4b71-b0c2-a527b7f7f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-b645a0f9-98b8-4e9a-8916-9c5d3de17971,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-f9d5bd7e-d24b-424a-81d6-386a6e2e1a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-d9df731d-0ecb-4d15-9ef0-fb97a2ef794a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122468433-172.17.0.15-1597112571447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41323,DS-7b387aa6-85f8-4ac0-9eb0-a7de4e6dc4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-c58155f3-0cd2-44aa-82cd-024a2f83785a,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-583f812e-ecf8-4c7e-927f-4870194462ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-f79c09c4-b9bd-42a9-8530-7942ceccc9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-d9b1db7c-0804-45cb-a79d-fa6ba65791bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-451582c2-9c73-4d7d-b858-5bccc1a313f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-77607074-bf50-42c0-89bb-fa7541f751ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-0cc3f1e1-208e-429a-a240-c10cf8b28f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122468433-172.17.0.15-1597112571447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41323,DS-7b387aa6-85f8-4ac0-9eb0-a7de4e6dc4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-c58155f3-0cd2-44aa-82cd-024a2f83785a,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-583f812e-ecf8-4c7e-927f-4870194462ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-f79c09c4-b9bd-42a9-8530-7942ceccc9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-d9b1db7c-0804-45cb-a79d-fa6ba65791bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-451582c2-9c73-4d7d-b858-5bccc1a313f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-77607074-bf50-42c0-89bb-fa7541f751ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-0cc3f1e1-208e-429a-a240-c10cf8b28f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961223445-172.17.0.15-1597112934094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-34abc676-848d-447d-971b-0f67c0702f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-9dede180-9d16-472d-94e1-e53633dd9048,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-5633e892-3cb6-4ca7-b539-0d51eb793770,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-2b62a8c0-97c1-4c2e-891c-2781c1a0e180,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-9b5af89d-fc7a-4e99-b8a8-b06dfc3ec005,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-27fc65b2-8bd4-48d2-bf3c-e0c1e7fd450a,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-1ac5f07f-5e23-4695-9b6b-e6e6b386ebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-f043aeec-a841-4b58-a665-040db74751c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961223445-172.17.0.15-1597112934094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36299,DS-34abc676-848d-447d-971b-0f67c0702f86,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-9dede180-9d16-472d-94e1-e53633dd9048,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-5633e892-3cb6-4ca7-b539-0d51eb793770,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-2b62a8c0-97c1-4c2e-891c-2781c1a0e180,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-9b5af89d-fc7a-4e99-b8a8-b06dfc3ec005,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-27fc65b2-8bd4-48d2-bf3c-e0c1e7fd450a,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-1ac5f07f-5e23-4695-9b6b-e6e6b386ebd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-f043aeec-a841-4b58-a665-040db74751c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759910672-172.17.0.15-1597113400557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35499,DS-ed4f4797-110e-4481-85e2-ffe3eed90908,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-7d3cab93-d32c-461a-bd28-252c763aceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-c4f8f248-a84a-400c-b80e-f4779139470d,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-a0f1f546-8114-41fe-85f3-238d9f6a2dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-580274f5-62e9-46e9-9987-7ab6020ec140,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-2717e9dd-26fd-4006-ae64-96a606b550aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-511d5252-cdfd-454b-99a3-44c76ef0418f,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-ccb9f453-4979-4ea8-8af8-c9abffa8999f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759910672-172.17.0.15-1597113400557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35499,DS-ed4f4797-110e-4481-85e2-ffe3eed90908,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-7d3cab93-d32c-461a-bd28-252c763aceb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-c4f8f248-a84a-400c-b80e-f4779139470d,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-a0f1f546-8114-41fe-85f3-238d9f6a2dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-580274f5-62e9-46e9-9987-7ab6020ec140,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-2717e9dd-26fd-4006-ae64-96a606b550aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-511d5252-cdfd-454b-99a3-44c76ef0418f,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-ccb9f453-4979-4ea8-8af8-c9abffa8999f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931103621-172.17.0.15-1597113769049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-6eb40d2b-e37e-459e-b1e3-bae762c1aa30,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-f77955eb-ebd4-44ac-a6c2-d0df0fd713f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-1cd41139-4a75-4851-b843-48562501e167,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-afad1b79-e571-4e91-8439-16ebf6c62e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-64bae51c-331d-4f22-9045-a4b332342842,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-f12d5c1d-d1c3-4f80-97ed-64b73de0aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-2ad3f260-588c-4e93-a4d7-ebc07ad3b131,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-3d8bd96f-b80c-40d2-a6fa-4979bfb47d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931103621-172.17.0.15-1597113769049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-6eb40d2b-e37e-459e-b1e3-bae762c1aa30,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-f77955eb-ebd4-44ac-a6c2-d0df0fd713f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-1cd41139-4a75-4851-b843-48562501e167,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-afad1b79-e571-4e91-8439-16ebf6c62e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-64bae51c-331d-4f22-9045-a4b332342842,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-f12d5c1d-d1c3-4f80-97ed-64b73de0aa45,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-2ad3f260-588c-4e93-a4d7-ebc07ad3b131,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-3d8bd96f-b80c-40d2-a6fa-4979bfb47d5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333183909-172.17.0.15-1597114239411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-7f12901c-c35e-415b-b5e9-839c351e868c,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-46d58826-f3b3-40e5-98e7-2c1df5800b49,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-71ad3b8c-b022-41e0-a421-d746a8d07c80,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-a6bda009-4fcb-4b55-baaa-a68236c129ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-90327ba5-f80b-4496-9c54-94b2e626645e,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-0f5d7e73-ef03-4ac7-81ec-6fe1dc6b62a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-838e9784-1eac-41ad-b438-9b18348856a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-dc07cbdb-d57c-4069-8d91-0cf737e49a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333183909-172.17.0.15-1597114239411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-7f12901c-c35e-415b-b5e9-839c351e868c,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-46d58826-f3b3-40e5-98e7-2c1df5800b49,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-71ad3b8c-b022-41e0-a421-d746a8d07c80,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-a6bda009-4fcb-4b55-baaa-a68236c129ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-90327ba5-f80b-4496-9c54-94b2e626645e,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-0f5d7e73-ef03-4ac7-81ec-6fe1dc6b62a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-838e9784-1eac-41ad-b438-9b18348856a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-dc07cbdb-d57c-4069-8d91-0cf737e49a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770576123-172.17.0.15-1597114337054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44574,DS-86eeefda-e764-4fa0-8c1c-b2c0cd8120cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-c387903b-a5a2-4854-915a-f2389ce064ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-7609f2a7-4890-4fdb-8fc0-76986d54ebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-fb905927-1751-4d13-8cc5-5ff41cf63cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-1da7bd0a-db82-4c50-823e-a3dbc1bf2369,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-1f6237cc-b06d-4ed9-b485-bffbab3dd1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-09a2df70-7f7b-40e3-ba84-394d5bbc154f,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-70f4f620-de34-4273-baa2-6409cbf80f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770576123-172.17.0.15-1597114337054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44574,DS-86eeefda-e764-4fa0-8c1c-b2c0cd8120cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-c387903b-a5a2-4854-915a-f2389ce064ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-7609f2a7-4890-4fdb-8fc0-76986d54ebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-fb905927-1751-4d13-8cc5-5ff41cf63cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-1da7bd0a-db82-4c50-823e-a3dbc1bf2369,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-1f6237cc-b06d-4ed9-b485-bffbab3dd1f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-09a2df70-7f7b-40e3-ba84-394d5bbc154f,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-70f4f620-de34-4273-baa2-6409cbf80f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.bytes-per-checksum
component: hdfs:NameNode
v1: 524288
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997876227-172.17.0.15-1597115645346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44508,DS-5e8a6a87-4703-416a-9453-da617a93ef67,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-5fe6f42a-f6aa-4596-abb8-847d7df9fffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-b057a7c3-72c5-4c76-afbf-f6ab7d1eac65,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-b76e22bc-245d-4630-a238-e427dc8c97e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-4c5d5ca0-6518-41da-b8d5-9e242835c676,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-9a148437-e798-49de-8774-2e6a25daecda,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-c7e9cb71-f9ea-442a-ac96-e8a86de3e1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-9f78c45f-7dc9-4a7a-ad8b-88eb5e0689ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997876227-172.17.0.15-1597115645346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44508,DS-5e8a6a87-4703-416a-9453-da617a93ef67,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-5fe6f42a-f6aa-4596-abb8-847d7df9fffa,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-b057a7c3-72c5-4c76-afbf-f6ab7d1eac65,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-b76e22bc-245d-4630-a238-e427dc8c97e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-4c5d5ca0-6518-41da-b8d5-9e242835c676,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-9a148437-e798-49de-8774-2e6a25daecda,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-c7e9cb71-f9ea-442a-ac96-e8a86de3e1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-9f78c45f-7dc9-4a7a-ad8b-88eb5e0689ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4959
