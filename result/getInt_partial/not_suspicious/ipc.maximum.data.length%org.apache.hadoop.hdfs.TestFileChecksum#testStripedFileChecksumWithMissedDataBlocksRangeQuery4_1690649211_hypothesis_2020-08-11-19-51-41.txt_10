reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016968812-172.17.0.10-1597175794971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-57f7a713-b81c-413d-9586-9bd6b77f66b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-2b2c9a17-0e12-4532-a313-138f29a57d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-c45717f8-51b6-43a4-b3b0-48e786b15761,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-1b319b7f-6eb5-481a-8dcd-bdaba112986c,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-79c7f432-a3e0-4d14-aa6b-3af7f376c298,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-7f0d7ae3-1263-4d45-8d1c-065128ed8020,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-fa6e283d-e631-4ecd-91a9-01d0b98b2e05,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-473c275c-a562-40b1-8f65-a74bf16a1364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1016968812-172.17.0.10-1597175794971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-57f7a713-b81c-413d-9586-9bd6b77f66b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-2b2c9a17-0e12-4532-a313-138f29a57d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-c45717f8-51b6-43a4-b3b0-48e786b15761,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-1b319b7f-6eb5-481a-8dcd-bdaba112986c,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-79c7f432-a3e0-4d14-aa6b-3af7f376c298,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-7f0d7ae3-1263-4d45-8d1c-065128ed8020,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-fa6e283d-e631-4ecd-91a9-01d0b98b2e05,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-473c275c-a562-40b1-8f65-a74bf16a1364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423083460-172.17.0.10-1597175913377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-e29baef5-e9eb-4315-b06d-f212a70bc4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-aaa38e3d-21c8-42a1-a450-d655b011401d,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-0aa1569d-10a2-4f42-a8c8-70db6b1803b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-b9dfb49f-a4aa-4886-b56c-abd0ae2f3445,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-e06a0dee-a148-4110-8ea8-a6c90322a664,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-d521c260-6cf5-45d1-87d2-b4708ade9808,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-f586e411-3315-4bff-a526-3ecce7131c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-1ab23704-9382-4be8-8537-b6d4e8a6ae46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423083460-172.17.0.10-1597175913377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36988,DS-e29baef5-e9eb-4315-b06d-f212a70bc4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-aaa38e3d-21c8-42a1-a450-d655b011401d,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-0aa1569d-10a2-4f42-a8c8-70db6b1803b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-b9dfb49f-a4aa-4886-b56c-abd0ae2f3445,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-e06a0dee-a148-4110-8ea8-a6c90322a664,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-d521c260-6cf5-45d1-87d2-b4708ade9808,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-f586e411-3315-4bff-a526-3ecce7131c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-1ab23704-9382-4be8-8537-b6d4e8a6ae46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284046052-172.17.0.10-1597176145008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34639,DS-9732405f-1e45-4e34-814f-d15e5b0888ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-2c28af38-3f56-4873-a7b6-5487331c3033,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-c3d7e7ab-2310-4a30-9b37-017181eee29a,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-ad639bd1-9ec4-4bc5-a4aa-30c6de16b076,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-8dbf1a0c-5321-4904-b6c4-5d9571cebf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-22eb8e8c-6c6d-4a91-8f3e-8950f19556c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-3a380b9a-f911-455d-ad3f-f879780d947b,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-6ea5848d-ad20-4cbd-a95f-d197e9f0916b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284046052-172.17.0.10-1597176145008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34639,DS-9732405f-1e45-4e34-814f-d15e5b0888ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-2c28af38-3f56-4873-a7b6-5487331c3033,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-c3d7e7ab-2310-4a30-9b37-017181eee29a,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-ad639bd1-9ec4-4bc5-a4aa-30c6de16b076,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-8dbf1a0c-5321-4904-b6c4-5d9571cebf2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-22eb8e8c-6c6d-4a91-8f3e-8950f19556c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-3a380b9a-f911-455d-ad3f-f879780d947b,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-6ea5848d-ad20-4cbd-a95f-d197e9f0916b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47855626-172.17.0.10-1597176362243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38137,DS-f6d51cbe-547c-43c7-a24b-173abe0db475,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-279cfd35-3ec4-4c20-bd8e-f80f69dc9e60,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-3c2b0b41-f6e2-41ca-9d00-eafb1f085d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-25b61a19-c5f5-419b-9803-14a7ffdc1f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-5f494735-a7aa-4fb7-9215-e7217dc5636b,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-70957800-8670-47bd-8edc-79b71c2abafb,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-ad0d2645-1f60-43a8-9bc2-aaee734b8d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-26f92af4-2b08-4c81-9411-f1740ad80857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47855626-172.17.0.10-1597176362243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38137,DS-f6d51cbe-547c-43c7-a24b-173abe0db475,DISK], DatanodeInfoWithStorage[127.0.0.1:37525,DS-279cfd35-3ec4-4c20-bd8e-f80f69dc9e60,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-3c2b0b41-f6e2-41ca-9d00-eafb1f085d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40862,DS-25b61a19-c5f5-419b-9803-14a7ffdc1f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-5f494735-a7aa-4fb7-9215-e7217dc5636b,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-70957800-8670-47bd-8edc-79b71c2abafb,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-ad0d2645-1f60-43a8-9bc2-aaee734b8d15,DISK], DatanodeInfoWithStorage[127.0.0.1:38202,DS-26f92af4-2b08-4c81-9411-f1740ad80857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123511658-172.17.0.10-1597176494063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41497,DS-71d92fe0-4962-48ef-8ae0-4960c041f7de,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-cfe29728-4f6f-459d-8f87-fe6ce5a1d78b,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-d02eb545-d28d-45ae-b8fc-ce753ca916c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-24ae8bdc-b01f-4d36-bf6d-2620cc314656,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-334316cd-e42f-4355-ab72-bd35c4e4871c,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-18198f26-9ac9-4ec2-8902-cea6bcda4331,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-baa23347-b395-403f-bafa-356f068a214b,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-4dbaf398-a724-4f67-a2a2-69539179de1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123511658-172.17.0.10-1597176494063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41497,DS-71d92fe0-4962-48ef-8ae0-4960c041f7de,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-cfe29728-4f6f-459d-8f87-fe6ce5a1d78b,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-d02eb545-d28d-45ae-b8fc-ce753ca916c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-24ae8bdc-b01f-4d36-bf6d-2620cc314656,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-334316cd-e42f-4355-ab72-bd35c4e4871c,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-18198f26-9ac9-4ec2-8902-cea6bcda4331,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-baa23347-b395-403f-bafa-356f068a214b,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-4dbaf398-a724-4f67-a2a2-69539179de1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932377320-172.17.0.10-1597176854829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-05689a66-ee4d-444d-9714-054160a95f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-118e8ed4-00bd-45c8-81c6-efbe1b7baa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-de869798-89ec-48a5-b113-ccb78c502b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-d0f10c90-edf7-45c4-be76-2a23b1b2c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-3f7aade9-56ef-45d2-97ed-62da1a06f742,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-2a6164a7-8e7b-410e-87d7-85b790384804,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-d1b491c0-3248-4c81-83e5-3884fd757bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-af17596f-b8a0-4ebb-8f27-620f0e591ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1932377320-172.17.0.10-1597176854829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37167,DS-05689a66-ee4d-444d-9714-054160a95f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-118e8ed4-00bd-45c8-81c6-efbe1b7baa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37764,DS-de869798-89ec-48a5-b113-ccb78c502b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-d0f10c90-edf7-45c4-be76-2a23b1b2c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-3f7aade9-56ef-45d2-97ed-62da1a06f742,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-2a6164a7-8e7b-410e-87d7-85b790384804,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-d1b491c0-3248-4c81-83e5-3884fd757bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-af17596f-b8a0-4ebb-8f27-620f0e591ca0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766091480-172.17.0.10-1597176969337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46659,DS-c92ee8dd-cfd7-4cb4-b08f-ba6e2fc3a851,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-00f2777d-6263-44fc-b8ba-7c142976bccc,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-c998120a-ef12-4ced-b3a9-fc5535bafe01,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-75746ef9-c595-42d3-982d-e2e9b67d65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-b4eadf39-185d-474d-a3e3-b62c5c08fa60,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-4e16b2e8-62e7-4b2c-8a52-e304ae1dc9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-398a9921-60fd-4230-aa38-6c068cd29f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-f2f222fb-f99d-4498-8ef1-f86acffa9a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766091480-172.17.0.10-1597176969337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46659,DS-c92ee8dd-cfd7-4cb4-b08f-ba6e2fc3a851,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-00f2777d-6263-44fc-b8ba-7c142976bccc,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-c998120a-ef12-4ced-b3a9-fc5535bafe01,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-75746ef9-c595-42d3-982d-e2e9b67d65eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-b4eadf39-185d-474d-a3e3-b62c5c08fa60,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-4e16b2e8-62e7-4b2c-8a52-e304ae1dc9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-398a9921-60fd-4230-aa38-6c068cd29f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-f2f222fb-f99d-4498-8ef1-f86acffa9a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177682778-172.17.0.10-1597177148272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44905,DS-79af0e84-36d7-42cc-ba2a-37dac8b9babd,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-5556db6e-3bee-48f3-afe3-3bb1d5730fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-78f59ec3-56c6-457e-9368-ccec6bea42de,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-22ca43c3-c094-4ff7-945a-9dbc7831c99f,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-7b3f9d1b-7c7f-4513-9a05-818093a1c6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-9e023913-3639-42ec-965c-511a6dbf9686,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-92866de7-da2a-4772-94ad-30ca24bdacfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-8ce3dba5-0a08-4445-ae6a-2f45143547b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177682778-172.17.0.10-1597177148272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44905,DS-79af0e84-36d7-42cc-ba2a-37dac8b9babd,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-5556db6e-3bee-48f3-afe3-3bb1d5730fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-78f59ec3-56c6-457e-9368-ccec6bea42de,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-22ca43c3-c094-4ff7-945a-9dbc7831c99f,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-7b3f9d1b-7c7f-4513-9a05-818093a1c6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-9e023913-3639-42ec-965c-511a6dbf9686,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-92866de7-da2a-4772-94ad-30ca24bdacfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-8ce3dba5-0a08-4445-ae6a-2f45143547b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226142880-172.17.0.10-1597177247635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44307,DS-8ea07fdf-7847-4aa0-81b6-1642ec363b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-d3cf5023-84af-4c04-8dd6-1ae1a0e0e25e,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-a051b76f-6cc4-4c88-b956-fc95e3a6b4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-f7b85403-1d0b-4ca8-b845-265b8c69ad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-bd47760f-8902-458c-bf6f-3bcdbd7390ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-208bd2b7-b3da-4293-8060-dc0175af1431,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-85507d07-7156-4849-9813-d3edc83ac731,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-afa57e95-8b0e-4f39-a9e6-442c2dd882a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226142880-172.17.0.10-1597177247635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44307,DS-8ea07fdf-7847-4aa0-81b6-1642ec363b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-d3cf5023-84af-4c04-8dd6-1ae1a0e0e25e,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-a051b76f-6cc4-4c88-b956-fc95e3a6b4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-f7b85403-1d0b-4ca8-b845-265b8c69ad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-bd47760f-8902-458c-bf6f-3bcdbd7390ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-208bd2b7-b3da-4293-8060-dc0175af1431,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-85507d07-7156-4849-9813-d3edc83ac731,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-afa57e95-8b0e-4f39-a9e6-442c2dd882a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449324710-172.17.0.10-1597177519531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-5158bb35-96d4-433b-897a-b2bd7b3941dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-32749abc-3f4f-4455-939d-05d01a44eb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-fee73803-331b-42af-84ef-e3d0c42ad351,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-4e7a7b70-b8cc-4483-9f3e-182e7044543d,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-4d98a6da-750c-4221-8716-52052dfeddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-3665f2f2-172e-486d-9774-a9767f2b0df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-6774c0c7-247c-431e-8211-0f51a4b49155,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-56bde20b-0c56-4d34-adf4-d5f505ccfdcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-449324710-172.17.0.10-1597177519531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42365,DS-5158bb35-96d4-433b-897a-b2bd7b3941dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-32749abc-3f4f-4455-939d-05d01a44eb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-fee73803-331b-42af-84ef-e3d0c42ad351,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-4e7a7b70-b8cc-4483-9f3e-182e7044543d,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-4d98a6da-750c-4221-8716-52052dfeddc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-3665f2f2-172e-486d-9774-a9767f2b0df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-6774c0c7-247c-431e-8211-0f51a4b49155,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-56bde20b-0c56-4d34-adf4-d5f505ccfdcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223604607-172.17.0.10-1597178598228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38400,DS-9c0f228e-4ee5-4505-8896-676e5ed70ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-1b7112e8-338a-4c20-8ce7-b9b240bb55f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-741da0fc-8936-439a-af3d-5f9a1a36195e,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-5c917995-692d-4f4c-b333-42c741cbd262,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-48f49abd-8abd-44fe-a289-c8d42307a0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-d1bc09e6-c7df-42b6-82b2-b21662472b66,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-3d4a27f0-c9f1-4866-9ec1-714773600b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-e3117c0b-68ea-4975-864e-d303fea2f837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-223604607-172.17.0.10-1597178598228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38400,DS-9c0f228e-4ee5-4505-8896-676e5ed70ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-1b7112e8-338a-4c20-8ce7-b9b240bb55f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-741da0fc-8936-439a-af3d-5f9a1a36195e,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-5c917995-692d-4f4c-b333-42c741cbd262,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-48f49abd-8abd-44fe-a289-c8d42307a0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-d1bc09e6-c7df-42b6-82b2-b21662472b66,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-3d4a27f0-c9f1-4866-9ec1-714773600b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40698,DS-e3117c0b-68ea-4975-864e-d303fea2f837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316806807-172.17.0.10-1597178884691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45033,DS-1a173154-1f92-4077-8248-8a70e57adc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-81193a3f-5c6f-4046-96b6-4ea3721034ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-1aadb613-eb47-4a5d-b9d5-de5c1a704f06,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-e9197245-277c-4556-8821-1b850b4e7902,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-c832d704-6b2e-44b8-839e-8a15905fe379,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-78e688d2-38dd-4a41-ac0d-01933ab5d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-76f93cb3-e031-433a-986b-169d9845532f,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-b04adf96-c81f-4e7e-bd13-54093765621c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316806807-172.17.0.10-1597178884691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45033,DS-1a173154-1f92-4077-8248-8a70e57adc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-81193a3f-5c6f-4046-96b6-4ea3721034ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-1aadb613-eb47-4a5d-b9d5-de5c1a704f06,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-e9197245-277c-4556-8821-1b850b4e7902,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-c832d704-6b2e-44b8-839e-8a15905fe379,DISK], DatanodeInfoWithStorage[127.0.0.1:35464,DS-78e688d2-38dd-4a41-ac0d-01933ab5d1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-76f93cb3-e031-433a-986b-169d9845532f,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-b04adf96-c81f-4e7e-bd13-54093765621c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301017661-172.17.0.10-1597178951791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-2ab8c41e-244a-4063-8bf0-941c211b7a08,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-1e334b33-c874-4e04-8aa4-635d3bf6cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-63f865ca-5206-4c1e-b81d-63831d44466c,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-2fb61140-684e-41ee-bf8e-3e9a8ddf08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-24ce3f9b-c6f0-4008-9fac-7138d893090b,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-22979d3b-8347-484b-b7d4-bb10eac1c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-9629950a-485a-4bd3-a79f-974d11773530,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-e5d8ce58-067c-4478-a489-5b9e395d5209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301017661-172.17.0.10-1597178951791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45804,DS-2ab8c41e-244a-4063-8bf0-941c211b7a08,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-1e334b33-c874-4e04-8aa4-635d3bf6cfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-63f865ca-5206-4c1e-b81d-63831d44466c,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-2fb61140-684e-41ee-bf8e-3e9a8ddf08fe,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-24ce3f9b-c6f0-4008-9fac-7138d893090b,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-22979d3b-8347-484b-b7d4-bb10eac1c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-9629950a-485a-4bd3-a79f-974d11773530,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-e5d8ce58-067c-4478-a489-5b9e395d5209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574217500-172.17.0.10-1597179187200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-2e0163f7-8c2b-4b34-a66c-e76035a25888,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-00369a64-7150-4e24-bf69-f32135345e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-b820c842-6db0-4a8b-a91e-0a5704cda0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-ac68fbbc-f461-4036-95c1-d55284499934,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-87cb9f4f-e180-48e8-a5c8-fcbf7598eb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-62d32ebd-9a68-400a-8c7b-07e00902286a,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-b8583426-fd08-4dae-a15f-b86f76aff138,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-2b79c212-0378-46da-b1bb-811ec3f8d5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574217500-172.17.0.10-1597179187200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34813,DS-2e0163f7-8c2b-4b34-a66c-e76035a25888,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-00369a64-7150-4e24-bf69-f32135345e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-b820c842-6db0-4a8b-a91e-0a5704cda0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-ac68fbbc-f461-4036-95c1-d55284499934,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-87cb9f4f-e180-48e8-a5c8-fcbf7598eb41,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-62d32ebd-9a68-400a-8c7b-07e00902286a,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-b8583426-fd08-4dae-a15f-b86f76aff138,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-2b79c212-0378-46da-b1bb-811ec3f8d5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215524188-172.17.0.10-1597179366944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-9d6371df-dadb-4a63-90b8-9ba89c008543,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-5317b60a-0874-405c-a948-446b996b596d,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-abd0b838-c287-48ed-89e3-fad39718b720,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-30d9de87-74f5-43f4-969b-29e652595a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-874592a6-6d3e-40f0-bb78-202f99cd8f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-163324ab-22fa-46f3-b4d6-797f71b68ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-859429d5-9f28-497f-99a6-975c9b45465b,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-bb46d085-23ed-4f0e-a65e-4f3cd8fd74c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215524188-172.17.0.10-1597179366944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-9d6371df-dadb-4a63-90b8-9ba89c008543,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-5317b60a-0874-405c-a948-446b996b596d,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-abd0b838-c287-48ed-89e3-fad39718b720,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-30d9de87-74f5-43f4-969b-29e652595a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-874592a6-6d3e-40f0-bb78-202f99cd8f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-163324ab-22fa-46f3-b4d6-797f71b68ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-859429d5-9f28-497f-99a6-975c9b45465b,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-bb46d085-23ed-4f0e-a65e-4f3cd8fd74c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257709838-172.17.0.10-1597179448481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-06d7c757-76c3-49cd-962e-91008ee6a9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-7f674aeb-287a-4752-b595-01a6ed0f4e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-8d80429d-f073-4d95-9bce-9504e77a014c,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-564da207-15be-4c11-b59c-cae31a5796dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-1a92fc3f-1bd4-40c3-a6a6-eb782cbf67d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-d03982b5-019a-484f-ac96-b5f36970ba3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-1a185b06-2cee-4979-b4ac-88cc81e91f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-4b73542d-a5a6-47d0-8319-18a1315727a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257709838-172.17.0.10-1597179448481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-06d7c757-76c3-49cd-962e-91008ee6a9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-7f674aeb-287a-4752-b595-01a6ed0f4e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-8d80429d-f073-4d95-9bce-9504e77a014c,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-564da207-15be-4c11-b59c-cae31a5796dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-1a92fc3f-1bd4-40c3-a6a6-eb782cbf67d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-d03982b5-019a-484f-ac96-b5f36970ba3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-1a185b06-2cee-4979-b4ac-88cc81e91f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-4b73542d-a5a6-47d0-8319-18a1315727a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029062895-172.17.0.10-1597179766107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46326,DS-0dd8e1b0-7927-4c5c-8d10-cf360cd2da43,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-a6e1bc85-d6c9-4d4a-9370-403d4e93b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-07a2a33a-28be-4c17-9136-fe7b1511f1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-9ee63d3a-a38f-4543-b0e1-4aab431ea906,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-a77d71f4-669e-4945-8c5b-a76dcd339b88,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-4fe68372-6b9a-4966-8590-6f1c2f4707ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-3adbe592-c805-4e42-a708-43367ecd7020,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-5196c0d0-9bc8-49da-8285-75a4d66e191c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029062895-172.17.0.10-1597179766107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46326,DS-0dd8e1b0-7927-4c5c-8d10-cf360cd2da43,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-a6e1bc85-d6c9-4d4a-9370-403d4e93b1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-07a2a33a-28be-4c17-9136-fe7b1511f1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-9ee63d3a-a38f-4543-b0e1-4aab431ea906,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-a77d71f4-669e-4945-8c5b-a76dcd339b88,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-4fe68372-6b9a-4966-8590-6f1c2f4707ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-3adbe592-c805-4e42-a708-43367ecd7020,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-5196c0d0-9bc8-49da-8285-75a4d66e191c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668686490-172.17.0.10-1597179862334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38710,DS-06f7711e-5f27-4495-a17e-4255c26ebf25,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-14065887-4278-43c0-9506-08ad539f1fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-c9238174-180d-4f94-9840-0fda825713b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5fb54beb-1c67-4ee6-a09a-5b7e3dd6bf04,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-db16e7e3-cb24-4edf-a9bb-c7ce1011536a,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-604c949d-0dc6-4b5a-b87f-5a4568d760f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-d1bfb03d-602c-474a-a41d-eaf9f7c694d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-6cdb0c54-5a5c-482f-8f2b-6ec060992f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668686490-172.17.0.10-1597179862334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38710,DS-06f7711e-5f27-4495-a17e-4255c26ebf25,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-14065887-4278-43c0-9506-08ad539f1fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-c9238174-180d-4f94-9840-0fda825713b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-5fb54beb-1c67-4ee6-a09a-5b7e3dd6bf04,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-db16e7e3-cb24-4edf-a9bb-c7ce1011536a,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-604c949d-0dc6-4b5a-b87f-5a4568d760f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-d1bfb03d-602c-474a-a41d-eaf9f7c694d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-6cdb0c54-5a5c-482f-8f2b-6ec060992f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825351136-172.17.0.10-1597179934097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-e0d88914-e750-4671-916a-c2f2791ef711,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-a649f0da-3466-4c71-a457-3db2db3fc7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-df595487-a9d4-41fa-b0e5-552e94acd0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-d4d292cc-b27b-4074-9373-18392ed5abda,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-a8a19b6f-38f7-489d-935c-74baea4c8e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-7b608499-286a-47ff-930e-1b304921781f,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-8623dae7-8908-42e2-b0cc-8c28a5d4e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-21559213-31dc-44e4-af2f-edcb845eca66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825351136-172.17.0.10-1597179934097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46654,DS-e0d88914-e750-4671-916a-c2f2791ef711,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-a649f0da-3466-4c71-a457-3db2db3fc7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-df595487-a9d4-41fa-b0e5-552e94acd0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-d4d292cc-b27b-4074-9373-18392ed5abda,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-a8a19b6f-38f7-489d-935c-74baea4c8e04,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-7b608499-286a-47ff-930e-1b304921781f,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-8623dae7-8908-42e2-b0cc-8c28a5d4e63d,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-21559213-31dc-44e4-af2f-edcb845eca66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096231599-172.17.0.10-1597180237739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33960,DS-357e6e96-044d-4abd-ad5e-6b3e5c2aab3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-8d98bee4-b1d8-4bf7-9dbf-28fcfef40498,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-8bec83e3-45b6-40a4-bd0c-2e856f7e4c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-eff3f029-bed4-408d-9932-5dc334b7e48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-1b2e88e8-9dad-4b5e-8327-d196d7ed5810,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-91e0316f-311b-4a7a-8887-050a59129302,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-0a6a8927-75bd-49b3-a39e-918c848aa867,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-f19dc477-2937-4b81-9c67-a01b041899cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096231599-172.17.0.10-1597180237739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33960,DS-357e6e96-044d-4abd-ad5e-6b3e5c2aab3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-8d98bee4-b1d8-4bf7-9dbf-28fcfef40498,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-8bec83e3-45b6-40a4-bd0c-2e856f7e4c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-eff3f029-bed4-408d-9932-5dc334b7e48e,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-1b2e88e8-9dad-4b5e-8327-d196d7ed5810,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-91e0316f-311b-4a7a-8887-050a59129302,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-0a6a8927-75bd-49b3-a39e-918c848aa867,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-f19dc477-2937-4b81-9c67-a01b041899cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376011555-172.17.0.10-1597180308002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-6e6e084a-34f8-4e81-9677-e4555350b878,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-d5023593-9af7-4651-8faf-47c9b16f2858,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-b99b36d5-aadd-4700-a74b-bb2a8faf9f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-d11bee77-7467-4504-a0cb-210cf4528d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-ccf64056-7fee-4bbd-914b-5a1855605a72,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-ec1b5dbd-a21d-46a8-a4ea-64e774701326,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-5e9c53d7-6ea4-4953-8153-f4656feccaea,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-84618995-fba2-4fe0-920d-1f39a94c2b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376011555-172.17.0.10-1597180308002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-6e6e084a-34f8-4e81-9677-e4555350b878,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-d5023593-9af7-4651-8faf-47c9b16f2858,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-b99b36d5-aadd-4700-a74b-bb2a8faf9f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-d11bee77-7467-4504-a0cb-210cf4528d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-ccf64056-7fee-4bbd-914b-5a1855605a72,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-ec1b5dbd-a21d-46a8-a4ea-64e774701326,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-5e9c53d7-6ea4-4953-8153-f4656feccaea,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-84618995-fba2-4fe0-920d-1f39a94c2b47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919063668-172.17.0.10-1597180592001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-a48a8158-edcf-42bb-a744-01aef4ac5fff,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-985c2433-a9a5-4c41-9bc0-e6a4a01bb8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-9922be3a-c317-4d8e-a802-5c89ce8d59b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-468cfd5a-7f86-4e0d-9aea-81667f41f360,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-8f3e7c9b-e78f-423d-be06-0c3c22497dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-16c2319d-2892-420d-9b52-b1fc5f5dd801,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-6508f4d2-949e-402f-9e64-9dabed8ec454,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-e9737395-2f0d-4c88-8bf3-196d65eda94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919063668-172.17.0.10-1597180592001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34044,DS-a48a8158-edcf-42bb-a744-01aef4ac5fff,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-985c2433-a9a5-4c41-9bc0-e6a4a01bb8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-9922be3a-c317-4d8e-a802-5c89ce8d59b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40254,DS-468cfd5a-7f86-4e0d-9aea-81667f41f360,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-8f3e7c9b-e78f-423d-be06-0c3c22497dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-16c2319d-2892-420d-9b52-b1fc5f5dd801,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-6508f4d2-949e-402f-9e64-9dabed8ec454,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-e9737395-2f0d-4c88-8bf3-196d65eda94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 1024
v2: 67108864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100110212-172.17.0.10-1597180773071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-58bd0031-db72-400c-aba1-b29e12a85e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-dc5d7a7d-4fe2-46ca-9bda-9f73fb585cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-67254090-dbd5-41c4-b0a1-0925e5651a30,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-d9733b8e-4c35-4b66-af71-ae6529167f56,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-4f117d8c-dc6d-48bc-9e75-d5e864b8e923,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-962e88e6-56a7-41b5-8506-ccf5b7bd4b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-611d39c1-2982-4ca9-8632-aaa2fbb81aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-4fd00e32-d924-41ab-a2c8-ed6ca1f247e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100110212-172.17.0.10-1597180773071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43913,DS-58bd0031-db72-400c-aba1-b29e12a85e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-dc5d7a7d-4fe2-46ca-9bda-9f73fb585cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-67254090-dbd5-41c4-b0a1-0925e5651a30,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-d9733b8e-4c35-4b66-af71-ae6529167f56,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-4f117d8c-dc6d-48bc-9e75-d5e864b8e923,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-962e88e6-56a7-41b5-8506-ccf5b7bd4b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-611d39c1-2982-4ca9-8632-aaa2fbb81aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-4fd00e32-d924-41ab-a2c8-ed6ca1f247e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5326
