reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034225913-172.17.0.17-1597199805368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-4fa61c41-c440-4156-94f1-300b6495a76a,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-ecafa343-2cf1-4c7c-8fb7-3872402008ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-0a2cc62f-caca-4077-9927-9b95782fe6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-8a991a1e-e32c-49f7-a93f-1621e5eff242,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-d15723b5-89cc-465d-befd-e19a97ce74a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-8af72c36-5bec-4481-aeb5-0858717c0df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-747d8503-92f2-47d3-a3a8-966e7cf35c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-e50a0930-2a41-44f9-b1fb-45e0bfc29d72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2034225913-172.17.0.17-1597199805368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35678,DS-4fa61c41-c440-4156-94f1-300b6495a76a,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-ecafa343-2cf1-4c7c-8fb7-3872402008ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-0a2cc62f-caca-4077-9927-9b95782fe6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-8a991a1e-e32c-49f7-a93f-1621e5eff242,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-d15723b5-89cc-465d-befd-e19a97ce74a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-8af72c36-5bec-4481-aeb5-0858717c0df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-747d8503-92f2-47d3-a3a8-966e7cf35c90,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-e50a0930-2a41-44f9-b1fb-45e0bfc29d72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367196316-172.17.0.17-1597200458707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36822,DS-d62de29f-e444-49be-b037-6e192d71a2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-98765f77-98b5-463c-aa20-5fafb097b93e,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-fb04ffe3-abb0-4d47-ba34-fab27da3fae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-3ee8dbb1-1e4f-485c-9f04-fd94dacbd652,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-cbdaca68-a9c2-4492-a4d5-3e7f57e32188,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-c38017aa-2450-461f-bf0b-74686979f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-177c4661-5203-4ce6-857b-0da07fc58347,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-742004e6-210a-4eae-af3e-aa464c9d6e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367196316-172.17.0.17-1597200458707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36822,DS-d62de29f-e444-49be-b037-6e192d71a2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-98765f77-98b5-463c-aa20-5fafb097b93e,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-fb04ffe3-abb0-4d47-ba34-fab27da3fae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-3ee8dbb1-1e4f-485c-9f04-fd94dacbd652,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-cbdaca68-a9c2-4492-a4d5-3e7f57e32188,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-c38017aa-2450-461f-bf0b-74686979f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-177c4661-5203-4ce6-857b-0da07fc58347,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-742004e6-210a-4eae-af3e-aa464c9d6e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756913332-172.17.0.17-1597200504319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-2acf7305-26e5-43f6-9dbe-40abe448ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-5ee89012-9886-4d97-a620-e455f4cb865b,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-e0c31894-5b93-445e-83d9-1a7d22751729,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-6b044584-55db-4b3e-91f7-fafa981d0a51,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-36bf5dfd-54c3-4e94-8b8c-162df834de0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-58c419a3-b916-46b9-92c0-8a0f69bf58e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-5dab0b55-bf80-4c61-82e1-daefe6030fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-8cfb9cba-cb07-4063-bff0-130773b19a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756913332-172.17.0.17-1597200504319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40313,DS-2acf7305-26e5-43f6-9dbe-40abe448ae58,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-5ee89012-9886-4d97-a620-e455f4cb865b,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-e0c31894-5b93-445e-83d9-1a7d22751729,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-6b044584-55db-4b3e-91f7-fafa981d0a51,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-36bf5dfd-54c3-4e94-8b8c-162df834de0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-58c419a3-b916-46b9-92c0-8a0f69bf58e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-5dab0b55-bf80-4c61-82e1-daefe6030fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-8cfb9cba-cb07-4063-bff0-130773b19a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819520142-172.17.0.17-1597201203942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-6e96a919-0375-4455-8dfa-96f5b5e2f96c,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-1f205f13-211f-40eb-8390-9581e266f723,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-c6555b06-4a01-47f3-9872-dae28acae937,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-fdc8ba92-174e-4b01-8f07-4461c2fc87f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-89882f4a-3ac5-4b37-9fea-531fd2632667,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-c172c8ae-a4dd-41a2-9129-747046f8055d,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-03722001-5751-49f2-b3a4-4671929f8e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-edc7ae25-1deb-434c-9007-8efff8297130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819520142-172.17.0.17-1597201203942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42252,DS-6e96a919-0375-4455-8dfa-96f5b5e2f96c,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-1f205f13-211f-40eb-8390-9581e266f723,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-c6555b06-4a01-47f3-9872-dae28acae937,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-fdc8ba92-174e-4b01-8f07-4461c2fc87f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-89882f4a-3ac5-4b37-9fea-531fd2632667,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-c172c8ae-a4dd-41a2-9129-747046f8055d,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-03722001-5751-49f2-b3a4-4671929f8e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-edc7ae25-1deb-434c-9007-8efff8297130,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372279577-172.17.0.17-1597201961918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37097,DS-2fbf233a-7084-4731-b0c8-1760bf3bb6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-568bc592-adb9-4c8c-8c13-169c3924454b,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-7c700dd6-1a7b-4fd6-b676-7207d110f186,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-ec1317de-13d8-494e-825c-7a96c13d9546,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-ae37f4fb-8c7c-4b5b-80f3-819f8c71efac,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-54077d44-addd-4db2-8e57-b5767d0f7eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-c57961ae-1cff-4a6f-a0bd-85b9c7928b71,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-56f5ab1c-619b-46c2-b184-41871cbb3886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372279577-172.17.0.17-1597201961918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37097,DS-2fbf233a-7084-4731-b0c8-1760bf3bb6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-568bc592-adb9-4c8c-8c13-169c3924454b,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-7c700dd6-1a7b-4fd6-b676-7207d110f186,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-ec1317de-13d8-494e-825c-7a96c13d9546,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-ae37f4fb-8c7c-4b5b-80f3-819f8c71efac,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-54077d44-addd-4db2-8e57-b5767d0f7eab,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-c57961ae-1cff-4a6f-a0bd-85b9c7928b71,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-56f5ab1c-619b-46c2-b184-41871cbb3886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161849209-172.17.0.17-1597202135503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-8165555f-3bb8-49d9-ad0b-04bdb2cb55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-58f31c80-2557-44ec-8f08-dc0ba411ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-5de5a674-a05a-4dbc-a61e-17264a6383ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-7e62644f-5cbc-4c93-9ef7-1850e191ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-10b41ee3-0823-4d26-9902-d5af44c416a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-75cedcff-380c-4005-95c8-6510e9904347,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-36f4976c-f4cc-4414-98fc-b2ba3600883b,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-7e94a81c-8ac7-40ae-a956-3f08cfeb26ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161849209-172.17.0.17-1597202135503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-8165555f-3bb8-49d9-ad0b-04bdb2cb55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-58f31c80-2557-44ec-8f08-dc0ba411ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-5de5a674-a05a-4dbc-a61e-17264a6383ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-7e62644f-5cbc-4c93-9ef7-1850e191ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-10b41ee3-0823-4d26-9902-d5af44c416a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-75cedcff-380c-4005-95c8-6510e9904347,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-36f4976c-f4cc-4414-98fc-b2ba3600883b,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-7e94a81c-8ac7-40ae-a956-3f08cfeb26ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662563634-172.17.0.17-1597203837645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45101,DS-ed730f61-d077-4051-9556-7df46d6612d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-8a1c05e8-7782-4309-8b65-625b87592640,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-65d39d24-0966-4da8-8847-26cebc5176bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-a51ddb60-46ec-4682-ab52-01e469a36bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-a5789f0a-00fa-4428-8f5f-aea34f0bc80a,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-d948033a-b90b-4cd8-84cf-d14fa441c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-8aafac59-a886-460c-a535-d345f9033bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-42c8c579-2e32-407d-a052-7a8039ad5c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662563634-172.17.0.17-1597203837645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45101,DS-ed730f61-d077-4051-9556-7df46d6612d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-8a1c05e8-7782-4309-8b65-625b87592640,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-65d39d24-0966-4da8-8847-26cebc5176bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-a51ddb60-46ec-4682-ab52-01e469a36bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-a5789f0a-00fa-4428-8f5f-aea34f0bc80a,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-d948033a-b90b-4cd8-84cf-d14fa441c5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-8aafac59-a886-460c-a535-d345f9033bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-42c8c579-2e32-407d-a052-7a8039ad5c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486934800-172.17.0.17-1597204169082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46468,DS-180c83a2-1027-4948-9ea8-81ceb6f5d2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-07d1d795-5553-4e34-b4c9-6b150cd3a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-f1b9cd98-afac-43f2-bd80-d9af809ef41d,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-8fe930bb-a9e4-4df4-a4a4-a458a026eb33,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-ddbf22b1-6810-410e-bc5e-9b0e74309421,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-a05b5391-31b2-4ed9-b61c-a6ad7b824e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-2b125c54-3ac2-4d29-a98f-8455bd6b4956,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-957ba481-4c36-426c-82d6-8de5e82b2218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486934800-172.17.0.17-1597204169082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46468,DS-180c83a2-1027-4948-9ea8-81ceb6f5d2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-07d1d795-5553-4e34-b4c9-6b150cd3a1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-f1b9cd98-afac-43f2-bd80-d9af809ef41d,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-8fe930bb-a9e4-4df4-a4a4-a458a026eb33,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-ddbf22b1-6810-410e-bc5e-9b0e74309421,DISK], DatanodeInfoWithStorage[127.0.0.1:43957,DS-a05b5391-31b2-4ed9-b61c-a6ad7b824e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-2b125c54-3ac2-4d29-a98f-8455bd6b4956,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-957ba481-4c36-426c-82d6-8de5e82b2218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626154666-172.17.0.17-1597205479853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38908,DS-aa69ac0c-1e8d-40d0-8f7b-a05c817badfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-ad48c7fd-95de-487f-a7d9-0c9a8f4df833,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-a6459201-58e8-4c1f-84a5-4f869518ddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-1a20beea-a39e-44c1-9294-057a0e7afbca,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-0e1df651-9f5e-423f-8e30-aaae8eda115c,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-663f0283-dbb8-4502-bd14-ec7966c86dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-1bbbcf70-a79b-4054-ba13-8ac2fe600964,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-da6deaf9-0c68-4e34-b3a5-214b56161f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626154666-172.17.0.17-1597205479853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38908,DS-aa69ac0c-1e8d-40d0-8f7b-a05c817badfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-ad48c7fd-95de-487f-a7d9-0c9a8f4df833,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-a6459201-58e8-4c1f-84a5-4f869518ddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-1a20beea-a39e-44c1-9294-057a0e7afbca,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-0e1df651-9f5e-423f-8e30-aaae8eda115c,DISK], DatanodeInfoWithStorage[127.0.0.1:43378,DS-663f0283-dbb8-4502-bd14-ec7966c86dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-1bbbcf70-a79b-4054-ba13-8ac2fe600964,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-da6deaf9-0c68-4e34-b3a5-214b56161f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145093970-172.17.0.17-1597205965892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-bdaa5b35-c690-46ad-997d-f5619cd0f000,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-2101af04-2433-41a2-a2ea-f70783a45226,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-62ee0ef3-632e-4d04-a432-5939ac07cebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-f653a047-f15b-4a54-82af-36631db03faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-42356cec-19cc-4401-b08c-baf99374869a,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-860e99e2-1d3d-4306-825c-e69ea213dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-9892a860-0fbc-45d8-86c2-f61ea97567f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-448c8332-98b1-452f-85b0-41e7c7944f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145093970-172.17.0.17-1597205965892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-bdaa5b35-c690-46ad-997d-f5619cd0f000,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-2101af04-2433-41a2-a2ea-f70783a45226,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-62ee0ef3-632e-4d04-a432-5939ac07cebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-f653a047-f15b-4a54-82af-36631db03faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-42356cec-19cc-4401-b08c-baf99374869a,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-860e99e2-1d3d-4306-825c-e69ea213dc21,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-9892a860-0fbc-45d8-86c2-f61ea97567f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-448c8332-98b1-452f-85b0-41e7c7944f3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.metrics.logger.period.seconds
component: hdfs:DataNode
v1: 600
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612619849-172.17.0.17-1597206318787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36505,DS-98f2c382-cd3f-4d60-b8ce-51c53582e8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-fd08b4da-3382-4b72-80cb-0904e0c98ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-4a3e931c-f948-4a9b-8245-1a15dae7305a,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-205b9209-7534-4a39-806d-794f3d3c0cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-54bbc0cc-f722-4ca0-81de-3634e4e46e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-397694c0-410e-4c13-a1b5-089054af986a,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-a697b99d-616a-4cba-b995-faa33107c958,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-f0e82c35-d1a5-475e-9c11-e14e31c42ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1612619849-172.17.0.17-1597206318787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36505,DS-98f2c382-cd3f-4d60-b8ce-51c53582e8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-fd08b4da-3382-4b72-80cb-0904e0c98ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-4a3e931c-f948-4a9b-8245-1a15dae7305a,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-205b9209-7534-4a39-806d-794f3d3c0cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-54bbc0cc-f722-4ca0-81de-3634e4e46e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-397694c0-410e-4c13-a1b5-089054af986a,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-a697b99d-616a-4cba-b995-faa33107c958,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-f0e82c35-d1a5-475e-9c11-e14e31c42ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6835
