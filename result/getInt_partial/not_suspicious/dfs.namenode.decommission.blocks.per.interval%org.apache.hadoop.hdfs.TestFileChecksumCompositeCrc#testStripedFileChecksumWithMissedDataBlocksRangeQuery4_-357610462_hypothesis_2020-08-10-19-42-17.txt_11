reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983572353-172.17.0.9-1597088854104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38529,DS-79dc7a53-5378-49a1-b015-fe64490044fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-9f128a2e-1ce2-40b1-91dd-7f122af4e033,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-0087477a-5cb6-49ad-aff0-e3fe19cff840,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-a5560975-56f6-4b83-9970-201da47c30df,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-800d3fea-7129-4a68-a67c-62df936e8925,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-ef4373d2-0f8f-41a7-9361-311542b52b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-0c232494-3f45-45d2-8766-047225da5445,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-8fbc1bb5-25dd-4395-9cd3-cc5fc7b2d9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983572353-172.17.0.9-1597088854104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38529,DS-79dc7a53-5378-49a1-b015-fe64490044fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-9f128a2e-1ce2-40b1-91dd-7f122af4e033,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-0087477a-5cb6-49ad-aff0-e3fe19cff840,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-a5560975-56f6-4b83-9970-201da47c30df,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-800d3fea-7129-4a68-a67c-62df936e8925,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-ef4373d2-0f8f-41a7-9361-311542b52b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-0c232494-3f45-45d2-8766-047225da5445,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-8fbc1bb5-25dd-4395-9cd3-cc5fc7b2d9c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618679897-172.17.0.9-1597088890388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-8abfe61f-3cf9-4610-a411-e05f1f484b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-ae5b7111-4b86-4e8a-9a00-2fa063a30278,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-62695865-8616-4e9f-a529-3c34c3e1e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-dad91282-a10f-427c-b922-2070ec742d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-4222b5aa-7cd7-4481-9bb9-c23cdfb74f93,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-40486429-1d59-4356-b1f4-d0fa0fae2610,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-c0b842b1-59fa-4c24-866b-cdee4e4923b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-5bb8b87b-1e60-4ffa-b3b7-3737f6c4992b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618679897-172.17.0.9-1597088890388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34378,DS-8abfe61f-3cf9-4610-a411-e05f1f484b83,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-ae5b7111-4b86-4e8a-9a00-2fa063a30278,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-62695865-8616-4e9f-a529-3c34c3e1e11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-dad91282-a10f-427c-b922-2070ec742d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-4222b5aa-7cd7-4481-9bb9-c23cdfb74f93,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-40486429-1d59-4356-b1f4-d0fa0fae2610,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-c0b842b1-59fa-4c24-866b-cdee4e4923b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-5bb8b87b-1e60-4ffa-b3b7-3737f6c4992b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758330469-172.17.0.9-1597089942174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45740,DS-0d6b621b-6bff-4aef-b41b-b075d3f18225,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-cd061c75-2afe-4b83-ac58-a78343d4214c,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-4599903a-488b-4d89-a6e0-103c5e9d2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-758bc28e-621c-4f9a-b047-6522b3e85539,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-7b9f65bc-9552-4f2c-a37b-57a40a0d81da,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-6340d3e3-c246-454b-99be-41c5c791838a,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-3a40dea5-5173-4520-b043-505246f1084f,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-d44f60c8-44f2-4f11-8813-2e6eabf97e70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758330469-172.17.0.9-1597089942174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45740,DS-0d6b621b-6bff-4aef-b41b-b075d3f18225,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-cd061c75-2afe-4b83-ac58-a78343d4214c,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-4599903a-488b-4d89-a6e0-103c5e9d2e23,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-758bc28e-621c-4f9a-b047-6522b3e85539,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-7b9f65bc-9552-4f2c-a37b-57a40a0d81da,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-6340d3e3-c246-454b-99be-41c5c791838a,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-3a40dea5-5173-4520-b043-505246f1084f,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-d44f60c8-44f2-4f11-8813-2e6eabf97e70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75704289-172.17.0.9-1597090007343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34186,DS-caf1b2f1-a522-439c-8988-024f094c568b,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-10b20c5b-17a0-403a-b0b3-d2be7e78168e,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-e0f1612b-6755-451d-9502-f1142a36d4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-f52c8ea7-7cd6-489f-a79b-bd70f41f64f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-f7ad4542-3c61-4203-8156-28247fa796fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-9905dea4-5726-41fa-9f94-5feafbb8017c,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-af50733b-2435-4ef4-94b6-92a870aaba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-593d1d69-2eba-4a95-8e7f-a2d8c2119db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75704289-172.17.0.9-1597090007343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34186,DS-caf1b2f1-a522-439c-8988-024f094c568b,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-10b20c5b-17a0-403a-b0b3-d2be7e78168e,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-e0f1612b-6755-451d-9502-f1142a36d4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-f52c8ea7-7cd6-489f-a79b-bd70f41f64f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-f7ad4542-3c61-4203-8156-28247fa796fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-9905dea4-5726-41fa-9f94-5feafbb8017c,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-af50733b-2435-4ef4-94b6-92a870aaba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-593d1d69-2eba-4a95-8e7f-a2d8c2119db4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203586263-172.17.0.9-1597090050700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38652,DS-7b96f44c-3904-46aa-bbfa-28ed02bea9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-2c43b5a6-5268-4b5f-bb4b-881346c0ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-13690d89-6a7e-41fb-b96d-6f24bcc8e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-1d4aeae1-4918-41da-ba75-c5a540dae8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-0aef776c-1f4a-421a-8611-e14dedb8990c,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-b5aed29a-1540-4b9c-8dc2-0768350be707,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-f3664e8a-2434-41a8-94b7-b85dc1b408ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-04e4b851-a38a-4139-9552-b54a9e12c166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203586263-172.17.0.9-1597090050700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38652,DS-7b96f44c-3904-46aa-bbfa-28ed02bea9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-2c43b5a6-5268-4b5f-bb4b-881346c0ae79,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-13690d89-6a7e-41fb-b96d-6f24bcc8e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-1d4aeae1-4918-41da-ba75-c5a540dae8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-0aef776c-1f4a-421a-8611-e14dedb8990c,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-b5aed29a-1540-4b9c-8dc2-0768350be707,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-f3664e8a-2434-41a8-94b7-b85dc1b408ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-04e4b851-a38a-4139-9552-b54a9e12c166,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654172571-172.17.0.9-1597090335940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-4ce59bde-1571-42bd-bea4-af60f1103a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-73a06d15-663b-4838-8a0e-31743c1b3261,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-cd09629c-e5cf-43fc-89d2-ba35771ca70f,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-85f8f2b9-902e-4e3d-89b2-bb74e702721e,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-a930f60d-861c-4178-a288-da3bf356c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-8dd435e6-fe1e-433f-9771-d852f5318be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-70ea22f4-413c-483a-ad7f-43160c74320c,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-ab34c35f-0778-4306-89a4-7cb6032e5d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654172571-172.17.0.9-1597090335940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45323,DS-4ce59bde-1571-42bd-bea4-af60f1103a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-73a06d15-663b-4838-8a0e-31743c1b3261,DISK], DatanodeInfoWithStorage[127.0.0.1:34738,DS-cd09629c-e5cf-43fc-89d2-ba35771ca70f,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-85f8f2b9-902e-4e3d-89b2-bb74e702721e,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-a930f60d-861c-4178-a288-da3bf356c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-8dd435e6-fe1e-433f-9771-d852f5318be5,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-70ea22f4-413c-483a-ad7f-43160c74320c,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-ab34c35f-0778-4306-89a4-7cb6032e5d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301807734-172.17.0.9-1597090514991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-36c5341d-682e-4aa8-ae02-caf1cff15690,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-cb065516-400e-438e-adc2-420416c73f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-7e2771e9-b41f-4d3e-87af-8a2f83b334aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-ae9af5ac-ebb8-41ce-b02a-ab5dc4f298dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-96400d1e-2731-4d3c-a502-8d1f8a74d7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-6a8cae65-509e-482d-b58f-8b4f0854b83e,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-3941c846-6857-496a-8791-154886808f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-7a30e08d-180a-4c42-b23e-ce58179956ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301807734-172.17.0.9-1597090514991:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46414,DS-36c5341d-682e-4aa8-ae02-caf1cff15690,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-cb065516-400e-438e-adc2-420416c73f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-7e2771e9-b41f-4d3e-87af-8a2f83b334aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-ae9af5ac-ebb8-41ce-b02a-ab5dc4f298dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-96400d1e-2731-4d3c-a502-8d1f8a74d7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-6a8cae65-509e-482d-b58f-8b4f0854b83e,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-3941c846-6857-496a-8791-154886808f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-7a30e08d-180a-4c42-b23e-ce58179956ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518319777-172.17.0.9-1597091186810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38177,DS-d0a234d7-6575-4496-915c-8de8e7a5794a,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-e103fc48-a0cd-4e41-b7ee-fa74d7df2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-e6450099-af37-4b0f-9df8-bd44ba0feac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-62b945d6-70d2-4478-8ec7-7b4e96cac0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-78b73749-c87f-4277-9681-9acc3d440ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-f4f3463c-c4a6-4623-b8c1-e698eff0da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-6271b2ae-5d0e-4cb0-a0a0-f9a7f1b40f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-60b5f5ce-0c61-4b05-8190-0d045fb7c086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518319777-172.17.0.9-1597091186810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38177,DS-d0a234d7-6575-4496-915c-8de8e7a5794a,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-e103fc48-a0cd-4e41-b7ee-fa74d7df2eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-e6450099-af37-4b0f-9df8-bd44ba0feac6,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-62b945d6-70d2-4478-8ec7-7b4e96cac0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-78b73749-c87f-4277-9681-9acc3d440ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-f4f3463c-c4a6-4623-b8c1-e698eff0da5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-6271b2ae-5d0e-4cb0-a0a0-f9a7f1b40f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-60b5f5ce-0c61-4b05-8190-0d045fb7c086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690824645-172.17.0.9-1597091931315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-33a81b54-8e78-4359-be1a-cc71d179232a,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-fa4a9b5f-5238-4722-b0c0-182c27d4c7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-315f12a4-3e52-4313-949b-58cc6a3824f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-dbe40e92-e537-4e13-acbc-d21d237ac178,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-24f8eb2f-96ce-4370-bc03-3b8e822756e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-bc64b84f-5200-457f-98eb-19e2d0c61190,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-9e35c518-6fa8-4577-9cea-dc19d572916e,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-be08baa1-f9e8-41df-9096-446dac662e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690824645-172.17.0.9-1597091931315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-33a81b54-8e78-4359-be1a-cc71d179232a,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-fa4a9b5f-5238-4722-b0c0-182c27d4c7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-315f12a4-3e52-4313-949b-58cc6a3824f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-dbe40e92-e537-4e13-acbc-d21d237ac178,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-24f8eb2f-96ce-4370-bc03-3b8e822756e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-bc64b84f-5200-457f-98eb-19e2d0c61190,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-9e35c518-6fa8-4577-9cea-dc19d572916e,DISK], DatanodeInfoWithStorage[127.0.0.1:40015,DS-be08baa1-f9e8-41df-9096-446dac662e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310794658-172.17.0.9-1597092227063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-517226da-da7e-4df4-819e-2eb90bfcc4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-335e4c16-1b67-4e97-ae53-61a713148fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-322ba350-752d-4575-940b-7d9a4c4344ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-86ae5271-e0a4-4bfe-92d2-9be5ed6b5612,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-a6c4918c-20dc-4b4d-8279-ab2742a2ddfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-e2ac1fe9-db25-4a2c-84c5-e00dde29f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-60941a4a-2eb5-4abf-986d-bab5a3a8aa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-e8bc3685-67d8-4a7e-8e4c-bf27217a709e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310794658-172.17.0.9-1597092227063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40437,DS-517226da-da7e-4df4-819e-2eb90bfcc4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-335e4c16-1b67-4e97-ae53-61a713148fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-322ba350-752d-4575-940b-7d9a4c4344ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-86ae5271-e0a4-4bfe-92d2-9be5ed6b5612,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-a6c4918c-20dc-4b4d-8279-ab2742a2ddfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-e2ac1fe9-db25-4a2c-84c5-e00dde29f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-60941a4a-2eb5-4abf-986d-bab5a3a8aa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-e8bc3685-67d8-4a7e-8e4c-bf27217a709e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166010945-172.17.0.9-1597092502064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33988,DS-6ac9260f-10ed-45b1-8168-cb63823d34cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-5c5dac05-78b3-49b1-998b-7eaffc7d4b78,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-cb36accc-066b-40ba-ba4f-a748d8ad25f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-2d5a5330-974a-428b-b50f-0c4a94a8760c,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-a0d63470-37c1-46c6-b9ac-bdcdec8d736e,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-4f6d6147-d660-41dc-b1ce-36fcc9264b47,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-eb88a44c-28c8-4759-bcbf-d10127da3fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-85fb56f7-ee9e-472a-b950-7089f7b288e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166010945-172.17.0.9-1597092502064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33988,DS-6ac9260f-10ed-45b1-8168-cb63823d34cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46267,DS-5c5dac05-78b3-49b1-998b-7eaffc7d4b78,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-cb36accc-066b-40ba-ba4f-a748d8ad25f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-2d5a5330-974a-428b-b50f-0c4a94a8760c,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-a0d63470-37c1-46c6-b9ac-bdcdec8d736e,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-4f6d6147-d660-41dc-b1ce-36fcc9264b47,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-eb88a44c-28c8-4759-bcbf-d10127da3fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-85fb56f7-ee9e-472a-b950-7089f7b288e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376896761-172.17.0.9-1597092566214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36958,DS-a8d3f5bc-4d62-4351-8f77-0ffd8759846c,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-b3f1d5bb-dec3-4ee8-b8d6-6d7ec2fd6e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-53d19128-6f1d-4a46-9f51-9411b160285e,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-7342739f-1613-4e88-bc38-e7318c5e8739,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-74e486ed-a993-4f64-97a2-0c76caf7d40c,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-31094843-ce2b-42ba-9720-7d723322f37b,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-16d3e1e6-2710-496f-a54e-d7235f633df2,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-4baeb39d-e2c2-4c40-a2a0-0a20de07f106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376896761-172.17.0.9-1597092566214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36958,DS-a8d3f5bc-4d62-4351-8f77-0ffd8759846c,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-b3f1d5bb-dec3-4ee8-b8d6-6d7ec2fd6e14,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-53d19128-6f1d-4a46-9f51-9411b160285e,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-7342739f-1613-4e88-bc38-e7318c5e8739,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-74e486ed-a993-4f64-97a2-0c76caf7d40c,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-31094843-ce2b-42ba-9720-7d723322f37b,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-16d3e1e6-2710-496f-a54e-d7235f633df2,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-4baeb39d-e2c2-4c40-a2a0-0a20de07f106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20631733-172.17.0.9-1597093068106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-ea2637ee-1b44-42c0-b1c7-5a159c2dbc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-25d58b07-4629-430a-bcbc-e10fc6fc96da,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-2e60674b-3b04-4db2-a1da-e8825848c00b,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-d191b1a3-9ff9-4a98-bde7-bc67b30de009,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-0d2bfb56-c69a-4146-a10a-e9323ccfb0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-3a2ae024-da50-4a1a-ada3-c45dd9601b33,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-6e0a5ad7-bace-4a6b-8210-8a876d5c62c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-9a45fdc2-974d-4e73-b87a-6a8898cfe145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20631733-172.17.0.9-1597093068106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-ea2637ee-1b44-42c0-b1c7-5a159c2dbc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-25d58b07-4629-430a-bcbc-e10fc6fc96da,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-2e60674b-3b04-4db2-a1da-e8825848c00b,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-d191b1a3-9ff9-4a98-bde7-bc67b30de009,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-0d2bfb56-c69a-4146-a10a-e9323ccfb0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-3a2ae024-da50-4a1a-ada3-c45dd9601b33,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-6e0a5ad7-bace-4a6b-8210-8a876d5c62c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-9a45fdc2-974d-4e73-b87a-6a8898cfe145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.blocks.per.interval
component: hdfs:NameNode
v1: 500000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771333685-172.17.0.9-1597093521049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43910,DS-42869ab7-3004-473d-930a-57d5ef730725,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-4937ba88-898a-451a-b55c-8108b9e60f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-21ff4263-95a9-4d6f-ae13-9b7bdf13af07,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-5ebc977e-00b1-4e10-89b7-080fb328e872,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-97577f53-ea06-4287-8397-e1c068088d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-12bb22de-27e7-461c-8520-d624fb83a74d,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-3ad11369-968e-47bd-a502-f150027f93bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-f3f77c07-30e4-4691-89cf-6757e590e65b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771333685-172.17.0.9-1597093521049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43910,DS-42869ab7-3004-473d-930a-57d5ef730725,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-4937ba88-898a-451a-b55c-8108b9e60f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-21ff4263-95a9-4d6f-ae13-9b7bdf13af07,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-5ebc977e-00b1-4e10-89b7-080fb328e872,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-97577f53-ea06-4287-8397-e1c068088d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-12bb22de-27e7-461c-8520-d624fb83a74d,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-3ad11369-968e-47bd-a502-f150027f93bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-f3f77c07-30e4-4691-89cf-6757e590e65b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5177
