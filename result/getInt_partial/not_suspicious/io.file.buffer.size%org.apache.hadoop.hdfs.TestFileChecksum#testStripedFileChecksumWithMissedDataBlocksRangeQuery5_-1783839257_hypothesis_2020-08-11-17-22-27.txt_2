reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822038343-172.17.0.6-1597166559955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35396,DS-db85bf00-a5b9-483b-a6bd-b6efa970e46b,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-684f8f9c-33c5-4154-8c47-6ed29ea1e6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-1226d298-eb8c-456c-91f0-55b1a5de38dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-e0ffb0ea-98d5-4c6f-9684-4fc339db441d,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-ef034552-fb71-4e64-926d-d7b3542d5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-bf427c99-c82e-41d7-84ea-138a0c1ad159,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-009e1c70-adb8-4520-8c90-393eb991e179,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-e86e643e-7833-4f1f-a7fe-658e8eefb772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822038343-172.17.0.6-1597166559955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35396,DS-db85bf00-a5b9-483b-a6bd-b6efa970e46b,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-684f8f9c-33c5-4154-8c47-6ed29ea1e6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-1226d298-eb8c-456c-91f0-55b1a5de38dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-e0ffb0ea-98d5-4c6f-9684-4fc339db441d,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-ef034552-fb71-4e64-926d-d7b3542d5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-bf427c99-c82e-41d7-84ea-138a0c1ad159,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-009e1c70-adb8-4520-8c90-393eb991e179,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-e86e643e-7833-4f1f-a7fe-658e8eefb772,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511678603-172.17.0.6-1597166598045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36928,DS-044a5c0b-17c7-4e73-92db-cc666db6aacb,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-ec335a24-060b-4363-b2a3-8dcac14208b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-f72c9f36-afd4-4975-9b5a-e20d78c1c90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-58d9d972-c3b9-4ee0-bc8f-f1e0b308f708,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-e8c7c5ec-17e5-4613-84de-dcf6bcef03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-a19f4d86-b09a-4652-b53b-951d7c8fee02,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-0284fea3-24cb-41c5-8259-e0fb7ace4e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-4fd0a388-4787-40d3-a761-b61d396d575d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511678603-172.17.0.6-1597166598045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36928,DS-044a5c0b-17c7-4e73-92db-cc666db6aacb,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-ec335a24-060b-4363-b2a3-8dcac14208b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-f72c9f36-afd4-4975-9b5a-e20d78c1c90d,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-58d9d972-c3b9-4ee0-bc8f-f1e0b308f708,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-e8c7c5ec-17e5-4613-84de-dcf6bcef03c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-a19f4d86-b09a-4652-b53b-951d7c8fee02,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-0284fea3-24cb-41c5-8259-e0fb7ace4e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39912,DS-4fd0a388-4787-40d3-a761-b61d396d575d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889562141-172.17.0.6-1597166638575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37415,DS-71c81c2b-662f-4f6e-875b-9540d8e6dc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-3f252fc9-563a-4907-a0aa-6d3936a0151b,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-a4b02b3b-3a47-4e52-8906-f814d4eca25e,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-d519df4c-e629-4f8b-89a8-ba716650a540,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-f656cea2-31c7-40a4-b11e-5e509e8bb02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-8b4c195d-3929-460b-a95e-a77cba38ed3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-714f737d-5069-4856-8476-c13e40be22a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-d4af12f2-b273-4efe-b1cc-9122f55d12b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889562141-172.17.0.6-1597166638575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37415,DS-71c81c2b-662f-4f6e-875b-9540d8e6dc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-3f252fc9-563a-4907-a0aa-6d3936a0151b,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-a4b02b3b-3a47-4e52-8906-f814d4eca25e,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-d519df4c-e629-4f8b-89a8-ba716650a540,DISK], DatanodeInfoWithStorage[127.0.0.1:43229,DS-f656cea2-31c7-40a4-b11e-5e509e8bb02a,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-8b4c195d-3929-460b-a95e-a77cba38ed3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-714f737d-5069-4856-8476-c13e40be22a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-d4af12f2-b273-4efe-b1cc-9122f55d12b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991713487-172.17.0.6-1597166714773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38167,DS-82cea187-35a5-47c1-8c4f-59f22187fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-898a8012-a116-4ad0-b52f-665124b12a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-5442f767-1bc6-44de-9382-c6d8374fc342,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-3b856c9e-a0bb-4161-a416-793945c09ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-8192745a-c92f-483c-b06c-4462c1f6ee59,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-3d9f833e-f05f-4647-a3f2-fe4dd8401790,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-74380038-fdc2-4c72-bd0d-a703dcf22f42,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-23bde08d-840d-4470-b311-5cf50aa7ae64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991713487-172.17.0.6-1597166714773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38167,DS-82cea187-35a5-47c1-8c4f-59f22187fe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-898a8012-a116-4ad0-b52f-665124b12a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-5442f767-1bc6-44de-9382-c6d8374fc342,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-3b856c9e-a0bb-4161-a416-793945c09ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-8192745a-c92f-483c-b06c-4462c1f6ee59,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-3d9f833e-f05f-4647-a3f2-fe4dd8401790,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-74380038-fdc2-4c72-bd0d-a703dcf22f42,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-23bde08d-840d-4470-b311-5cf50aa7ae64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277409381-172.17.0.6-1597166745220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-aca8b240-6edb-4aa4-839b-61003066f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-5b062c4a-d1a0-4c4c-8ca0-e70557fff4be,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-7bdaa914-4906-4768-a54c-0918dd276ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-a109b5f6-4065-48cd-aebb-53c56c66ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-65520fdb-dea6-43ce-98ff-f749e5f18a47,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-a3fcbf5a-6dc3-49da-938d-41478596efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-443ead38-c055-4b37-9e5f-851b8673429b,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-087f3dd9-5d63-4f8b-a18f-8ebe734b019e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277409381-172.17.0.6-1597166745220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-aca8b240-6edb-4aa4-839b-61003066f88f,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-5b062c4a-d1a0-4c4c-8ca0-e70557fff4be,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-7bdaa914-4906-4768-a54c-0918dd276ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-a109b5f6-4065-48cd-aebb-53c56c66ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-65520fdb-dea6-43ce-98ff-f749e5f18a47,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-a3fcbf5a-6dc3-49da-938d-41478596efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-443ead38-c055-4b37-9e5f-851b8673429b,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-087f3dd9-5d63-4f8b-a18f-8ebe734b019e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237034533-172.17.0.6-1597166783637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-ed12a8a9-d249-4b6c-86b3-bc84f332b782,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-49a96f86-8b89-44f8-9f35-d912e104e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-58c624ab-2221-4b02-926e-50f2aae11a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-39ca3098-74e5-4d61-b3fb-f6e02dd5f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-af4d4aae-02a9-49d7-83cc-d68c7b0562ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-0fe9614a-905a-43e2-bb4c-5dac939bf3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-8a5f1cf6-8ab2-4133-a714-9b858266df65,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-de8cc4be-2704-4c27-bf51-d4abcea7e7f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237034533-172.17.0.6-1597166783637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-ed12a8a9-d249-4b6c-86b3-bc84f332b782,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-49a96f86-8b89-44f8-9f35-d912e104e17a,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-58c624ab-2221-4b02-926e-50f2aae11a78,DISK], DatanodeInfoWithStorage[127.0.0.1:45894,DS-39ca3098-74e5-4d61-b3fb-f6e02dd5f42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-af4d4aae-02a9-49d7-83cc-d68c7b0562ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-0fe9614a-905a-43e2-bb4c-5dac939bf3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-8a5f1cf6-8ab2-4133-a714-9b858266df65,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-de8cc4be-2704-4c27-bf51-d4abcea7e7f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958696968-172.17.0.6-1597166886533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41743,DS-7c6f5d04-0d60-42ac-8972-725f33b9bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-0881ec59-bee5-4d45-85a4-fccbda78f680,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-667ec608-bff5-48f2-89cc-ce256fa58c27,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-7816fd7e-7bdd-435e-893e-0bb1ded71e78,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-27d9a094-ec07-4334-953e-6fca62c569fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-4cef5d6a-6795-43ba-b605-5406c4e8d9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-3fa3cdca-1e53-48ad-b062-cb6428cd0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-d36b56c3-c294-435c-a4d7-840c6fcd757f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958696968-172.17.0.6-1597166886533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41743,DS-7c6f5d04-0d60-42ac-8972-725f33b9bb54,DISK], DatanodeInfoWithStorage[127.0.0.1:34890,DS-0881ec59-bee5-4d45-85a4-fccbda78f680,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-667ec608-bff5-48f2-89cc-ce256fa58c27,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-7816fd7e-7bdd-435e-893e-0bb1ded71e78,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-27d9a094-ec07-4334-953e-6fca62c569fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-4cef5d6a-6795-43ba-b605-5406c4e8d9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-3fa3cdca-1e53-48ad-b062-cb6428cd0a98,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-d36b56c3-c294-435c-a4d7-840c6fcd757f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948267914-172.17.0.6-1597167042818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-0d3d37a4-2775-4153-a3e7-3805aeead0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-c3a9466d-b198-4ca8-b1ef-6cbc787e4044,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-fe47a94a-2f2d-4fba-8731-60baf7f7eae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-5afda9a9-97f5-41e1-b475-f9cea8dc11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-e51ced61-372b-419d-bfed-1264f68d39c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-dd464a45-ee47-4159-a6da-f150dea2ae45,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-c2d80e67-f984-4705-9729-f8f6f26f3afc,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-51e41393-9da2-418c-b401-aa97a69ada11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948267914-172.17.0.6-1597167042818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34593,DS-0d3d37a4-2775-4153-a3e7-3805aeead0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-c3a9466d-b198-4ca8-b1ef-6cbc787e4044,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-fe47a94a-2f2d-4fba-8731-60baf7f7eae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-5afda9a9-97f5-41e1-b475-f9cea8dc11c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-e51ced61-372b-419d-bfed-1264f68d39c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-dd464a45-ee47-4159-a6da-f150dea2ae45,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-c2d80e67-f984-4705-9729-f8f6f26f3afc,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-51e41393-9da2-418c-b401-aa97a69ada11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920214394-172.17.0.6-1597167476069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35272,DS-a184fc64-ece7-4ab0-80cd-bedccc39d579,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-f738cba9-2fe1-4b92-a692-b0955d977efe,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-6c94ec4d-c9bd-479b-aff8-cb18fd6aadfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-82ab7ec4-a043-4bfa-8c81-cb507b79cd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-82c9a74b-f523-4435-ab7a-a4eb525c90eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-f872a23f-f6a4-4fe7-a526-98ee7bcfad03,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-584232af-9275-462f-8322-8a88e08ddbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-2e0bfa47-1fa4-4e11-8cd5-0ca7c883f52e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920214394-172.17.0.6-1597167476069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35272,DS-a184fc64-ece7-4ab0-80cd-bedccc39d579,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-f738cba9-2fe1-4b92-a692-b0955d977efe,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-6c94ec4d-c9bd-479b-aff8-cb18fd6aadfb,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-82ab7ec4-a043-4bfa-8c81-cb507b79cd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-82c9a74b-f523-4435-ab7a-a4eb525c90eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-f872a23f-f6a4-4fe7-a526-98ee7bcfad03,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-584232af-9275-462f-8322-8a88e08ddbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-2e0bfa47-1fa4-4e11-8cd5-0ca7c883f52e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80359352-172.17.0.6-1597168131601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-4662302b-138a-4e25-9608-3f5bb27ddea7,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-6f2736a0-f383-4a03-9753-8d639bc250a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-aac2fa3b-4db8-40c9-b29c-a1f892cb95a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-836debe5-614c-4703-aec4-02dc15982f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-64fda1e6-0964-46f6-9e36-4e39a5c3c381,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-997a5637-93f3-4dc2-99f1-609f7984ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-b4aa149e-25a9-4ec5-aaba-2ad7d2afb95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-c8ef414d-4619-4269-951f-f338e4afb4c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80359352-172.17.0.6-1597168131601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-4662302b-138a-4e25-9608-3f5bb27ddea7,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-6f2736a0-f383-4a03-9753-8d639bc250a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-aac2fa3b-4db8-40c9-b29c-a1f892cb95a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-836debe5-614c-4703-aec4-02dc15982f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-64fda1e6-0964-46f6-9e36-4e39a5c3c381,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-997a5637-93f3-4dc2-99f1-609f7984ff30,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-b4aa149e-25a9-4ec5-aaba-2ad7d2afb95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-c8ef414d-4619-4269-951f-f338e4afb4c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529711722-172.17.0.6-1597168249344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40094,DS-2529336e-d137-4523-bd34-ebaae385a306,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-c903fa13-ec48-4046-a657-8b601e8796c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-7d4cb31d-1dbe-40ce-9779-e32901530e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-7617dcf1-404b-472b-b88c-05398762af0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-e14e5952-03ee-4d7b-a9c6-6653d8cba816,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-74bda7f3-4ea4-40e6-acbb-2a47bd029cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-b49bce54-fa1a-4545-91d1-c2d233a3db59,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-0238c4c8-8346-4578-97c0-a86f44b932a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529711722-172.17.0.6-1597168249344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40094,DS-2529336e-d137-4523-bd34-ebaae385a306,DISK], DatanodeInfoWithStorage[127.0.0.1:46856,DS-c903fa13-ec48-4046-a657-8b601e8796c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-7d4cb31d-1dbe-40ce-9779-e32901530e85,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-7617dcf1-404b-472b-b88c-05398762af0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-e14e5952-03ee-4d7b-a9c6-6653d8cba816,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-74bda7f3-4ea4-40e6-acbb-2a47bd029cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-b49bce54-fa1a-4545-91d1-c2d233a3db59,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-0238c4c8-8346-4578-97c0-a86f44b932a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629984890-172.17.0.6-1597168396073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-2818929e-8baf-40af-92e6-497045232779,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-5e38acd9-277f-498e-a24b-6716f144bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-35b97064-7d95-4ca5-b0f2-64004b1f2c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-1a64c0d6-d3fc-41b9-986f-37e4cad86aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-25cf67cc-d01d-40bd-b6a4-ff8556cebc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-075ec965-50f4-45a5-a211-2c1b0c7bfc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b7976299-dc28-4cb1-b537-9acf9cdc97d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-945729a3-b582-4aee-8877-8a008b540a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-629984890-172.17.0.6-1597168396073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-2818929e-8baf-40af-92e6-497045232779,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-5e38acd9-277f-498e-a24b-6716f144bc71,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-35b97064-7d95-4ca5-b0f2-64004b1f2c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-1a64c0d6-d3fc-41b9-986f-37e4cad86aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-25cf67cc-d01d-40bd-b6a4-ff8556cebc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-075ec965-50f4-45a5-a211-2c1b0c7bfc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-b7976299-dc28-4cb1-b537-9acf9cdc97d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-945729a3-b582-4aee-8877-8a008b540a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184050929-172.17.0.6-1597168505972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-20758a8f-539c-46e1-9ec8-d89a3492f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-4f495ec5-a483-46bf-9295-a5b283bedea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-89f03834-ea83-40b4-ba22-78cdbdf0ed70,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-108fab72-cceb-4fd4-bf50-55983d6baaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-c982028a-0e5e-4681-ab5e-04481f1c9741,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-a6cf2827-9327-4740-b6eb-58cbb0436902,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-ad9b5698-91b7-4b31-bdd1-5842b93c9c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-e119791e-1d13-47e1-a749-752514101219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-184050929-172.17.0.6-1597168505972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41387,DS-20758a8f-539c-46e1-9ec8-d89a3492f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-4f495ec5-a483-46bf-9295-a5b283bedea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-89f03834-ea83-40b4-ba22-78cdbdf0ed70,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-108fab72-cceb-4fd4-bf50-55983d6baaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-c982028a-0e5e-4681-ab5e-04481f1c9741,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-a6cf2827-9327-4740-b6eb-58cbb0436902,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-ad9b5698-91b7-4b31-bdd1-5842b93c9c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-e119791e-1d13-47e1-a749-752514101219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142980699-172.17.0.6-1597168758657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33915,DS-6a4b5b8e-5087-471b-a1c3-3d13c2a9d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-01b44b35-012a-4688-8642-0564454c46b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-8ca60a8c-af28-4c28-98ae-434f69ed7a92,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-527561bc-34ba-4e68-9351-d3a778f209b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-8a6f9196-ae34-43b5-877f-1f7834525a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-782fea74-04af-444c-a94f-62796c2e28d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-2e9348c8-7de8-43e0-8eed-2fa2328ddaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-b977c94c-a2a0-4127-ba20-4f66b2666b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142980699-172.17.0.6-1597168758657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33915,DS-6a4b5b8e-5087-471b-a1c3-3d13c2a9d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-01b44b35-012a-4688-8642-0564454c46b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-8ca60a8c-af28-4c28-98ae-434f69ed7a92,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-527561bc-34ba-4e68-9351-d3a778f209b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-8a6f9196-ae34-43b5-877f-1f7834525a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-782fea74-04af-444c-a94f-62796c2e28d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-2e9348c8-7de8-43e0-8eed-2fa2328ddaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36793,DS-b977c94c-a2a0-4127-ba20-4f66b2666b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692476361-172.17.0.6-1597169287018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44514,DS-40dd3224-df41-4945-91ff-900c6e3be14e,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-18ad4395-2a22-4721-aba7-89c7bfc13052,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-0de46f96-42bf-4ba2-aae6-b11c9f5377b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-00fb1536-d32f-4884-8cf0-03575d69b614,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-b7a3af54-d4f9-4d74-b456-960f9a4a12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-07164626-26f9-446d-8561-fb7d02beaeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-875f79d9-cde1-4b12-82da-7315aa430e93,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-0668921b-b757-4738-b62c-8aa5177b68ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692476361-172.17.0.6-1597169287018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44514,DS-40dd3224-df41-4945-91ff-900c6e3be14e,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-18ad4395-2a22-4721-aba7-89c7bfc13052,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-0de46f96-42bf-4ba2-aae6-b11c9f5377b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33114,DS-00fb1536-d32f-4884-8cf0-03575d69b614,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-b7a3af54-d4f9-4d74-b456-960f9a4a12b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45979,DS-07164626-26f9-446d-8561-fb7d02beaeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-875f79d9-cde1-4b12-82da-7315aa430e93,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-0668921b-b757-4738-b62c-8aa5177b68ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929831157-172.17.0.6-1597169905361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40037,DS-b451b5cb-e729-41f8-9874-170873b3c51d,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b90ff850-5fac-4272-a765-48128f5e63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-43110c0c-a6a2-45a3-9b9e-83561cbab99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-7a677513-59e5-429c-a5f9-a8f8257249f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-7fe5e156-8567-41c6-b968-9d9c26d6f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-ca8f8582-39a9-4a6f-8b88-9eb02922b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-693da9c4-3cf8-4c5a-abaf-90a55b9634a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-d4ac3ffc-698d-4ea2-a19b-0a239c24dbaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929831157-172.17.0.6-1597169905361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40037,DS-b451b5cb-e729-41f8-9874-170873b3c51d,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b90ff850-5fac-4272-a765-48128f5e63c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-43110c0c-a6a2-45a3-9b9e-83561cbab99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-7a677513-59e5-429c-a5f9-a8f8257249f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-7fe5e156-8567-41c6-b968-9d9c26d6f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-ca8f8582-39a9-4a6f-8b88-9eb02922b02d,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-693da9c4-3cf8-4c5a-abaf-90a55b9634a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-d4ac3ffc-698d-4ea2-a19b-0a239c24dbaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181622636-172.17.0.6-1597170170825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-bc23e9ca-fe39-4c45-b4f4-a7385dea1435,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-6e79c0e0-6067-4d9d-a2bf-832c413da882,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-27bf3c8d-f4c4-4377-af05-73faf6a0159e,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-bfadfcdf-febb-4b2c-b650-e4a733c035a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-96aa7a39-43f3-4927-8bad-0c1b4257946e,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-01ed9e06-8bb2-4eb9-8087-e2f8a2b13a31,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-734611b3-9704-414d-b539-a59f13d50fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-d8cab8da-69e8-4ec2-9781-8bf7d08f13d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181622636-172.17.0.6-1597170170825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38975,DS-bc23e9ca-fe39-4c45-b4f4-a7385dea1435,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-6e79c0e0-6067-4d9d-a2bf-832c413da882,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-27bf3c8d-f4c4-4377-af05-73faf6a0159e,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-bfadfcdf-febb-4b2c-b650-e4a733c035a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-96aa7a39-43f3-4927-8bad-0c1b4257946e,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-01ed9e06-8bb2-4eb9-8087-e2f8a2b13a31,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-734611b3-9704-414d-b539-a59f13d50fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-d8cab8da-69e8-4ec2-9781-8bf7d08f13d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584305409-172.17.0.6-1597170326596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45797,DS-80e47cb6-cc07-4fe2-b847-fd283f6cc3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-4704a9a7-2286-40b9-a492-e1ee8d597c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-34a298b9-52aa-4849-bd76-9b7f5d33b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-f5aaf230-33d1-47fa-8d4c-4c7a518e3dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-b464e75d-e9aa-4a75-8935-cc022cfd4aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-31560353-e86d-4ffa-afec-0f7f0b54c6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-8a85958f-7ea6-48e9-942b-9a4e9e54fc27,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-8c2a42bd-7b3a-486f-8bf9-b5565669ccf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584305409-172.17.0.6-1597170326596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45797,DS-80e47cb6-cc07-4fe2-b847-fd283f6cc3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-4704a9a7-2286-40b9-a492-e1ee8d597c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-34a298b9-52aa-4849-bd76-9b7f5d33b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-f5aaf230-33d1-47fa-8d4c-4c7a518e3dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-b464e75d-e9aa-4a75-8935-cc022cfd4aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-31560353-e86d-4ffa-afec-0f7f0b54c6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-8a85958f-7ea6-48e9-942b-9a4e9e54fc27,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-8c2a42bd-7b3a-486f-8bf9-b5565669ccf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370446588-172.17.0.6-1597170651297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39919,DS-44e7f1e0-5b35-45f0-b2b6-610f26a38e64,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-b03567b7-f6a0-431c-9300-b4c7b5abcc08,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-e9e3187a-eb6b-40a6-b878-f03528d88c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-93cfbe31-38b4-4049-8d4c-00fca89aef85,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-de7712b7-5b54-45e1-81dd-58ed6161313b,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-d948dc18-f326-4f6b-b785-0a83e461e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-55bd1b69-e3ee-4db2-a14a-d1c7cdcab044,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-03c459d1-1d2a-4676-9456-815f3785aede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370446588-172.17.0.6-1597170651297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39919,DS-44e7f1e0-5b35-45f0-b2b6-610f26a38e64,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-b03567b7-f6a0-431c-9300-b4c7b5abcc08,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-e9e3187a-eb6b-40a6-b878-f03528d88c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-93cfbe31-38b4-4049-8d4c-00fca89aef85,DISK], DatanodeInfoWithStorage[127.0.0.1:46427,DS-de7712b7-5b54-45e1-81dd-58ed6161313b,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-d948dc18-f326-4f6b-b785-0a83e461e4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-55bd1b69-e3ee-4db2-a14a-d1c7cdcab044,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-03c459d1-1d2a-4676-9456-815f3785aede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441635949-172.17.0.6-1597170995879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37828,DS-bc52339c-27b4-4de4-a46e-d1e234475c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-a26e9b75-acdb-43f4-9595-93ad26767c04,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-37ee0a84-8954-4252-b9df-702c2f533d23,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-f23772dc-4297-4a09-a6a9-9fea0ac5ec46,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-305d0d2b-9f74-4e34-84f8-fd40dbf60892,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-a727c9ba-524e-4fab-941a-01fdd5dc4825,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-5000b20d-30b9-471d-b633-8cbcb7e4e8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-91847eba-5c94-4044-b1a5-702460a34637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1441635949-172.17.0.6-1597170995879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37828,DS-bc52339c-27b4-4de4-a46e-d1e234475c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-a26e9b75-acdb-43f4-9595-93ad26767c04,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-37ee0a84-8954-4252-b9df-702c2f533d23,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-f23772dc-4297-4a09-a6a9-9fea0ac5ec46,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-305d0d2b-9f74-4e34-84f8-fd40dbf60892,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-a727c9ba-524e-4fab-941a-01fdd5dc4825,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-5000b20d-30b9-471d-b633-8cbcb7e4e8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-91847eba-5c94-4044-b1a5-702460a34637,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789508047-172.17.0.6-1597171150143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41620,DS-fbb09bfc-34d7-4a26-9741-7d4def310c46,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-cd1ab754-588c-4583-82ff-3360bba98d91,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-f978af5b-1424-4646-acef-39b541b8d018,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-e201ed4f-9333-4930-8ab0-ac29be4b5377,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-29f33597-5448-46ac-8875-a14ca36d5d19,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-b92723c3-b68a-41ff-a0c2-29229f6aea97,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-18d41073-8f25-47e1-af9f-8cc9007603b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-c651aec4-bb3b-44fa-9ed7-03fb18450a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1789508047-172.17.0.6-1597171150143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41620,DS-fbb09bfc-34d7-4a26-9741-7d4def310c46,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-cd1ab754-588c-4583-82ff-3360bba98d91,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-f978af5b-1424-4646-acef-39b541b8d018,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-e201ed4f-9333-4930-8ab0-ac29be4b5377,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-29f33597-5448-46ac-8875-a14ca36d5d19,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-b92723c3-b68a-41ff-a0c2-29229f6aea97,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-18d41073-8f25-47e1-af9f-8cc9007603b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-c651aec4-bb3b-44fa-9ed7-03fb18450a70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999694312-172.17.0.6-1597171337837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-30cd3a9c-f4bf-43d8-8242-9d0e5bc0e1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-c290527c-6828-49d7-a9dc-ee3b9b4e637a,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-3ee52a0a-b75a-4678-a12d-a34de33298a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-ed592efd-a891-4fbf-84d4-ede947a3ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-35f650a1-f09b-4c32-8b53-5c08e5db4bab,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-404d9b93-686e-41db-acfb-833a7e9f47fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-729ed907-f158-46e9-8569-785efc07da60,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-c5f87aa6-f314-4a72-abd8-fb87b22dd141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999694312-172.17.0.6-1597171337837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40163,DS-30cd3a9c-f4bf-43d8-8242-9d0e5bc0e1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-c290527c-6828-49d7-a9dc-ee3b9b4e637a,DISK], DatanodeInfoWithStorage[127.0.0.1:33111,DS-3ee52a0a-b75a-4678-a12d-a34de33298a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-ed592efd-a891-4fbf-84d4-ede947a3ac3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-35f650a1-f09b-4c32-8b53-5c08e5db4bab,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-404d9b93-686e-41db-acfb-833a7e9f47fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-729ed907-f158-46e9-8569-785efc07da60,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-c5f87aa6-f314-4a72-abd8-fb87b22dd141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993070760-172.17.0.6-1597171370949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-8e59038a-dd16-454c-a9dd-8bec43c50c28,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-122ec654-29db-4636-8074-609a7a45159a,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-a1a4a095-aebe-4714-8e10-9d7eedb4ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-e9ff7c10-739b-4958-9870-7388fb15959d,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-7097196a-e6d6-4ff7-8b6d-a77ccfefa268,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-ee614a07-00e6-4220-8ce4-19cad881cc94,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-626a21a3-05b7-4caf-8daf-08b652197990,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-292a1c09-914f-42ab-a889-e5622e2c20e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993070760-172.17.0.6-1597171370949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-8e59038a-dd16-454c-a9dd-8bec43c50c28,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-122ec654-29db-4636-8074-609a7a45159a,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-a1a4a095-aebe-4714-8e10-9d7eedb4ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-e9ff7c10-739b-4958-9870-7388fb15959d,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-7097196a-e6d6-4ff7-8b6d-a77ccfefa268,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-ee614a07-00e6-4220-8ce4-19cad881cc94,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-626a21a3-05b7-4caf-8daf-08b652197990,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-292a1c09-914f-42ab-a889-e5622e2c20e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129129619-172.17.0.6-1597171626587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35747,DS-df3f3380-cfb2-4142-8199-c01fe0b1eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-9baeba16-a237-49f5-9c6b-de779ea2b274,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-ab2d0a08-2fe2-4d35-83a5-1c0e2821ebe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-0a85332b-f52c-4cb9-b8ad-a3ae209cf8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-66fe943e-f2ed-4385-8fa4-77f3b77d3a22,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-8ac11974-e1ec-48b1-9f54-6db5992f261b,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-8122334d-bdd7-413b-a480-fcf443d565bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-a9ee46bf-2883-4dac-87cd-6bc3da5c149d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129129619-172.17.0.6-1597171626587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35747,DS-df3f3380-cfb2-4142-8199-c01fe0b1eef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-9baeba16-a237-49f5-9c6b-de779ea2b274,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-ab2d0a08-2fe2-4d35-83a5-1c0e2821ebe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-0a85332b-f52c-4cb9-b8ad-a3ae209cf8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-66fe943e-f2ed-4385-8fa4-77f3b77d3a22,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-8ac11974-e1ec-48b1-9f54-6db5992f261b,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-8122334d-bdd7-413b-a480-fcf443d565bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-a9ee46bf-2883-4dac-87cd-6bc3da5c149d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5616
