reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509406077-172.17.0.11-1597187857346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-c0e36542-798f-406c-9fec-554c01253ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-2c6feb0f-eabd-4b23-aee1-27653ff8a47c,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-30ad0c3d-21a4-4c38-9402-cd4f4888f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-e972e243-13ea-4cad-a925-ddf0cea83248,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-091f34c1-007f-4404-a7fb-3ab747ceb2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-5e6c84cc-1e9c-45d6-aec7-123b08eaf070,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-4a159e0f-59bd-4cec-9aba-3ec442260493,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-7982de24-95ae-496b-aae9-b1e1867872b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509406077-172.17.0.11-1597187857346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45496,DS-c0e36542-798f-406c-9fec-554c01253ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-2c6feb0f-eabd-4b23-aee1-27653ff8a47c,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-30ad0c3d-21a4-4c38-9402-cd4f4888f6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-e972e243-13ea-4cad-a925-ddf0cea83248,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-091f34c1-007f-4404-a7fb-3ab747ceb2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-5e6c84cc-1e9c-45d6-aec7-123b08eaf070,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-4a159e0f-59bd-4cec-9aba-3ec442260493,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-7982de24-95ae-496b-aae9-b1e1867872b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627278060-172.17.0.11-1597187969731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-dd689bda-9a04-4fdf-a21c-28ce991f9826,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-0d0a7a17-f237-42a4-a056-4b6adbffb874,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-7ade0564-a399-4957-abbc-0e21b8e82ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-2ee01250-584c-471a-b9f1-0e85444c2965,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-7a889e27-0d50-46b5-b3e4-860cd605200c,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-abd1701a-9a76-4827-b4c4-b1949ba4463c,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-798ef014-e1ab-40b4-96aa-25931e8d522e,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-b2c00e52-0345-48e7-b860-79fd77ca2487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627278060-172.17.0.11-1597187969731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-dd689bda-9a04-4fdf-a21c-28ce991f9826,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-0d0a7a17-f237-42a4-a056-4b6adbffb874,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-7ade0564-a399-4957-abbc-0e21b8e82ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-2ee01250-584c-471a-b9f1-0e85444c2965,DISK], DatanodeInfoWithStorage[127.0.0.1:41107,DS-7a889e27-0d50-46b5-b3e4-860cd605200c,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-abd1701a-9a76-4827-b4c4-b1949ba4463c,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-798ef014-e1ab-40b4-96aa-25931e8d522e,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-b2c00e52-0345-48e7-b860-79fd77ca2487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603493126-172.17.0.11-1597188075290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46510,DS-092dd620-37a3-489b-aa50-72ab64eee4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-b037ee28-af91-4b48-86b9-b850a86c8a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-c941c6c5-dfb0-4ef9-9abc-24037486fde3,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-e38410a1-1d75-4e22-85f4-c102a9477e74,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-35974339-3a0f-4105-bb53-0e49e014c345,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-9fbaa334-64d1-484c-b0b3-9f34566393a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-09e5dd7b-bb30-4718-a1dd-56ea1f44d63c,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-cd53ec50-fa7d-4cea-8ab0-8cb924f1a85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1603493126-172.17.0.11-1597188075290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46510,DS-092dd620-37a3-489b-aa50-72ab64eee4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-b037ee28-af91-4b48-86b9-b850a86c8a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-c941c6c5-dfb0-4ef9-9abc-24037486fde3,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-e38410a1-1d75-4e22-85f4-c102a9477e74,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-35974339-3a0f-4105-bb53-0e49e014c345,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-9fbaa334-64d1-484c-b0b3-9f34566393a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-09e5dd7b-bb30-4718-a1dd-56ea1f44d63c,DISK], DatanodeInfoWithStorage[127.0.0.1:37695,DS-cd53ec50-fa7d-4cea-8ab0-8cb924f1a85a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22610632-172.17.0.11-1597188115002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42642,DS-b46d74a8-6b05-47b0-a9e3-0a28bafd5e76,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-596a016f-f75b-4e9b-9a6c-5ec4db5fdcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-5d9ea958-e2ac-4c63-afbd-e491bddd5ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-355a2c43-071b-4502-98c6-961d0e8abfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-f0356cdc-5858-4870-a17b-e7caf0074ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-0bf7e5ea-3aab-4937-87c5-0742c9e16f43,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-730361c5-a496-412b-8e69-c0b02d5a75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-9a73f298-84a2-48ce-a4f3-4eed76711c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22610632-172.17.0.11-1597188115002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42642,DS-b46d74a8-6b05-47b0-a9e3-0a28bafd5e76,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-596a016f-f75b-4e9b-9a6c-5ec4db5fdcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-5d9ea958-e2ac-4c63-afbd-e491bddd5ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-355a2c43-071b-4502-98c6-961d0e8abfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-f0356cdc-5858-4870-a17b-e7caf0074ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-0bf7e5ea-3aab-4937-87c5-0742c9e16f43,DISK], DatanodeInfoWithStorage[127.0.0.1:40923,DS-730361c5-a496-412b-8e69-c0b02d5a75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-9a73f298-84a2-48ce-a4f3-4eed76711c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110906676-172.17.0.11-1597188160098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40591,DS-cefd961f-d097-4da8-8b08-28b2496ea970,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-3035e293-d240-48f2-800b-019c27e04419,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-b181eb06-5f22-4003-9d26-c639a3884fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-434fecc0-42b4-4025-b569-120a2ab492e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-41632487-b0cc-455f-bb7f-bdd7860d4644,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-02ba828a-9a46-4c1b-b0f2-2e0ca7b6cd70,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-35c7795c-9165-4f92-b7f6-717bf6785b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-84fc8af3-3919-4815-8a65-a20efe4fb422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110906676-172.17.0.11-1597188160098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40591,DS-cefd961f-d097-4da8-8b08-28b2496ea970,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-3035e293-d240-48f2-800b-019c27e04419,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-b181eb06-5f22-4003-9d26-c639a3884fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-434fecc0-42b4-4025-b569-120a2ab492e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-41632487-b0cc-455f-bb7f-bdd7860d4644,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-02ba828a-9a46-4c1b-b0f2-2e0ca7b6cd70,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-35c7795c-9165-4f92-b7f6-717bf6785b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-84fc8af3-3919-4815-8a65-a20efe4fb422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777433778-172.17.0.11-1597188385216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44695,DS-2e46968f-d536-46b9-a5c9-1c09fc4ee0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-39c4fb08-0302-491c-aae2-f2cce504dd03,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-0e5cbb19-2516-4dee-85ff-8239aa396b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-bd6a7e8e-8e82-4415-954e-d78bc318daca,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-a454dab3-21a2-43bb-adf6-64212f4c8b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-774c0a78-e6b0-42c5-8b0e-3de5f9a3ce51,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-292fa1d5-acac-4c57-8d22-4b0bf9b2733e,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-c49eda44-bfd3-473b-adb0-28358d7790c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777433778-172.17.0.11-1597188385216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44695,DS-2e46968f-d536-46b9-a5c9-1c09fc4ee0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-39c4fb08-0302-491c-aae2-f2cce504dd03,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-0e5cbb19-2516-4dee-85ff-8239aa396b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-bd6a7e8e-8e82-4415-954e-d78bc318daca,DISK], DatanodeInfoWithStorage[127.0.0.1:35877,DS-a454dab3-21a2-43bb-adf6-64212f4c8b49,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-774c0a78-e6b0-42c5-8b0e-3de5f9a3ce51,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-292fa1d5-acac-4c57-8d22-4b0bf9b2733e,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-c49eda44-bfd3-473b-adb0-28358d7790c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993633992-172.17.0.11-1597188703101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-bfb793f4-08d9-439c-8194-27717f6f802e,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-8857c886-826d-4634-83e2-8159c7f611e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-e0fa7b3c-ba16-4ad6-9b50-8b3bbb836c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-29103237-8109-4efb-a284-7506878603ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-a929a177-ea48-41e9-85ea-a830566d6ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-8669ce0e-faea-4dbc-aa67-cea6169e6728,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-841e8f44-083b-44c6-a528-c558a2ec4a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-113e3377-1535-4dcf-ac6f-16cd01b4a76b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993633992-172.17.0.11-1597188703101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40120,DS-bfb793f4-08d9-439c-8194-27717f6f802e,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-8857c886-826d-4634-83e2-8159c7f611e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-e0fa7b3c-ba16-4ad6-9b50-8b3bbb836c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-29103237-8109-4efb-a284-7506878603ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-a929a177-ea48-41e9-85ea-a830566d6ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:38388,DS-8669ce0e-faea-4dbc-aa67-cea6169e6728,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-841e8f44-083b-44c6-a528-c558a2ec4a75,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-113e3377-1535-4dcf-ac6f-16cd01b4a76b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283041069-172.17.0.11-1597189955613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38106,DS-c0a4479b-1ce8-4c7c-8ce6-563d66a718c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-e7deab9e-cf35-412b-be68-e01251964f21,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b11625ac-dbe9-4728-aac1-fe1ee3c81385,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-d818b858-1a8e-484b-92a5-166f0be354df,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-83460649-a4d1-4d73-9272-14057eb077e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-293f1c3c-91b0-474e-9339-1b84bffe79a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-fe85ca09-3175-48cd-87d6-63ed45962c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-8c352a58-a6d0-4f43-a98f-8aa42c18d7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283041069-172.17.0.11-1597189955613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38106,DS-c0a4479b-1ce8-4c7c-8ce6-563d66a718c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-e7deab9e-cf35-412b-be68-e01251964f21,DISK], DatanodeInfoWithStorage[127.0.0.1:38468,DS-b11625ac-dbe9-4728-aac1-fe1ee3c81385,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-d818b858-1a8e-484b-92a5-166f0be354df,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-83460649-a4d1-4d73-9272-14057eb077e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-293f1c3c-91b0-474e-9339-1b84bffe79a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-fe85ca09-3175-48cd-87d6-63ed45962c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-8c352a58-a6d0-4f43-a98f-8aa42c18d7e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614546616-172.17.0.11-1597190607899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38089,DS-36f28a34-f966-4c0a-baf2-9810073faef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-864d5a19-709d-4605-bb80-f5d33cee1bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-59324262-e980-4eb8-87e1-957988e85aad,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-da7b705d-51cf-4236-af5b-72ef35ccd197,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-83b97e98-2c97-4162-8f27-01c662f36f08,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-4a0aa454-aa21-4929-b5b4-923710588b33,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-6af3167c-3382-41b0-82e8-be36be9cbefb,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-9a755c97-abf9-489d-be45-b945acf4fb1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614546616-172.17.0.11-1597190607899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38089,DS-36f28a34-f966-4c0a-baf2-9810073faef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-864d5a19-709d-4605-bb80-f5d33cee1bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-59324262-e980-4eb8-87e1-957988e85aad,DISK], DatanodeInfoWithStorage[127.0.0.1:46773,DS-da7b705d-51cf-4236-af5b-72ef35ccd197,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-83b97e98-2c97-4162-8f27-01c662f36f08,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-4a0aa454-aa21-4929-b5b4-923710588b33,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-6af3167c-3382-41b0-82e8-be36be9cbefb,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-9a755c97-abf9-489d-be45-b945acf4fb1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024627461-172.17.0.11-1597191241905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36101,DS-43d75f36-5071-42f8-b965-46e9c0af74a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-c0188525-699a-46aa-9c76-aa4edb201c36,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-ebaa2822-5f89-4072-a472-5c5979d00182,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-9945f65f-fcf7-47b4-8d93-bda5d3308e44,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-d7377a2e-1a54-444c-8eb8-2269b058e1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-53436041-785e-43dc-af8b-b122881e98ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-f9fce6fb-c114-4901-a0d7-7a13cb72e2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-0a8e16df-ba9a-4e14-9060-8db820b181f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024627461-172.17.0.11-1597191241905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36101,DS-43d75f36-5071-42f8-b965-46e9c0af74a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-c0188525-699a-46aa-9c76-aa4edb201c36,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-ebaa2822-5f89-4072-a472-5c5979d00182,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-9945f65f-fcf7-47b4-8d93-bda5d3308e44,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-d7377a2e-1a54-444c-8eb8-2269b058e1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-53436041-785e-43dc-af8b-b122881e98ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-f9fce6fb-c114-4901-a0d7-7a13cb72e2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-0a8e16df-ba9a-4e14-9060-8db820b181f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953053407-172.17.0.11-1597191644272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36282,DS-fee9fa5f-ba4a-4e1a-8a0f-d46300469d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-86b52d14-bfc0-467b-a076-8b66f8b3d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-e30a8e88-ab7e-4749-a569-02f458ba781e,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-b7cd3b29-1549-4c4b-8d10-66fc979c791f,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-68c3a7f6-7d17-477c-ac63-d87453605779,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-175a0145-5eaf-468d-b088-fce4f693c174,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-d28536d9-b4c1-4a0c-b84b-4ae809350fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-d215203c-a750-4c39-952f-daac0790953e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953053407-172.17.0.11-1597191644272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36282,DS-fee9fa5f-ba4a-4e1a-8a0f-d46300469d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-86b52d14-bfc0-467b-a076-8b66f8b3d02f,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-e30a8e88-ab7e-4749-a569-02f458ba781e,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-b7cd3b29-1549-4c4b-8d10-66fc979c791f,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-68c3a7f6-7d17-477c-ac63-d87453605779,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-175a0145-5eaf-468d-b088-fce4f693c174,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-d28536d9-b4c1-4a0c-b84b-4ae809350fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-d215203c-a750-4c39-952f-daac0790953e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778241514-172.17.0.11-1597192391621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-2ad0f82c-eea0-4e11-b06f-1cbbe40e98a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-8ba16ae5-6d37-4cd8-9795-2cda122caa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-64cc5f82-eac2-4cf5-b8e6-a1560e9eec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-5282a49c-2b9f-46a1-9ac0-c278c1b86355,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-c7a59bcc-1873-424e-8237-3834bd3f3549,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-20f5f7bb-0cd0-4517-ab7e-b9c7dd8fa036,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-4e17987a-e620-4165-8122-aab40c5c8ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-04f90e0c-1518-401f-9e92-974ff1ddc443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1778241514-172.17.0.11-1597192391621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38352,DS-2ad0f82c-eea0-4e11-b06f-1cbbe40e98a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-8ba16ae5-6d37-4cd8-9795-2cda122caa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-64cc5f82-eac2-4cf5-b8e6-a1560e9eec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-5282a49c-2b9f-46a1-9ac0-c278c1b86355,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-c7a59bcc-1873-424e-8237-3834bd3f3549,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-20f5f7bb-0cd0-4517-ab7e-b9c7dd8fa036,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-4e17987a-e620-4165-8122-aab40c5c8ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-04f90e0c-1518-401f-9e92-974ff1ddc443,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5501
