reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236336504-172.17.0.4-1597200885782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-40198521-85c6-4977-a930-8ad883d6f3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-6c32776a-8a50-46ed-adbd-857b5d1f3bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-7f4e4fb8-ad8e-4247-8be7-95cfc644961a,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-dd2d2294-dfe2-47b9-8ce1-37bc8c012a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-88f7ded1-6753-4101-8817-43f746235331,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-092d20a2-ce66-4f90-a1b8-704389c13d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-2b4e1cf5-8ba7-4ba8-9469-4dfa71889eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-f2dfacef-9aa8-445f-8008-410a0b0dcc74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236336504-172.17.0.4-1597200885782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-40198521-85c6-4977-a930-8ad883d6f3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-6c32776a-8a50-46ed-adbd-857b5d1f3bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-7f4e4fb8-ad8e-4247-8be7-95cfc644961a,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-dd2d2294-dfe2-47b9-8ce1-37bc8c012a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-88f7ded1-6753-4101-8817-43f746235331,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-092d20a2-ce66-4f90-a1b8-704389c13d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-2b4e1cf5-8ba7-4ba8-9469-4dfa71889eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-f2dfacef-9aa8-445f-8008-410a0b0dcc74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765310135-172.17.0.4-1597201166092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-b4634cd4-668a-4625-808a-58d6b2a941ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-3203a6bd-4561-4b87-b35f-556461eb9aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-2d2e5b16-b1b3-4371-8cea-b906da6290f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-b8197624-5e50-434a-8fad-eb343f62f5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-03628f92-d4a9-4eac-939c-d33dccffd449,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-9592775c-d6bf-4827-a539-36b3013ab833,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-9ac46647-8308-4469-ae9a-163d6c6b5a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-5abe387c-bd4d-44ae-8698-0c83884fe159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765310135-172.17.0.4-1597201166092:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35873,DS-b4634cd4-668a-4625-808a-58d6b2a941ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-3203a6bd-4561-4b87-b35f-556461eb9aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-2d2e5b16-b1b3-4371-8cea-b906da6290f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-b8197624-5e50-434a-8fad-eb343f62f5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-03628f92-d4a9-4eac-939c-d33dccffd449,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-9592775c-d6bf-4827-a539-36b3013ab833,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-9ac46647-8308-4469-ae9a-163d6c6b5a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-5abe387c-bd4d-44ae-8698-0c83884fe159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717914761-172.17.0.4-1597201350195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-7adf746f-7e80-4e59-bfcf-594e0d233290,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-28d266e2-69cb-4b89-bce7-9f0b49e7789f,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-2c4cdb3b-d6c3-472f-8a25-52d81c450624,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-8d011f55-02b7-40d2-9b6f-fbe5f31e580a,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-23dfbcbc-43b4-4a9e-866a-ccb47ceaf1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-ace85705-9fb4-4805-8f01-4f0fb66bba06,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-df018fd9-b618-4686-bee5-d7f1115f5a31,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-3e9e7291-51a6-4ff6-b58b-00e71b90ae45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717914761-172.17.0.4-1597201350195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-7adf746f-7e80-4e59-bfcf-594e0d233290,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-28d266e2-69cb-4b89-bce7-9f0b49e7789f,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-2c4cdb3b-d6c3-472f-8a25-52d81c450624,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-8d011f55-02b7-40d2-9b6f-fbe5f31e580a,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-23dfbcbc-43b4-4a9e-866a-ccb47ceaf1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-ace85705-9fb4-4805-8f01-4f0fb66bba06,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-df018fd9-b618-4686-bee5-d7f1115f5a31,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-3e9e7291-51a6-4ff6-b58b-00e71b90ae45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254420038-172.17.0.4-1597201836576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-1153911b-ea91-4416-b0b2-83448e1e9217,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-0e7af237-c944-4422-8553-210e1a4685be,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-d195cd12-6b79-4c85-b540-a9b2d0c4cfde,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-ba047476-0316-46d7-825c-b078bfd54b95,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-ab4298e2-050b-4d20-b635-5e1e22caebf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-b47c0505-836f-49bf-9803-d12ce92e1b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-ce4e382f-4685-4948-a09d-ab0807d80602,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-59f58961-be0b-41b8-b26a-be5b7d781f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254420038-172.17.0.4-1597201836576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-1153911b-ea91-4416-b0b2-83448e1e9217,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-0e7af237-c944-4422-8553-210e1a4685be,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-d195cd12-6b79-4c85-b540-a9b2d0c4cfde,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-ba047476-0316-46d7-825c-b078bfd54b95,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-ab4298e2-050b-4d20-b635-5e1e22caebf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-b47c0505-836f-49bf-9803-d12ce92e1b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-ce4e382f-4685-4948-a09d-ab0807d80602,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-59f58961-be0b-41b8-b26a-be5b7d781f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11192250-172.17.0.4-1597202072960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39592,DS-54a45fe5-b33c-41ed-9b29-922d24391d72,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-a9787c8e-f6ce-46c2-a877-f3be938bf750,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-1b4b7423-f327-47e8-ac73-b4d5bf4904d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-6885a856-2007-4572-b4a3-e4a26ee5d952,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-e8008496-c13a-4b44-855c-503a82cc7aad,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-c95227e2-ef75-40f9-a6ab-2bad2879276d,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-29ee2bac-6e14-460e-8959-b23923746af5,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-cde3ff1d-f667-49c4-b53d-ffab226112eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11192250-172.17.0.4-1597202072960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39592,DS-54a45fe5-b33c-41ed-9b29-922d24391d72,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-a9787c8e-f6ce-46c2-a877-f3be938bf750,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-1b4b7423-f327-47e8-ac73-b4d5bf4904d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-6885a856-2007-4572-b4a3-e4a26ee5d952,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-e8008496-c13a-4b44-855c-503a82cc7aad,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-c95227e2-ef75-40f9-a6ab-2bad2879276d,DISK], DatanodeInfoWithStorage[127.0.0.1:35451,DS-29ee2bac-6e14-460e-8959-b23923746af5,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-cde3ff1d-f667-49c4-b53d-ffab226112eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816906738-172.17.0.4-1597202216658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34525,DS-c3448052-8fb1-4546-b1d6-23167b71bcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-404f7682-4354-4825-b708-9d32b156d686,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-5f0a4766-2399-4ecf-af06-f841dc113e55,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-db26a31c-bf03-4716-b075-0a1fa153ad0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-aa01a3a8-1ff9-424d-8539-36f1b3735986,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-9a5475f8-460b-4ea6-9fdd-5c90db265e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-22cc1426-5232-4561-b483-6a52715ca893,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-b05596c7-68bb-4bd2-a3be-794d307d0781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1816906738-172.17.0.4-1597202216658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34525,DS-c3448052-8fb1-4546-b1d6-23167b71bcf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-404f7682-4354-4825-b708-9d32b156d686,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-5f0a4766-2399-4ecf-af06-f841dc113e55,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-db26a31c-bf03-4716-b075-0a1fa153ad0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-aa01a3a8-1ff9-424d-8539-36f1b3735986,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-9a5475f8-460b-4ea6-9fdd-5c90db265e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-22cc1426-5232-4561-b483-6a52715ca893,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-b05596c7-68bb-4bd2-a3be-794d307d0781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913981864-172.17.0.4-1597202394296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-3701c4aa-c2e1-4ceb-a7c5-b90d8c2fa3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-ac38fae1-c1fc-4789-9752-fc43b57af54f,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-9cbb96ac-dcf0-4871-916e-c4a39d494d06,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-25180bae-0b41-4fe0-875c-12ef342691e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-1b5b04a3-576d-4d59-8d62-af867925cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-d357089d-2536-44b6-b02b-cb9ff75549bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-62dd368c-c16b-426a-9fe7-2bb3a043d599,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-c9a582cf-05b7-418a-a937-abed63c42021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913981864-172.17.0.4-1597202394296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-3701c4aa-c2e1-4ceb-a7c5-b90d8c2fa3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-ac38fae1-c1fc-4789-9752-fc43b57af54f,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-9cbb96ac-dcf0-4871-916e-c4a39d494d06,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-25180bae-0b41-4fe0-875c-12ef342691e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-1b5b04a3-576d-4d59-8d62-af867925cf53,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-d357089d-2536-44b6-b02b-cb9ff75549bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-62dd368c-c16b-426a-9fe7-2bb3a043d599,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-c9a582cf-05b7-418a-a937-abed63c42021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155532955-172.17.0.4-1597203326488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-399b7cd8-1810-450e-9715-737e73de8073,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-0235550d-88f3-4598-bc59-d8aa1316a3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-8ae21413-7405-40c9-976a-5d1d7eafe9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-af6b5acb-b32a-48b8-bd2c-fcc0ed57de8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-6733ab6f-9831-49f9-b153-85ab28893909,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-ce71caa6-490c-482f-9184-dd59d54ecdce,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-4f91ff3d-e1b5-4f17-9ae3-af424473b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-528ff650-c6dd-483c-b745-792dd10884a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155532955-172.17.0.4-1597203326488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-399b7cd8-1810-450e-9715-737e73de8073,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-0235550d-88f3-4598-bc59-d8aa1316a3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-8ae21413-7405-40c9-976a-5d1d7eafe9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-af6b5acb-b32a-48b8-bd2c-fcc0ed57de8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-6733ab6f-9831-49f9-b153-85ab28893909,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-ce71caa6-490c-482f-9184-dd59d54ecdce,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-4f91ff3d-e1b5-4f17-9ae3-af424473b24e,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-528ff650-c6dd-483c-b745-792dd10884a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450209301-172.17.0.4-1597203487870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-976dc9bd-3281-4d84-ad08-05ac7f809087,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-29750f8f-6961-447d-8b71-6da9e4620253,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-6fcabbc9-6e71-4269-9726-73be7c9e8881,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-873f2c8c-dc68-4713-b7ac-bcfc1cd7995e,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-9b9c3eae-f3d7-4c9f-b680-465a8bf4fa39,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-c88a4be0-93d2-4dad-aaf9-bff4c8f065d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-5948d9b7-0100-4c5b-ba21-bd766e259103,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-c70d8fb6-b5b6-4b8d-aa2a-0bca88c52824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1450209301-172.17.0.4-1597203487870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46369,DS-976dc9bd-3281-4d84-ad08-05ac7f809087,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-29750f8f-6961-447d-8b71-6da9e4620253,DISK], DatanodeInfoWithStorage[127.0.0.1:35839,DS-6fcabbc9-6e71-4269-9726-73be7c9e8881,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-873f2c8c-dc68-4713-b7ac-bcfc1cd7995e,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-9b9c3eae-f3d7-4c9f-b680-465a8bf4fa39,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-c88a4be0-93d2-4dad-aaf9-bff4c8f065d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33175,DS-5948d9b7-0100-4c5b-ba21-bd766e259103,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-c70d8fb6-b5b6-4b8d-aa2a-0bca88c52824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146179717-172.17.0.4-1597203519362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-8dd26eb4-3184-4e40-99b9-7f87a6eac36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-cbc77133-e9ba-4aa5-8c22-b0553e4b029d,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-9f9e8005-f1d9-4dd6-86b4-5492f2ab65e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-0756706a-0231-4ce9-8c4a-121af4b9bed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-a0fdc417-9e5e-46d0-be3d-17e7459f5c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-c2e0e53c-89ec-451e-87c0-7329a65f46d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-5b1b84e8-118e-43c3-a6ec-3c76d1035426,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-ef73010e-70e4-415e-a4a6-d78a3af6f76a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-146179717-172.17.0.4-1597203519362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40509,DS-8dd26eb4-3184-4e40-99b9-7f87a6eac36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-cbc77133-e9ba-4aa5-8c22-b0553e4b029d,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-9f9e8005-f1d9-4dd6-86b4-5492f2ab65e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-0756706a-0231-4ce9-8c4a-121af4b9bed3,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-a0fdc417-9e5e-46d0-be3d-17e7459f5c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-c2e0e53c-89ec-451e-87c0-7329a65f46d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-5b1b84e8-118e-43c3-a6ec-3c76d1035426,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-ef73010e-70e4-415e-a4a6-d78a3af6f76a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252837686-172.17.0.4-1597203618178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33547,DS-f94c8a5b-a000-48be-abb0-7d74e2d9c281,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-bfb12653-f0ec-4c28-80ab-d76de5520692,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-78da56ef-ca4e-403c-b719-7016a41d7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-c69a85ae-f962-425e-b05f-ebf5798eef8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-1cd095e6-355a-4150-98e8-762b9d842bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-69686eac-14d3-412f-9cbb-8a095edb1f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-9238d71a-2fd6-4e40-a395-d2b855226329,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-4f43495a-12be-45e4-8d1f-751ce9b75f1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252837686-172.17.0.4-1597203618178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33547,DS-f94c8a5b-a000-48be-abb0-7d74e2d9c281,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-bfb12653-f0ec-4c28-80ab-d76de5520692,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-78da56ef-ca4e-403c-b719-7016a41d7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-c69a85ae-f962-425e-b05f-ebf5798eef8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-1cd095e6-355a-4150-98e8-762b9d842bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-69686eac-14d3-412f-9cbb-8a095edb1f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-9238d71a-2fd6-4e40-a395-d2b855226329,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-4f43495a-12be-45e4-8d1f-751ce9b75f1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745467269-172.17.0.4-1597203746601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33935,DS-b4725d2b-39f2-4324-b625-f45e99534293,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-bb6faef1-be25-4075-8c79-5735f55a8245,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-e08cba63-22e6-4ad1-9077-cb6c8c454fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-d61ea3f3-bf21-4666-b668-b3f1ce53882a,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-e54c8f6a-d16b-460b-89c7-e4124ce2af00,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-3ff105ee-5a4b-4f2b-95ad-121df08ca0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-b9ec0f86-e17c-41f5-b50f-529e2840c585,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-0644b98a-ac86-4761-8626-3a32fa606d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745467269-172.17.0.4-1597203746601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33935,DS-b4725d2b-39f2-4324-b625-f45e99534293,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-bb6faef1-be25-4075-8c79-5735f55a8245,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-e08cba63-22e6-4ad1-9077-cb6c8c454fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-d61ea3f3-bf21-4666-b668-b3f1ce53882a,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-e54c8f6a-d16b-460b-89c7-e4124ce2af00,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-3ff105ee-5a4b-4f2b-95ad-121df08ca0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-b9ec0f86-e17c-41f5-b50f-529e2840c585,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-0644b98a-ac86-4761-8626-3a32fa606d27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829431215-172.17.0.4-1597204017171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35893,DS-6c6219e2-7497-4704-bb57-630ff36d362a,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-c7f035d5-2532-49e6-a1fd-12ae1f524f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-d733b928-37f8-4f1c-a1fe-2a65ab0dc3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-4410da58-b857-4787-8d9b-128f955be513,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-ed802667-b331-4395-a93a-b6c40a8738ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-2087f3b0-0f67-4aff-bab2-27bb66ed3771,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-256cfcc7-3044-4722-85fe-7acbb94cbc27,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-5f99e498-74c6-4b63-8e6b-c8bcd2bd1bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829431215-172.17.0.4-1597204017171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35893,DS-6c6219e2-7497-4704-bb57-630ff36d362a,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-c7f035d5-2532-49e6-a1fd-12ae1f524f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-d733b928-37f8-4f1c-a1fe-2a65ab0dc3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-4410da58-b857-4787-8d9b-128f955be513,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-ed802667-b331-4395-a93a-b6c40a8738ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-2087f3b0-0f67-4aff-bab2-27bb66ed3771,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-256cfcc7-3044-4722-85fe-7acbb94cbc27,DISK], DatanodeInfoWithStorage[127.0.0.1:41960,DS-5f99e498-74c6-4b63-8e6b-c8bcd2bd1bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540385304-172.17.0.4-1597204356804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36848,DS-45f87f4e-15ff-48ea-9c80-545f0c4f62f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-df65a019-108c-4e44-a8bd-b6731e0fc4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-d8df5ec5-b3f2-4fb2-a316-9ac2349c2a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-4cfb47fd-132c-4233-8e43-ca5e1be53888,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-6704eb6f-b92e-4d92-8869-cda40121bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-cae301d4-5ef2-4094-908f-2599c3c77298,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-497a2f8b-c1ed-4820-b31e-f4bc8068f799,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-79bc50f8-7d62-407f-ba88-ba299b2eeee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540385304-172.17.0.4-1597204356804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36848,DS-45f87f4e-15ff-48ea-9c80-545f0c4f62f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-df65a019-108c-4e44-a8bd-b6731e0fc4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-d8df5ec5-b3f2-4fb2-a316-9ac2349c2a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-4cfb47fd-132c-4233-8e43-ca5e1be53888,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-6704eb6f-b92e-4d92-8869-cda40121bff2,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-cae301d4-5ef2-4094-908f-2599c3c77298,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-497a2f8b-c1ed-4820-b31e-f4bc8068f799,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-79bc50f8-7d62-407f-ba88-ba299b2eeee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84592115-172.17.0.4-1597204461332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-53f607d3-bc91-4360-99f3-3dfe6fd77d86,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-1161306c-5b2a-4a56-b390-4c8688f9ddfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-b9ea0f01-8c14-475d-84c4-6ca5d4cad9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-f4f185e6-1a5f-495b-9a9f-7bdfd93d6847,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-515d8678-5ca7-480f-a484-6f99fd1a8563,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-66b111c0-7e68-45f2-9e8f-e3fb49869463,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-a0adf73b-e669-40c8-82f8-b2850f41a5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-197a5cc5-31af-496b-bbac-773d73f6599c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84592115-172.17.0.4-1597204461332:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33898,DS-53f607d3-bc91-4360-99f3-3dfe6fd77d86,DISK], DatanodeInfoWithStorage[127.0.0.1:39047,DS-1161306c-5b2a-4a56-b390-4c8688f9ddfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-b9ea0f01-8c14-475d-84c4-6ca5d4cad9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-f4f185e6-1a5f-495b-9a9f-7bdfd93d6847,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-515d8678-5ca7-480f-a484-6f99fd1a8563,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-66b111c0-7e68-45f2-9e8f-e3fb49869463,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-a0adf73b-e669-40c8-82f8-b2850f41a5f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-197a5cc5-31af-496b-bbac-773d73f6599c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218388625-172.17.0.4-1597204571387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35540,DS-05eb229f-de32-444e-a37f-1f10cb1f6bde,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-eed4891a-41cd-4726-bea2-b3d8adceb8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-735f92bb-b445-4535-b891-249b7390ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-05af7b74-cea5-4544-813e-7d1d973c13cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-ee7b108d-10e4-4b89-a909-1009318c4f96,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-ad35e470-d8b7-457e-9f11-3ab88b5dfb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-e1bac043-56a4-46d7-abae-52a256f244fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-d1942439-fab2-42a3-8646-5ea3c10638a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218388625-172.17.0.4-1597204571387:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35540,DS-05eb229f-de32-444e-a37f-1f10cb1f6bde,DISK], DatanodeInfoWithStorage[127.0.0.1:45670,DS-eed4891a-41cd-4726-bea2-b3d8adceb8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-735f92bb-b445-4535-b891-249b7390ff51,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-05af7b74-cea5-4544-813e-7d1d973c13cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-ee7b108d-10e4-4b89-a909-1009318c4f96,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-ad35e470-d8b7-457e-9f11-3ab88b5dfb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-e1bac043-56a4-46d7-abae-52a256f244fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-d1942439-fab2-42a3-8646-5ea3c10638a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048215606-172.17.0.4-1597204639941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-f9af1dc9-e130-4762-ae73-e24d812a7a69,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-3a788091-ade3-46d7-acd8-4d5ce09f6b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-0ca883c7-5ddf-4365-9db4-80db9d38d85b,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-ce2f4d0f-6a85-4bdd-84c5-273ef7820df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f61d0718-38ee-42ce-ba56-3f9268f192e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-d3ae4b5d-7007-41c6-b380-6d9abdd9ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-f824f2aa-ae63-4346-b197-385775a502d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-435576c3-3bf0-4297-83f6-940eed0838a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048215606-172.17.0.4-1597204639941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-f9af1dc9-e130-4762-ae73-e24d812a7a69,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-3a788091-ade3-46d7-acd8-4d5ce09f6b91,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-0ca883c7-5ddf-4365-9db4-80db9d38d85b,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-ce2f4d0f-6a85-4bdd-84c5-273ef7820df2,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-f61d0718-38ee-42ce-ba56-3f9268f192e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-d3ae4b5d-7007-41c6-b380-6d9abdd9ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-f824f2aa-ae63-4346-b197-385775a502d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-435576c3-3bf0-4297-83f6-940eed0838a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284622311-172.17.0.4-1597204717284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-7d3ee077-9503-4599-bc47-3165af07a857,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-d0dfe7ab-ec9b-4ba9-9bf5-0166aa3ab2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-16545ae4-acfb-45ed-b288-252fd97f6b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-5ef9bda3-dbbe-4126-9f9c-8ddd0933d174,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-ebffd973-6c42-49a4-a8a0-54e6a95b84d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-aff510f7-ecbe-4034-8571-a1aecc6f4e85,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-8f1a884d-04a7-499f-87a3-79665b13924a,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-2918b6b8-02f9-4bb0-92bc-843b29d296dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1284622311-172.17.0.4-1597204717284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-7d3ee077-9503-4599-bc47-3165af07a857,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-d0dfe7ab-ec9b-4ba9-9bf5-0166aa3ab2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-16545ae4-acfb-45ed-b288-252fd97f6b68,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-5ef9bda3-dbbe-4126-9f9c-8ddd0933d174,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-ebffd973-6c42-49a4-a8a0-54e6a95b84d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46215,DS-aff510f7-ecbe-4034-8571-a1aecc6f4e85,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-8f1a884d-04a7-499f-87a3-79665b13924a,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-2918b6b8-02f9-4bb0-92bc-843b29d296dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778270215-172.17.0.4-1597204863254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33609,DS-f2710936-fca1-4105-8a8f-332497b0ef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-f2a96003-0d47-4d53-9717-fd7a9969c9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-05a33a25-eeee-4a26-8576-a8ba75d34abe,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-a3741bc9-df60-47be-b57a-eeb4d9e29386,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-25b450e4-6620-4e7e-99d7-386b9922854a,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-0a24ade3-2751-4a51-8479-9ef6cb188f55,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-06688d71-28fd-4369-a3a2-3024cc5ffb92,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-ce62be91-6948-47f9-8115-b219cc59b3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778270215-172.17.0.4-1597204863254:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33609,DS-f2710936-fca1-4105-8a8f-332497b0ef8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-f2a96003-0d47-4d53-9717-fd7a9969c9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-05a33a25-eeee-4a26-8576-a8ba75d34abe,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-a3741bc9-df60-47be-b57a-eeb4d9e29386,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-25b450e4-6620-4e7e-99d7-386b9922854a,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-0a24ade3-2751-4a51-8479-9ef6cb188f55,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-06688d71-28fd-4369-a3a2-3024cc5ffb92,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-ce62be91-6948-47f9-8115-b219cc59b3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:NameNode
v1: 4096
v2: 2048
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225846644-172.17.0.4-1597205314370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35087,DS-1b38d822-1082-4a96-bb32-45743c0134ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-dcbc370c-64f9-4cda-a60b-1aff6328ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-403b6f68-8789-4471-b259-d5373d0ed5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-d5c043af-49ca-426d-b08e-32c2ae636a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-f65b8262-767f-4853-800d-34605c26bfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-1f3f94ef-8fa6-44b3-897e-aa1ee36f8e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-e5ad6542-6cdd-4d18-80f4-9b8cb1a9b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-674a376d-caa8-44b2-a97a-7784bc4dec27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225846644-172.17.0.4-1597205314370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35087,DS-1b38d822-1082-4a96-bb32-45743c0134ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-dcbc370c-64f9-4cda-a60b-1aff6328ac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-403b6f68-8789-4471-b259-d5373d0ed5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-d5c043af-49ca-426d-b08e-32c2ae636a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-f65b8262-767f-4853-800d-34605c26bfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-1f3f94ef-8fa6-44b3-897e-aa1ee36f8e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-e5ad6542-6cdd-4d18-80f4-9b8cb1a9b7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-674a376d-caa8-44b2-a97a-7784bc4dec27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5209
