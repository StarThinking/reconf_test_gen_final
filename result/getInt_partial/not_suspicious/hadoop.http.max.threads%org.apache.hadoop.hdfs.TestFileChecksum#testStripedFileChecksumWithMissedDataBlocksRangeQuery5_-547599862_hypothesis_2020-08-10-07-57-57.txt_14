reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778055574-172.17.0.9-1597046578143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-beeab961-0cf6-4ad9-91fe-7d84a281dd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-2849f007-d0b2-4df7-95b9-e2d336ad0e46,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-9ab8adf9-886a-4205-b159-270b9f026335,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-0cbb8c0d-f963-4d8f-b9b0-94061398e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-6b45f213-45b0-44a2-b510-948a8f13bcca,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-f0699042-1838-467a-a86e-6a2897e7a2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-0ea53bfe-a4a1-46db-a658-e8db692846dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-5df5c95d-e58d-4fc3-9743-4c2347186a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-778055574-172.17.0.9-1597046578143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-beeab961-0cf6-4ad9-91fe-7d84a281dd1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-2849f007-d0b2-4df7-95b9-e2d336ad0e46,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-9ab8adf9-886a-4205-b159-270b9f026335,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-0cbb8c0d-f963-4d8f-b9b0-94061398e38d,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-6b45f213-45b0-44a2-b510-948a8f13bcca,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-f0699042-1838-467a-a86e-6a2897e7a2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-0ea53bfe-a4a1-46db-a658-e8db692846dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-5df5c95d-e58d-4fc3-9743-4c2347186a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017381149-172.17.0.9-1597046722970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-a1cbf0e1-0a94-44b5-8673-b517ae6bf41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-a95c8872-8abf-446d-8fd5-d8fe96967bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-b731786f-f408-4217-bbfd-11d000982614,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-1d4ba213-563b-4bf9-a89d-5a5788a5963d,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-3e73f296-c730-43fb-8719-4e98d8e70b79,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-195248a4-7ba7-46ae-b737-c0af6abe61f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-515a522e-4738-48e7-bf6e-14b767d10aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-afe3402d-f886-4690-a4b0-727f829ff4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017381149-172.17.0.9-1597046722970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42401,DS-a1cbf0e1-0a94-44b5-8673-b517ae6bf41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-a95c8872-8abf-446d-8fd5-d8fe96967bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-b731786f-f408-4217-bbfd-11d000982614,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-1d4ba213-563b-4bf9-a89d-5a5788a5963d,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-3e73f296-c730-43fb-8719-4e98d8e70b79,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-195248a4-7ba7-46ae-b737-c0af6abe61f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-515a522e-4738-48e7-bf6e-14b767d10aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-afe3402d-f886-4690-a4b0-727f829ff4ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891440757-172.17.0.9-1597046988837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37604,DS-089e6772-c2e6-47e6-9797-040707eddea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-5b3bebf2-b761-4fbf-8d65-cbba205694fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-d29231d7-ea27-42a8-b9d3-0f689f1b8448,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-d1c3dee8-8a83-47fb-af11-47906d2f2fed,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-814cfc08-d435-4827-ab46-fae57e0f8ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-436a6b43-bb3b-4a89-ad71-021a65d534b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-e494f760-8bdf-4d86-8d23-bcaa1d542a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-1f4c8484-0f5e-4330-beb0-d3b79f410d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891440757-172.17.0.9-1597046988837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37604,DS-089e6772-c2e6-47e6-9797-040707eddea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-5b3bebf2-b761-4fbf-8d65-cbba205694fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-d29231d7-ea27-42a8-b9d3-0f689f1b8448,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-d1c3dee8-8a83-47fb-af11-47906d2f2fed,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-814cfc08-d435-4827-ab46-fae57e0f8ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-436a6b43-bb3b-4a89-ad71-021a65d534b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-e494f760-8bdf-4d86-8d23-bcaa1d542a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-1f4c8484-0f5e-4330-beb0-d3b79f410d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350294060-172.17.0.9-1597047528905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-86528d71-bf3a-4cb4-a13e-189c633fc925,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-89bfd352-24cc-4150-8229-0f207cedd2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-722eadc5-1653-4140-be92-d60c69f7b522,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-0e8040ca-0e1f-4e95-873c-816f94b15fae,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-427ec387-f5c3-4b04-bcdf-0186266a73e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-e5a80b98-70b9-4fec-8a10-c07aaa41a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-adeec35a-1171-4ca8-a96e-7e7f1e770cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-b45f1255-3a51-4505-94ed-ff4e28c4f286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350294060-172.17.0.9-1597047528905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-86528d71-bf3a-4cb4-a13e-189c633fc925,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-89bfd352-24cc-4150-8229-0f207cedd2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-722eadc5-1653-4140-be92-d60c69f7b522,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-0e8040ca-0e1f-4e95-873c-816f94b15fae,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-427ec387-f5c3-4b04-bcdf-0186266a73e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-e5a80b98-70b9-4fec-8a10-c07aaa41a6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-adeec35a-1171-4ca8-a96e-7e7f1e770cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-b45f1255-3a51-4505-94ed-ff4e28c4f286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044546123-172.17.0.9-1597048423581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33556,DS-e74d97fe-a092-47fe-9138-a4601218ac13,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-0a19a0a2-d192-4dff-9d4a-46d85f29bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-ef0a0d82-b468-4c02-93ec-983d25d90686,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-8cfb9194-e852-404b-9e7b-a4d660923f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-9be9d693-07ad-4eb2-9dbd-15ca64bcf5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-1ef24ff0-3bd0-4dcd-8310-fbe38d90b3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-95ccd19d-4027-4278-bf3e-71e4f0a45aec,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-69a9938f-c62e-4b4e-9467-08b1739fc231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044546123-172.17.0.9-1597048423581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33556,DS-e74d97fe-a092-47fe-9138-a4601218ac13,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-0a19a0a2-d192-4dff-9d4a-46d85f29bb61,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-ef0a0d82-b468-4c02-93ec-983d25d90686,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-8cfb9194-e852-404b-9e7b-a4d660923f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-9be9d693-07ad-4eb2-9dbd-15ca64bcf5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-1ef24ff0-3bd0-4dcd-8310-fbe38d90b3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-95ccd19d-4027-4278-bf3e-71e4f0a45aec,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-69a9938f-c62e-4b4e-9467-08b1739fc231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942121944-172.17.0.9-1597048663119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36329,DS-df990393-083e-4299-909a-3cd9b2915bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-bb06a90f-02dc-46b8-9355-5b0b0a9faabd,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-ad2e4837-8064-4339-8f1e-1606504dd96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-d353c7f4-85ee-4870-8962-b07b65a3b664,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-b21d9ea7-a26c-4b6a-9d0f-e447bafaf8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-2fb60180-5b2f-47f8-9d75-90f7ea826392,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-c1c118b7-a200-4231-a13e-355468067ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-9b161484-e077-42ef-b44d-473ebc112102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942121944-172.17.0.9-1597048663119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36329,DS-df990393-083e-4299-909a-3cd9b2915bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-bb06a90f-02dc-46b8-9355-5b0b0a9faabd,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-ad2e4837-8064-4339-8f1e-1606504dd96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-d353c7f4-85ee-4870-8962-b07b65a3b664,DISK], DatanodeInfoWithStorage[127.0.0.1:45155,DS-b21d9ea7-a26c-4b6a-9d0f-e447bafaf8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40690,DS-2fb60180-5b2f-47f8-9d75-90f7ea826392,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-c1c118b7-a200-4231-a13e-355468067ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-9b161484-e077-42ef-b44d-473ebc112102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490039718-172.17.0.9-1597049781762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34533,DS-d988a516-3f90-42a6-b9ac-3049622959a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-ee01a6e2-ecf3-49f3-ba6c-1c32b59fea5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-e56bfa36-df61-43ff-9529-a70f196ee94d,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-e0cb9e27-0da4-4192-b16a-5e8352acd4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-fa9054f9-b4b3-41bd-ba0d-5e77b4df5609,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-06ceeda7-0b02-45c7-8ecf-0c4e712219d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-26fdc766-71db-4c93-acba-c3d4a394647d,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-9a1cf5f2-1d08-4a3a-8df6-67358b8f0c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490039718-172.17.0.9-1597049781762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34533,DS-d988a516-3f90-42a6-b9ac-3049622959a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-ee01a6e2-ecf3-49f3-ba6c-1c32b59fea5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-e56bfa36-df61-43ff-9529-a70f196ee94d,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-e0cb9e27-0da4-4192-b16a-5e8352acd4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-fa9054f9-b4b3-41bd-ba0d-5e77b4df5609,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-06ceeda7-0b02-45c7-8ecf-0c4e712219d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34414,DS-26fdc766-71db-4c93-acba-c3d4a394647d,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-9a1cf5f2-1d08-4a3a-8df6-67358b8f0c48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856084124-172.17.0.9-1597050232874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-7000d0ba-7dbd-49cc-bf4d-4744595429d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-ca9c67dc-a229-491d-94e6-af68ee4871ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-7ca9b043-2bba-46a9-9cfc-c38e02805818,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-8696d27d-b275-4e60-8b9e-c71c0641d070,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-6f68239a-65db-4932-8602-cd685f3229b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-d57abc82-278a-4324-a7c3-cc664bdb6fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-db21a42f-8d17-45e6-9074-856f7e5d5732,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-200c1f5f-de06-4a85-aee4-8c835f420115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856084124-172.17.0.9-1597050232874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-7000d0ba-7dbd-49cc-bf4d-4744595429d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-ca9c67dc-a229-491d-94e6-af68ee4871ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-7ca9b043-2bba-46a9-9cfc-c38e02805818,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-8696d27d-b275-4e60-8b9e-c71c0641d070,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-6f68239a-65db-4932-8602-cd685f3229b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-d57abc82-278a-4324-a7c3-cc664bdb6fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-db21a42f-8d17-45e6-9074-856f7e5d5732,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-200c1f5f-de06-4a85-aee4-8c835f420115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919378287-172.17.0.9-1597050517591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34471,DS-bb1d7ea1-eef8-40f9-92ec-033d24a8f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-39625327-feeb-40eb-a50b-cf0400b2fa94,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-af58b6d0-be06-461c-8203-04780ef22d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-ad8d2aac-d9a7-4094-b1cd-140326d8246e,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-fbb03afa-c9cc-40a4-9514-fc257e87b86f,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-246e9626-0bf9-42f8-af14-5c53c9a9495c,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-8698b1b8-fc90-4107-a72b-4950f545e977,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-8f7856a3-ab99-4224-a02b-50db1bdfda6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919378287-172.17.0.9-1597050517591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34471,DS-bb1d7ea1-eef8-40f9-92ec-033d24a8f7aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-39625327-feeb-40eb-a50b-cf0400b2fa94,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-af58b6d0-be06-461c-8203-04780ef22d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-ad8d2aac-d9a7-4094-b1cd-140326d8246e,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-fbb03afa-c9cc-40a4-9514-fc257e87b86f,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-246e9626-0bf9-42f8-af14-5c53c9a9495c,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-8698b1b8-fc90-4107-a72b-4950f545e977,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-8f7856a3-ab99-4224-a02b-50db1bdfda6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989597917-172.17.0.9-1597050587728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-69bc4c94-4959-4be4-be5c-a4cf31fa3adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-52ef14b2-726d-49c9-9c3b-dfb82852d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-7478b4e9-1019-48dc-9582-1b885be2c480,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-73bddb9d-44e9-412f-a8b3-9b4e6dde02f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-1a908c21-b87c-45c4-af85-a8cb94992173,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-d89bfcf3-57d0-4d35-a923-35e758680e91,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-868ad5e0-33f6-4683-acbb-4f8123a3b4af,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-ba72e0d1-c4fe-4719-999e-745ac3ab39f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989597917-172.17.0.9-1597050587728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-69bc4c94-4959-4be4-be5c-a4cf31fa3adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-52ef14b2-726d-49c9-9c3b-dfb82852d68b,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-7478b4e9-1019-48dc-9582-1b885be2c480,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-73bddb9d-44e9-412f-a8b3-9b4e6dde02f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-1a908c21-b87c-45c4-af85-a8cb94992173,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-d89bfcf3-57d0-4d35-a923-35e758680e91,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-868ad5e0-33f6-4683-acbb-4f8123a3b4af,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-ba72e0d1-c4fe-4719-999e-745ac3ab39f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707800209-172.17.0.9-1597050906161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36484,DS-0b3211b2-9c77-4657-a384-fe704f989591,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-e7f501fd-9c49-4b37-9d25-91756c90abaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-2e908c3e-41ea-43e1-a5e4-3e854744205e,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-f0601061-efd0-4c71-bb9f-aed02a65670e,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-5cdd3645-b686-4364-92ef-985b6a208e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-f643e8b7-3961-4e54-8a47-12edf4a6ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-02d00494-2fc1-4e5b-9ae2-47adb38f2e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-c298a573-7b16-4bed-9309-75e7eca0aa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1707800209-172.17.0.9-1597050906161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36484,DS-0b3211b2-9c77-4657-a384-fe704f989591,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-e7f501fd-9c49-4b37-9d25-91756c90abaa,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-2e908c3e-41ea-43e1-a5e4-3e854744205e,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-f0601061-efd0-4c71-bb9f-aed02a65670e,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-5cdd3645-b686-4364-92ef-985b6a208e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-f643e8b7-3961-4e54-8a47-12edf4a6ffee,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-02d00494-2fc1-4e5b-9ae2-47adb38f2e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-c298a573-7b16-4bed-9309-75e7eca0aa38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316176275-172.17.0.9-1597051307669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42046,DS-a9e556f3-37af-49a3-87d6-7c8cf01b3340,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-3d44dcd1-1fe1-4d64-8c99-c26758a7c3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-1c6ec8fe-0a89-48ac-8b7c-30f8e5a6087a,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-c58266fe-81f0-46d0-8b0b-3b38e99b7106,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-64e385e0-bfa1-4aba-b314-a951f605b48d,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-d442e54e-eec4-47a9-b3d8-a13d52daeacd,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-55e5032a-ce2e-4d54-95bb-03a52f5b1aef,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-e1b18982-1bbf-4c85-8bea-1d440a117ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316176275-172.17.0.9-1597051307669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42046,DS-a9e556f3-37af-49a3-87d6-7c8cf01b3340,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-3d44dcd1-1fe1-4d64-8c99-c26758a7c3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-1c6ec8fe-0a89-48ac-8b7c-30f8e5a6087a,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-c58266fe-81f0-46d0-8b0b-3b38e99b7106,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-64e385e0-bfa1-4aba-b314-a951f605b48d,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-d442e54e-eec4-47a9-b3d8-a13d52daeacd,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-55e5032a-ce2e-4d54-95bb-03a52f5b1aef,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-e1b18982-1bbf-4c85-8bea-1d440a117ae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: 10
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647423052-172.17.0.9-1597051626086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43639,DS-9c6b4aba-d9a0-4f5a-9120-4ad1da44d07e,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-d101e391-2f9b-4979-869b-7520032e5b16,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-19b0db9b-a33c-4729-a507-5f5d2f0f153b,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-7b928c96-7f51-48fe-b3fc-3b73f5cf2a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-497e566e-ae67-4a40-a9bd-e9f15fd811d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-61218083-d6be-40fd-885f-783eec394e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-5bf0578d-449d-4b18-959f-6af6198a7d22,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-7e6af878-bcf1-485c-be1d-d1a0cfde00a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647423052-172.17.0.9-1597051626086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43639,DS-9c6b4aba-d9a0-4f5a-9120-4ad1da44d07e,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-d101e391-2f9b-4979-869b-7520032e5b16,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-19b0db9b-a33c-4729-a507-5f5d2f0f153b,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-7b928c96-7f51-48fe-b3fc-3b73f5cf2a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-497e566e-ae67-4a40-a9bd-e9f15fd811d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-61218083-d6be-40fd-885f-783eec394e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-5bf0578d-449d-4b18-959f-6af6198a7d22,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-7e6af878-bcf1-485c-be1d-d1a0cfde00a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5406
