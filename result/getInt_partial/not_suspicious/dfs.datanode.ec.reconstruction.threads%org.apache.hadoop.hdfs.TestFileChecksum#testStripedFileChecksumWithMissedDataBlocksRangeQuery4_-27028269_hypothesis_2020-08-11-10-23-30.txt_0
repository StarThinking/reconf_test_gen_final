reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805594078-172.17.0.4-1597141524215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42140,DS-9c3b94ed-4a9d-4c45-9d4b-791ee73107c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-2875c642-8419-408c-a5d1-8e2ead18c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-efce292e-86c1-4227-a7ed-1484d38fde3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-7d4db527-3370-4143-baac-e1c0c2ccdbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-5e00e2df-f25f-42ba-a66c-3d7a1293de4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-4522913c-9999-49a7-b66b-6cf667842d03,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-3eb9acc0-5e28-4a1b-be33-743d2813a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-5819cab4-7e0f-4686-943e-dcebe552add5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805594078-172.17.0.4-1597141524215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42140,DS-9c3b94ed-4a9d-4c45-9d4b-791ee73107c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-2875c642-8419-408c-a5d1-8e2ead18c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-efce292e-86c1-4227-a7ed-1484d38fde3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-7d4db527-3370-4143-baac-e1c0c2ccdbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-5e00e2df-f25f-42ba-a66c-3d7a1293de4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-4522913c-9999-49a7-b66b-6cf667842d03,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-3eb9acc0-5e28-4a1b-be33-743d2813a2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-5819cab4-7e0f-4686-943e-dcebe552add5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41872918-172.17.0.4-1597142022412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37553,DS-ef4648d2-1703-4832-8019-fbe037f40f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-0ebebdb4-942d-4647-83ad-5b86fb098114,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-b8e48b62-f4d9-4c33-ad74-f66531e37ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-e32b6e1c-c2d5-4f83-b04a-5913a2c35d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-7c7c9e57-f8f1-4790-83d5-53fb2c3067d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-d845a948-4e54-4b62-9fbc-e4f020d4925f,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-f2d4abd3-212f-459e-9943-c136b197bc18,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-e9baf646-cb5b-4e7f-b168-262895267518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-41872918-172.17.0.4-1597142022412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37553,DS-ef4648d2-1703-4832-8019-fbe037f40f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-0ebebdb4-942d-4647-83ad-5b86fb098114,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-b8e48b62-f4d9-4c33-ad74-f66531e37ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-e32b6e1c-c2d5-4f83-b04a-5913a2c35d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-7c7c9e57-f8f1-4790-83d5-53fb2c3067d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-d845a948-4e54-4b62-9fbc-e4f020d4925f,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-f2d4abd3-212f-459e-9943-c136b197bc18,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-e9baf646-cb5b-4e7f-b168-262895267518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225926291-172.17.0.4-1597142062571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-71ff37f7-50b4-475e-a02e-5ae19f031fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-8adfb309-5f91-45af-81c9-5459edb56d18,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-576a2be1-809a-4572-8088-790b08928237,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-11e06b8a-25f0-45ae-a685-d18884dcaa03,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-fa0a1276-0864-42ea-8d53-d5b84f53a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-30e2df3e-bd41-4901-b895-2bfb7d0b4015,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-014a0621-3e8b-49b2-b48f-209c93ba7253,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-b9b1b6ad-a5c7-41a2-954f-1bbab26e66c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225926291-172.17.0.4-1597142062571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35857,DS-71ff37f7-50b4-475e-a02e-5ae19f031fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-8adfb309-5f91-45af-81c9-5459edb56d18,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-576a2be1-809a-4572-8088-790b08928237,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-11e06b8a-25f0-45ae-a685-d18884dcaa03,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-fa0a1276-0864-42ea-8d53-d5b84f53a0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-30e2df3e-bd41-4901-b895-2bfb7d0b4015,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-014a0621-3e8b-49b2-b48f-209c93ba7253,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-b9b1b6ad-a5c7-41a2-954f-1bbab26e66c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941278028-172.17.0.4-1597142353147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42860,DS-8c443653-d952-4f74-8828-557f0eecaea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-84647903-77d4-4180-b687-a2551f90e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-a49bba68-d45c-47a5-891d-f0b6c691fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-dd20e1a5-dc78-4a87-bf0e-74ae4c3b6fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-17049f20-cccd-45cf-a70c-964c4c22a52c,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-795412f2-eeb4-4255-b38c-7a63831df0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-bcbd191f-944b-4cc6-8338-48be9c27cb70,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-01e19a42-5fe0-42ba-98ef-ec14d9908c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941278028-172.17.0.4-1597142353147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42860,DS-8c443653-d952-4f74-8828-557f0eecaea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-84647903-77d4-4180-b687-a2551f90e34d,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-a49bba68-d45c-47a5-891d-f0b6c691fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-dd20e1a5-dc78-4a87-bf0e-74ae4c3b6fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-17049f20-cccd-45cf-a70c-964c4c22a52c,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-795412f2-eeb4-4255-b38c-7a63831df0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-bcbd191f-944b-4cc6-8338-48be9c27cb70,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-01e19a42-5fe0-42ba-98ef-ec14d9908c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718627879-172.17.0.4-1597142617248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38224,DS-385b7255-19c2-469f-93e3-cbfe91ea869f,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-f6ce650b-77a8-4c33-9cbd-e4ac5481a8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-9b010087-700d-454e-901f-bd6327497c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-d19a02e2-98e1-4881-ae34-ba5dd8743a74,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-34ff2690-f322-4622-a773-5ccec227285e,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-4673a8f5-70d1-40db-91b4-d976e3540bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-f0bcbd64-b543-4ab0-bb9b-54da64e2d495,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-4d296ecd-aee3-4100-a294-0f849dd58069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718627879-172.17.0.4-1597142617248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38224,DS-385b7255-19c2-469f-93e3-cbfe91ea869f,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-f6ce650b-77a8-4c33-9cbd-e4ac5481a8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-9b010087-700d-454e-901f-bd6327497c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-d19a02e2-98e1-4881-ae34-ba5dd8743a74,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-34ff2690-f322-4622-a773-5ccec227285e,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-4673a8f5-70d1-40db-91b4-d976e3540bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-f0bcbd64-b543-4ab0-bb9b-54da64e2d495,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-4d296ecd-aee3-4100-a294-0f849dd58069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006488200-172.17.0.4-1597143743684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-adf32660-7efd-43f9-9f89-5919a02804b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-071e57c0-ed23-43f4-bf36-4cf83fc103e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-a673ad8b-7565-446c-a5d4-01d934a0b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-67472fc1-470f-4e0b-a326-c4b4f63ad69b,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-9badfdc0-cf7f-49ca-b276-119e588ec054,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-d2b2e3e5-0cf1-4143-a1cc-b759dd61cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-04dc90f6-7b70-4ea2-b0fb-cb307bb08bca,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-fdf2f79a-babe-4911-93a0-4a2423a43e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1006488200-172.17.0.4-1597143743684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-adf32660-7efd-43f9-9f89-5919a02804b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-071e57c0-ed23-43f4-bf36-4cf83fc103e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-a673ad8b-7565-446c-a5d4-01d934a0b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-67472fc1-470f-4e0b-a326-c4b4f63ad69b,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-9badfdc0-cf7f-49ca-b276-119e588ec054,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-d2b2e3e5-0cf1-4143-a1cc-b759dd61cbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-04dc90f6-7b70-4ea2-b0fb-cb307bb08bca,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-fdf2f79a-babe-4911-93a0-4a2423a43e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563441166-172.17.0.4-1597143993933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40548,DS-79f0946c-cf7f-4b1c-bda6-34bf4df63231,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-d183a7c4-fefe-4813-8f5a-5b4c257796c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-bf987375-c2ab-49a0-9632-ebdaa12ebfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-8455954a-6c7d-47e9-9cac-a636805ffcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-ffa6adb0-2db1-4b70-97c7-1a2579bc4ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-9bfaaf82-9195-4397-bae1-2ad495bb612a,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-23e884b0-52d4-474e-92a8-10614485c87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-ced3e5da-ad0a-45e8-bef1-113f814b0f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563441166-172.17.0.4-1597143993933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40548,DS-79f0946c-cf7f-4b1c-bda6-34bf4df63231,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-d183a7c4-fefe-4813-8f5a-5b4c257796c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-bf987375-c2ab-49a0-9632-ebdaa12ebfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-8455954a-6c7d-47e9-9cac-a636805ffcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-ffa6adb0-2db1-4b70-97c7-1a2579bc4ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:33229,DS-9bfaaf82-9195-4397-bae1-2ad495bb612a,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-23e884b0-52d4-474e-92a8-10614485c87d,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-ced3e5da-ad0a-45e8-bef1-113f814b0f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510959468-172.17.0.4-1597144204156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-4e56b302-62ef-4f19-907f-3e3ef66b145b,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-a7c6ee26-5497-411c-a083-9767b785515f,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-b9d4857a-69d6-44d2-b3e3-5b1853c45832,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-ebc2830a-2558-4570-a091-efe763067dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-3dcb6ceb-f40e-42f4-9a96-b41f1adbd4af,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-91f2427c-1254-47d3-b271-15b5b3026ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-08976b9c-3c11-43e9-883b-763e6e121032,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-1dac553d-4a62-4015-8302-9086153722ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510959468-172.17.0.4-1597144204156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-4e56b302-62ef-4f19-907f-3e3ef66b145b,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-a7c6ee26-5497-411c-a083-9767b785515f,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-b9d4857a-69d6-44d2-b3e3-5b1853c45832,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-ebc2830a-2558-4570-a091-efe763067dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-3dcb6ceb-f40e-42f4-9a96-b41f1adbd4af,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-91f2427c-1254-47d3-b271-15b5b3026ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-08976b9c-3c11-43e9-883b-763e6e121032,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-1dac553d-4a62-4015-8302-9086153722ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358863347-172.17.0.4-1597144243883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39556,DS-3eaa8dba-7853-4b19-a3f7-896a67dda4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-eee955fd-2b92-4716-a642-ddad8ae8970b,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-398bcd88-a138-426c-af7e-e3cfd395cdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-d1f90689-ad3f-4a4c-b0e2-93bff9591983,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-ffb367f4-1b25-4d7d-b26d-29a2ac934045,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-9c215c26-3968-4368-bd63-3ebcd1089649,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-93fe6d82-beb7-48f7-bf6e-25cade7ddf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-e9f7964f-f13a-440f-9ade-276b55cb44b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358863347-172.17.0.4-1597144243883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39556,DS-3eaa8dba-7853-4b19-a3f7-896a67dda4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-eee955fd-2b92-4716-a642-ddad8ae8970b,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-398bcd88-a138-426c-af7e-e3cfd395cdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-d1f90689-ad3f-4a4c-b0e2-93bff9591983,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-ffb367f4-1b25-4d7d-b26d-29a2ac934045,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-9c215c26-3968-4368-bd63-3ebcd1089649,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-93fe6d82-beb7-48f7-bf6e-25cade7ddf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-e9f7964f-f13a-440f-9ade-276b55cb44b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049730425-172.17.0.4-1597144281561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37737,DS-b47a38c2-7510-417c-8dee-e7ad7a7aa05f,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-19d37d9f-9d18-4df7-9cdc-9c3e41fda354,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-0eb72b91-d3b2-4cf7-ab38-39636ed09d87,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-74397d2e-219a-41c4-bdba-68fa7ccaba82,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-65b07d1a-a126-4393-9e6f-07284d48a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-f117b5b0-5fcd-4bd0-a26e-50580db7e3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-1bbeea65-fee3-4d71-8af4-45e54ba43e40,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-2e60ac07-e193-4ff6-b658-5c7f165990d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049730425-172.17.0.4-1597144281561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37737,DS-b47a38c2-7510-417c-8dee-e7ad7a7aa05f,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-19d37d9f-9d18-4df7-9cdc-9c3e41fda354,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-0eb72b91-d3b2-4cf7-ab38-39636ed09d87,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-74397d2e-219a-41c4-bdba-68fa7ccaba82,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-65b07d1a-a126-4393-9e6f-07284d48a7ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-f117b5b0-5fcd-4bd0-a26e-50580db7e3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-1bbeea65-fee3-4d71-8af4-45e54ba43e40,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-2e60ac07-e193-4ff6-b658-5c7f165990d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232713117-172.17.0.4-1597144317441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-ecb151a8-c377-44a3-ba2e-44eaa3f8000e,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-17788691-ff90-48df-b83e-489d9928444f,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-dadef30a-838e-435f-a0d7-a287fdf40144,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-69ae8aee-7b12-4a6d-8b5d-41114a335d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-179636a7-733b-4562-b096-614d9783c354,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-006cf545-f8f4-4cdb-a235-4848d66e772e,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-5a4503cc-8547-4eb3-9c80-d95786573170,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-f9a4416a-e278-47d1-81c6-32849555d98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232713117-172.17.0.4-1597144317441:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38773,DS-ecb151a8-c377-44a3-ba2e-44eaa3f8000e,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-17788691-ff90-48df-b83e-489d9928444f,DISK], DatanodeInfoWithStorage[127.0.0.1:42886,DS-dadef30a-838e-435f-a0d7-a287fdf40144,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-69ae8aee-7b12-4a6d-8b5d-41114a335d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-179636a7-733b-4562-b096-614d9783c354,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-006cf545-f8f4-4cdb-a235-4848d66e772e,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-5a4503cc-8547-4eb3-9c80-d95786573170,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-f9a4416a-e278-47d1-81c6-32849555d98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694585560-172.17.0.4-1597144471646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-c915ee4b-efd5-432b-a303-13adf95040da,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-029ad2c7-0068-41ad-956c-f65886fec4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-9d4c857c-c6e2-4163-8dd7-39dd0ebbccea,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-66daf38b-b172-4a4b-a288-98ba05666faf,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-1182cc29-9e91-41d2-8ad5-a6e445383639,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-682ffb15-9b2d-4eab-aaa0-7045f259bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-41dd3a80-54d9-4f9c-bd5b-234ae731db37,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-2f5a6b0f-eb5e-4879-a066-b80dd98f38c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694585560-172.17.0.4-1597144471646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-c915ee4b-efd5-432b-a303-13adf95040da,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-029ad2c7-0068-41ad-956c-f65886fec4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-9d4c857c-c6e2-4163-8dd7-39dd0ebbccea,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-66daf38b-b172-4a4b-a288-98ba05666faf,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-1182cc29-9e91-41d2-8ad5-a6e445383639,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-682ffb15-9b2d-4eab-aaa0-7045f259bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-41dd3a80-54d9-4f9c-bd5b-234ae731db37,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-2f5a6b0f-eb5e-4879-a066-b80dd98f38c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937090312-172.17.0.4-1597144956073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-7429c097-693a-4429-9ebd-5553047e3bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-e578b977-bf83-49b7-8a01-0c24925226d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-a2446445-b678-4bff-aef0-cef49ab080e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-1ca000ab-60dc-4413-8a0f-d3726910ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-e05863a0-222a-4c07-afad-d26873482b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-e60d1027-09a4-4298-964a-eb2d8337277b,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-d2e48261-267f-47c0-a9ab-966df8194c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-591d8a50-084a-4b12-8dcd-f49aa5cb1049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937090312-172.17.0.4-1597144956073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-7429c097-693a-4429-9ebd-5553047e3bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-e578b977-bf83-49b7-8a01-0c24925226d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-a2446445-b678-4bff-aef0-cef49ab080e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-1ca000ab-60dc-4413-8a0f-d3726910ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-e05863a0-222a-4c07-afad-d26873482b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-e60d1027-09a4-4298-964a-eb2d8337277b,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-d2e48261-267f-47c0-a9ab-966df8194c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-591d8a50-084a-4b12-8dcd-f49aa5cb1049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959788806-172.17.0.4-1597144993250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37036,DS-5576c102-764d-4ad3-84cc-43392703d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-24c24905-e3e2-45dc-adce-7f0f1fbb0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-b7606af7-5dae-410f-90b5-11540ca5f57a,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-6b1a9b9d-de80-4cef-9dcf-5c80dc5f0728,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-decad796-d30e-4db9-8819-bc7364467697,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-a5c1a588-5afd-4d0d-9432-1723752b2232,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-5ef52922-757e-4d7c-8dd9-04ef0b430fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-a14a8f37-d221-4b61-9674-b2bc75a58c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1959788806-172.17.0.4-1597144993250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37036,DS-5576c102-764d-4ad3-84cc-43392703d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43479,DS-24c24905-e3e2-45dc-adce-7f0f1fbb0c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-b7606af7-5dae-410f-90b5-11540ca5f57a,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-6b1a9b9d-de80-4cef-9dcf-5c80dc5f0728,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-decad796-d30e-4db9-8819-bc7364467697,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-a5c1a588-5afd-4d0d-9432-1723752b2232,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-5ef52922-757e-4d7c-8dd9-04ef0b430fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-a14a8f37-d221-4b61-9674-b2bc75a58c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983224308-172.17.0.4-1597145615696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-6c816b64-1b9c-4d31-82ba-19543021f2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-e503e344-3765-453f-9b4e-52effbb148de,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-d8207e9e-5d00-4932-8129-b4e454a32cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-d3db2c43-f846-40c8-8383-2d6c91e238fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-ce2191ea-fd2e-41a4-8c51-11c2065f0103,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-ca41f95f-f56a-48b7-b927-f80e761128e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-95d8902d-699f-47a8-8d4b-7c9d15e9fbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-95025d75-84d8-4721-b51c-e3a24db805ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983224308-172.17.0.4-1597145615696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34564,DS-6c816b64-1b9c-4d31-82ba-19543021f2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-e503e344-3765-453f-9b4e-52effbb148de,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-d8207e9e-5d00-4932-8129-b4e454a32cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-d3db2c43-f846-40c8-8383-2d6c91e238fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-ce2191ea-fd2e-41a4-8c51-11c2065f0103,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-ca41f95f-f56a-48b7-b927-f80e761128e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-95d8902d-699f-47a8-8d4b-7c9d15e9fbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-95025d75-84d8-4721-b51c-e3a24db805ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756837791-172.17.0.4-1597145725280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-7953cdc3-bfd7-426b-af59-97dde48c4659,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-c99f97d7-705c-4db4-a663-09622693f819,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-8363a498-00bd-45a6-85bf-421fe7b0c45e,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-31673524-4a5b-437c-89bb-52af4cfe7f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-3c9ed40d-98c0-4b42-b820-62bc74c219c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-54cbdb76-5b4a-463b-b13c-4705bfb3fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-a04f5d6c-4b3a-4fe0-92a8-e7663a0cc484,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-5acbc09a-126c-4b86-855f-1edad4b7fbbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756837791-172.17.0.4-1597145725280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-7953cdc3-bfd7-426b-af59-97dde48c4659,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-c99f97d7-705c-4db4-a663-09622693f819,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-8363a498-00bd-45a6-85bf-421fe7b0c45e,DISK], DatanodeInfoWithStorage[127.0.0.1:39861,DS-31673524-4a5b-437c-89bb-52af4cfe7f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-3c9ed40d-98c0-4b42-b820-62bc74c219c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-54cbdb76-5b4a-463b-b13c-4705bfb3fc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-a04f5d6c-4b3a-4fe0-92a8-e7663a0cc484,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-5acbc09a-126c-4b86-855f-1edad4b7fbbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665396191-172.17.0.4-1597145990247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-2c476d58-412b-4534-858f-ca89ea87b681,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-0a25a29d-f14a-4215-99d0-97dd66be75a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-9401e21f-6f71-42d5-be75-606421608691,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-7b36ea5c-db9e-4197-8b01-51413caffa72,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-58c9b06e-a310-4ac7-8b65-2681adbd615e,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-e77fd73a-13ea-432e-9635-5d44478a0664,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-6a223993-47c7-4c68-8288-88567a05c67b,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-a873d023-13f8-495f-8a08-c12096f208c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1665396191-172.17.0.4-1597145990247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-2c476d58-412b-4534-858f-ca89ea87b681,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-0a25a29d-f14a-4215-99d0-97dd66be75a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-9401e21f-6f71-42d5-be75-606421608691,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-7b36ea5c-db9e-4197-8b01-51413caffa72,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-58c9b06e-a310-4ac7-8b65-2681adbd615e,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-e77fd73a-13ea-432e-9635-5d44478a0664,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-6a223993-47c7-4c68-8288-88567a05c67b,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-a873d023-13f8-495f-8a08-c12096f208c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077783952-172.17.0.4-1597146109209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-054a02a7-9c5d-4b26-b2b3-2965089c31d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-b5ae4578-dd39-4bb8-872e-2a1871a1b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-d69d1dbc-1491-4051-80d8-62ced6690548,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-4fcde4a6-60f8-48f7-9385-b04bb5fcf5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-30735a06-a2a3-4c61-8224-76d28eafa381,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-773357ec-83e9-4f3d-97fb-8774399ccedc,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-6ff3a0f5-69e4-44d0-a62c-905e27c98bad,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-11318571-2a9e-4bc0-80d1-6393433b3a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077783952-172.17.0.4-1597146109209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45012,DS-054a02a7-9c5d-4b26-b2b3-2965089c31d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-b5ae4578-dd39-4bb8-872e-2a1871a1b3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-d69d1dbc-1491-4051-80d8-62ced6690548,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-4fcde4a6-60f8-48f7-9385-b04bb5fcf5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-30735a06-a2a3-4c61-8224-76d28eafa381,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-773357ec-83e9-4f3d-97fb-8774399ccedc,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-6ff3a0f5-69e4-44d0-a62c-905e27c98bad,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-11318571-2a9e-4bc0-80d1-6393433b3a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093840736-172.17.0.4-1597146484616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-e8494a7b-cac3-47c8-b4f3-0b36057241da,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-56adf2ae-ef89-4a70-b1eb-de0c3896877f,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-9449142e-cf58-4d99-88cc-0191e6d7c63a,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-e2cb68a4-e71f-4979-9478-9a63f0cc9cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-b35731b1-3314-476c-b373-3e25dc1af8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-ce893f59-bd88-4fd8-b5b4-ccdad6cdabba,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-b1c8a812-2a15-439e-8283-1afa1a828ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-753a71e3-7843-49ec-a327-c08fb15c5ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093840736-172.17.0.4-1597146484616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-e8494a7b-cac3-47c8-b4f3-0b36057241da,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-56adf2ae-ef89-4a70-b1eb-de0c3896877f,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-9449142e-cf58-4d99-88cc-0191e6d7c63a,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-e2cb68a4-e71f-4979-9478-9a63f0cc9cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-b35731b1-3314-476c-b373-3e25dc1af8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-ce893f59-bd88-4fd8-b5b4-ccdad6cdabba,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-b1c8a812-2a15-439e-8283-1afa1a828ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-753a71e3-7843-49ec-a327-c08fb15c5ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5446
