reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225084056-172.17.0.5-1597179141029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-ccefc4fe-bcfe-4f97-9038-da6a87cd4119,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-385424a5-73b1-4b53-ae57-c7a82d29018a,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-39cffb38-7d4d-448d-b953-d6dde9c3a512,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-e72151ee-6f9a-4206-b1c9-75bc366dedc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-8d5c0c6a-dad5-4385-9dea-3010bacced1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-2cf1affe-c00b-415e-a04c-e56687bd129e,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-016694de-e4dc-4f40-8cfe-a91723d01556,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-e0d908f3-73c4-4897-8860-e7c28045415a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225084056-172.17.0.5-1597179141029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-ccefc4fe-bcfe-4f97-9038-da6a87cd4119,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-385424a5-73b1-4b53-ae57-c7a82d29018a,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-39cffb38-7d4d-448d-b953-d6dde9c3a512,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-e72151ee-6f9a-4206-b1c9-75bc366dedc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-8d5c0c6a-dad5-4385-9dea-3010bacced1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-2cf1affe-c00b-415e-a04c-e56687bd129e,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-016694de-e4dc-4f40-8cfe-a91723d01556,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-e0d908f3-73c4-4897-8860-e7c28045415a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864914610-172.17.0.5-1597179641722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-18bca273-071a-4775-8189-130e174e143c,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-9c996a1d-3244-4e1c-97c0-f37846f2506d,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-0540fcc4-b4dc-4929-ab0e-cb1b84ab23e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-f23003b6-8d12-4ad2-8c98-457bddac8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-c468a199-cb8b-4bec-ab61-a0968e663e81,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-51a51b58-3588-4809-9b4f-5f5365f145bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-582f9f08-9391-4063-b9f2-6f603c3121a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-7829908f-23fa-41fb-9578-7d3d4d321340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864914610-172.17.0.5-1597179641722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-18bca273-071a-4775-8189-130e174e143c,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-9c996a1d-3244-4e1c-97c0-f37846f2506d,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-0540fcc4-b4dc-4929-ab0e-cb1b84ab23e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-f23003b6-8d12-4ad2-8c98-457bddac8a54,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-c468a199-cb8b-4bec-ab61-a0968e663e81,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-51a51b58-3588-4809-9b4f-5f5365f145bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-582f9f08-9391-4063-b9f2-6f603c3121a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-7829908f-23fa-41fb-9578-7d3d4d321340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294424152-172.17.0.5-1597179864018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-ad9ab69f-7e19-4a66-8d7d-c1c85b0198c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-d5433ad5-ecbb-4f3b-8ff1-01705efc9507,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-384bc60c-5e54-4baf-9f94-0eb58386850d,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-7620d479-e247-4aa6-970f-0c3831b29612,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-c3279702-f260-4b16-8dc0-4e5323b483f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-944fd6bb-4c6d-415e-94f9-34d714392b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-ec7edff2-2672-4300-aae5-867ca12db360,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-06d3d71f-79ca-482f-91f3-a1863937168b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1294424152-172.17.0.5-1597179864018:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43948,DS-ad9ab69f-7e19-4a66-8d7d-c1c85b0198c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-d5433ad5-ecbb-4f3b-8ff1-01705efc9507,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-384bc60c-5e54-4baf-9f94-0eb58386850d,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-7620d479-e247-4aa6-970f-0c3831b29612,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-c3279702-f260-4b16-8dc0-4e5323b483f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-944fd6bb-4c6d-415e-94f9-34d714392b52,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-ec7edff2-2672-4300-aae5-867ca12db360,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-06d3d71f-79ca-482f-91f3-a1863937168b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272823979-172.17.0.5-1597180372373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37368,DS-94fc76dc-c31f-4802-b4a1-6e050e5a9cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-8648778c-95f1-441f-8285-736a013bac92,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-1c3abfd1-5019-4319-8d2e-26cc1b085b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-79cce0f5-d055-4082-b74b-18e0e879c24a,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-1bf6fb93-7620-4565-b52e-ab29bcd0ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-50a874b9-3d06-438d-9c0c-c4e1b5c455dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-62823d89-2436-44f3-a724-ad9108155d96,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-fe4d8100-4fa5-44ef-a73d-fad36dee98b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272823979-172.17.0.5-1597180372373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37368,DS-94fc76dc-c31f-4802-b4a1-6e050e5a9cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-8648778c-95f1-441f-8285-736a013bac92,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-1c3abfd1-5019-4319-8d2e-26cc1b085b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-79cce0f5-d055-4082-b74b-18e0e879c24a,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-1bf6fb93-7620-4565-b52e-ab29bcd0ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:41905,DS-50a874b9-3d06-438d-9c0c-c4e1b5c455dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-62823d89-2436-44f3-a724-ad9108155d96,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-fe4d8100-4fa5-44ef-a73d-fad36dee98b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523799289-172.17.0.5-1597180413352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37438,DS-820ee829-e5f6-475d-a54b-57b9d2c4d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-cdba5cf9-05e9-4759-b7a0-1b29f4a06572,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-08fc775f-7a0a-4354-ba96-3146106d494f,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-1cccbd78-092a-4b8c-8be3-1ce22a71cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-0a0918b8-9532-4044-b7d6-08084335158d,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-bf9cdc32-1c38-46c7-ac3d-9dcd4f0d2bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-cc09b492-8e25-4589-8637-2877bb74b8de,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-a41ede2f-dc03-4a35-821e-180a2f6e7dce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523799289-172.17.0.5-1597180413352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37438,DS-820ee829-e5f6-475d-a54b-57b9d2c4d2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-cdba5cf9-05e9-4759-b7a0-1b29f4a06572,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-08fc775f-7a0a-4354-ba96-3146106d494f,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-1cccbd78-092a-4b8c-8be3-1ce22a71cd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-0a0918b8-9532-4044-b7d6-08084335158d,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-bf9cdc32-1c38-46c7-ac3d-9dcd4f0d2bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-cc09b492-8e25-4589-8637-2877bb74b8de,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-a41ede2f-dc03-4a35-821e-180a2f6e7dce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515911612-172.17.0.5-1597180961197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-2cc3497f-53ea-4ae3-b012-fe34014e52a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-f0fbbc59-f3e1-4cf2-9017-3ceaf0a2e995,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-474b28e7-c6dc-4726-9b94-cf7be7535696,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-67a718db-0afb-4160-87da-16524031b117,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-1bf6c5bc-8342-4afd-9a73-fe772dcfd0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-7a9599d1-599d-4d5a-91a1-d402baf382c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-6ea0952a-63eb-48c6-8392-36cef8321cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-a88b9b76-800a-44da-9ec7-7c05e593177d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-515911612-172.17.0.5-1597180961197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39424,DS-2cc3497f-53ea-4ae3-b012-fe34014e52a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-f0fbbc59-f3e1-4cf2-9017-3ceaf0a2e995,DISK], DatanodeInfoWithStorage[127.0.0.1:39174,DS-474b28e7-c6dc-4726-9b94-cf7be7535696,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-67a718db-0afb-4160-87da-16524031b117,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-1bf6c5bc-8342-4afd-9a73-fe772dcfd0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-7a9599d1-599d-4d5a-91a1-d402baf382c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-6ea0952a-63eb-48c6-8392-36cef8321cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-a88b9b76-800a-44da-9ec7-7c05e593177d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220079447-172.17.0.5-1597181633042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-278471bf-cfe6-41e9-9c69-be4f49dee6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-1a890731-049b-4cf5-9505-bba66e880887,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-2fcb66f3-18ed-4443-ab21-fdb2c30f5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-80da2fd9-0758-4ed5-8d8e-97063dae816c,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-a5e56d53-5d2a-4332-b877-4a2f5f772193,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-1ed861bb-db5a-4a1c-93ec-67df8a5d4d66,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-fda33803-7bdd-421b-9744-eb3b7d826251,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-a7d7ca4e-6b8c-4a72-98a6-b67d506abf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220079447-172.17.0.5-1597181633042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-278471bf-cfe6-41e9-9c69-be4f49dee6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-1a890731-049b-4cf5-9505-bba66e880887,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-2fcb66f3-18ed-4443-ab21-fdb2c30f5f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-80da2fd9-0758-4ed5-8d8e-97063dae816c,DISK], DatanodeInfoWithStorage[127.0.0.1:43044,DS-a5e56d53-5d2a-4332-b877-4a2f5f772193,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-1ed861bb-db5a-4a1c-93ec-67df8a5d4d66,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-fda33803-7bdd-421b-9744-eb3b7d826251,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-a7d7ca4e-6b8c-4a72-98a6-b67d506abf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710373269-172.17.0.5-1597181792862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41747,DS-8accbf95-95eb-4231-8a36-452f6ca0b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-3079c3b1-5203-488c-b922-10cdde79a17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b7c07896-32da-44f8-9dd7-91b5024856f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-ae32a53e-e7b4-4c4b-9dcb-e6873620e8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-58d5efc3-9b66-4136-8136-8d5f5bde2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-c7d4bf94-74ef-45c0-a615-b9bb20851625,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-65559170-bd76-42d6-b7a2-99c5550c0e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-d77b8ef1-bf67-4106-897f-63f77e16ffc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-710373269-172.17.0.5-1597181792862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41747,DS-8accbf95-95eb-4231-8a36-452f6ca0b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-3079c3b1-5203-488c-b922-10cdde79a17a,DISK], DatanodeInfoWithStorage[127.0.0.1:45256,DS-b7c07896-32da-44f8-9dd7-91b5024856f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-ae32a53e-e7b4-4c4b-9dcb-e6873620e8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-58d5efc3-9b66-4136-8136-8d5f5bde2c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-c7d4bf94-74ef-45c0-a615-b9bb20851625,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-65559170-bd76-42d6-b7a2-99c5550c0e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-d77b8ef1-bf67-4106-897f-63f77e16ffc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146126588-172.17.0.5-1597181986414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35378,DS-4fb77402-531a-4755-aea2-c2dacfeabd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-3e3f2d75-dc18-455b-ab60-cb24bdd8b32a,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-6473e72f-285d-4526-b46e-0bcaab6bcfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-2897b03c-74ee-4b31-9f59-aba770a3196a,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-a2938ac6-620d-4b4f-b4b0-a673b662e002,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-2fe28116-6099-4b69-bafb-b85d16ca864f,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-77fb09ca-bb4e-45aa-8b48-e9322e0d1208,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-03ae2488-b4f6-4c63-9594-9ca5b93faa75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146126588-172.17.0.5-1597181986414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35378,DS-4fb77402-531a-4755-aea2-c2dacfeabd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-3e3f2d75-dc18-455b-ab60-cb24bdd8b32a,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-6473e72f-285d-4526-b46e-0bcaab6bcfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-2897b03c-74ee-4b31-9f59-aba770a3196a,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-a2938ac6-620d-4b4f-b4b0-a673b662e002,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-2fe28116-6099-4b69-bafb-b85d16ca864f,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-77fb09ca-bb4e-45aa-8b48-e9322e0d1208,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-03ae2488-b4f6-4c63-9594-9ca5b93faa75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163645997-172.17.0.5-1597182420292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44481,DS-85f8ba97-632a-42c5-98e0-34e492201bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-50a4e22b-50e0-48da-8325-b44efd5c5892,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-985a369b-7d9d-4e73-a9af-d6da32a76f33,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-7cf5a882-bac3-4457-b286-da04ae010a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-53ee8f0e-b44a-4837-b770-6f5a9a913745,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-21e02c31-8def-4f14-a59f-893c80c6acef,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-97da8a27-c5c8-4e4d-a5ef-6bbe60efa2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-e9c29fbc-a5f9-4240-91cc-9d8493ea3cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-163645997-172.17.0.5-1597182420292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44481,DS-85f8ba97-632a-42c5-98e0-34e492201bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-50a4e22b-50e0-48da-8325-b44efd5c5892,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-985a369b-7d9d-4e73-a9af-d6da32a76f33,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-7cf5a882-bac3-4457-b286-da04ae010a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-53ee8f0e-b44a-4837-b770-6f5a9a913745,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-21e02c31-8def-4f14-a59f-893c80c6acef,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-97da8a27-c5c8-4e4d-a5ef-6bbe60efa2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-e9c29fbc-a5f9-4240-91cc-9d8493ea3cd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995976079-172.17.0.5-1597182820440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-73292893-30bb-4fa2-9958-3f7c8daa71ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-3a88d618-8c50-43ac-b3a9-2041158b8264,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-6dc420da-231a-4f27-9efa-573d2dc331f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-aee2531d-524c-406a-8ced-7a5472f06011,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-69ec2a2d-88e2-4a95-8e7d-285b0e896aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-683f10d2-baad-4771-afa6-8c4ce33e21ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-c6401846-1ee9-44bd-aba3-f97f8320adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-2f89dfb0-8b76-4328-abae-a82104b7320a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995976079-172.17.0.5-1597182820440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41233,DS-73292893-30bb-4fa2-9958-3f7c8daa71ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-3a88d618-8c50-43ac-b3a9-2041158b8264,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-6dc420da-231a-4f27-9efa-573d2dc331f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-aee2531d-524c-406a-8ced-7a5472f06011,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-69ec2a2d-88e2-4a95-8e7d-285b0e896aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-683f10d2-baad-4771-afa6-8c4ce33e21ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-c6401846-1ee9-44bd-aba3-f97f8320adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-2f89dfb0-8b76-4328-abae-a82104b7320a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624994750-172.17.0.5-1597182943038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-1024a3c4-81bd-4ce5-9197-857cfcd17018,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-f651d3af-a509-4783-9f7e-9e423b2b5a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-e66f677b-8f4e-4236-9d93-4dc6030fd61e,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-d3cf0cfb-e3ce-40bd-8537-fc0bebb05338,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-1d359979-6ebc-4931-a030-6579a46a2e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-92a5c193-d71d-4674-b5d9-63c41d2cd9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-3dc99575-8a4e-450f-a05e-38c2a744b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-e2fb0fda-91d7-48fc-a67a-2817420b042a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1624994750-172.17.0.5-1597182943038:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37878,DS-1024a3c4-81bd-4ce5-9197-857cfcd17018,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-f651d3af-a509-4783-9f7e-9e423b2b5a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-e66f677b-8f4e-4236-9d93-4dc6030fd61e,DISK], DatanodeInfoWithStorage[127.0.0.1:37760,DS-d3cf0cfb-e3ce-40bd-8537-fc0bebb05338,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-1d359979-6ebc-4931-a030-6579a46a2e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-92a5c193-d71d-4674-b5d9-63c41d2cd9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-3dc99575-8a4e-450f-a05e-38c2a744b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-e2fb0fda-91d7-48fc-a67a-2817420b042a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370788310-172.17.0.5-1597183067805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-cd4764f6-5f7c-4996-a28a-18d27cb51343,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-11b58f37-bd23-4082-be07-bb4b4b1a3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-a3dae8da-5003-4200-986e-780890362210,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-40690e73-b355-4746-b437-f1a0737f4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-31ffbf4e-b91d-4796-b73b-242b00a276c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-f5f03086-62f1-41ea-b6d5-c28ece629781,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-fa56c5c0-0100-45d1-9033-bf9af316861b,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-9ee2ff28-25e4-41f1-8abd-3e7a11a1e94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370788310-172.17.0.5-1597183067805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35029,DS-cd4764f6-5f7c-4996-a28a-18d27cb51343,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-11b58f37-bd23-4082-be07-bb4b4b1a3be0,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-a3dae8da-5003-4200-986e-780890362210,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-40690e73-b355-4746-b437-f1a0737f4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-31ffbf4e-b91d-4796-b73b-242b00a276c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-f5f03086-62f1-41ea-b6d5-c28ece629781,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-fa56c5c0-0100-45d1-9033-bf9af316861b,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-9ee2ff28-25e4-41f1-8abd-3e7a11a1e94f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760859388-172.17.0.5-1597183113664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35729,DS-f5604e68-54e6-4e44-9615-87400a3c1fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a89ddf0a-5ce2-457a-a7f6-c1a35f55b344,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-5eac4e61-f351-4357-8481-eb60d9f01031,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-82118358-901a-47f5-9056-2edc0d0f34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-c8eb4ef4-cd79-49a1-8efb-7cac103fbd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-7325e324-33c2-4744-b553-072954455d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-7f292d01-e422-41cf-a24f-54342920cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-aea448b1-aff5-4e53-ac35-94489256b4ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-760859388-172.17.0.5-1597183113664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35729,DS-f5604e68-54e6-4e44-9615-87400a3c1fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a89ddf0a-5ce2-457a-a7f6-c1a35f55b344,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-5eac4e61-f351-4357-8481-eb60d9f01031,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-82118358-901a-47f5-9056-2edc0d0f34fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-c8eb4ef4-cd79-49a1-8efb-7cac103fbd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-7325e324-33c2-4744-b553-072954455d42,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-7f292d01-e422-41cf-a24f-54342920cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-aea448b1-aff5-4e53-ac35-94489256b4ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142475490-172.17.0.5-1597183953837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-9ac39d6f-34c4-447d-97e2-359bbe624e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-c46bd1e0-9264-4ac6-a2a7-a5e50ca249db,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-b5a5cb7d-4d3a-416f-89a0-8a8cbb88e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-3ea9e1d1-0359-4798-8f92-878afc5a2b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-6b6a0f25-e4ab-4aa8-8385-d74291932cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-6cf9957d-7042-4742-a3ff-689f1661a41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-09690003-7df6-48ac-ab9c-69f6513c0e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-1d5b9fde-54ee-4a5e-95b6-0130a6f6bbb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142475490-172.17.0.5-1597183953837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-9ac39d6f-34c4-447d-97e2-359bbe624e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-c46bd1e0-9264-4ac6-a2a7-a5e50ca249db,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-b5a5cb7d-4d3a-416f-89a0-8a8cbb88e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-3ea9e1d1-0359-4798-8f92-878afc5a2b91,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-6b6a0f25-e4ab-4aa8-8385-d74291932cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-6cf9957d-7042-4742-a3ff-689f1661a41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-09690003-7df6-48ac-ab9c-69f6513c0e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-1d5b9fde-54ee-4a5e-95b6-0130a6f6bbb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777242216-172.17.0.5-1597184260511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-e1018f81-4b56-4d5a-b95a-37ed10724c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-1b98d761-b303-445e-92a8-2f4210ca95f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-7122b90d-248e-4d47-9311-6a201fc22c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-ca8c981a-1815-43ad-8e37-d612f4327cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-0fb6237e-1bd1-462e-bece-7d3c966409d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-d70b1f4a-6bc9-4eec-9316-6ade5d9fc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-4a3fea51-4928-4dce-a0a2-33d3939f70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-bbdd8cc2-ebee-4f78-b02f-046ac7a7781d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1777242216-172.17.0.5-1597184260511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40626,DS-e1018f81-4b56-4d5a-b95a-37ed10724c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-1b98d761-b303-445e-92a8-2f4210ca95f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-7122b90d-248e-4d47-9311-6a201fc22c00,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-ca8c981a-1815-43ad-8e37-d612f4327cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-0fb6237e-1bd1-462e-bece-7d3c966409d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-d70b1f4a-6bc9-4eec-9316-6ade5d9fc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-4a3fea51-4928-4dce-a0a2-33d3939f70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-bbdd8cc2-ebee-4f78-b02f-046ac7a7781d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206280654-172.17.0.5-1597184897411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40771,DS-21318da1-71e8-4fd8-97f6-eaf255137d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-c1149f37-959a-4f00-90e9-3e8267437765,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-5c745135-e6a5-471b-b4ea-24b082a3c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-87a24bfc-bfed-4657-be5a-d8caeb3fa29a,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-0a73daad-d559-4dd7-801c-5ce6ee467719,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-39a85b32-7e01-4ff9-940b-bb1e1e3f2ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-47718e3c-e878-4200-9ec8-641264d26289,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-c0d75bf5-f24b-4893-9416-6f6227f9125c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206280654-172.17.0.5-1597184897411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40771,DS-21318da1-71e8-4fd8-97f6-eaf255137d17,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-c1149f37-959a-4f00-90e9-3e8267437765,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-5c745135-e6a5-471b-b4ea-24b082a3c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-87a24bfc-bfed-4657-be5a-d8caeb3fa29a,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-0a73daad-d559-4dd7-801c-5ce6ee467719,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-39a85b32-7e01-4ff9-940b-bb1e1e3f2ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-47718e3c-e878-4200-9ec8-641264d26289,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-c0d75bf5-f24b-4893-9416-6f6227f9125c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645033057-172.17.0.5-1597185040558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45366,DS-5e794ab4-a0e1-41a3-af76-f928b23076ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-3db1bdab-dbd3-46a8-b687-ad11ef336a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-6799e277-158e-4ae1-a1bc-d0b3258cc859,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-025f0237-7fe3-45e7-a9a5-f14b5b36ea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-e26f241e-c11c-428b-91c8-e28b5bd917d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-5d24a577-07c8-42fc-9c9a-27500c0cd0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-1e65515a-68b9-464e-815f-a17097522447,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-97d1d8b3-3c5d-4098-824a-744667ee3853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645033057-172.17.0.5-1597185040558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45366,DS-5e794ab4-a0e1-41a3-af76-f928b23076ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-3db1bdab-dbd3-46a8-b687-ad11ef336a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-6799e277-158e-4ae1-a1bc-d0b3258cc859,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-025f0237-7fe3-45e7-a9a5-f14b5b36ea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-e26f241e-c11c-428b-91c8-e28b5bd917d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-5d24a577-07c8-42fc-9c9a-27500c0cd0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-1e65515a-68b9-464e-815f-a17097522447,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-97d1d8b3-3c5d-4098-824a-744667ee3853,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 0
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785826633-172.17.0.5-1597185445666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46844,DS-bafb3272-631d-42f4-8814-b12b4cdb2028,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-03db7ecc-1d5d-41b2-9dff-5488b70f2564,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-765ecce7-972d-400d-893b-8cbf7411576a,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-9a6510b4-5dad-46de-8d47-7061dfcfe896,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-20faa5e4-ad76-4830-9161-480160e68acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-6173ea4d-c15f-49c6-8b99-95030bebe03d,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-d627728b-b60a-4125-ab9e-71b00a99350f,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-5d4c9b1c-a89b-48c2-b8f5-75b292f3dd9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-785826633-172.17.0.5-1597185445666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46844,DS-bafb3272-631d-42f4-8814-b12b4cdb2028,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-03db7ecc-1d5d-41b2-9dff-5488b70f2564,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-765ecce7-972d-400d-893b-8cbf7411576a,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-9a6510b4-5dad-46de-8d47-7061dfcfe896,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-20faa5e4-ad76-4830-9161-480160e68acc,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-6173ea4d-c15f-49c6-8b99-95030bebe03d,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-d627728b-b60a-4125-ab9e-71b00a99350f,DISK], DatanodeInfoWithStorage[127.0.0.1:33937,DS-5d4c9b1c-a89b-48c2-b8f5-75b292f3dd9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6675
