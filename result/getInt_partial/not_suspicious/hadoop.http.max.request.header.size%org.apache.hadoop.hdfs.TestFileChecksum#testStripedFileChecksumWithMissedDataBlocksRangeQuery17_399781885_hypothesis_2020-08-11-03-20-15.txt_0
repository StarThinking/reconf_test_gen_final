reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827319540-172.17.0.14-1597116434950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-67834265-f969-46d1-994f-484a1151ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-29fac249-cd80-4d7a-a7b6-d12c3e84a3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-7363782a-b415-4c8b-b372-bb7ba258a7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-fff825bf-b02b-49b0-9233-b55f054bd8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-944df147-41f1-418f-9c08-b102ca2a445c,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-2a1dffbd-d482-403f-b87a-fac42c64c0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-827b2412-1ac4-4858-9d29-7c55e55cef74,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-7411dd7a-51ce-46a8-a4ab-becb9afc586a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-827319540-172.17.0.14-1597116434950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36622,DS-67834265-f969-46d1-994f-484a1151ff1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-29fac249-cd80-4d7a-a7b6-d12c3e84a3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-7363782a-b415-4c8b-b372-bb7ba258a7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-fff825bf-b02b-49b0-9233-b55f054bd8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-944df147-41f1-418f-9c08-b102ca2a445c,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-2a1dffbd-d482-403f-b87a-fac42c64c0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-827b2412-1ac4-4858-9d29-7c55e55cef74,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-7411dd7a-51ce-46a8-a4ab-becb9afc586a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102759183-172.17.0.14-1597117038312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38277,DS-083993d8-8412-483f-b8d9-0ff0cc486941,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-c39cfaa3-8f96-4609-a14e-a6bf57e40e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4d0e200b-c259-4da6-8214-0d40a419dd24,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-1d4424d3-5138-4efc-ac2f-1bf63a79989a,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-ffb65622-d0b4-4c17-a349-3fc7d1cab31f,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-c9c09579-d8f0-4f1c-b070-b07635e27890,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-96b1a9da-ea04-4709-b7d7-b7c706ab8441,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-9e9590be-0cc8-4fe0-9a97-e4386fbd00bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102759183-172.17.0.14-1597117038312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38277,DS-083993d8-8412-483f-b8d9-0ff0cc486941,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-c39cfaa3-8f96-4609-a14e-a6bf57e40e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-4d0e200b-c259-4da6-8214-0d40a419dd24,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-1d4424d3-5138-4efc-ac2f-1bf63a79989a,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-ffb65622-d0b4-4c17-a349-3fc7d1cab31f,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-c9c09579-d8f0-4f1c-b070-b07635e27890,DISK], DatanodeInfoWithStorage[127.0.0.1:42035,DS-96b1a9da-ea04-4709-b7d7-b7c706ab8441,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-9e9590be-0cc8-4fe0-9a97-e4386fbd00bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292789912-172.17.0.14-1597118107902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-de7ef5ec-9d6f-4d31-bf99-1ffb0d38f019,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a8574595-d958-49e8-883a-18f6c88e893c,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-c45d81d5-f875-4674-9a08-3575c7100058,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-291ef621-2b71-4117-b304-c3491e9f0b17,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-b6cf29b0-02c3-47a6-b8c2-98562174cc65,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-d64f6d86-1eac-4c8a-a622-74ef64ca4c43,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-b7ddcbe6-87fb-4106-a1dd-8517f30707ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-5bb94bc3-f941-4c0e-8a77-600890873600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1292789912-172.17.0.14-1597118107902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46748,DS-de7ef5ec-9d6f-4d31-bf99-1ffb0d38f019,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a8574595-d958-49e8-883a-18f6c88e893c,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-c45d81d5-f875-4674-9a08-3575c7100058,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-291ef621-2b71-4117-b304-c3491e9f0b17,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-b6cf29b0-02c3-47a6-b8c2-98562174cc65,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-d64f6d86-1eac-4c8a-a622-74ef64ca4c43,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-b7ddcbe6-87fb-4106-a1dd-8517f30707ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-5bb94bc3-f941-4c0e-8a77-600890873600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864085965-172.17.0.14-1597118685311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-f1328d1d-56d1-45ff-9276-03cfa0cbb847,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-b323b151-1581-43d5-bee3-e3d15784852c,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-3e4751f9-4603-44de-b78e-e5fdbcb9b884,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-f4f97709-fa71-405f-9700-46576937d653,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-7f0030e1-fedb-489a-9c0b-63fb7df8df18,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-355f63f7-ab72-49e9-a6b9-595e8d204033,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-710d10d0-64ad-4445-bce5-013da4de15fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-83e031a8-0c18-4a89-a99e-e7d7810dc77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864085965-172.17.0.14-1597118685311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-f1328d1d-56d1-45ff-9276-03cfa0cbb847,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-b323b151-1581-43d5-bee3-e3d15784852c,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-3e4751f9-4603-44de-b78e-e5fdbcb9b884,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-f4f97709-fa71-405f-9700-46576937d653,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-7f0030e1-fedb-489a-9c0b-63fb7df8df18,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-355f63f7-ab72-49e9-a6b9-595e8d204033,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-710d10d0-64ad-4445-bce5-013da4de15fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-83e031a8-0c18-4a89-a99e-e7d7810dc77c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131708953-172.17.0.14-1597118752757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-e1b92e16-e620-4fcf-ad47-72e55c23b901,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-9026749e-eca9-4607-bab4-9cf9276e3eec,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-34e69a09-8246-44d1-ae8a-bb89053cb2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-0930d915-b52a-4392-9189-b849e9447302,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-bface449-5692-4fca-8da5-f32993dc3541,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-6186d4a9-7fb1-4eed-8c6f-de226681902e,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-995b4961-9193-49b3-ab9c-db179244e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-e10a06c9-f2c3-44d4-89c7-0681e7435c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131708953-172.17.0.14-1597118752757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34821,DS-e1b92e16-e620-4fcf-ad47-72e55c23b901,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-9026749e-eca9-4607-bab4-9cf9276e3eec,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-34e69a09-8246-44d1-ae8a-bb89053cb2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-0930d915-b52a-4392-9189-b849e9447302,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-bface449-5692-4fca-8da5-f32993dc3541,DISK], DatanodeInfoWithStorage[127.0.0.1:40197,DS-6186d4a9-7fb1-4eed-8c6f-de226681902e,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-995b4961-9193-49b3-ab9c-db179244e5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-e10a06c9-f2c3-44d4-89c7-0681e7435c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677249156-172.17.0.14-1597118897735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-784c0a48-4b1f-4ecd-8013-0c87e3563e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-90aac850-9cb4-4222-bc35-4ae33c6cb8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-5d89c0dc-82d8-41cd-8c85-b608d1481fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-a53fb045-bc2e-4898-9e9a-802de8fe399b,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-8aee3cb9-3556-475c-afce-f0d8014d2a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-c9863016-12c7-40f1-90c0-21bd6e81cf44,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-a1c1f6c8-c7db-4153-a5fa-29d93f7e5b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-2b647846-106b-40cd-8e66-25b174f6559d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677249156-172.17.0.14-1597118897735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-784c0a48-4b1f-4ecd-8013-0c87e3563e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-90aac850-9cb4-4222-bc35-4ae33c6cb8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-5d89c0dc-82d8-41cd-8c85-b608d1481fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-a53fb045-bc2e-4898-9e9a-802de8fe399b,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-8aee3cb9-3556-475c-afce-f0d8014d2a94,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-c9863016-12c7-40f1-90c0-21bd6e81cf44,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-a1c1f6c8-c7db-4153-a5fa-29d93f7e5b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-2b647846-106b-40cd-8e66-25b174f6559d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458782135-172.17.0.14-1597119696696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41079,DS-72a01c11-895b-4fcd-afb6-3949b5d0ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-2a6fd600-9a05-4baa-b757-1727522d3626,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-db0319bc-636f-419b-a4b3-a83125c21e80,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-6adba53b-629d-4e38-8cb2-0e9a0f839179,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-c6c05b69-7679-4f68-ad3a-5c1a6548c930,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-c32c0b37-42f9-4ec5-8b6d-877c07d261d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-1a8fc86e-9d24-4543-8c0c-671c8b331be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-6f1f28df-9b8b-48cc-86b2-a0b4a81cf63a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-458782135-172.17.0.14-1597119696696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41079,DS-72a01c11-895b-4fcd-afb6-3949b5d0ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-2a6fd600-9a05-4baa-b757-1727522d3626,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-db0319bc-636f-419b-a4b3-a83125c21e80,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-6adba53b-629d-4e38-8cb2-0e9a0f839179,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-c6c05b69-7679-4f68-ad3a-5c1a6548c930,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-c32c0b37-42f9-4ec5-8b6d-877c07d261d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-1a8fc86e-9d24-4543-8c0c-671c8b331be9,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-6f1f28df-9b8b-48cc-86b2-a0b4a81cf63a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466282804-172.17.0.14-1597119734596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39869,DS-f6a3293b-26bc-4482-89bb-e03cd43fb813,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-f036a691-bbc5-42a0-9f21-a70caef2c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-d3520e05-e55d-4e20-9afc-71da75cb6982,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-368989ad-56a9-485a-b225-860db6db93b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-33a1b0f9-51a7-4de4-8995-4aa6352a7da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-eb358412-34c2-4497-a51a-b03005bebf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-01ffe0e2-e36b-4c46-ac9f-46edf9271015,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-5c7e1f76-edf6-478f-9071-9cf2c20bd212,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466282804-172.17.0.14-1597119734596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39869,DS-f6a3293b-26bc-4482-89bb-e03cd43fb813,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-f036a691-bbc5-42a0-9f21-a70caef2c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-d3520e05-e55d-4e20-9afc-71da75cb6982,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-368989ad-56a9-485a-b225-860db6db93b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-33a1b0f9-51a7-4de4-8995-4aa6352a7da2,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-eb358412-34c2-4497-a51a-b03005bebf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-01ffe0e2-e36b-4c46-ac9f-46edf9271015,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-5c7e1f76-edf6-478f-9071-9cf2c20bd212,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839020159-172.17.0.14-1597120005514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44016,DS-11a336d6-3918-480a-a954-4901fb029519,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-87425d53-dcb6-4b10-9c00-763a39f79d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-00bddb0a-c11f-4957-9fc3-a8ec92e6142a,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-ad00d04e-5d51-44e6-8b5c-a77393269374,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-86dd0187-130a-4008-815e-e41a1b301fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-d152f947-5bad-4890-9730-8e9505ae84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-e7308eb9-847d-4ed0-a7d5-2d9e11ffdb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-ac4c8f20-d508-4218-92b6-5695eeb47fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839020159-172.17.0.14-1597120005514:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44016,DS-11a336d6-3918-480a-a954-4901fb029519,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-87425d53-dcb6-4b10-9c00-763a39f79d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-00bddb0a-c11f-4957-9fc3-a8ec92e6142a,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-ad00d04e-5d51-44e6-8b5c-a77393269374,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-86dd0187-130a-4008-815e-e41a1b301fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-d152f947-5bad-4890-9730-8e9505ae84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-e7308eb9-847d-4ed0-a7d5-2d9e11ffdb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-ac4c8f20-d508-4218-92b6-5695eeb47fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388207528-172.17.0.14-1597120074905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-a9d2e2e8-577d-4b6e-b403-35a57ad3298d,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-b6349a72-cab4-4373-a590-02befde3d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-094aa892-2e85-401b-9e4c-5ad1e4a63160,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-2400f386-7f84-40e0-a085-1e235e7f8d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-b811b5d4-02a1-47ef-9357-44170404d100,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-5e1a1d47-983e-4a82-803d-145937bbb2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-fd267880-4875-43bd-9e5d-82a57844d3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-998aa6b5-aabc-4ceb-904b-a333a1ca35b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388207528-172.17.0.14-1597120074905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-a9d2e2e8-577d-4b6e-b403-35a57ad3298d,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-b6349a72-cab4-4373-a590-02befde3d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-094aa892-2e85-401b-9e4c-5ad1e4a63160,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-2400f386-7f84-40e0-a085-1e235e7f8d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-b811b5d4-02a1-47ef-9357-44170404d100,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-5e1a1d47-983e-4a82-803d-145937bbb2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-fd267880-4875-43bd-9e5d-82a57844d3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-998aa6b5-aabc-4ceb-904b-a333a1ca35b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715166699-172.17.0.14-1597120385169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42433,DS-0c010209-1fe0-45cd-8cff-a479e6ee9dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-9e7c95bb-ab14-47e4-9b2a-51cd512739e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-14c85a0d-f8d8-46e5-90cc-d2d53ac4c273,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-c2594312-f565-4002-89ba-10f7dbb43b66,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-90402d2c-176d-41d9-ba39-0aab9731bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-90e90aea-7770-4fe8-bd41-af3c5a1b32d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-5f4f041c-8eb7-48f5-9c23-1d6f4a175e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-e68eddff-4f5c-4b06-aab2-2c0c516eac1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-715166699-172.17.0.14-1597120385169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42433,DS-0c010209-1fe0-45cd-8cff-a479e6ee9dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-9e7c95bb-ab14-47e4-9b2a-51cd512739e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-14c85a0d-f8d8-46e5-90cc-d2d53ac4c273,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-c2594312-f565-4002-89ba-10f7dbb43b66,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-90402d2c-176d-41d9-ba39-0aab9731bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-90e90aea-7770-4fe8-bd41-af3c5a1b32d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-5f4f041c-8eb7-48f5-9c23-1d6f4a175e94,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-e68eddff-4f5c-4b06-aab2-2c0c516eac1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847083658-172.17.0.14-1597120428505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44949,DS-f8c83001-05aa-49d5-9037-0514a0b9e041,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-2dd937c2-db13-46d2-9711-1101955309e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-f61d1641-6d8b-45f6-b1ec-0e99b9d76cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-7cb7a1a6-08e2-4608-94cc-4121eb436055,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-77ac15fb-9084-4cfa-97b6-cab122d82698,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-c9cad1a5-bc13-4fd4-80d5-53cedfcd5dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-711219a0-6515-40f3-ab02-791de7ea7f97,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-4f0da223-7b0c-4c65-8999-91e22aef851f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847083658-172.17.0.14-1597120428505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44949,DS-f8c83001-05aa-49d5-9037-0514a0b9e041,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-2dd937c2-db13-46d2-9711-1101955309e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-f61d1641-6d8b-45f6-b1ec-0e99b9d76cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-7cb7a1a6-08e2-4608-94cc-4121eb436055,DISK], DatanodeInfoWithStorage[127.0.0.1:44144,DS-77ac15fb-9084-4cfa-97b6-cab122d82698,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-c9cad1a5-bc13-4fd4-80d5-53cedfcd5dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-711219a0-6515-40f3-ab02-791de7ea7f97,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-4f0da223-7b0c-4c65-8999-91e22aef851f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404302513-172.17.0.14-1597120538940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41301,DS-a01a20a6-39af-4972-b370-aa48aa1b59db,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-14426eff-92f1-452a-8577-73a867d73593,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-40a989b0-6a69-4c28-b551-b9a165b13654,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-498a4686-9d54-4f32-9dfe-04b4dd5a4b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-7f15172f-7725-4e41-a88f-07926169ba39,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-0eb61028-4634-42ff-b536-28a2f31ce656,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-042ac45c-b15a-4405-a207-7e22e2a7e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-60e8f73d-8b4a-426b-9981-8901a2048270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404302513-172.17.0.14-1597120538940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41301,DS-a01a20a6-39af-4972-b370-aa48aa1b59db,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-14426eff-92f1-452a-8577-73a867d73593,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-40a989b0-6a69-4c28-b551-b9a165b13654,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-498a4686-9d54-4f32-9dfe-04b4dd5a4b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-7f15172f-7725-4e41-a88f-07926169ba39,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-0eb61028-4634-42ff-b536-28a2f31ce656,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-042ac45c-b15a-4405-a207-7e22e2a7e4de,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-60e8f73d-8b4a-426b-9981-8901a2048270,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963111047-172.17.0.14-1597120659872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44994,DS-ad809a99-8f88-4d96-9351-2b9eb0dfa43a,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-b47825e1-6509-4e47-b33a-baaddf7d7829,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-2e3014ce-ad39-4812-83c8-0c91ba224bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-c641f408-814c-4e1d-92fc-dd8a5666cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-45aef7ee-92a6-41e9-adf7-dcb5b7bbdc21,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-65cdedb1-2d95-4b25-b82c-2c2dc92504e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-c37b5d20-82dc-45cf-b7d2-de3960e9dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-64ebff87-5dd8-412f-a71d-83382b8c351c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963111047-172.17.0.14-1597120659872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44994,DS-ad809a99-8f88-4d96-9351-2b9eb0dfa43a,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-b47825e1-6509-4e47-b33a-baaddf7d7829,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-2e3014ce-ad39-4812-83c8-0c91ba224bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-c641f408-814c-4e1d-92fc-dd8a5666cde5,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-45aef7ee-92a6-41e9-adf7-dcb5b7bbdc21,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-65cdedb1-2d95-4b25-b82c-2c2dc92504e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-c37b5d20-82dc-45cf-b7d2-de3960e9dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-64ebff87-5dd8-412f-a71d-83382b8c351c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962797925-172.17.0.14-1597120755699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-7f4dcdb5-b8f8-428c-9311-e95b8b015799,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-89bbf7ad-3b9a-4658-bcd6-ed93cb0e7597,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-eb24ac0d-f7a7-4ab6-8cda-4237d9df5f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-70d92bc6-ae54-43d0-ade5-82497f71748f,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-0c6f31bc-5a9d-4041-8550-7f7bbc82e5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-683c2c10-1361-4c95-83ea-df0b57605034,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-96935ab2-12eb-4da4-8603-f53823fb77b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-fdd8d33a-6c98-4e6e-85af-9ecd11b979c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962797925-172.17.0.14-1597120755699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39308,DS-7f4dcdb5-b8f8-428c-9311-e95b8b015799,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-89bbf7ad-3b9a-4658-bcd6-ed93cb0e7597,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-eb24ac0d-f7a7-4ab6-8cda-4237d9df5f71,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-70d92bc6-ae54-43d0-ade5-82497f71748f,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-0c6f31bc-5a9d-4041-8550-7f7bbc82e5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-683c2c10-1361-4c95-83ea-df0b57605034,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-96935ab2-12eb-4da4-8603-f53823fb77b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-fdd8d33a-6c98-4e6e-85af-9ecd11b979c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:NameNode
v1: 131072
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850324275-172.17.0.14-1597120989191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-9222fe36-a63d-4d20-8cf6-79085f293d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-696ecf62-506a-450e-85cd-9474c1cb9563,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-9bc464f2-a5fd-4860-b450-123f1f5a4ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-5f31bef8-8021-4fed-8a77-1deb200ac03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-d8012723-348d-4e12-8e9f-96d4ee720a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-4a2bdd1a-2f74-439f-aad0-9af91057c593,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-3fb89e1b-c3fd-4874-8f00-2a8ec2e3d7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-f4f43cbf-01fe-44ee-93ae-df432b4fbe35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850324275-172.17.0.14-1597120989191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41767,DS-9222fe36-a63d-4d20-8cf6-79085f293d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-696ecf62-506a-450e-85cd-9474c1cb9563,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-9bc464f2-a5fd-4860-b450-123f1f5a4ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-5f31bef8-8021-4fed-8a77-1deb200ac03a,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-d8012723-348d-4e12-8e9f-96d4ee720a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-4a2bdd1a-2f74-439f-aad0-9af91057c593,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-3fb89e1b-c3fd-4874-8f00-2a8ec2e3d7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-f4f43cbf-01fe-44ee-93ae-df432b4fbe35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5286
