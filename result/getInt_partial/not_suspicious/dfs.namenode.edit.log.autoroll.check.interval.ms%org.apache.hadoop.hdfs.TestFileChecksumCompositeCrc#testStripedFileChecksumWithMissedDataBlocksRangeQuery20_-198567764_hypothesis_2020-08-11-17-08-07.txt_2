reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929330710-172.17.0.17-1597165828699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-24fd7d21-edf2-4dda-9eb6-53ae6ab5cd56,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-696998cd-e08d-4612-bce2-79dcda86b390,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-99477622-d51e-48d8-a928-27cc17a2c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-4ab14bb9-b6ac-4743-b05d-6d75ad704245,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-643b3901-ba9a-4a9f-b0b7-c13a57efb6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-7ddef03f-e1e9-49cb-ba92-65feb1a3cbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-d7959c5b-7a6f-4737-a984-6f95cb169565,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-7a088095-86b7-4d3c-83cd-29e8b762811f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929330710-172.17.0.17-1597165828699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34869,DS-24fd7d21-edf2-4dda-9eb6-53ae6ab5cd56,DISK], DatanodeInfoWithStorage[127.0.0.1:39612,DS-696998cd-e08d-4612-bce2-79dcda86b390,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-99477622-d51e-48d8-a928-27cc17a2c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-4ab14bb9-b6ac-4743-b05d-6d75ad704245,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-643b3901-ba9a-4a9f-b0b7-c13a57efb6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-7ddef03f-e1e9-49cb-ba92-65feb1a3cbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-d7959c5b-7a6f-4737-a984-6f95cb169565,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-7a088095-86b7-4d3c-83cd-29e8b762811f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500343016-172.17.0.17-1597165969032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-9e9eb7dd-5cad-4c5a-9ac2-740828521dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-a32d536e-61d2-44e9-b7ff-c180fb6e7347,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-625e09b2-e543-4ec3-90e6-e3f539d5db22,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-b3634283-b732-41b4-baa2-f250f19f1013,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-3ac8207b-873a-4cae-8646-66cb6946742d,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-c3f1d29b-b217-4360-a3cf-8519834630e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-1941eaf4-c3eb-4abb-899a-83700dc5e0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-04312573-148b-460a-ac3d-ae09dd929459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-500343016-172.17.0.17-1597165969032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37143,DS-9e9eb7dd-5cad-4c5a-9ac2-740828521dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-a32d536e-61d2-44e9-b7ff-c180fb6e7347,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-625e09b2-e543-4ec3-90e6-e3f539d5db22,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-b3634283-b732-41b4-baa2-f250f19f1013,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-3ac8207b-873a-4cae-8646-66cb6946742d,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-c3f1d29b-b217-4360-a3cf-8519834630e9,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-1941eaf4-c3eb-4abb-899a-83700dc5e0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-04312573-148b-460a-ac3d-ae09dd929459,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538943580-172.17.0.17-1597166004076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43373,DS-d1fa123e-db7b-4dbe-b000-b1ed25060c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-aeb877e6-4107-4b50-aba3-eb187d498ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-b195cce3-b688-47f1-a52e-56769921bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-107e6f31-759e-434d-856a-d9c25d81f31c,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-ab8e48ce-0192-4a5d-a7c7-d0e765182680,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-66f9c358-7239-4fb3-b70c-b63179ef0df3,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-78bd6556-918f-4293-832c-e40e9478e616,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-a783eab4-6d44-42ec-9c04-4c5f767469f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1538943580-172.17.0.17-1597166004076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43373,DS-d1fa123e-db7b-4dbe-b000-b1ed25060c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-aeb877e6-4107-4b50-aba3-eb187d498ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-b195cce3-b688-47f1-a52e-56769921bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-107e6f31-759e-434d-856a-d9c25d81f31c,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-ab8e48ce-0192-4a5d-a7c7-d0e765182680,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-66f9c358-7239-4fb3-b70c-b63179ef0df3,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-78bd6556-918f-4293-832c-e40e9478e616,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-a783eab4-6d44-42ec-9c04-4c5f767469f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852838842-172.17.0.17-1597166067886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-8f10044c-6f31-4d25-87b6-0b4a5394d512,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-a9c68c2a-b26d-498e-97b9-5471bbe910c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-b3118b11-81cc-41f7-870d-169b83708d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-e0f23cfd-ad8c-4b77-8000-f922a77c257f,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-e77d44e0-00fa-4de4-a917-b28783953846,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-fbe22f43-caae-4657-a58d-46a2aa18363a,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-2c7330bd-08e8-40a8-a566-fdf034af71fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-fe6fad78-0f69-42bf-9f13-6a674b7e0fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-852838842-172.17.0.17-1597166067886:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-8f10044c-6f31-4d25-87b6-0b4a5394d512,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-a9c68c2a-b26d-498e-97b9-5471bbe910c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-b3118b11-81cc-41f7-870d-169b83708d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-e0f23cfd-ad8c-4b77-8000-f922a77c257f,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-e77d44e0-00fa-4de4-a917-b28783953846,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-fbe22f43-caae-4657-a58d-46a2aa18363a,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-2c7330bd-08e8-40a8-a566-fdf034af71fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-fe6fad78-0f69-42bf-9f13-6a674b7e0fe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457476526-172.17.0.17-1597166207016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-7ae59179-ec99-411f-ad91-98704a00da8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-d2690f03-2fce-4c83-a18d-99c793952c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-4507e992-5ec6-47b1-8fb8-96938a1de608,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-2b38b645-2f2b-4be6-9e71-625e0892b236,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-4ac308b9-bcea-4bca-87dd-00cf21f9a3be,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-41e50ebc-ff7f-46d6-8959-ad04e8208bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-4ca6aef4-84d0-4e40-954c-5e4e9aa6b69a,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-959faea9-75ee-4303-9fff-629146ac7631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457476526-172.17.0.17-1597166207016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46403,DS-7ae59179-ec99-411f-ad91-98704a00da8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-d2690f03-2fce-4c83-a18d-99c793952c81,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-4507e992-5ec6-47b1-8fb8-96938a1de608,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-2b38b645-2f2b-4be6-9e71-625e0892b236,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-4ac308b9-bcea-4bca-87dd-00cf21f9a3be,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-41e50ebc-ff7f-46d6-8959-ad04e8208bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-4ca6aef4-84d0-4e40-954c-5e4e9aa6b69a,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-959faea9-75ee-4303-9fff-629146ac7631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645359875-172.17.0.17-1597166314468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-9bbdc719-117d-4d0c-bf6c-705f4449966c,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-7d2c7402-4af5-442f-99da-ef2a81c829bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-2515b01c-82f2-4291-9c75-55cf0df1d67d,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-606fd579-b0f2-43c4-9beb-bb4ca6eebd24,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-d6c2e0c4-4cb3-42d0-bb9f-d1594862078f,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-fae0bbb0-ad0e-40e4-89b6-748e4711bb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-4f5608f2-c5cd-4897-8d2b-83766add4ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-b9d589ca-ef54-47c9-9355-fd8535483cb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1645359875-172.17.0.17-1597166314468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33688,DS-9bbdc719-117d-4d0c-bf6c-705f4449966c,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-7d2c7402-4af5-442f-99da-ef2a81c829bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-2515b01c-82f2-4291-9c75-55cf0df1d67d,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-606fd579-b0f2-43c4-9beb-bb4ca6eebd24,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-d6c2e0c4-4cb3-42d0-bb9f-d1594862078f,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-fae0bbb0-ad0e-40e4-89b6-748e4711bb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-4f5608f2-c5cd-4897-8d2b-83766add4ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-b9d589ca-ef54-47c9-9355-fd8535483cb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357463077-172.17.0.17-1597167071993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-f027032a-aca7-4cda-916b-f38c9c24ef10,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-5c72ac8b-41ef-45fb-9773-68b510d4e07f,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-276c2ad5-e665-4acc-9a9c-db97c318ccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-c00929a8-638c-4dec-80a5-b0ca96e73618,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-7441f330-b89c-467d-8fa6-5080c4d98a78,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-1ca41512-d542-4ad3-8081-4b9ed5bb11f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-4d425f88-db82-48cd-9576-02b62a2223b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-3c76ea09-8884-4339-b7bb-133b9e484cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-357463077-172.17.0.17-1597167071993:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-f027032a-aca7-4cda-916b-f38c9c24ef10,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-5c72ac8b-41ef-45fb-9773-68b510d4e07f,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-276c2ad5-e665-4acc-9a9c-db97c318ccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35350,DS-c00929a8-638c-4dec-80a5-b0ca96e73618,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-7441f330-b89c-467d-8fa6-5080c4d98a78,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-1ca41512-d542-4ad3-8081-4b9ed5bb11f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-4d425f88-db82-48cd-9576-02b62a2223b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-3c76ea09-8884-4339-b7bb-133b9e484cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227967954-172.17.0.17-1597167173458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44594,DS-5824024b-c3fa-49b2-977b-35816144b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-7c4cc9b3-8bdc-4811-939c-51c069c1619d,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-a6334cf0-f422-43a1-95c3-0b72f4326a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-e8eae592-58a1-4587-8ed0-70a9e9e88e70,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-9813da9a-c557-4765-8324-f1ccdecc291b,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-a0359f67-cf1e-4924-8199-e4e8a06f8557,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-c16321b6-c005-4fdf-8eb1-cfdc6b8f1953,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-6ed0cf25-2741-4dc5-9506-78cd97439729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-227967954-172.17.0.17-1597167173458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44594,DS-5824024b-c3fa-49b2-977b-35816144b6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-7c4cc9b3-8bdc-4811-939c-51c069c1619d,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-a6334cf0-f422-43a1-95c3-0b72f4326a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-e8eae592-58a1-4587-8ed0-70a9e9e88e70,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-9813da9a-c557-4765-8324-f1ccdecc291b,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-a0359f67-cf1e-4924-8199-e4e8a06f8557,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-c16321b6-c005-4fdf-8eb1-cfdc6b8f1953,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-6ed0cf25-2741-4dc5-9506-78cd97439729,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641458159-172.17.0.17-1597167643165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-e9cab7d4-91a8-4316-b860-c087a1594ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-f6b0bb5d-0485-464d-83ac-e96bcd2498d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-6c5e3ec6-735b-4215-a691-5fb9be609155,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-1012119b-62f3-4462-8a68-9cd237f98361,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-1246461a-5f82-48d9-bc77-51656ac2ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-560a7743-2558-414b-b07c-6010e557f433,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-e106a8a5-f551-4fd8-8bf5-74d9ab0e5350,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-e4796134-80a6-4438-af06-cf3324eae5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641458159-172.17.0.17-1597167643165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-e9cab7d4-91a8-4316-b860-c087a1594ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-f6b0bb5d-0485-464d-83ac-e96bcd2498d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-6c5e3ec6-735b-4215-a691-5fb9be609155,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-1012119b-62f3-4462-8a68-9cd237f98361,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-1246461a-5f82-48d9-bc77-51656ac2ea10,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-560a7743-2558-414b-b07c-6010e557f433,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-e106a8a5-f551-4fd8-8bf5-74d9ab0e5350,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-e4796134-80a6-4438-af06-cf3324eae5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724635491-172.17.0.17-1597167682480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-c3bf8e99-7679-4079-97d6-493a5d4673c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-4b8145ff-231c-497d-875e-fd9be3223f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-cffd5c92-a9df-40a7-a91c-3fc0eb520cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-d26c3ace-4bc5-4a0a-be1a-25853cd3798c,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-8cbcea28-86d9-43f5-8ba5-9144cc92d564,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-3b79c8da-0265-4b27-8b2f-8708d5341e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-88367d25-8e73-4e5a-bde5-0dc1d821f376,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-ae2b336d-3aba-43f8-b3ff-4736efd22477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724635491-172.17.0.17-1597167682480:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-c3bf8e99-7679-4079-97d6-493a5d4673c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-4b8145ff-231c-497d-875e-fd9be3223f46,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-cffd5c92-a9df-40a7-a91c-3fc0eb520cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-d26c3ace-4bc5-4a0a-be1a-25853cd3798c,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-8cbcea28-86d9-43f5-8ba5-9144cc92d564,DISK], DatanodeInfoWithStorage[127.0.0.1:39541,DS-3b79c8da-0265-4b27-8b2f-8708d5341e67,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-88367d25-8e73-4e5a-bde5-0dc1d821f376,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-ae2b336d-3aba-43f8-b3ff-4736efd22477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751495470-172.17.0.17-1597168199924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-af91098a-fb06-4b00-9ffb-8cc879533d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-cf6578c6-319b-4846-9d47-8f8690e4ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-540fb3eb-c4ec-480a-8e90-593b2264798e,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-fa6cb70d-7cd7-4f4a-904a-9d171e1e3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-304c3f67-f082-4496-810f-bb6eff3efde6,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-5922b332-d4cb-4604-83ca-8ab42c6cde6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-696373d9-383d-4230-b6e4-1d9a550810ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-fef6954b-c50c-445b-b290-63fd027f0ff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751495470-172.17.0.17-1597168199924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-af91098a-fb06-4b00-9ffb-8cc879533d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-cf6578c6-319b-4846-9d47-8f8690e4ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-540fb3eb-c4ec-480a-8e90-593b2264798e,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-fa6cb70d-7cd7-4f4a-904a-9d171e1e3b87,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-304c3f67-f082-4496-810f-bb6eff3efde6,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-5922b332-d4cb-4604-83ca-8ab42c6cde6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43514,DS-696373d9-383d-4230-b6e4-1d9a550810ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-fef6954b-c50c-445b-b290-63fd027f0ff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597245034-172.17.0.17-1597168305645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36966,DS-ac8471c4-71c4-44b4-90d4-960da9ca5a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-f07c2ab6-2162-4d4d-966c-dd50a44f6771,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-b82cb11b-bcd5-499e-97ea-a103cfd81366,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-eb793751-ba56-41ea-96cb-11cefbfa8bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-110f70ba-fec4-4d4f-97fd-e8a77ca4003f,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-fe5605f7-064d-4ef5-bf22-772c41eb8c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-2d815dba-e8cb-4796-9997-c370a2434065,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-45470bbc-79ed-43a1-8db2-4bb42344e3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597245034-172.17.0.17-1597168305645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36966,DS-ac8471c4-71c4-44b4-90d4-960da9ca5a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-f07c2ab6-2162-4d4d-966c-dd50a44f6771,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-b82cb11b-bcd5-499e-97ea-a103cfd81366,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-eb793751-ba56-41ea-96cb-11cefbfa8bad,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-110f70ba-fec4-4d4f-97fd-e8a77ca4003f,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-fe5605f7-064d-4ef5-bf22-772c41eb8c48,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-2d815dba-e8cb-4796-9997-c370a2434065,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-45470bbc-79ed-43a1-8db2-4bb42344e3c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829993816-172.17.0.17-1597168869522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-a4f05195-7aa3-46a7-b7fc-1099e73d13e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-edfbbc4a-4a5a-4dd7-8f22-bac1fb10c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-412ead7a-a857-43aa-acbc-2d4cb4f88db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-31d37930-fc80-4e8b-9e27-06817512d3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-77495bea-2627-47dc-b188-2210838e920b,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-0ea40a67-a9b0-4dda-a90b-7a8f05f1d038,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-623ecee4-ea70-4094-a0f3-09ae547f6bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-666b75a3-8ab7-4423-8aad-ba1981c50d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829993816-172.17.0.17-1597168869522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-a4f05195-7aa3-46a7-b7fc-1099e73d13e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-edfbbc4a-4a5a-4dd7-8f22-bac1fb10c06a,DISK], DatanodeInfoWithStorage[127.0.0.1:40916,DS-412ead7a-a857-43aa-acbc-2d4cb4f88db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-31d37930-fc80-4e8b-9e27-06817512d3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-77495bea-2627-47dc-b188-2210838e920b,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-0ea40a67-a9b0-4dda-a90b-7a8f05f1d038,DISK], DatanodeInfoWithStorage[127.0.0.1:41109,DS-623ecee4-ea70-4094-a0f3-09ae547f6bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-666b75a3-8ab7-4423-8aad-ba1981c50d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-425345957-172.17.0.17-1597168997420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41923,DS-a551c674-d618-4c32-9fbe-18a694233d33,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-e9de23cb-3394-4522-8e82-d73018b063df,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-83c5e932-8f30-41cb-b068-34311e171932,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-56129431-d48e-4883-81d6-2d971d3d8db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-680ddccd-61d6-4da5-ba2f-1261cf83f490,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-2ab9cb03-419b-44fd-b802-e4be74af5eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-9d04eec3-e9c5-444d-b6c9-072a2e00d831,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-794d2b71-921b-4f07-ad54-46eddaa15171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-425345957-172.17.0.17-1597168997420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41923,DS-a551c674-d618-4c32-9fbe-18a694233d33,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-e9de23cb-3394-4522-8e82-d73018b063df,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-83c5e932-8f30-41cb-b068-34311e171932,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-56129431-d48e-4883-81d6-2d971d3d8db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-680ddccd-61d6-4da5-ba2f-1261cf83f490,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-2ab9cb03-419b-44fd-b802-e4be74af5eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-9d04eec3-e9c5-444d-b6c9-072a2e00d831,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-794d2b71-921b-4f07-ad54-46eddaa15171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350904615-172.17.0.17-1597169069023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39078,DS-82d1d4db-15e6-4149-be26-3e71606510b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-dee116b8-fc2d-4589-9c70-cf0aef6205b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-07770775-2b07-4038-b88b-5ea64ef41f40,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-2ecf0863-1b43-4c28-ae4a-5838f896da63,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-bac8aa8f-b4b3-41e3-bba2-d271904c3db2,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-74e6aace-12c7-4130-aa1b-5210aba434eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-96b689d3-d998-42be-b5ce-686eb2c49230,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-1474e149-346c-4002-b571-54848b4143ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-350904615-172.17.0.17-1597169069023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39078,DS-82d1d4db-15e6-4149-be26-3e71606510b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-dee116b8-fc2d-4589-9c70-cf0aef6205b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-07770775-2b07-4038-b88b-5ea64ef41f40,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-2ecf0863-1b43-4c28-ae4a-5838f896da63,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-bac8aa8f-b4b3-41e3-bba2-d271904c3db2,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-74e6aace-12c7-4130-aa1b-5210aba434eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-96b689d3-d998-42be-b5ce-686eb2c49230,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-1474e149-346c-4002-b571-54848b4143ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252853612-172.17.0.17-1597169165795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45748,DS-402c1853-89aa-4919-bad5-4f2215e2c449,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-5e39e029-6c06-48c6-8eff-8b06e077941d,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-ae352bee-5d38-4791-99b2-b5c7816f107e,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-c102cdfd-869f-4e19-a32c-4a15709ec8af,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-624a7f94-7efe-4787-ad93-1efea903536b,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-6174798c-4f17-498a-abca-808634502092,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-0bf286a2-6bea-46e0-880a-79b238e55b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-e1dd11d0-5038-4b1b-9211-2a1c46e37cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1252853612-172.17.0.17-1597169165795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45748,DS-402c1853-89aa-4919-bad5-4f2215e2c449,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-5e39e029-6c06-48c6-8eff-8b06e077941d,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-ae352bee-5d38-4791-99b2-b5c7816f107e,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-c102cdfd-869f-4e19-a32c-4a15709ec8af,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-624a7f94-7efe-4787-ad93-1efea903536b,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-6174798c-4f17-498a-abca-808634502092,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-0bf286a2-6bea-46e0-880a-79b238e55b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-e1dd11d0-5038-4b1b-9211-2a1c46e37cc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952824516-172.17.0.17-1597169233350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-e53bd42f-e99a-46c7-9dfd-d4ae4ec6e305,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-6911974c-a618-40fc-8c77-d775e9144245,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-761afb21-b317-4715-91b3-ac2f2b0f9023,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-79403f5b-beb1-4685-8660-fd659158eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-0cbabdba-0a1c-4f43-92ca-becea0cdbe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-19c5b088-d0d1-4ee0-9fee-9a8daa734a47,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-b2acbc91-d5d3-4100-8dd7-bf719ee5e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-1e14cfe9-de45-4f86-a5f3-93b513cff31b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952824516-172.17.0.17-1597169233350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33210,DS-e53bd42f-e99a-46c7-9dfd-d4ae4ec6e305,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-6911974c-a618-40fc-8c77-d775e9144245,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-761afb21-b317-4715-91b3-ac2f2b0f9023,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-79403f5b-beb1-4685-8660-fd659158eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-0cbabdba-0a1c-4f43-92ca-becea0cdbe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-19c5b088-d0d1-4ee0-9fee-9a8daa734a47,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-b2acbc91-d5d3-4100-8dd7-bf719ee5e1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-1e14cfe9-de45-4f86-a5f3-93b513cff31b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864755983-172.17.0.17-1597169501538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34414,DS-1e25918d-61c1-40ad-a372-7c183d444ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-42ce2351-9d94-4e67-9979-a7146f1ee80e,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-f426879c-be15-4cde-b77b-835f800a3e43,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-6b44d5e8-e8f7-4f5c-807b-c81dd199e2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-1256ab0b-a15a-41be-8ad5-396bd7b8cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-7a361627-885f-4973-900f-7273c1e0b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-e7b7f70e-2c11-4786-a655-e07379005b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-be0213b2-e82e-4855-96a2-dec130477d9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864755983-172.17.0.17-1597169501538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34414,DS-1e25918d-61c1-40ad-a372-7c183d444ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-42ce2351-9d94-4e67-9979-a7146f1ee80e,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-f426879c-be15-4cde-b77b-835f800a3e43,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-6b44d5e8-e8f7-4f5c-807b-c81dd199e2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-1256ab0b-a15a-41be-8ad5-396bd7b8cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-7a361627-885f-4973-900f-7273c1e0b46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-e7b7f70e-2c11-4786-a655-e07379005b63,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-be0213b2-e82e-4855-96a2-dec130477d9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751369745-172.17.0.17-1597169636758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44074,DS-24278945-4291-4277-a6f0-4ed98ee9b71c,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-c9c88279-d43d-4254-b1a0-6f5c64770a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-41c13731-243a-47a8-9924-fac1e57a660e,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-a41ff6b4-aa9b-4a0f-85ab-a4a6dcfa697f,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-0433136c-0257-4eed-8db9-e7a0d9127c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-e73f537c-1e76-4bd8-9a11-0ed28ea75e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-4886d5ef-23c7-44b3-ae02-b3d9aaf55277,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-bbc934a4-16c9-4dfc-90f6-107140ec0764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1751369745-172.17.0.17-1597169636758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44074,DS-24278945-4291-4277-a6f0-4ed98ee9b71c,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-c9c88279-d43d-4254-b1a0-6f5c64770a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37152,DS-41c13731-243a-47a8-9924-fac1e57a660e,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-a41ff6b4-aa9b-4a0f-85ab-a4a6dcfa697f,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-0433136c-0257-4eed-8db9-e7a0d9127c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-e73f537c-1e76-4bd8-9a11-0ed28ea75e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-4886d5ef-23c7-44b3-ae02-b3d9aaf55277,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-bbc934a4-16c9-4dfc-90f6-107140ec0764,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930597410-172.17.0.17-1597169828471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39275,DS-d0757ad9-4419-4807-aaaf-d9d1aa547416,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-881cffcf-4e8f-47e4-b3c9-d49e6ccc8526,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-af853e7b-1bb2-4a3e-8ebf-6a301d065ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-5f224749-09b6-468d-9bcd-825484749777,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-aacbd353-f073-48d9-a3c8-d1302c2ab6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-607f9d37-8a72-49b9-bff5-2e72abf6728b,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-be71d772-dca2-42ac-b1cc-82beec54ff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-24fc6765-0230-44a7-9c0b-ca7a0c884179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1930597410-172.17.0.17-1597169828471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39275,DS-d0757ad9-4419-4807-aaaf-d9d1aa547416,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-881cffcf-4e8f-47e4-b3c9-d49e6ccc8526,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-af853e7b-1bb2-4a3e-8ebf-6a301d065ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-5f224749-09b6-468d-9bcd-825484749777,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-aacbd353-f073-48d9-a3c8-d1302c2ab6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-607f9d37-8a72-49b9-bff5-2e72abf6728b,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-be71d772-dca2-42ac-b1cc-82beec54ff7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-24fc6765-0230-44a7-9c0b-ca7a0c884179,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469034223-172.17.0.17-1597170071113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36538,DS-eabb1058-5629-4acb-aaca-e8f10751224a,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-89ba85c2-479a-4362-aa9a-34c7d5a0bf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-b069ad34-d1b8-46e8-ba20-19616c2146c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-465e16f2-8338-42ff-a77d-3cb8c5527738,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-5d093a75-f0aa-430b-8bed-abf848e90d25,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-42000123-f8fb-40ad-aa1c-a3ddac11a7de,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-bc1ee2ad-1dee-4e89-b1b0-02b73de4ef48,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-dc179d2b-acec-4657-a570-77eaa7f318a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-469034223-172.17.0.17-1597170071113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36538,DS-eabb1058-5629-4acb-aaca-e8f10751224a,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-89ba85c2-479a-4362-aa9a-34c7d5a0bf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-b069ad34-d1b8-46e8-ba20-19616c2146c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-465e16f2-8338-42ff-a77d-3cb8c5527738,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-5d093a75-f0aa-430b-8bed-abf848e90d25,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-42000123-f8fb-40ad-aa1c-a3ddac11a7de,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-bc1ee2ad-1dee-4e89-b1b0-02b73de4ef48,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-dc179d2b-acec-4657-a570-77eaa7f318a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39072605-172.17.0.17-1597170318940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36702,DS-061d5dad-6ad8-4b78-a02f-0a5aa591b9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-1bb23934-ab3d-4e79-92db-e7f27a071ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-6ada86be-9180-4ffd-9154-749825f694d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-a918ba25-cc2b-4751-a468-1afd7bf73f62,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-ed1dc031-f961-41c5-a57b-11f0bc83b742,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-86621f72-bca1-47be-ab38-2ce99f302a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-b106ca7e-d7f6-4f68-9ef1-28e0ed211b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-033dcf39-e43c-4021-9711-71670e91fe85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39072605-172.17.0.17-1597170318940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36702,DS-061d5dad-6ad8-4b78-a02f-0a5aa591b9d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-1bb23934-ab3d-4e79-92db-e7f27a071ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-6ada86be-9180-4ffd-9154-749825f694d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-a918ba25-cc2b-4751-a468-1afd7bf73f62,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-ed1dc031-f961-41c5-a57b-11f0bc83b742,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-86621f72-bca1-47be-ab38-2ce99f302a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-b106ca7e-d7f6-4f68-9ef1-28e0ed211b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-033dcf39-e43c-4021-9711-71670e91fe85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186368914-172.17.0.17-1597170510157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43765,DS-cd970cf0-9284-4c85-bf7b-a22d40968a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-011e88dc-20e9-425d-a124-baf7c92cf39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-63ce8c62-b954-4a5b-a7b8-ea0703496d59,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-e6904211-a873-409d-8539-12a222eb320c,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-9d1a95a9-0282-4f1f-90b9-8361df279022,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-b25886fc-0eae-4d5d-8de6-05976f74f127,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-5413b6da-eb16-477b-a5d8-75e807c90001,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-35725e9b-1d9c-4df9-a92b-aea04b3aef5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186368914-172.17.0.17-1597170510157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43765,DS-cd970cf0-9284-4c85-bf7b-a22d40968a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-011e88dc-20e9-425d-a124-baf7c92cf39c,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-63ce8c62-b954-4a5b-a7b8-ea0703496d59,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-e6904211-a873-409d-8539-12a222eb320c,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-9d1a95a9-0282-4f1f-90b9-8361df279022,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-b25886fc-0eae-4d5d-8de6-05976f74f127,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-5413b6da-eb16-477b-a5d8-75e807c90001,DISK], DatanodeInfoWithStorage[127.0.0.1:42842,DS-35725e9b-1d9c-4df9-a92b-aea04b3aef5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edit.log.autoroll.check.interval.ms
component: hdfs:NameNode
v1: 300
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097530459-172.17.0.17-1597171046850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43176,DS-720293c6-092e-450e-87c2-e503fc865809,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-47655583-80ba-4f5d-82b1-5845e2a9a7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-ea0e079f-dfc8-4552-a613-20debdb111a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-b9f45a0d-f5fd-43a1-bb9f-09a609cd2ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-36f2c010-2d1e-4ff8-a534-09cbe953f878,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-c8c05a72-a3ef-4050-b9b2-d3307cca8dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-64b9ec46-dd9e-42e5-a97a-0764efc7ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-dfe225a1-3f17-4164-89cc-777d4670744a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097530459-172.17.0.17-1597171046850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43176,DS-720293c6-092e-450e-87c2-e503fc865809,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-47655583-80ba-4f5d-82b1-5845e2a9a7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-ea0e079f-dfc8-4552-a613-20debdb111a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-b9f45a0d-f5fd-43a1-bb9f-09a609cd2ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-36f2c010-2d1e-4ff8-a534-09cbe953f878,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-c8c05a72-a3ef-4050-b9b2-d3307cca8dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-64b9ec46-dd9e-42e5-a97a-0764efc7ec60,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-dfe225a1-3f17-4164-89cc-777d4670744a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5383
