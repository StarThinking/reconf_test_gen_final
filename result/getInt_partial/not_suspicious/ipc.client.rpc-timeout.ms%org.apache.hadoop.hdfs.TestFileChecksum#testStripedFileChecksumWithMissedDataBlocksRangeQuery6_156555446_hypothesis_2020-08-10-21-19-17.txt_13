reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370243464-172.17.0.20-1597094562015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33909,DS-d526dc66-9e16-48e4-a430-e611f8d2b529,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-0e7003bf-7bc7-44bb-8bd0-0a2645210d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-b82d1427-952f-4323-a0a7-b1e416b6604a,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-acf595a9-8545-447f-86b6-4817bd7878d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-a7c5cb71-21bf-4428-a701-424ac97dfabb,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-3611ee26-401e-4e51-a90a-e81c500ee449,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-ccbe3e19-9d1d-490f-aee9-ca86203c24df,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-5ec53c07-53af-4327-af23-71fb4c9d16d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370243464-172.17.0.20-1597094562015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33909,DS-d526dc66-9e16-48e4-a430-e611f8d2b529,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-0e7003bf-7bc7-44bb-8bd0-0a2645210d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-b82d1427-952f-4323-a0a7-b1e416b6604a,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-acf595a9-8545-447f-86b6-4817bd7878d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-a7c5cb71-21bf-4428-a701-424ac97dfabb,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-3611ee26-401e-4e51-a90a-e81c500ee449,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-ccbe3e19-9d1d-490f-aee9-ca86203c24df,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-5ec53c07-53af-4327-af23-71fb4c9d16d5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556135352-172.17.0.20-1597094891447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-24524798-09ae-46db-8335-d58254b79872,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-86114664-3f98-425b-b0ca-32f9cfc459f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-0646b977-a91c-402c-8de3-94a5aead595a,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-7b8a560c-eea4-4d1b-89fb-c01bc8ccbc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-b43fb8c4-16d8-41be-900a-f8954f48347b,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-2ac89e15-a924-40e6-bc0e-af3c716455c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-513a5b50-9df7-41f0-8938-2ff8926a0232,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-82d26986-5e68-439e-af4b-7c2fa73dadac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556135352-172.17.0.20-1597094891447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34448,DS-24524798-09ae-46db-8335-d58254b79872,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-86114664-3f98-425b-b0ca-32f9cfc459f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-0646b977-a91c-402c-8de3-94a5aead595a,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-7b8a560c-eea4-4d1b-89fb-c01bc8ccbc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-b43fb8c4-16d8-41be-900a-f8954f48347b,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-2ac89e15-a924-40e6-bc0e-af3c716455c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-513a5b50-9df7-41f0-8938-2ff8926a0232,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-82d26986-5e68-439e-af4b-7c2fa73dadac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347597827-172.17.0.20-1597095716637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39634,DS-2403148a-ef7f-484d-9495-f8951d2ba3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-09271cf3-9ba3-4a14-85bf-bba6d5037eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-1dce49c3-6782-4fe7-8595-e8a10e9ee29a,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-a5ecb0c6-24af-4ff2-b962-cd7deaa0ed80,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-ab8217b6-3525-4a7a-af7f-53fac2400ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-08619122-a247-4309-badd-ded015defbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-1ad962b8-5e1e-4441-822a-802b53379468,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-e0d50358-4a8c-4bb6-a2f3-90e6d931ba11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347597827-172.17.0.20-1597095716637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39634,DS-2403148a-ef7f-484d-9495-f8951d2ba3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-09271cf3-9ba3-4a14-85bf-bba6d5037eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-1dce49c3-6782-4fe7-8595-e8a10e9ee29a,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-a5ecb0c6-24af-4ff2-b962-cd7deaa0ed80,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-ab8217b6-3525-4a7a-af7f-53fac2400ade,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-08619122-a247-4309-badd-ded015defbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-1ad962b8-5e1e-4441-822a-802b53379468,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-e0d50358-4a8c-4bb6-a2f3-90e6d931ba11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663873819-172.17.0.20-1597095830865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46235,DS-c28e6ab4-06ac-4acf-bf32-d05135ee0e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-b59db7e5-f59b-427e-af4a-d7452a1d4371,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-90b71c7f-6945-4f60-8e8e-701b9c8cd5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-999340a7-9ee4-498d-92f1-84ef105f6c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-e3650055-c708-4851-adfe-788f07b9575f,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-5a2bec92-a17a-4688-86e9-d491b35c5fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-744af47a-7dcf-4242-944c-355e02914c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-cbfe4214-a4cb-4af9-a03e-d704d5b9f00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-663873819-172.17.0.20-1597095830865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46235,DS-c28e6ab4-06ac-4acf-bf32-d05135ee0e05,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-b59db7e5-f59b-427e-af4a-d7452a1d4371,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-90b71c7f-6945-4f60-8e8e-701b9c8cd5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-999340a7-9ee4-498d-92f1-84ef105f6c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-e3650055-c708-4851-adfe-788f07b9575f,DISK], DatanodeInfoWithStorage[127.0.0.1:36955,DS-5a2bec92-a17a-4688-86e9-d491b35c5fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-744af47a-7dcf-4242-944c-355e02914c47,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-cbfe4214-a4cb-4af9-a03e-d704d5b9f00e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335980743-172.17.0.20-1597095895874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39894,DS-ec882b05-64ad-45e0-9f95-2d2c106aa302,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-12bfafd9-fcde-4f5c-a5ef-79cbe5d2b528,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-e777515f-cb0b-4bce-85ac-85c7dacd813d,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-4650d1b1-ac2b-4ad4-b2d4-e84f1e03bc28,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-0ff6785e-53dd-4d33-8100-d703a2cbee25,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-ab737413-e333-424e-a3af-1cb26f61b76e,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-4e11243b-3f28-4d83-bb4f-165c36301a32,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-4e497881-b492-4389-bb74-dec4ca3dced1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335980743-172.17.0.20-1597095895874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39894,DS-ec882b05-64ad-45e0-9f95-2d2c106aa302,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-12bfafd9-fcde-4f5c-a5ef-79cbe5d2b528,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-e777515f-cb0b-4bce-85ac-85c7dacd813d,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-4650d1b1-ac2b-4ad4-b2d4-e84f1e03bc28,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-0ff6785e-53dd-4d33-8100-d703a2cbee25,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-ab737413-e333-424e-a3af-1cb26f61b76e,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-4e11243b-3f28-4d83-bb4f-165c36301a32,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-4e497881-b492-4389-bb74-dec4ca3dced1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697390467-172.17.0.20-1597095967629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39886,DS-c0fe8573-1910-43b1-9540-f426407135f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-b9b9f58e-72ad-4aa9-9319-e312d5bd5ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-99da53b4-5479-469c-be5e-814d9f103ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-567c05c4-94f8-495c-857c-e9f27af4ba30,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-58b2f1b3-c408-4b4a-ab04-b1071bcaf99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-f84faf6a-559f-4a8e-a461-5c8bceea379b,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-37a5e908-6716-4541-a20b-170dc8566db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-5a67ee58-6f00-4c64-8358-a0eea5f41af7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697390467-172.17.0.20-1597095967629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39886,DS-c0fe8573-1910-43b1-9540-f426407135f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-b9b9f58e-72ad-4aa9-9319-e312d5bd5ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-99da53b4-5479-469c-be5e-814d9f103ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-567c05c4-94f8-495c-857c-e9f27af4ba30,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-58b2f1b3-c408-4b4a-ab04-b1071bcaf99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-f84faf6a-559f-4a8e-a461-5c8bceea379b,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-37a5e908-6716-4541-a20b-170dc8566db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-5a67ee58-6f00-4c64-8358-a0eea5f41af7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044528229-172.17.0.20-1597096518958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-2b0abd5d-f4cc-4834-9513-a8105ad7a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-17bb4cd2-b163-421b-82ff-ab5c513cb07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-a207008e-a50e-4bfd-94a0-a2dc43d06a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-6d5aec92-b012-4b21-90b5-3aef379f88b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-b171f186-2421-4eea-a26d-c21364d8177a,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-2b5f8fdd-e079-4a3d-ab5f-6d07b15cf786,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-502c117a-bd9a-46d5-8df5-c73a452a0270,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-c6557f85-201d-458b-a722-979ae1d5e6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044528229-172.17.0.20-1597096518958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38423,DS-2b0abd5d-f4cc-4834-9513-a8105ad7a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:45435,DS-17bb4cd2-b163-421b-82ff-ab5c513cb07a,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-a207008e-a50e-4bfd-94a0-a2dc43d06a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-6d5aec92-b012-4b21-90b5-3aef379f88b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-b171f186-2421-4eea-a26d-c21364d8177a,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-2b5f8fdd-e079-4a3d-ab5f-6d07b15cf786,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-502c117a-bd9a-46d5-8df5-c73a452a0270,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-c6557f85-201d-458b-a722-979ae1d5e6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214904021-172.17.0.20-1597096561385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-21066332-ea50-4670-a922-948d6e675947,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-2a231505-455a-4b25-b6bc-a30015ab8949,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-cffa38ef-1d46-4f56-beaa-e24a7cb354c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-2863f1e3-87ac-44ff-a581-917afc2d1005,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-82f473a0-0ad5-452c-94ea-39431928a253,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-80b47449-e5b1-4e5e-8414-4ca8d104bb87,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-497276a7-4d76-43c2-9726-16303a4ca193,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-7bed6db2-f7db-45d6-a602-1c3f07e18953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214904021-172.17.0.20-1597096561385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38879,DS-21066332-ea50-4670-a922-948d6e675947,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-2a231505-455a-4b25-b6bc-a30015ab8949,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-cffa38ef-1d46-4f56-beaa-e24a7cb354c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-2863f1e3-87ac-44ff-a581-917afc2d1005,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-82f473a0-0ad5-452c-94ea-39431928a253,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-80b47449-e5b1-4e5e-8414-4ca8d104bb87,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-497276a7-4d76-43c2-9726-16303a4ca193,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-7bed6db2-f7db-45d6-a602-1c3f07e18953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290324977-172.17.0.20-1597096752340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39273,DS-42e807bd-9a23-4804-933f-a90ebd887609,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-99896d7d-3f83-44b8-be7d-371d40c0818b,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-40cdc6e1-e528-42db-aa3b-5984570223ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-7c0f9212-1bfd-443a-9a02-b2c39b136633,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-7ac3f9e0-1f3a-4d16-8477-b18eb201b313,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-d12cac4d-873f-40c7-8832-509578efdf29,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-ded6dcc2-63c1-482d-8b2a-69f1b6d6e299,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-ad6fe2d9-a6c7-48bf-8467-311bc1268e0f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290324977-172.17.0.20-1597096752340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39273,DS-42e807bd-9a23-4804-933f-a90ebd887609,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-99896d7d-3f83-44b8-be7d-371d40c0818b,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-40cdc6e1-e528-42db-aa3b-5984570223ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-7c0f9212-1bfd-443a-9a02-b2c39b136633,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-7ac3f9e0-1f3a-4d16-8477-b18eb201b313,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-d12cac4d-873f-40c7-8832-509578efdf29,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-ded6dcc2-63c1-482d-8b2a-69f1b6d6e299,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-ad6fe2d9-a6c7-48bf-8467-311bc1268e0f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092700848-172.17.0.20-1597096785331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-63fc93be-4e8b-41d9-aaa3-d573abac0663,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-f3188fe7-d6db-4832-9d2a-e3fbf56937df,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-044701f9-ba77-4dc2-b5c1-6fafd5d0088a,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-a9629668-d6c8-4d5e-a510-dbf05ca4ff81,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-a1d01bd0-85bd-405a-add5-b63f3d3c5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-aa982d86-b4a7-4477-a58f-61d45d83b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-aed3f6cb-7c61-425e-b4c7-fad29b8af010,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-728c4b51-46ca-44f8-89bb-d9b3113abb33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092700848-172.17.0.20-1597096785331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46255,DS-63fc93be-4e8b-41d9-aaa3-d573abac0663,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-f3188fe7-d6db-4832-9d2a-e3fbf56937df,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-044701f9-ba77-4dc2-b5c1-6fafd5d0088a,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-a9629668-d6c8-4d5e-a510-dbf05ca4ff81,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-a1d01bd0-85bd-405a-add5-b63f3d3c5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-aa982d86-b4a7-4477-a58f-61d45d83b9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-aed3f6cb-7c61-425e-b4c7-fad29b8af010,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-728c4b51-46ca-44f8-89bb-d9b3113abb33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228549287-172.17.0.20-1597097724394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-c7c3c6b9-b946-4b36-a941-ee83475b5c06,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-13b08cb8-367d-4d05-983f-05a3de8043cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-716c0876-917a-4377-aaf3-3ae75235b3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-10370171-4d69-4c08-b239-7b2aa1d43943,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-e1b3c317-aa77-4097-b66a-37144eff2e87,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-6db1f2fe-8f5e-449e-ade1-0b178e427549,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-8655eb2d-5161-43c0-a433-f150cdc1a3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-288250d9-c3b2-4638-b22a-7a32e227e9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228549287-172.17.0.20-1597097724394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-c7c3c6b9-b946-4b36-a941-ee83475b5c06,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-13b08cb8-367d-4d05-983f-05a3de8043cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-716c0876-917a-4377-aaf3-3ae75235b3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-10370171-4d69-4c08-b239-7b2aa1d43943,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-e1b3c317-aa77-4097-b66a-37144eff2e87,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-6db1f2fe-8f5e-449e-ade1-0b178e427549,DISK], DatanodeInfoWithStorage[127.0.0.1:45401,DS-8655eb2d-5161-43c0-a433-f150cdc1a3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-288250d9-c3b2-4638-b22a-7a32e227e9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564709332-172.17.0.20-1597097791478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38495,DS-1ddcff65-6bcf-4f67-b623-2cf7eb32e963,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-5ef028e1-8d3d-4c60-82e6-f4192731c674,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-e9c2d211-3f66-4fe6-9329-dcf3f548ae76,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-82ddcb1b-edc4-49c0-9848-d71d28247ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-5dc5cb13-da2d-495c-abc2-e5d68ae99651,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-8f5e6996-7bfa-47f3-a96f-660f34c61cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-d4fc9468-2c81-499f-beaa-ea769a4537cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-657b4a40-0a47-4e36-9212-87ddd4a9d734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564709332-172.17.0.20-1597097791478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38495,DS-1ddcff65-6bcf-4f67-b623-2cf7eb32e963,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-5ef028e1-8d3d-4c60-82e6-f4192731c674,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-e9c2d211-3f66-4fe6-9329-dcf3f548ae76,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-82ddcb1b-edc4-49c0-9848-d71d28247ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-5dc5cb13-da2d-495c-abc2-e5d68ae99651,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-8f5e6996-7bfa-47f3-a96f-660f34c61cda,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-d4fc9468-2c81-499f-beaa-ea769a4537cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-657b4a40-0a47-4e36-9212-87ddd4a9d734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314176346-172.17.0.20-1597098128062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38963,DS-45be89f0-9156-43ee-a8d9-31d8f1a1414d,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-363da4a8-6ad7-424a-a633-699a879671bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-1b5b9470-6a97-4ae3-8318-01508ba931c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-87b6646a-2072-47e2-b417-cff602d8b684,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-cc86f475-f8cf-40d0-9591-ff7e30a36faf,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-b1ece03a-81e1-4b4c-99ad-fb00ada3554b,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-00062b0f-6f1b-4354-b438-9122033fcf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-9bc1d87e-73b8-4726-a489-bf1f3a238d7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314176346-172.17.0.20-1597098128062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38963,DS-45be89f0-9156-43ee-a8d9-31d8f1a1414d,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-363da4a8-6ad7-424a-a633-699a879671bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-1b5b9470-6a97-4ae3-8318-01508ba931c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-87b6646a-2072-47e2-b417-cff602d8b684,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-cc86f475-f8cf-40d0-9591-ff7e30a36faf,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-b1ece03a-81e1-4b4c-99ad-fb00ada3554b,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-00062b0f-6f1b-4354-b438-9122033fcf5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-9bc1d87e-73b8-4726-a489-bf1f3a238d7c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313787581-172.17.0.20-1597098548485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32997,DS-18235472-43d5-4a44-8fb2-a0df30a514e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-64b323cf-5446-4652-8e60-3fc3a443b53b,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-96634672-f9ad-48e0-b68d-172b93f2dc79,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-681ec2b9-8a5f-43da-8154-827ca43b269b,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-97ae8a10-cc2c-4411-a098-d5cf7f1bde92,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-e509e237-2617-4c9d-a8bc-563e8000100b,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-1346ae2a-247c-44a7-9b4c-58012c3b2e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-3d12036b-28cf-40dd-9c46-eb093ba5223f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313787581-172.17.0.20-1597098548485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32997,DS-18235472-43d5-4a44-8fb2-a0df30a514e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-64b323cf-5446-4652-8e60-3fc3a443b53b,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-96634672-f9ad-48e0-b68d-172b93f2dc79,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-681ec2b9-8a5f-43da-8154-827ca43b269b,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-97ae8a10-cc2c-4411-a098-d5cf7f1bde92,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-e509e237-2617-4c9d-a8bc-563e8000100b,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-1346ae2a-247c-44a7-9b4c-58012c3b2e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-3d12036b-28cf-40dd-9c46-eb093ba5223f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165870460-172.17.0.20-1597098625723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-6742dd19-e5e9-461e-88a7-fa7c67a7a2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-4343d4cf-5406-4d93-a05a-c956c41e6588,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-ca060409-d31f-4cb1-9f27-fc9bde1ca340,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-7db33df8-fda6-43a1-918c-b36522fcf095,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-4d893f0e-ecef-43d9-904e-895faff5d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-2c02e003-3e92-4f13-9f82-b024ec315279,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-d6046199-b5bf-460d-88fb-aebb9a63f219,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-6fd8e227-378a-42ce-9f13-99b64ff666f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-165870460-172.17.0.20-1597098625723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46824,DS-6742dd19-e5e9-461e-88a7-fa7c67a7a2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-4343d4cf-5406-4d93-a05a-c956c41e6588,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-ca060409-d31f-4cb1-9f27-fc9bde1ca340,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-7db33df8-fda6-43a1-918c-b36522fcf095,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-4d893f0e-ecef-43d9-904e-895faff5d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-2c02e003-3e92-4f13-9f82-b024ec315279,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-d6046199-b5bf-460d-88fb-aebb9a63f219,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-6fd8e227-378a-42ce-9f13-99b64ff666f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400767053-172.17.0.20-1597098666750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-f33c589d-b760-42b2-9be3-93e8765bb333,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-d8a55899-149e-4f78-904b-df53721dfc70,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-bbd790b5-c0fd-42a2-8111-2493ebed27c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-25ef2bbf-3012-4e7e-93b8-7cb515e553f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-6d0817d6-e7b4-4a33-aeeb-fb0e01c8685b,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-4133578d-c061-4492-8f14-3caad615e78e,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-dfd8dfbf-82a3-4f04-bf53-894671337807,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-00b19832-9f5e-4aa7-8e52-962b011730ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1400767053-172.17.0.20-1597098666750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45518,DS-f33c589d-b760-42b2-9be3-93e8765bb333,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-d8a55899-149e-4f78-904b-df53721dfc70,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-bbd790b5-c0fd-42a2-8111-2493ebed27c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-25ef2bbf-3012-4e7e-93b8-7cb515e553f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-6d0817d6-e7b4-4a33-aeeb-fb0e01c8685b,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-4133578d-c061-4492-8f14-3caad615e78e,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-dfd8dfbf-82a3-4f04-bf53-894671337807,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-00b19832-9f5e-4aa7-8e52-962b011730ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061786823-172.17.0.20-1597098948393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-1a1b426b-d03e-40c7-b24e-f4dfc22970e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-4bc7a440-1fae-4440-9d5e-3adb74719ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-e83a79f5-1005-4227-a2c3-34693f465344,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-315dd5b8-ef27-49c2-adc2-8b0b463f89f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-21840bdf-d463-4b44-8b71-fc882bf712d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-d0671de4-6731-4968-8249-dc448d03127d,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-0102767c-7dd0-4528-8418-721018eaedea,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-c3e3c619-8f0e-45b5-b18b-63ec0182be5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061786823-172.17.0.20-1597098948393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37653,DS-1a1b426b-d03e-40c7-b24e-f4dfc22970e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35676,DS-4bc7a440-1fae-4440-9d5e-3adb74719ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-e83a79f5-1005-4227-a2c3-34693f465344,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-315dd5b8-ef27-49c2-adc2-8b0b463f89f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-21840bdf-d463-4b44-8b71-fc882bf712d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-d0671de4-6731-4968-8249-dc448d03127d,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-0102767c-7dd0-4528-8418-721018eaedea,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-c3e3c619-8f0e-45b5-b18b-63ec0182be5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289472966-172.17.0.20-1597099401948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-c1e0bd8f-9c83-4d88-aa85-38e3ba048190,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-6a0f69a3-7f5d-45ff-b23d-f07a72a4512d,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-c6aaae36-1b3e-40e8-8e0a-cb7c39da21bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-5bd5e06f-c087-4176-808b-9491a757c807,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-a721500f-a966-47b5-ba8d-5bedcd722852,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-fe94a77b-9c98-44a9-b16f-2d10feedd911,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-70fd2b26-f2f3-42de-ad17-620c7f804af6,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-0e9badf3-bdc0-4dbd-bfcb-e71d4be24407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289472966-172.17.0.20-1597099401948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34486,DS-c1e0bd8f-9c83-4d88-aa85-38e3ba048190,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-6a0f69a3-7f5d-45ff-b23d-f07a72a4512d,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-c6aaae36-1b3e-40e8-8e0a-cb7c39da21bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-5bd5e06f-c087-4176-808b-9491a757c807,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-a721500f-a966-47b5-ba8d-5bedcd722852,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-fe94a77b-9c98-44a9-b16f-2d10feedd911,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-70fd2b26-f2f3-42de-ad17-620c7f804af6,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-0e9badf3-bdc0-4dbd-bfcb-e71d4be24407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231131854-172.17.0.20-1597099437111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45732,DS-efe0c9b9-4943-4c73-a029-0a512124b649,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-53fe8083-7569-4b09-9711-678bdedf8158,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-cdce4b2c-c771-4dfb-bb84-0e9ff75369c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-bbf237d5-2df9-4a7c-9182-bb3c93670211,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-7e34ee4e-c0c5-4cda-a3ff-09c0ab21cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-2d26a680-bae9-4e3e-a5e0-300fb6b8b90f,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-db08030e-a6d2-4b5f-a796-6884a0905b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-1bbc956d-a7bf-4b83-aa50-9edaffe71ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231131854-172.17.0.20-1597099437111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45732,DS-efe0c9b9-4943-4c73-a029-0a512124b649,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-53fe8083-7569-4b09-9711-678bdedf8158,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-cdce4b2c-c771-4dfb-bb84-0e9ff75369c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-bbf237d5-2df9-4a7c-9182-bb3c93670211,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-7e34ee4e-c0c5-4cda-a3ff-09c0ab21cc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-2d26a680-bae9-4e3e-a5e0-300fb6b8b90f,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-db08030e-a6d2-4b5f-a796-6884a0905b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-1bbc956d-a7bf-4b83-aa50-9edaffe71ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337077719-172.17.0.20-1597099555379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35838,DS-0329d0da-f923-4593-9975-1f88c4b7bfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-e2b07253-57f1-4c1b-91a4-4adac354591b,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-6d8136f6-1b03-4967-99ef-d3a3ff7dada3,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-bfcadcb1-49d5-4f1b-aba7-2ac9d6b1cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-ad4d41c0-5f70-46ca-be75-21ce46c455bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-a151f45e-5d3d-494a-8b54-3566efb22c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-11ea3a22-6229-4396-87b9-60acbdc650fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-21124a37-ccc3-4921-8b85-172b30d650e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337077719-172.17.0.20-1597099555379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35838,DS-0329d0da-f923-4593-9975-1f88c4b7bfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-e2b07253-57f1-4c1b-91a4-4adac354591b,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-6d8136f6-1b03-4967-99ef-d3a3ff7dada3,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-bfcadcb1-49d5-4f1b-aba7-2ac9d6b1cea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-ad4d41c0-5f70-46ca-be75-21ce46c455bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-a151f45e-5d3d-494a-8b54-3566efb22c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37617,DS-11ea3a22-6229-4396-87b9-60acbdc650fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-21124a37-ccc3-4921-8b85-172b30d650e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828848287-172.17.0.20-1597099668459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33202,DS-cb850c6d-bb6b-43bf-b002-11cc5aac40c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-a6be9c8f-0a45-4b21-90d6-8ebd1431550f,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-2f09329a-a01b-4a41-ad0a-e2933a08e5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-675a393f-3e87-40da-b033-dc5c38df1748,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-9c46ea33-e05d-46c9-ad58-90949702da5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-def84ec1-3279-4965-a421-eeb555c0dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9c8dda9c-32b2-46f6-81b8-0a54cec282c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-0245a9ac-ad66-4e6c-8486-282bfa54f2e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828848287-172.17.0.20-1597099668459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33202,DS-cb850c6d-bb6b-43bf-b002-11cc5aac40c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-a6be9c8f-0a45-4b21-90d6-8ebd1431550f,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-2f09329a-a01b-4a41-ad0a-e2933a08e5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-675a393f-3e87-40da-b033-dc5c38df1748,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-9c46ea33-e05d-46c9-ad58-90949702da5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-def84ec1-3279-4965-a421-eeb555c0dc28,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-9c8dda9c-32b2-46f6-81b8-0a54cec282c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-0245a9ac-ad66-4e6c-8486-282bfa54f2e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 60000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669284273-172.17.0.20-1597099880746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36449,DS-612e32e1-381b-4f8d-b2ea-9bb77fe67a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-d43e2302-fb75-41e6-bcbe-df4e8df4c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-3c32ac95-a988-4b53-8d2e-b9574a26520e,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-ee580cf9-0b8a-4a16-a63a-e5b0b661067c,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-5628c5c4-cdd3-4f78-aea8-da7ff56f84de,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-bea2558a-c1a7-48a1-83e1-b76f1248193a,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-939e211e-2b50-489b-9569-47d1e66c1391,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-1b425d25-c6e8-49ad-b0ca-ff10ab716036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669284273-172.17.0.20-1597099880746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36449,DS-612e32e1-381b-4f8d-b2ea-9bb77fe67a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-d43e2302-fb75-41e6-bcbe-df4e8df4c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-3c32ac95-a988-4b53-8d2e-b9574a26520e,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-ee580cf9-0b8a-4a16-a63a-e5b0b661067c,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-5628c5c4-cdd3-4f78-aea8-da7ff56f84de,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-bea2558a-c1a7-48a1-83e1-b76f1248193a,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-939e211e-2b50-489b-9569-47d1e66c1391,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-1b425d25-c6e8-49ad-b0ca-ff10ab716036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5577
