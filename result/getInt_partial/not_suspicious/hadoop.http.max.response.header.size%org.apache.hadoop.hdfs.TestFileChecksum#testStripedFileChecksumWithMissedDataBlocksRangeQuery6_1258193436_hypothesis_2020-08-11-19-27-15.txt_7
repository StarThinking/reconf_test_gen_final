reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027044611-172.17.0.20-1597174132914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-87b5c2df-cf82-4442-b82e-0006848eb82e,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-fc3c3dc1-4da6-4ebb-ae40-9ef694bd5405,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-4e61626c-674b-487a-a0ef-ca2bde026ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-6875a9f9-19f4-461a-a8f3-b6c25c73c978,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-8e1648db-7f1b-4a7d-a198-760df51d026a,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-b6607c0b-6426-429b-a57b-b75a648c07a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e14ceed5-7647-4031-a502-06fb9d362f19,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-4ae40fd5-6f50-47b3-8fc3-51a60bbced4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1027044611-172.17.0.20-1597174132914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-87b5c2df-cf82-4442-b82e-0006848eb82e,DISK], DatanodeInfoWithStorage[127.0.0.1:34004,DS-fc3c3dc1-4da6-4ebb-ae40-9ef694bd5405,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-4e61626c-674b-487a-a0ef-ca2bde026ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-6875a9f9-19f4-461a-a8f3-b6c25c73c978,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-8e1648db-7f1b-4a7d-a198-760df51d026a,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-b6607c0b-6426-429b-a57b-b75a648c07a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e14ceed5-7647-4031-a502-06fb9d362f19,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-4ae40fd5-6f50-47b3-8fc3-51a60bbced4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703391290-172.17.0.20-1597174179749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-8d55defb-2e3f-4d4f-8d3a-b762a1ec5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-d40ea742-0003-4252-a527-bdb3544bfdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-6981a70b-5ec0-4d79-8988-286bc12094e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-3df80a2a-8815-44f1-ae6a-e77561b38565,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-a75c6680-8251-4791-a7db-9d1241d94936,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-78231b5b-0780-4f1b-a9fa-c3afe5fc9160,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-c0f9ce2e-4763-4a6f-817d-61e3f16fdbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-15390898-7e90-4ef9-8c85-aa31fd0c0dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703391290-172.17.0.20-1597174179749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37545,DS-8d55defb-2e3f-4d4f-8d3a-b762a1ec5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-d40ea742-0003-4252-a527-bdb3544bfdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-6981a70b-5ec0-4d79-8988-286bc12094e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-3df80a2a-8815-44f1-ae6a-e77561b38565,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-a75c6680-8251-4791-a7db-9d1241d94936,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-78231b5b-0780-4f1b-a9fa-c3afe5fc9160,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-c0f9ce2e-4763-4a6f-817d-61e3f16fdbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-15390898-7e90-4ef9-8c85-aa31fd0c0dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738034225-172.17.0.20-1597174585795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46066,DS-b9e175c6-ec61-4f7c-93ea-a3e0f1bbe8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-e8a8ab24-23db-4309-9e45-7cc3d0a3ae47,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-b7f11b73-ad99-46a6-811a-83a67b3f72a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-e5aaff83-99ed-4866-a454-1813165b82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-05827222-335c-4e08-8b98-4520dfb514cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-a5250322-0316-4618-aaf4-51f5362bc9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-0b93ad54-3ed1-4570-9d9d-ec62b089e167,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-4108a1b2-bda8-4747-998c-1953f431805b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738034225-172.17.0.20-1597174585795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46066,DS-b9e175c6-ec61-4f7c-93ea-a3e0f1bbe8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-e8a8ab24-23db-4309-9e45-7cc3d0a3ae47,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-b7f11b73-ad99-46a6-811a-83a67b3f72a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-e5aaff83-99ed-4866-a454-1813165b82a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-05827222-335c-4e08-8b98-4520dfb514cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-a5250322-0316-4618-aaf4-51f5362bc9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-0b93ad54-3ed1-4570-9d9d-ec62b089e167,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-4108a1b2-bda8-4747-998c-1953f431805b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100503160-172.17.0.20-1597174787327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46338,DS-fc85a9fd-ea10-4283-868a-3e508f9f6974,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-90e4a0f2-6c44-4c6b-95e2-66241b392893,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-9763c8c4-aa73-4388-a9f9-1c75e6be45c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-2084cee7-cf8f-4ee6-88f4-638337447540,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-0b7beef5-63a9-494c-bfeb-4d5406d811a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-c64d3120-46a9-4f79-b72a-7fdf50fb7b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-467d3063-da71-4aaf-b9c1-a90a230b058a,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-6cd28af8-4c48-4c52-afdf-c2dbeb41ca18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2100503160-172.17.0.20-1597174787327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46338,DS-fc85a9fd-ea10-4283-868a-3e508f9f6974,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-90e4a0f2-6c44-4c6b-95e2-66241b392893,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-9763c8c4-aa73-4388-a9f9-1c75e6be45c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-2084cee7-cf8f-4ee6-88f4-638337447540,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-0b7beef5-63a9-494c-bfeb-4d5406d811a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-c64d3120-46a9-4f79-b72a-7fdf50fb7b19,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-467d3063-da71-4aaf-b9c1-a90a230b058a,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-6cd28af8-4c48-4c52-afdf-c2dbeb41ca18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447507483-172.17.0.20-1597174823753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-1a027b62-7fb1-4393-a8a5-b0bcd187e160,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-24e20084-cd60-4bb6-a513-4b4fbced4c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-e284288a-1a36-4a0a-844c-1a058c0c32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-09b85ec6-ffe9-4264-9227-c14836b079ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-5bc36c93-4471-4b26-bed0-9fa2f8c41c63,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-c2a92eef-9a8d-4a76-9bf1-d4e1cd73398b,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-ceddb13b-f0db-43cf-a02b-e6395efa04c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-43e83030-e623-448d-b4b6-dfa1d4646006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447507483-172.17.0.20-1597174823753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43047,DS-1a027b62-7fb1-4393-a8a5-b0bcd187e160,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-24e20084-cd60-4bb6-a513-4b4fbced4c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-e284288a-1a36-4a0a-844c-1a058c0c32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-09b85ec6-ffe9-4264-9227-c14836b079ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-5bc36c93-4471-4b26-bed0-9fa2f8c41c63,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-c2a92eef-9a8d-4a76-9bf1-d4e1cd73398b,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-ceddb13b-f0db-43cf-a02b-e6395efa04c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41366,DS-43e83030-e623-448d-b4b6-dfa1d4646006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045469734-172.17.0.20-1597175067292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33195,DS-52dd9197-aeba-4e61-b3ce-603b300848a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-b034275f-5db0-4f84-bb51-6af5c08ddf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-cfece6fd-ceab-4cca-bb55-62076ed6f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-0da330c9-28cd-4663-9389-183c9bc85e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-5283daba-8f41-47c4-89f2-3de3d713d6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-825300fe-6c36-471e-bfe1-48d640cc377a,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-a0cc0a97-0c69-418c-b45c-db93afd14f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-b0dc30e3-bd95-43aa-930a-73b6019096fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045469734-172.17.0.20-1597175067292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33195,DS-52dd9197-aeba-4e61-b3ce-603b300848a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-b034275f-5db0-4f84-bb51-6af5c08ddf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-cfece6fd-ceab-4cca-bb55-62076ed6f08a,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-0da330c9-28cd-4663-9389-183c9bc85e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-5283daba-8f41-47c4-89f2-3de3d713d6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-825300fe-6c36-471e-bfe1-48d640cc377a,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-a0cc0a97-0c69-418c-b45c-db93afd14f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-b0dc30e3-bd95-43aa-930a-73b6019096fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767186914-172.17.0.20-1597175342829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41332,DS-77301e59-b7a1-4e1f-96da-389ee27752ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-6d07fad0-262d-4ad2-a561-8e5361dd46a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-d172248b-5e7c-4739-8830-e5ee8c3dde31,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-b7d6c491-5a73-420c-9e15-008b12a37f56,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-8b073d63-fa6e-4b92-bb13-bf4545a48033,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-209909b8-1c44-4f2e-bc5d-06b295af9b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-fe9c3d51-f5e3-4b6e-a0f8-526e5f80babe,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-040075d1-9600-4490-bae4-0c8cda5fe2a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767186914-172.17.0.20-1597175342829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41332,DS-77301e59-b7a1-4e1f-96da-389ee27752ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-6d07fad0-262d-4ad2-a561-8e5361dd46a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-d172248b-5e7c-4739-8830-e5ee8c3dde31,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-b7d6c491-5a73-420c-9e15-008b12a37f56,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-8b073d63-fa6e-4b92-bb13-bf4545a48033,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-209909b8-1c44-4f2e-bc5d-06b295af9b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-fe9c3d51-f5e3-4b6e-a0f8-526e5f80babe,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-040075d1-9600-4490-bae4-0c8cda5fe2a2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129844776-172.17.0.20-1597175432287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-a2123f00-2a94-4795-93a4-daa8b267097b,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-94b76776-7bf8-476f-97ba-70d4667d737f,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-7c89a558-e207-4867-8560-b0fc399d33ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-3cf2b1cc-641d-47a7-b8a8-1ca2858251dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-64a38d9b-83c5-4edb-b1de-df65fb506bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-f9685d66-c164-4ec2-b376-5a4f72863354,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-ad22f4ee-2344-4685-a330-364fe0546fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-94fcd25e-a94c-4ece-89be-b0ff34cbdc1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129844776-172.17.0.20-1597175432287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45555,DS-a2123f00-2a94-4795-93a4-daa8b267097b,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-94b76776-7bf8-476f-97ba-70d4667d737f,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-7c89a558-e207-4867-8560-b0fc399d33ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-3cf2b1cc-641d-47a7-b8a8-1ca2858251dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-64a38d9b-83c5-4edb-b1de-df65fb506bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-f9685d66-c164-4ec2-b376-5a4f72863354,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-ad22f4ee-2344-4685-a330-364fe0546fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-94fcd25e-a94c-4ece-89be-b0ff34cbdc1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869718527-172.17.0.20-1597175631633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43935,DS-45a63db8-5fb3-43c5-8480-cca3dfb9f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-019fd3a0-de84-421c-b0df-830924e09797,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-742641a9-ce16-4c88-8f6c-916f1a41c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-4e9543d8-3d38-40d1-8b59-92d6cfdb8087,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-a77b1c4f-8f5c-47de-af17-ff9b89d79681,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-4122bb67-96e0-4181-9a7c-ef2b380173ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-203274a4-5921-489a-8dee-86f80235ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-c97e052c-1f15-40c1-b0e9-d0ee04398da8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869718527-172.17.0.20-1597175631633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43935,DS-45a63db8-5fb3-43c5-8480-cca3dfb9f22e,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-019fd3a0-de84-421c-b0df-830924e09797,DISK], DatanodeInfoWithStorage[127.0.0.1:45154,DS-742641a9-ce16-4c88-8f6c-916f1a41c28b,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-4e9543d8-3d38-40d1-8b59-92d6cfdb8087,DISK], DatanodeInfoWithStorage[127.0.0.1:45953,DS-a77b1c4f-8f5c-47de-af17-ff9b89d79681,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-4122bb67-96e0-4181-9a7c-ef2b380173ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-203274a4-5921-489a-8dee-86f80235ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-c97e052c-1f15-40c1-b0e9-d0ee04398da8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500499767-172.17.0.20-1597175843432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36183,DS-aa55c72d-e8ab-4c94-a9b4-2d7497b3cb05,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-df44827a-caef-46ac-9718-5615f75b2e29,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-87e8e0ea-f484-488f-b796-bf04ded099ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-2b7499ba-ece6-4e82-b2ad-5c523c988116,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-b495606c-6fa4-4a45-aa88-727d29eba7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-46a24978-40c1-4045-b80c-d3dae6ccd1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-31afd96b-d3fc-4fa3-96ee-7b550e49d6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-43b05e9c-b84f-47de-bc5f-7443a4204cfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500499767-172.17.0.20-1597175843432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36183,DS-aa55c72d-e8ab-4c94-a9b4-2d7497b3cb05,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-df44827a-caef-46ac-9718-5615f75b2e29,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-87e8e0ea-f484-488f-b796-bf04ded099ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-2b7499ba-ece6-4e82-b2ad-5c523c988116,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-b495606c-6fa4-4a45-aa88-727d29eba7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-46a24978-40c1-4045-b80c-d3dae6ccd1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-31afd96b-d3fc-4fa3-96ee-7b550e49d6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-43b05e9c-b84f-47de-bc5f-7443a4204cfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098480582-172.17.0.20-1597175960690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-9daa5748-a299-4aad-8e49-c7b51348b74c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-b81d0042-31ce-4b6d-8bb0-09092e76fcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-ee1b5af7-175f-48d7-9186-3a9fb0b63845,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-07cadfcc-ed8c-43c4-a07c-ea2e17296b17,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-792dc5df-3601-4eba-b8fb-dec2cba2dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-c16bbe7f-c2d8-4068-bcef-fe5e4e31c41b,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-63eba8f8-c476-47f1-a342-2c1578a36a41,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-5054c2f4-49cb-42c1-abe2-fc103f385d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098480582-172.17.0.20-1597175960690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-9daa5748-a299-4aad-8e49-c7b51348b74c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-b81d0042-31ce-4b6d-8bb0-09092e76fcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-ee1b5af7-175f-48d7-9186-3a9fb0b63845,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-07cadfcc-ed8c-43c4-a07c-ea2e17296b17,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-792dc5df-3601-4eba-b8fb-dec2cba2dc99,DISK], DatanodeInfoWithStorage[127.0.0.1:35763,DS-c16bbe7f-c2d8-4068-bcef-fe5e4e31c41b,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-63eba8f8-c476-47f1-a342-2c1578a36a41,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-5054c2f4-49cb-42c1-abe2-fc103f385d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715743373-172.17.0.20-1597176049426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-ab7070d7-9c82-4175-ad8b-d0998af943b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-49e42543-af6e-4915-ab38-27f83ac8de3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-91215140-8897-4bfd-b0c8-6762a2487b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-f56aaf49-c5ad-4d15-9ead-90cc29e8ec8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-f0195a55-4851-4067-b3bc-950e237a0993,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-436c9366-ef14-4f7a-869b-9eccc460ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-6a7edc9f-901d-4ea6-957a-44306aa33933,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-5920d6ad-0842-4e10-978c-80ca180facce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715743373-172.17.0.20-1597176049426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-ab7070d7-9c82-4175-ad8b-d0998af943b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-49e42543-af6e-4915-ab38-27f83ac8de3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-91215140-8897-4bfd-b0c8-6762a2487b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-f56aaf49-c5ad-4d15-9ead-90cc29e8ec8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-f0195a55-4851-4067-b3bc-950e237a0993,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-436c9366-ef14-4f7a-869b-9eccc460ba95,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-6a7edc9f-901d-4ea6-957a-44306aa33933,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-5920d6ad-0842-4e10-978c-80ca180facce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757835271-172.17.0.20-1597176089506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37923,DS-280a954b-c14f-4396-a47f-25cad5437691,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-9063f3e1-f0c0-4287-9d9b-883ec0fdea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-535fcb8e-2897-4c94-9ce8-02add2b2ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-d41f2ecc-f230-402d-a32a-6d9dd8acef81,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-fdca8e2c-a040-4318-bfb9-8c2d6caadac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-49f1be05-2128-402d-a13c-fd9ebfc17844,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-2df9f132-36c3-4748-8c79-30c68e286f97,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-ba842e81-255c-4f06-bcab-a61ce76be989,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757835271-172.17.0.20-1597176089506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37923,DS-280a954b-c14f-4396-a47f-25cad5437691,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-9063f3e1-f0c0-4287-9d9b-883ec0fdea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-535fcb8e-2897-4c94-9ce8-02add2b2ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-d41f2ecc-f230-402d-a32a-6d9dd8acef81,DISK], DatanodeInfoWithStorage[127.0.0.1:34213,DS-fdca8e2c-a040-4318-bfb9-8c2d6caadac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-49f1be05-2128-402d-a13c-fd9ebfc17844,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-2df9f132-36c3-4748-8c79-30c68e286f97,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-ba842e81-255c-4f06-bcab-a61ce76be989,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517671096-172.17.0.20-1597176236826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38581,DS-06dc25c0-37e7-46e3-b533-7908a8735d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-d92d9f7a-4ee8-4658-8829-a156c16c149b,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-7ceef4d5-d0b6-4f74-9611-d0233136ba33,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-636a66ef-434c-4a85-9276-11bf8c11d10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-7284ba8e-d9bd-4cf0-9c43-1a9b7913d415,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-9acab759-c78d-4903-b4b3-a97d7f2581ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-70149f09-174b-4c90-bcb6-83fc6857cdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-ef5de928-3782-49b6-ae93-75ba32ae30ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517671096-172.17.0.20-1597176236826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38581,DS-06dc25c0-37e7-46e3-b533-7908a8735d84,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-d92d9f7a-4ee8-4658-8829-a156c16c149b,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-7ceef4d5-d0b6-4f74-9611-d0233136ba33,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-636a66ef-434c-4a85-9276-11bf8c11d10b,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-7284ba8e-d9bd-4cf0-9c43-1a9b7913d415,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-9acab759-c78d-4903-b4b3-a97d7f2581ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-70149f09-174b-4c90-bcb6-83fc6857cdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-ef5de928-3782-49b6-ae93-75ba32ae30ac,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382393680-172.17.0.20-1597176768434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41248,DS-2db95a87-cca3-4dee-8f80-971b0df6493e,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-ac2bad8a-4716-4665-9a33-8e69529b35d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-21b23d1b-ebc8-49ed-9021-b9d708cd488d,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-1d3307ca-b771-438c-acdd-0aa771b3212c,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-b4998061-f3a1-4e1a-814d-1b2e9f1dd39d,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-4c2b6327-9c43-4fc0-bf91-02ff2247243c,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-c23045c7-9d63-40b2-908f-ce06759cf0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-dd178a6d-15aa-4fb6-9e8d-8826b12b8eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382393680-172.17.0.20-1597176768434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41248,DS-2db95a87-cca3-4dee-8f80-971b0df6493e,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-ac2bad8a-4716-4665-9a33-8e69529b35d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-21b23d1b-ebc8-49ed-9021-b9d708cd488d,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-1d3307ca-b771-438c-acdd-0aa771b3212c,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-b4998061-f3a1-4e1a-814d-1b2e9f1dd39d,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-4c2b6327-9c43-4fc0-bf91-02ff2247243c,DISK], DatanodeInfoWithStorage[127.0.0.1:36841,DS-c23045c7-9d63-40b2-908f-ce06759cf0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-dd178a6d-15aa-4fb6-9e8d-8826b12b8eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386084223-172.17.0.20-1597176858148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43015,DS-0cba4099-ea0a-4d9e-8cbf-7e1b3c044aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a1f2baa0-f33c-4891-b934-6f3d7b68c961,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-28cea622-9ffa-4e32-af13-c42237a7f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-6dd7f9d3-da9a-4ad6-9cc2-6d35f981e269,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-6cc434e8-53d6-4d44-a645-30dc0fe10ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-b95a40bc-d482-4604-838d-75e73047a650,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-074bd179-fa58-4d90-a11e-4df240778b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-e8462964-d94e-4622-b803-e29b3aa30a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1386084223-172.17.0.20-1597176858148:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43015,DS-0cba4099-ea0a-4d9e-8cbf-7e1b3c044aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-a1f2baa0-f33c-4891-b934-6f3d7b68c961,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-28cea622-9ffa-4e32-af13-c42237a7f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-6dd7f9d3-da9a-4ad6-9cc2-6d35f981e269,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-6cc434e8-53d6-4d44-a645-30dc0fe10ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-b95a40bc-d482-4604-838d-75e73047a650,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-074bd179-fa58-4d90-a11e-4df240778b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-e8462964-d94e-4622-b803-e29b3aa30a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518549829-172.17.0.20-1597176937427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34429,DS-f6f8e8e7-829b-49cf-85e9-4d47c3d14a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-f02e515c-210e-4f35-8156-b65d15ffebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-6451081d-201a-4ff0-91be-913cf5f676aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-1d1072c8-4713-4574-bc47-790383d7272e,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-8d0cd6b0-bb7b-4c82-81d7-2a6359c8ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-9e55325f-6912-4efa-9b49-6a0ca0893bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-2b2ee312-0ec0-46d9-a395-aa7cee37705e,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-daf44941-7a4a-4524-8a0d-64918319fbc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518549829-172.17.0.20-1597176937427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34429,DS-f6f8e8e7-829b-49cf-85e9-4d47c3d14a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-f02e515c-210e-4f35-8156-b65d15ffebdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-6451081d-201a-4ff0-91be-913cf5f676aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-1d1072c8-4713-4574-bc47-790383d7272e,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-8d0cd6b0-bb7b-4c82-81d7-2a6359c8ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-9e55325f-6912-4efa-9b49-6a0ca0893bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-2b2ee312-0ec0-46d9-a395-aa7cee37705e,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-daf44941-7a4a-4524-8a0d-64918319fbc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965836631-172.17.0.20-1597177064344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-23b697fd-f455-48b9-bdc5-f0794a52f539,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-37098277-dbe4-4ea3-987e-42f8552264aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-ac1dc4e9-73ef-4df6-ad4b-7e51026bc38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-22ebf795-3adb-47b2-913d-4556f997ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-e2d53628-3e96-48b4-9614-bbc874e4e205,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-909ea379-df7e-46a4-9f1d-faa08d05ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-3f0f5863-34b2-49df-8648-e73865b4d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-9cd915e2-2cf8-4211-972b-0539494b889d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965836631-172.17.0.20-1597177064344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-23b697fd-f455-48b9-bdc5-f0794a52f539,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-37098277-dbe4-4ea3-987e-42f8552264aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-ac1dc4e9-73ef-4df6-ad4b-7e51026bc38a,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-22ebf795-3adb-47b2-913d-4556f997ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-e2d53628-3e96-48b4-9614-bbc874e4e205,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-909ea379-df7e-46a4-9f1d-faa08d05ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:34871,DS-3f0f5863-34b2-49df-8648-e73865b4d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-9cd915e2-2cf8-4211-972b-0539494b889d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948020380-172.17.0.20-1597177106884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38088,DS-2a465d79-b0ca-4562-b60d-b0713b53a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-c9324ea6-69ca-4fba-a57b-d9bbd3bd73cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-8da44ad8-cd5d-4d6b-bb26-2d9a0f1babec,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-10186467-d5c9-4686-ac82-bc740a3d731f,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-427de1a5-b197-4f15-8829-4e99e5637a08,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-a575f0cf-d666-40ba-8395-2462db23b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-607646e8-4b4d-4a86-9ffa-7899ef188535,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-89bc96b9-b556-47df-8bb1-a5fee003a5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948020380-172.17.0.20-1597177106884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38088,DS-2a465d79-b0ca-4562-b60d-b0713b53a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-c9324ea6-69ca-4fba-a57b-d9bbd3bd73cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-8da44ad8-cd5d-4d6b-bb26-2d9a0f1babec,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-10186467-d5c9-4686-ac82-bc740a3d731f,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-427de1a5-b197-4f15-8829-4e99e5637a08,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-a575f0cf-d666-40ba-8395-2462db23b0da,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-607646e8-4b4d-4a86-9ffa-7899ef188535,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-89bc96b9-b556-47df-8bb1-a5fee003a5f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588998268-172.17.0.20-1597177227822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33481,DS-16e8e1aa-08ae-48cb-b1a5-4ae02ecea246,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-f5ee7bc8-f8ef-45bc-9a3f-abb9f8bc894b,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-7b5b23b5-c26f-4420-8d61-eb1e40af7e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-40fd069d-3e45-4823-b35f-e835059699ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-751ffc8f-1cca-4b01-b3d4-cb644faa4227,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-5505ad76-4a07-4980-9d17-52ea135520a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-9cc6716f-c76d-4e37-883e-d296f791a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-92bf667d-cb75-4fa1-b877-5b63ce9ed855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1588998268-172.17.0.20-1597177227822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33481,DS-16e8e1aa-08ae-48cb-b1a5-4ae02ecea246,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-f5ee7bc8-f8ef-45bc-9a3f-abb9f8bc894b,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-7b5b23b5-c26f-4420-8d61-eb1e40af7e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-40fd069d-3e45-4823-b35f-e835059699ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33304,DS-751ffc8f-1cca-4b01-b3d4-cb644faa4227,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-5505ad76-4a07-4980-9d17-52ea135520a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-9cc6716f-c76d-4e37-883e-d296f791a0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-92bf667d-cb75-4fa1-b877-5b63ce9ed855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272766684-172.17.0.20-1597177449897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46371,DS-1a3acd02-8cca-41ef-a4de-5880ca77ef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-151a4a98-b0b3-4d01-aedc-d7593cce05f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-525213ae-cce6-419d-9249-d50d5348123d,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-670b3971-07dc-42b0-b3b3-5d1c78bfc126,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-b7f7aa6d-491e-4449-afd8-5d3bbd2801e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-ec6e4389-a7dc-4cbf-bd68-061f630de580,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-286a1b6f-eeb3-4b80-b0e9-aacbda9f953b,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-70bc3ea3-30b4-4ded-8258-9f84c767522e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-272766684-172.17.0.20-1597177449897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46371,DS-1a3acd02-8cca-41ef-a4de-5880ca77ef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-151a4a98-b0b3-4d01-aedc-d7593cce05f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-525213ae-cce6-419d-9249-d50d5348123d,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-670b3971-07dc-42b0-b3b3-5d1c78bfc126,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-b7f7aa6d-491e-4449-afd8-5d3bbd2801e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-ec6e4389-a7dc-4cbf-bd68-061f630de580,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-286a1b6f-eeb3-4b80-b0e9-aacbda9f953b,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-70bc3ea3-30b4-4ded-8258-9f84c767522e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283480437-172.17.0.20-1597177484501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35362,DS-b883fedd-4965-46ae-b355-094836cd7f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-5590e6b0-6a48-4195-97d5-dd4c0ad5f742,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-7f470dd6-32b2-426e-a57a-85dfd4076a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-d62fdcb0-7580-4f13-aae2-bab680c7881b,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-f328ec4e-fa58-4ee1-bb1d-ca5f2250fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-b5a011db-39a6-4a73-be8f-253ca5aa27dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-f07a056b-d689-4b16-a7aa-af88255931aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-241d03fc-5d55-4f34-a036-6b0b98a4faba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283480437-172.17.0.20-1597177484501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35362,DS-b883fedd-4965-46ae-b355-094836cd7f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-5590e6b0-6a48-4195-97d5-dd4c0ad5f742,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-7f470dd6-32b2-426e-a57a-85dfd4076a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-d62fdcb0-7580-4f13-aae2-bab680c7881b,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-f328ec4e-fa58-4ee1-bb1d-ca5f2250fab4,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-b5a011db-39a6-4a73-be8f-253ca5aa27dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-f07a056b-d689-4b16-a7aa-af88255931aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-241d03fc-5d55-4f34-a036-6b0b98a4faba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960543682-172.17.0.20-1597177523527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46335,DS-e33c09f7-81ec-4eb8-aa91-35f6c737a637,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-443567b2-6049-4b57-9378-a7edaeaf03a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-9dac84df-6d8f-40c3-b971-9868f6152b85,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-d1973110-3e0a-4f78-a245-a3b3e6c6b758,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-9c0bd8c3-0745-47e5-aa40-1a83ec9c0aac,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-28da8d57-bff7-4994-8be8-d90348e8664a,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-59ee9d72-be5e-43f9-a93a-ef2dc95942b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-5d365312-e218-4943-a2a9-7c1fcce11786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960543682-172.17.0.20-1597177523527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46335,DS-e33c09f7-81ec-4eb8-aa91-35f6c737a637,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-443567b2-6049-4b57-9378-a7edaeaf03a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-9dac84df-6d8f-40c3-b971-9868f6152b85,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-d1973110-3e0a-4f78-a245-a3b3e6c6b758,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-9c0bd8c3-0745-47e5-aa40-1a83ec9c0aac,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-28da8d57-bff7-4994-8be8-d90348e8664a,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-59ee9d72-be5e-43f9-a93a-ef2dc95942b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-5d365312-e218-4943-a2a9-7c1fcce11786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073964342-172.17.0.20-1597177648605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-b3127980-aa6b-4b7a-9846-5800c0572521,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c0637ac0-342b-4548-922b-3e703e5247b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-491bad2a-ac87-464f-b993-fe023cc2afdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-f35c1b98-3ace-4254-a91b-addc494c4474,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-7812bb45-dee9-450c-8add-d9ef2cc0ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-cbbb8105-d56c-4f74-8635-adee15191cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-efdb8347-f496-407a-94e6-db92d450ea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-9fd8e69b-b9cd-4469-928d-ea52e2629786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073964342-172.17.0.20-1597177648605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45025,DS-b3127980-aa6b-4b7a-9846-5800c0572521,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-c0637ac0-342b-4548-922b-3e703e5247b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-491bad2a-ac87-464f-b993-fe023cc2afdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-f35c1b98-3ace-4254-a91b-addc494c4474,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-7812bb45-dee9-450c-8add-d9ef2cc0ba8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-cbbb8105-d56c-4f74-8635-adee15191cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-efdb8347-f496-407a-94e6-db92d450ea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-9fd8e69b-b9cd-4469-928d-ea52e2629786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892645779-172.17.0.20-1597177737404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-e4276390-a3db-424e-b662-52313e76aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-894bd8c8-b51d-4886-b126-1811ba34125d,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-545724ce-bf1b-4687-b916-c1c70dbd9112,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-0b1e83d2-7e6b-4a6f-8ca5-07abe895be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-32eaddde-77cd-43ec-b063-5963536e96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-438969cb-3ebd-41c1-84b2-6f8f9f509a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-3763af8c-a21e-4cd5-9618-9b23d117e43d,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-05271803-181d-43f5-975e-1bff96bbb56a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892645779-172.17.0.20-1597177737404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35181,DS-e4276390-a3db-424e-b662-52313e76aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-894bd8c8-b51d-4886-b126-1811ba34125d,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-545724ce-bf1b-4687-b916-c1c70dbd9112,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-0b1e83d2-7e6b-4a6f-8ca5-07abe895be5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-32eaddde-77cd-43ec-b063-5963536e96dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-438969cb-3ebd-41c1-84b2-6f8f9f509a58,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-3763af8c-a21e-4cd5-9618-9b23d117e43d,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-05271803-181d-43f5-975e-1bff96bbb56a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178130900-172.17.0.20-1597177948615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40483,DS-7d57515b-cc23-4f53-8e29-5313294952c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-3114cfdd-eced-46b7-80df-41c2b040595b,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-cc4d1e1f-ffba-46e7-8092-b61ddc2a553d,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-29687293-46d3-4eab-8a91-45e4317b9fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-c65151b3-fa56-4700-b967-b65d234b98fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-6e9a0dab-4194-44af-92fe-5299f57923a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-4e10ff5d-8fe2-4a1f-ae9c-7dc523c7ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-456e7080-bef0-4b4e-bc90-161eae7a0db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178130900-172.17.0.20-1597177948615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40483,DS-7d57515b-cc23-4f53-8e29-5313294952c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-3114cfdd-eced-46b7-80df-41c2b040595b,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-cc4d1e1f-ffba-46e7-8092-b61ddc2a553d,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-29687293-46d3-4eab-8a91-45e4317b9fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-c65151b3-fa56-4700-b967-b65d234b98fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-6e9a0dab-4194-44af-92fe-5299f57923a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-4e10ff5d-8fe2-4a1f-ae9c-7dc523c7ca3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-456e7080-bef0-4b4e-bc90-161eae7a0db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801198932-172.17.0.20-1597178077045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-b871e839-6b55-41cb-a3a4-4550cd1aaa79,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-b08c0bec-c8a2-4263-af30-6f51871138aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-79b28141-b93d-4d97-bf9d-7b2bf79dc044,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-f64ed55f-ae01-4111-abe3-4893bab3d43a,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-869105dd-cc1d-4f18-bda9-b1ad9c914abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-0cfd2f1e-578a-4db9-b0ec-70469094aa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-cad0a055-aa5f-499c-9dd7-f23812f46152,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-f594bd39-10a6-4274-98ed-32d3a20d200d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1801198932-172.17.0.20-1597178077045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33358,DS-b871e839-6b55-41cb-a3a4-4550cd1aaa79,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-b08c0bec-c8a2-4263-af30-6f51871138aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-79b28141-b93d-4d97-bf9d-7b2bf79dc044,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-f64ed55f-ae01-4111-abe3-4893bab3d43a,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-869105dd-cc1d-4f18-bda9-b1ad9c914abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-0cfd2f1e-578a-4db9-b0ec-70469094aa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-cad0a055-aa5f-499c-9dd7-f23812f46152,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-f594bd39-10a6-4274-98ed-32d3a20d200d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895710866-172.17.0.20-1597178126920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35473,DS-7d7adad1-f399-4aa4-bcb6-9716a3b77883,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-0c7e5018-ec12-447f-a86b-7f8c21037f44,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-38ae57a4-2d2e-4105-8b35-8fae2875ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-b7c479c2-d809-44f7-a686-ee1682ad2f40,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-666a9f0c-1f72-44be-a211-a0b6a74fd4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-638b2033-114c-409b-ad7d-865f26cbd0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-707db0ca-c3e5-4af3-ac50-0557a00d4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-abb5fdbc-ec17-4ac9-8cd6-357eed67df55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1895710866-172.17.0.20-1597178126920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35473,DS-7d7adad1-f399-4aa4-bcb6-9716a3b77883,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-0c7e5018-ec12-447f-a86b-7f8c21037f44,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-38ae57a4-2d2e-4105-8b35-8fae2875ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-b7c479c2-d809-44f7-a686-ee1682ad2f40,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-666a9f0c-1f72-44be-a211-a0b6a74fd4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-638b2033-114c-409b-ad7d-865f26cbd0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-707db0ca-c3e5-4af3-ac50-0557a00d4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-abb5fdbc-ec17-4ac9-8cd6-357eed67df55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733208959-172.17.0.20-1597178245371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41137,DS-62fb3748-6194-467a-8d46-b76eba8fc956,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-b62d8481-61ed-4229-ae1a-7e830199fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-f9bd2aae-a19b-4e67-a214-87ddcbe63d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-277b7cf4-554d-49b8-aff3-69544658002b,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-8922f333-39c3-40fa-98b5-88c257408e21,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-9243dbe6-53ef-47e3-82bb-c1cbd86de6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-29cef564-8fc7-4249-895f-d32652826170,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-bda88fd9-cf33-456c-9cf2-f95ec870b3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733208959-172.17.0.20-1597178245371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41137,DS-62fb3748-6194-467a-8d46-b76eba8fc956,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-b62d8481-61ed-4229-ae1a-7e830199fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-f9bd2aae-a19b-4e67-a214-87ddcbe63d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-277b7cf4-554d-49b8-aff3-69544658002b,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-8922f333-39c3-40fa-98b5-88c257408e21,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-9243dbe6-53ef-47e3-82bb-c1cbd86de6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-29cef564-8fc7-4249-895f-d32652826170,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-bda88fd9-cf33-456c-9cf2-f95ec870b3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902693334-172.17.0.20-1597178847636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44117,DS-ed62017c-02a0-4ff2-892d-5eb8b5f69e28,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-573691f2-0c04-40ba-8271-d5f0243da4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-a85a8070-47cc-4327-9314-18d7d643c687,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-c6e939b7-d050-4612-8578-195d8cfdada2,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-c9a75d2b-9c96-4869-a8ea-32ccda68d934,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-e4aac2f8-b685-4f69-976f-830e00180f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-188a9daa-79fa-43cb-a37a-3af6eeec0798,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-540c0336-d74a-420e-9e56-b5cffe2c4e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902693334-172.17.0.20-1597178847636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44117,DS-ed62017c-02a0-4ff2-892d-5eb8b5f69e28,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-573691f2-0c04-40ba-8271-d5f0243da4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-a85a8070-47cc-4327-9314-18d7d643c687,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-c6e939b7-d050-4612-8578-195d8cfdada2,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-c9a75d2b-9c96-4869-a8ea-32ccda68d934,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-e4aac2f8-b685-4f69-976f-830e00180f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-188a9daa-79fa-43cb-a37a-3af6eeec0798,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-540c0336-d74a-420e-9e56-b5cffe2c4e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031497065-172.17.0.20-1597179016188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-da57f70f-c9a0-458c-9445-8790102fff27,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-2582ce07-4de1-49c1-ae38-288398a7b123,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-35550fbb-4a94-44fd-b5a8-a7323d3dd41a,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-633f51a6-47a4-42fa-897f-be2e4050412d,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-acaa8fb7-803c-45c6-bdf8-d4a8365a8238,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-4dfa6067-6d2b-49b4-b771-8ec2889af19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-f7e9cdc8-54d0-4678-ad3c-ec2770b95321,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-c50bc1f3-863c-461c-8dbe-84e23e02cc77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031497065-172.17.0.20-1597179016188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39114,DS-da57f70f-c9a0-458c-9445-8790102fff27,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-2582ce07-4de1-49c1-ae38-288398a7b123,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-35550fbb-4a94-44fd-b5a8-a7323d3dd41a,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-633f51a6-47a4-42fa-897f-be2e4050412d,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-acaa8fb7-803c-45c6-bdf8-d4a8365a8238,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-4dfa6067-6d2b-49b4-b771-8ec2889af19f,DISK], DatanodeInfoWithStorage[127.0.0.1:33230,DS-f7e9cdc8-54d0-4678-ad3c-ec2770b95321,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-c50bc1f3-863c-461c-8dbe-84e23e02cc77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790310338-172.17.0.20-1597179186566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-2b2bbd58-37a0-4ada-b439-06f0f2d787a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-fb41950f-d919-4ffa-96d0-7b8ae7f3d541,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-f31f87ec-ff70-452a-a1ee-2cd2486656bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-c8053d6b-ca33-44f0-b3b2-14b6cfa32311,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-933e838b-cfb5-4e8a-97c3-2362020b7e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-622bab0c-a272-45c0-8ebf-ea23d83ad2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-3d7a618e-7a18-4127-b533-3821a0646451,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-4ac87550-c8ec-4b2e-a281-f66b4fd1d1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1790310338-172.17.0.20-1597179186566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39214,DS-2b2bbd58-37a0-4ada-b439-06f0f2d787a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-fb41950f-d919-4ffa-96d0-7b8ae7f3d541,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-f31f87ec-ff70-452a-a1ee-2cd2486656bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-c8053d6b-ca33-44f0-b3b2-14b6cfa32311,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-933e838b-cfb5-4e8a-97c3-2362020b7e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-622bab0c-a272-45c0-8ebf-ea23d83ad2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-3d7a618e-7a18-4127-b533-3821a0646451,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-4ac87550-c8ec-4b2e-a281-f66b4fd1d1ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696016156-172.17.0.20-1597179785585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46094,DS-6a734447-8f96-454b-939c-28b72ba33302,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-710c780a-da12-4432-a8b2-ad1e57f0f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-3addcd93-1c13-403a-8759-e9374b9b16f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-497be13c-ad33-439e-bc21-4c7c4a50d9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-3f10e95f-a1bf-4822-8033-db9be1e39cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-a8cbf38d-0a96-4e69-b3f0-10b326f485aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f53ac17c-e93d-4b2a-9d96-ecf46535d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-c2e3413a-7304-45ff-96c6-3373c3273257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-696016156-172.17.0.20-1597179785585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46094,DS-6a734447-8f96-454b-939c-28b72ba33302,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-710c780a-da12-4432-a8b2-ad1e57f0f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-3addcd93-1c13-403a-8759-e9374b9b16f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-497be13c-ad33-439e-bc21-4c7c4a50d9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-3f10e95f-a1bf-4822-8033-db9be1e39cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-a8cbf38d-0a96-4e69-b3f0-10b326f485aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-f53ac17c-e93d-4b2a-9d96-ecf46535d23d,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-c2e3413a-7304-45ff-96c6-3373c3273257,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906488354-172.17.0.20-1597179870360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-41cec851-7c60-400a-8455-0ca19af49b10,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-54f62fdc-873e-4b92-9973-a48e8b51c9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-6ff5fcf0-b8f0-48fc-b694-f18cd3a78b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-74312a5c-bd04-4200-afcf-283eb9fe3d00,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-e7930355-7c37-448c-bb9e-95b6a4627e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-e4e40213-89e7-458e-beb3-973c621d72e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-2a5ca8d1-16ad-48aa-b468-4d1dd7a2e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-664a2c42-11a9-4242-b1c5-9a2641bc238f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906488354-172.17.0.20-1597179870360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46341,DS-41cec851-7c60-400a-8455-0ca19af49b10,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-54f62fdc-873e-4b92-9973-a48e8b51c9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-6ff5fcf0-b8f0-48fc-b694-f18cd3a78b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-74312a5c-bd04-4200-afcf-283eb9fe3d00,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-e7930355-7c37-448c-bb9e-95b6a4627e63,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-e4e40213-89e7-458e-beb3-973c621d72e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-2a5ca8d1-16ad-48aa-b468-4d1dd7a2e4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40541,DS-664a2c42-11a9-4242-b1c5-9a2641bc238f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957675327-172.17.0.20-1597179999899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-b059eb9f-4f5c-4406-8361-bc4efdbd3b02,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-31c32066-27ce-4cc2-92c4-424b8592ed69,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-1afe1106-45d1-4779-8398-4a0586f7eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-14003c4d-7041-4e22-8844-83999c068494,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-53828dff-b75d-4f46-b23c-349e39cfcef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-530df2fe-5980-453a-bf28-f8c0be954d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-7d2dbe39-226a-4be0-a311-87eaf24c37ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-e8f2dacc-74be-4b88-b86d-d03e90afb635,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957675327-172.17.0.20-1597179999899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36537,DS-b059eb9f-4f5c-4406-8361-bc4efdbd3b02,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-31c32066-27ce-4cc2-92c4-424b8592ed69,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-1afe1106-45d1-4779-8398-4a0586f7eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-14003c4d-7041-4e22-8844-83999c068494,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-53828dff-b75d-4f46-b23c-349e39cfcef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-530df2fe-5980-453a-bf28-f8c0be954d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-7d2dbe39-226a-4be0-a311-87eaf24c37ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-e8f2dacc-74be-4b88-b86d-d03e90afb635,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369946476-172.17.0.20-1597180045191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41866,DS-01d1f996-57d1-4d7a-bb52-c519b25df1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-7f777f72-848b-4f0e-8b1b-086c3d127ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-31aabdbf-8185-42a3-9644-0fe7f1205e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-cb33a981-b260-4cf4-aa61-a0cb42a9617d,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-6cc3125b-44a4-40d4-ba20-0f0ffc4bbede,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-8cbfa5df-76fa-46f5-88bf-f2978a460c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-aa7c4709-2038-46b2-808e-6f8e73acc01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-7db36329-3936-45dd-a286-34dcc027a471,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369946476-172.17.0.20-1597180045191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41866,DS-01d1f996-57d1-4d7a-bb52-c519b25df1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-7f777f72-848b-4f0e-8b1b-086c3d127ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-31aabdbf-8185-42a3-9644-0fe7f1205e65,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-cb33a981-b260-4cf4-aa61-a0cb42a9617d,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-6cc3125b-44a4-40d4-ba20-0f0ffc4bbede,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-8cbfa5df-76fa-46f5-88bf-f2978a460c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-aa7c4709-2038-46b2-808e-6f8e73acc01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-7db36329-3936-45dd-a286-34dcc027a471,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588140142-172.17.0.20-1597180199900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-21c1bd05-5b22-47b1-8dbe-3eaf4452e503,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-103a2c93-d7f7-4154-addf-b934caefc73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-19c52ff1-1de6-458e-9ba9-f43e5e969af8,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-31e597cc-52ac-4c71-ad2d-5570b7e34de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-f7517fbc-9c29-49df-98ef-f56bbabc3aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-a3ffbe88-5a68-4612-853a-16166df3049f,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-05f23440-e8d0-49af-9485-476e411a5154,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-00dca308-f883-4831-9c11-b31d120d23e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588140142-172.17.0.20-1597180199900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33654,DS-21c1bd05-5b22-47b1-8dbe-3eaf4452e503,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-103a2c93-d7f7-4154-addf-b934caefc73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-19c52ff1-1de6-458e-9ba9-f43e5e969af8,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-31e597cc-52ac-4c71-ad2d-5570b7e34de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-f7517fbc-9c29-49df-98ef-f56bbabc3aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-a3ffbe88-5a68-4612-853a-16166df3049f,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-05f23440-e8d0-49af-9485-476e411a5154,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-00dca308-f883-4831-9c11-b31d120d23e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 8388608
v2: 65536
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389262716-172.17.0.20-1597180242390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44497,DS-06acf642-0706-4b02-88f1-e07e02e54b35,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-4a6d3b43-3282-4241-b6a6-e9d3b372098a,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-3c48ea0f-ad22-48fc-815b-c9a7ce106f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-26f5adbb-2627-436d-9876-d76822e123ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-04450ad3-16f9-4720-aee1-99601cea0c91,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-f5469a55-7072-440b-b884-b926c47a63bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-b8d07118-6585-4961-8496-e9f6db828bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-324b5f9e-a48d-41fc-81ce-2a39da6763e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389262716-172.17.0.20-1597180242390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44497,DS-06acf642-0706-4b02-88f1-e07e02e54b35,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-4a6d3b43-3282-4241-b6a6-e9d3b372098a,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-3c48ea0f-ad22-48fc-815b-c9a7ce106f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-26f5adbb-2627-436d-9876-d76822e123ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-04450ad3-16f9-4720-aee1-99601cea0c91,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-f5469a55-7072-440b-b884-b926c47a63bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-b8d07118-6585-4961-8496-e9f6db828bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-324b5f9e-a48d-41fc-81ce-2a39da6763e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 6232
