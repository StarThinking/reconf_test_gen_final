reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091846589-172.17.0.14-1597061492764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-972a8f87-4df5-4537-802a-014948db4e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-1617ad8a-48d6-4ac1-ad43-cf429fd7a1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-6e8c2330-1ac6-4486-a117-b659f7a90bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-c107d53c-4286-411d-af72-ef5a4fe34188,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-37c7adf1-0def-454a-8843-1487a64dae21,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-28c76562-fb36-4880-9747-5b6b39af8d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-6e492731-e6d1-4aae-adf5-f67fdbd2d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-b17d850d-8b15-46dc-979f-749611aef368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091846589-172.17.0.14-1597061492764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-972a8f87-4df5-4537-802a-014948db4e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-1617ad8a-48d6-4ac1-ad43-cf429fd7a1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-6e8c2330-1ac6-4486-a117-b659f7a90bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-c107d53c-4286-411d-af72-ef5a4fe34188,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-37c7adf1-0def-454a-8843-1487a64dae21,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-28c76562-fb36-4880-9747-5b6b39af8d10,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-6e492731-e6d1-4aae-adf5-f67fdbd2d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-b17d850d-8b15-46dc-979f-749611aef368,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569376644-172.17.0.14-1597061688740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33801,DS-a039a931-1e89-4714-9f6f-d5f9a5836023,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-413876d8-c0dc-49f6-b33f-54a443c0c267,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-b2f4d2e7-2550-4d8b-82b2-1bb5811c287d,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-2baf8b18-4422-4981-a805-1eaec342f506,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-a67f5644-2519-42e6-ac0f-4108d42427d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-db457eae-a2d4-4009-b62a-a3898011b997,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-cae4a9e2-10a6-4f41-9ae0-9af76d569d86,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-67c6f00f-2b80-4a76-b648-ae9caae7f3b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569376644-172.17.0.14-1597061688740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33801,DS-a039a931-1e89-4714-9f6f-d5f9a5836023,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-413876d8-c0dc-49f6-b33f-54a443c0c267,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-b2f4d2e7-2550-4d8b-82b2-1bb5811c287d,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-2baf8b18-4422-4981-a805-1eaec342f506,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-a67f5644-2519-42e6-ac0f-4108d42427d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-db457eae-a2d4-4009-b62a-a3898011b997,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-cae4a9e2-10a6-4f41-9ae0-9af76d569d86,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-67c6f00f-2b80-4a76-b648-ae9caae7f3b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692397174-172.17.0.14-1597061859694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42077,DS-39d3821b-c9f5-4153-828d-655e35c71318,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-6c066161-b4f9-4b88-b412-173ccfe12b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-310ee1e4-1f24-4976-abd1-70a8a7f6260a,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-e950542a-65d5-4938-8117-417b77518c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-73a42abc-085c-46ab-993d-fea32654d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-ee2f3176-19f6-48c9-ad7d-56c6cc09d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-3d33a0bd-aa4b-4016-90cd-0a3902a69e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-bb81b8cd-459f-4d47-bd3f-6ad2c7ed1fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692397174-172.17.0.14-1597061859694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42077,DS-39d3821b-c9f5-4153-828d-655e35c71318,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-6c066161-b4f9-4b88-b412-173ccfe12b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40503,DS-310ee1e4-1f24-4976-abd1-70a8a7f6260a,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-e950542a-65d5-4938-8117-417b77518c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-73a42abc-085c-46ab-993d-fea32654d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-ee2f3176-19f6-48c9-ad7d-56c6cc09d1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-3d33a0bd-aa4b-4016-90cd-0a3902a69e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-bb81b8cd-459f-4d47-bd3f-6ad2c7ed1fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933160071-172.17.0.14-1597061899713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-b88cd192-8895-483c-8955-33a65d2e3393,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-4534a1b7-4fe2-4fbf-bcb7-758ed935837d,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-cc627d2c-6071-4776-8f99-f264f869c23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-35720923-5b0c-4654-b2e8-27807c18fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-b93fad53-47f9-443b-88b8-87736a0a66a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ca7616cc-2b74-4041-956e-696063e6200f,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-17eb2bce-cb79-4189-8b65-f21ce6085ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-310d138e-14e7-4cd3-b579-e0e7be917c37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933160071-172.17.0.14-1597061899713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-b88cd192-8895-483c-8955-33a65d2e3393,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-4534a1b7-4fe2-4fbf-bcb7-758ed935837d,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-cc627d2c-6071-4776-8f99-f264f869c23d,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-35720923-5b0c-4654-b2e8-27807c18fb03,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-b93fad53-47f9-443b-88b8-87736a0a66a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-ca7616cc-2b74-4041-956e-696063e6200f,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-17eb2bce-cb79-4189-8b65-f21ce6085ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-310d138e-14e7-4cd3-b579-e0e7be917c37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165103313-172.17.0.14-1597062182359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-063fa16c-734b-44b6-8394-8db4bdbcf9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-8b9309a7-5486-4ced-9335-d57541050bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-94eeb0fd-3f46-47a6-9fdd-df2c96ac5e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-5ef72935-0950-43a8-b0cd-f1d53ced4da6,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-ecfa83e2-8d75-42ea-82b4-98290669ae07,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-12c1d989-6006-4371-a9bf-8f6665008fec,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-9b04d4e2-b8ea-4e67-a0b2-ce0b0a712606,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-c9e0bbd8-77bc-40e0-96e9-8c610ef416a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165103313-172.17.0.14-1597062182359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-063fa16c-734b-44b6-8394-8db4bdbcf9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-8b9309a7-5486-4ced-9335-d57541050bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-94eeb0fd-3f46-47a6-9fdd-df2c96ac5e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-5ef72935-0950-43a8-b0cd-f1d53ced4da6,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-ecfa83e2-8d75-42ea-82b4-98290669ae07,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-12c1d989-6006-4371-a9bf-8f6665008fec,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-9b04d4e2-b8ea-4e67-a0b2-ce0b0a712606,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-c9e0bbd8-77bc-40e0-96e9-8c610ef416a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087241836-172.17.0.14-1597062439094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-a1a6e867-7b8f-4e16-879e-4ca3fc003703,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-140537b6-ed28-4b52-868e-6efa03ce9259,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-5585be1d-c0a5-487a-8718-921af7c90783,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-eb79081a-c97c-455b-8c19-81ca871365e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-675d1fb2-1a5b-4f2a-9379-25aca06bdcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b465432a-5640-4130-ae77-39fe9274d312,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-d6ac7db2-a471-4e44-9d58-c5258f7c9b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-9394e2d0-ea44-4740-a8c8-9c0b51c26e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2087241836-172.17.0.14-1597062439094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34224,DS-a1a6e867-7b8f-4e16-879e-4ca3fc003703,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-140537b6-ed28-4b52-868e-6efa03ce9259,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-5585be1d-c0a5-487a-8718-921af7c90783,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-eb79081a-c97c-455b-8c19-81ca871365e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42653,DS-675d1fb2-1a5b-4f2a-9379-25aca06bdcb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-b465432a-5640-4130-ae77-39fe9274d312,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-d6ac7db2-a471-4e44-9d58-c5258f7c9b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-9394e2d0-ea44-4740-a8c8-9c0b51c26e29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961552778-172.17.0.14-1597062858547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35764,DS-722a39e7-c865-4ee8-8606-320e5489aa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-114d23d4-5ec2-4e8b-b920-31393b25317f,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-063e9976-9b18-435f-83a7-c8505a1d06ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-fc97d91f-eb3c-4c99-accb-d00c87869641,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-95aa87ba-835b-4728-a770-a1f39a13667f,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-9d20a72e-62b2-46fc-aee5-98b82f720929,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-99e1b09f-ca6f-419e-97e3-d74b7085c561,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-c5ef1fb0-fb36-4211-a8f0-6111790b78a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961552778-172.17.0.14-1597062858547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35764,DS-722a39e7-c865-4ee8-8606-320e5489aa3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-114d23d4-5ec2-4e8b-b920-31393b25317f,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-063e9976-9b18-435f-83a7-c8505a1d06ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-fc97d91f-eb3c-4c99-accb-d00c87869641,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-95aa87ba-835b-4728-a770-a1f39a13667f,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-9d20a72e-62b2-46fc-aee5-98b82f720929,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-99e1b09f-ca6f-419e-97e3-d74b7085c561,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-c5ef1fb0-fb36-4211-a8f0-6111790b78a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935756391-172.17.0.14-1597063342367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41761,DS-d9ef9cc9-160e-4f01-b68c-7b38c905b129,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-a2a2be29-9648-4b7f-aee3-1744bd15ae98,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-2a2e0263-ef5d-410f-b440-5352da31e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-fcb06c2e-034f-448f-8108-2a3d97b02ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-1268517a-f856-4c01-80c3-10a0708c7191,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-969dc86b-c439-487e-8cd0-5d8893fdfabd,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-f1942049-2047-43eb-a3ee-e91cb1874dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-a7633687-7681-4fde-860c-ba9c41b62c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935756391-172.17.0.14-1597063342367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41761,DS-d9ef9cc9-160e-4f01-b68c-7b38c905b129,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-a2a2be29-9648-4b7f-aee3-1744bd15ae98,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-2a2e0263-ef5d-410f-b440-5352da31e12b,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-fcb06c2e-034f-448f-8108-2a3d97b02ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-1268517a-f856-4c01-80c3-10a0708c7191,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-969dc86b-c439-487e-8cd0-5d8893fdfabd,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-f1942049-2047-43eb-a3ee-e91cb1874dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-a7633687-7681-4fde-860c-ba9c41b62c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473250107-172.17.0.14-1597063881845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43935,DS-26d4bf02-c822-4221-a3e1-663e2c6fc09d,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-ccfe21c1-360f-46d0-89d4-dd23904d44d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-38b82790-697a-44c6-9cb5-01f3bf90e478,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-dadcc85e-a499-4364-9e53-073c79976a98,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-7f4ffce6-e66e-4a02-95fe-fc1f376578b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-1bfb8146-f3e5-4307-9f55-a238926e702d,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-6b5d1298-00a5-422d-be66-0ec4c8d6c65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-9661d1b7-d0f4-4de0-85d2-004b980cf0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473250107-172.17.0.14-1597063881845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43935,DS-26d4bf02-c822-4221-a3e1-663e2c6fc09d,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-ccfe21c1-360f-46d0-89d4-dd23904d44d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-38b82790-697a-44c6-9cb5-01f3bf90e478,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-dadcc85e-a499-4364-9e53-073c79976a98,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-7f4ffce6-e66e-4a02-95fe-fc1f376578b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-1bfb8146-f3e5-4307-9f55-a238926e702d,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-6b5d1298-00a5-422d-be66-0ec4c8d6c65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-9661d1b7-d0f4-4de0-85d2-004b980cf0ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398046425-172.17.0.14-1597064006602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-7d5e39aa-6a38-40cc-b9c1-44f934c223fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-e619c45f-0e90-471a-9e55-83378e314ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-41c1b2bb-eb96-4ae1-a443-1218637f21ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-599cd1e0-e54a-429a-9ea0-872576011bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-c42cabf5-a8cf-4b00-9ae8-1060ecbc4663,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-9fc24cb6-a795-4b15-839f-e27d268a9808,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-0293a39d-8710-40eb-902d-2921aeae12f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-049ffefd-bbde-44ca-b04c-ca7e4c15f2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398046425-172.17.0.14-1597064006602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37540,DS-7d5e39aa-6a38-40cc-b9c1-44f934c223fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-e619c45f-0e90-471a-9e55-83378e314ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-41c1b2bb-eb96-4ae1-a443-1218637f21ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-599cd1e0-e54a-429a-9ea0-872576011bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-c42cabf5-a8cf-4b00-9ae8-1060ecbc4663,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-9fc24cb6-a795-4b15-839f-e27d268a9808,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-0293a39d-8710-40eb-902d-2921aeae12f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-049ffefd-bbde-44ca-b04c-ca7e4c15f2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347717316-172.17.0.14-1597064229880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-5343ed3f-d749-45a4-bc16-cd84bf210c49,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-a4d01fc4-12ce-438d-834a-bc9c15f46f68,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-fb3e4a6c-3484-47e1-a590-455270673d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-70662017-e96c-421b-bc3f-95a230380b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-fbe14e54-12f3-46c3-9cae-c00a985ad237,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-c27368fe-8d8d-40ca-914c-1de0cff3b486,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-48ae10d5-1bd8-4fce-b58f-63014dee515d,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-608cd797-9535-4761-9eaa-597737e02e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347717316-172.17.0.14-1597064229880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40639,DS-5343ed3f-d749-45a4-bc16-cd84bf210c49,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-a4d01fc4-12ce-438d-834a-bc9c15f46f68,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-fb3e4a6c-3484-47e1-a590-455270673d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-70662017-e96c-421b-bc3f-95a230380b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37284,DS-fbe14e54-12f3-46c3-9cae-c00a985ad237,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-c27368fe-8d8d-40ca-914c-1de0cff3b486,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-48ae10d5-1bd8-4fce-b58f-63014dee515d,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-608cd797-9535-4761-9eaa-597737e02e22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57885670-172.17.0.14-1597064268982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34634,DS-29ebbd9f-1e34-41f1-9afc-e48bfa692649,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-919b4636-45ef-4265-860c-5c138028039f,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-9ca063db-ce8f-4ec0-9e53-398a8650c6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-90411433-c4f1-42bc-933d-f057379d1fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-72611703-f1f6-4513-8483-45a1db0017ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-59326b1d-f85f-40f1-8b6e-76cf263cd892,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-5a989d2b-b407-4700-839b-b40de71556c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-e5bb93c7-aeae-4e6a-a971-ada0ed7419ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57885670-172.17.0.14-1597064268982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34634,DS-29ebbd9f-1e34-41f1-9afc-e48bfa692649,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-919b4636-45ef-4265-860c-5c138028039f,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-9ca063db-ce8f-4ec0-9e53-398a8650c6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-90411433-c4f1-42bc-933d-f057379d1fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-72611703-f1f6-4513-8483-45a1db0017ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-59326b1d-f85f-40f1-8b6e-76cf263cd892,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-5a989d2b-b407-4700-839b-b40de71556c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-e5bb93c7-aeae-4e6a-a971-ada0ed7419ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792025328-172.17.0.14-1597064303625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-48dc56ec-0193-4667-bc37-c70ba1a74970,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-ef7e9199-696a-4ca5-aef0-31d2ce49ca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-32cf7eb4-b7be-4e05-9a07-be3d9a5efa36,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-02ee2f9d-abab-4140-b682-140bc5abc658,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-2a017173-b7bb-4151-9166-287a49fdff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-98b2a751-9717-4468-b09b-c8cd07781849,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-b397c378-0b90-4aa4-972d-eba140055739,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-63f3cc8b-804a-4fee-9753-a2b7c47e0a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-792025328-172.17.0.14-1597064303625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-48dc56ec-0193-4667-bc37-c70ba1a74970,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-ef7e9199-696a-4ca5-aef0-31d2ce49ca1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-32cf7eb4-b7be-4e05-9a07-be3d9a5efa36,DISK], DatanodeInfoWithStorage[127.0.0.1:42178,DS-02ee2f9d-abab-4140-b682-140bc5abc658,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-2a017173-b7bb-4151-9166-287a49fdff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-98b2a751-9717-4468-b09b-c8cd07781849,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-b397c378-0b90-4aa4-972d-eba140055739,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-63f3cc8b-804a-4fee-9753-a2b7c47e0a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319552671-172.17.0.14-1597064847972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-39083318-43cb-4958-9291-3f693826ed00,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-9691536f-3f4f-4215-be4b-c08fe4a120cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-f8c2b477-e101-469f-910d-997176f802be,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-af9ff51a-1e4b-4006-980d-db3aecad2298,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-030a51c6-811b-4431-a811-8e049e767866,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-5b334b5f-583e-4cea-b02a-bb661af776c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-80fb5414-2a96-4845-8478-7f7c38e8254a,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-5535ccc3-e00e-4432-a0cb-62d0f602b533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1319552671-172.17.0.14-1597064847972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39351,DS-39083318-43cb-4958-9291-3f693826ed00,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-9691536f-3f4f-4215-be4b-c08fe4a120cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-f8c2b477-e101-469f-910d-997176f802be,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-af9ff51a-1e4b-4006-980d-db3aecad2298,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-030a51c6-811b-4431-a811-8e049e767866,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-5b334b5f-583e-4cea-b02a-bb661af776c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-80fb5414-2a96-4845-8478-7f7c38e8254a,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-5535ccc3-e00e-4432-a0cb-62d0f602b533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397733996-172.17.0.14-1597065067067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37547,DS-c98f7e45-300d-4275-a610-8292e61a3fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-c2f7d2e8-2854-4cef-94ed-1c0aa83adf83,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-d63b0559-ecf2-4f1b-a165-3728f3ff5e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-6500cded-f4d6-4c12-825c-5a2e560fa03d,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-396d8915-15f8-4ac0-acd3-e72b382c6783,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-e7285add-a50a-415b-b4ee-2d5ece5acaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-eb46fce7-eaff-4b00-84b5-3bae5059032e,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-ac45d493-7956-48e1-b946-5e1b5ad8d60e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397733996-172.17.0.14-1597065067067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37547,DS-c98f7e45-300d-4275-a610-8292e61a3fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-c2f7d2e8-2854-4cef-94ed-1c0aa83adf83,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-d63b0559-ecf2-4f1b-a165-3728f3ff5e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-6500cded-f4d6-4c12-825c-5a2e560fa03d,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-396d8915-15f8-4ac0-acd3-e72b382c6783,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-e7285add-a50a-415b-b4ee-2d5ece5acaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-eb46fce7-eaff-4b00-84b5-3bae5059032e,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-ac45d493-7956-48e1-b946-5e1b5ad8d60e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116656400-172.17.0.14-1597065465201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-4e2046c9-746e-43a0-80f6-f850e5ba3624,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-d4fdf616-0e40-4660-834d-83139b04a9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-f391bd54-3865-48d4-998f-b865be5d4c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-0968b941-9374-4ca2-a923-e992de8a8473,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-fe3064e6-323e-4e5c-a04b-125bf6a1992c,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-7354ca52-372d-47b5-a2ce-ef946bb31470,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-7f7f7c91-3e1a-4573-bd4b-1ea287e316f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-2ce01634-70d3-4ee2-ba7d-309d66dcc5d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116656400-172.17.0.14-1597065465201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42458,DS-4e2046c9-746e-43a0-80f6-f850e5ba3624,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-d4fdf616-0e40-4660-834d-83139b04a9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-f391bd54-3865-48d4-998f-b865be5d4c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-0968b941-9374-4ca2-a923-e992de8a8473,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-fe3064e6-323e-4e5c-a04b-125bf6a1992c,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-7354ca52-372d-47b5-a2ce-ef946bb31470,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-7f7f7c91-3e1a-4573-bd4b-1ea287e316f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-2ce01634-70d3-4ee2-ba7d-309d66dcc5d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308824044-172.17.0.14-1597066518920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-87e248b3-3151-42d8-8dd9-3a307b3bd06e,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-3e267ad7-a30f-4b19-b218-46d890eb3cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-3853b5d4-f284-48c1-ae30-3a023d2cac51,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-45ae181a-57d6-4ccb-8de5-6d0267fad743,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-bdeca3b1-e013-4e34-bbd5-6021eb6faba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-879af874-39a3-4687-a9a1-c6550e5a7bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-7fa13209-22af-4369-b37d-e6bc59edfa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-db9eef79-8910-4c99-a92d-ce074b7b65e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308824044-172.17.0.14-1597066518920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37907,DS-87e248b3-3151-42d8-8dd9-3a307b3bd06e,DISK], DatanodeInfoWithStorage[127.0.0.1:40572,DS-3e267ad7-a30f-4b19-b218-46d890eb3cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-3853b5d4-f284-48c1-ae30-3a023d2cac51,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-45ae181a-57d6-4ccb-8de5-6d0267fad743,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-bdeca3b1-e013-4e34-bbd5-6021eb6faba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-879af874-39a3-4687-a9a1-c6550e5a7bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-7fa13209-22af-4369-b37d-e6bc59edfa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-db9eef79-8910-4c99-a92d-ce074b7b65e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918623548-172.17.0.14-1597066712971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34256,DS-a9cf1caa-e1f8-44a2-8444-ec9a1e03fd12,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-68ff3558-567e-4f7c-ba74-2fc89d69a86d,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-61b1ff8a-0ba4-4d05-b3c6-69e18a4ed68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-a338c13e-c509-485e-a753-adfdcd8ef65b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-1950f182-4803-4a77-9280-8237cb698458,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-01b814ac-6451-4ae1-80b3-18a991d6fffb,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-6b84954f-d1a9-494e-bc09-5b1b8c40cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-aa8639a8-b059-4572-a369-997dc6dd13e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918623548-172.17.0.14-1597066712971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34256,DS-a9cf1caa-e1f8-44a2-8444-ec9a1e03fd12,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-68ff3558-567e-4f7c-ba74-2fc89d69a86d,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-61b1ff8a-0ba4-4d05-b3c6-69e18a4ed68e,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-a338c13e-c509-485e-a753-adfdcd8ef65b,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-1950f182-4803-4a77-9280-8237cb698458,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-01b814ac-6451-4ae1-80b3-18a991d6fffb,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-6b84954f-d1a9-494e-bc09-5b1b8c40cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-aa8639a8-b059-4572-a369-997dc6dd13e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5638
