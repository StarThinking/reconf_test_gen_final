reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362780624-172.17.0.5-1597181149520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32871,DS-4a81d3d7-b188-4cca-8bb2-112d4e0ecd48,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-ab3a2d4d-c149-4d56-bd7b-2222ba30d508,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-77e3aea5-99ba-4336-9b08-23a17deb6051,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-c78c19f2-aa72-4685-a0fb-a101aea9d651,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-c7cdb0c7-0ea1-48f3-b10c-88aa9b543cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-72d894b3-ba7d-4150-89bb-cc9955a1e8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-76bd270d-6c0d-41c1-adf2-1217ffe06b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-9efa69fe-7a52-4365-8e8e-39893d8bea4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362780624-172.17.0.5-1597181149520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32871,DS-4a81d3d7-b188-4cca-8bb2-112d4e0ecd48,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-ab3a2d4d-c149-4d56-bd7b-2222ba30d508,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-77e3aea5-99ba-4336-9b08-23a17deb6051,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-c78c19f2-aa72-4685-a0fb-a101aea9d651,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-c7cdb0c7-0ea1-48f3-b10c-88aa9b543cba,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-72d894b3-ba7d-4150-89bb-cc9955a1e8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-76bd270d-6c0d-41c1-adf2-1217ffe06b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-9efa69fe-7a52-4365-8e8e-39893d8bea4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588768892-172.17.0.5-1597181929830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-9c3cb211-7970-4f3f-83b4-8015c2169ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-48653036-6bcb-41e7-b24b-df35a51514ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-aeb282b9-8a16-48d1-878a-4c91071f876d,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-726958a9-90a4-413c-b93c-8195a03fcb37,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-d107e97d-8de8-45e9-a50b-e6f4346adc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-c82e062f-1357-432b-a429-fe7d624b6605,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-7076e2d0-8d26-4756-ac61-4e395ec6e123,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-099b2e5f-2e17-43b9-bffa-76f6e602279a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588768892-172.17.0.5-1597181929830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39583,DS-9c3cb211-7970-4f3f-83b4-8015c2169ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-48653036-6bcb-41e7-b24b-df35a51514ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-aeb282b9-8a16-48d1-878a-4c91071f876d,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-726958a9-90a4-413c-b93c-8195a03fcb37,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-d107e97d-8de8-45e9-a50b-e6f4346adc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-c82e062f-1357-432b-a429-fe7d624b6605,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-7076e2d0-8d26-4756-ac61-4e395ec6e123,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-099b2e5f-2e17-43b9-bffa-76f6e602279a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528162683-172.17.0.5-1597182532452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33989,DS-2a80f9bb-d7f0-4d05-82a4-95b5a2d8b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-99a059a5-db07-4fd6-8088-0744fb9cf52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-a120c891-86eb-40e4-bb9b-9b13c7c71fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-7f02952f-59dc-4ae0-bb5c-7bf5c0d2b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-e3fa9634-6cc3-469e-b251-31b4a6d7405b,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-797bdbaf-fba9-4eb7-8a57-3af083c33ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-e2416360-2107-4800-9ab4-3678652cff63,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-45bb2bc9-525b-47e8-94e9-6e1f2875d4a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1528162683-172.17.0.5-1597182532452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33989,DS-2a80f9bb-d7f0-4d05-82a4-95b5a2d8b28d,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-99a059a5-db07-4fd6-8088-0744fb9cf52a,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-a120c891-86eb-40e4-bb9b-9b13c7c71fce,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-7f02952f-59dc-4ae0-bb5c-7bf5c0d2b5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-e3fa9634-6cc3-469e-b251-31b4a6d7405b,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-797bdbaf-fba9-4eb7-8a57-3af083c33ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-e2416360-2107-4800-9ab4-3678652cff63,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-45bb2bc9-525b-47e8-94e9-6e1f2875d4a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640131452-172.17.0.5-1597183122268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33727,DS-33287dff-7d17-43fd-aec1-0a391ccb32ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-2d33a2d9-031c-4abc-882d-6591b5c338d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-e619578f-1a7d-4c62-9e3f-db5b147bcebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-09a37b09-97e3-4b59-a0a5-a2eeb4822239,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-753dda9e-f450-4190-9a0e-e60afe0b72f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-8a9bc826-aab1-43ad-954f-aa638e1c06ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-baf2b882-d664-4571-a7d7-812740bf8865,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-1264df1c-a91b-48c4-918e-9460992161a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640131452-172.17.0.5-1597183122268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33727,DS-33287dff-7d17-43fd-aec1-0a391ccb32ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-2d33a2d9-031c-4abc-882d-6591b5c338d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-e619578f-1a7d-4c62-9e3f-db5b147bcebb,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-09a37b09-97e3-4b59-a0a5-a2eeb4822239,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-753dda9e-f450-4190-9a0e-e60afe0b72f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-8a9bc826-aab1-43ad-954f-aa638e1c06ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-baf2b882-d664-4571-a7d7-812740bf8865,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-1264df1c-a91b-48c4-918e-9460992161a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420713216-172.17.0.5-1597184422046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-394d3f42-5454-4ea6-aad2-08fd2ed641d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-6f822bed-5bae-44a7-a1fc-ed43d03daeca,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-b7193452-3bdd-4fd0-b30b-a988719b8beb,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-b7f734ab-0a44-4123-867a-86f077cbd476,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-9dd768dd-853f-4d25-9f39-bf4b505a516e,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-61d5a0d3-dfcc-4422-aafe-29210db8609b,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-7bb70b23-a6f8-43f2-be9b-5d45d3c65a44,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-6ef6aa30-fd20-491b-9a22-59ba09e3a2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-420713216-172.17.0.5-1597184422046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-394d3f42-5454-4ea6-aad2-08fd2ed641d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-6f822bed-5bae-44a7-a1fc-ed43d03daeca,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-b7193452-3bdd-4fd0-b30b-a988719b8beb,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-b7f734ab-0a44-4123-867a-86f077cbd476,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-9dd768dd-853f-4d25-9f39-bf4b505a516e,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-61d5a0d3-dfcc-4422-aafe-29210db8609b,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-7bb70b23-a6f8-43f2-be9b-5d45d3c65a44,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-6ef6aa30-fd20-491b-9a22-59ba09e3a2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713627282-172.17.0.5-1597184512465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-d02c7ff2-157c-4bba-8d5e-0958c7239879,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-f6ede343-23f8-46d4-9ee1-c555a39249a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-3beea90b-7b06-4e53-886c-a2f12504d728,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-34141926-cac2-4f06-90b2-cebea447b4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-3c6d239d-152b-40aa-a66b-d4b51258984a,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-b83f9229-df5b-4c48-a561-002299c2def2,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-a677bdde-6118-4c6e-8b2f-e2cbf462003f,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-548d6600-5103-4145-950f-9e306d34860d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1713627282-172.17.0.5-1597184512465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33383,DS-d02c7ff2-157c-4bba-8d5e-0958c7239879,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-f6ede343-23f8-46d4-9ee1-c555a39249a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-3beea90b-7b06-4e53-886c-a2f12504d728,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-34141926-cac2-4f06-90b2-cebea447b4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-3c6d239d-152b-40aa-a66b-d4b51258984a,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-b83f9229-df5b-4c48-a561-002299c2def2,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-a677bdde-6118-4c6e-8b2f-e2cbf462003f,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-548d6600-5103-4145-950f-9e306d34860d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466293465-172.17.0.5-1597184789183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40179,DS-d48a0a24-ca63-4227-9963-0afb669a9dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-408801bc-9715-4de4-a2d9-b557fa2aec4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-d00ff0a7-ea12-4bd5-a9ee-6a8ac6f10181,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-a6053192-e239-4da2-a4c0-0422dfe73e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-04ee80b6-a452-46e5-a45f-3a6d0034a18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-2a13ac4a-03a2-4fd7-93c2-82b6d51cdcea,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-234130bc-1ff0-4560-8314-321da48c424a,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-e92561c8-7196-4453-b3f6-77ca444bb5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1466293465-172.17.0.5-1597184789183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40179,DS-d48a0a24-ca63-4227-9963-0afb669a9dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-408801bc-9715-4de4-a2d9-b557fa2aec4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-d00ff0a7-ea12-4bd5-a9ee-6a8ac6f10181,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-a6053192-e239-4da2-a4c0-0422dfe73e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39334,DS-04ee80b6-a452-46e5-a45f-3a6d0034a18f,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-2a13ac4a-03a2-4fd7-93c2-82b6d51cdcea,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-234130bc-1ff0-4560-8314-321da48c424a,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-e92561c8-7196-4453-b3f6-77ca444bb5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130869826-172.17.0.5-1597185317133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-4baabe9a-bc2c-4369-942c-bbd773b745b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-645fc28f-3a23-41cf-9471-696a007d54ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-8c435472-48a2-484e-a526-57e88060f59d,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-4b3ab48c-4bd4-49d9-a04a-2fc4cd548ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-ac7f0205-7853-4bce-9e35-cc895e72f856,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-3ab74335-106c-47f4-b197-05c07a4df596,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-6a3fc4bb-8f33-4ac7-8e50-196d6b807ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-b799a5ce-0926-4164-97c1-d9d9cb7f04f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130869826-172.17.0.5-1597185317133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46188,DS-4baabe9a-bc2c-4369-942c-bbd773b745b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-645fc28f-3a23-41cf-9471-696a007d54ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-8c435472-48a2-484e-a526-57e88060f59d,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-4b3ab48c-4bd4-49d9-a04a-2fc4cd548ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-ac7f0205-7853-4bce-9e35-cc895e72f856,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-3ab74335-106c-47f4-b197-05c07a4df596,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-6a3fc4bb-8f33-4ac7-8e50-196d6b807ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-b799a5ce-0926-4164-97c1-d9d9cb7f04f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32570272-172.17.0.5-1597185861252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-cd48d5d9-f0cb-4341-a66c-0ad85f8051e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-d000a10d-61f7-4870-b7b9-2d823866671c,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-e8eea3ac-01d8-4d1a-a8d7-6b9775b05282,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-68b18a8e-38ce-4fd5-b1f5-e2375cc68b24,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-ddaba59a-0a60-4e4f-a6fb-f33d6d67074c,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-119ea38f-bc01-44de-a9ce-dc2201490a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-9ac0179a-edfa-41c0-b7ab-a294614d4e02,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-0d351ae0-7b9f-4c81-a541-a1827bf69e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32570272-172.17.0.5-1597185861252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35464,DS-cd48d5d9-f0cb-4341-a66c-0ad85f8051e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-d000a10d-61f7-4870-b7b9-2d823866671c,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-e8eea3ac-01d8-4d1a-a8d7-6b9775b05282,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-68b18a8e-38ce-4fd5-b1f5-e2375cc68b24,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-ddaba59a-0a60-4e4f-a6fb-f33d6d67074c,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-119ea38f-bc01-44de-a9ce-dc2201490a96,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-9ac0179a-edfa-41c0-b7ab-a294614d4e02,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-0d351ae0-7b9f-4c81-a541-a1827bf69e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186610328-172.17.0.5-1597186179348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35580,DS-4653a369-a8ed-4e74-8b87-74cd66435c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-5a38f12c-1f4a-4bc2-9734-ffca8dbe8194,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-1c073d9a-e0ca-4fb9-a1a5-9f53fa16136a,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-98e52f9e-98b5-4f9c-b310-6c9f5e996d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-391ea336-1e58-42a9-90e5-eb0e4e2007e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-ab49a777-65f7-4d66-8ecb-a5782cebea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-6d8f6fb0-29ec-4ddf-9b34-43c2876a0679,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2e0eb302-849d-4b52-9a90-dd16371c192b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186610328-172.17.0.5-1597186179348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35580,DS-4653a369-a8ed-4e74-8b87-74cd66435c13,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-5a38f12c-1f4a-4bc2-9734-ffca8dbe8194,DISK], DatanodeInfoWithStorage[127.0.0.1:37170,DS-1c073d9a-e0ca-4fb9-a1a5-9f53fa16136a,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-98e52f9e-98b5-4f9c-b310-6c9f5e996d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-391ea336-1e58-42a9-90e5-eb0e4e2007e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-ab49a777-65f7-4d66-8ecb-a5782cebea5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-6d8f6fb0-29ec-4ddf-9b34-43c2876a0679,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-2e0eb302-849d-4b52-9a90-dd16371c192b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661194862-172.17.0.5-1597186255235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-b2fe3960-ec37-4027-a327-b3009c3fbc13,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-8fe7fe7d-2dec-4459-8b91-26c133e54f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-9fa96ab5-5901-4656-96c2-8bde7df8e8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-29fb4233-b665-41b7-87ca-c21aee92017d,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-828f042b-4d98-4d1f-bf0b-d7aa17096142,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-3f6753da-e6bc-43d9-b402-81dcf45e8a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-4fff5353-225a-46a6-81bf-8ac354b6f473,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-a8258b34-11ad-4d5f-b6d5-0e0149dd6576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1661194862-172.17.0.5-1597186255235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-b2fe3960-ec37-4027-a327-b3009c3fbc13,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-8fe7fe7d-2dec-4459-8b91-26c133e54f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-9fa96ab5-5901-4656-96c2-8bde7df8e8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-29fb4233-b665-41b7-87ca-c21aee92017d,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-828f042b-4d98-4d1f-bf0b-d7aa17096142,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-3f6753da-e6bc-43d9-b402-81dcf45e8a32,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-4fff5353-225a-46a6-81bf-8ac354b6f473,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-a8258b34-11ad-4d5f-b6d5-0e0149dd6576,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713175735-172.17.0.5-1597186370778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46285,DS-86047577-b9da-4fe6-beaa-dfab550610db,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-8fb695fe-c169-4d57-829a-0bda703f4ded,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-d6f59eb8-ba2b-4a51-af4c-f6da8cef7246,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-30ae859c-fe74-425e-af87-36b257c1684b,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-ad4c4624-38a9-4557-a889-f37a4109fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-99f8a9a4-a2e2-43d1-8074-a74dc13e49a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-dbc222cf-09ba-4e1a-ba42-7316395a3472,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-4613e9d1-d2c2-4bc1-8592-379a21260596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713175735-172.17.0.5-1597186370778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46285,DS-86047577-b9da-4fe6-beaa-dfab550610db,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-8fb695fe-c169-4d57-829a-0bda703f4ded,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-d6f59eb8-ba2b-4a51-af4c-f6da8cef7246,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-30ae859c-fe74-425e-af87-36b257c1684b,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-ad4c4624-38a9-4557-a889-f37a4109fec2,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-99f8a9a4-a2e2-43d1-8074-a74dc13e49a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-dbc222cf-09ba-4e1a-ba42-7316395a3472,DISK], DatanodeInfoWithStorage[127.0.0.1:36816,DS-4613e9d1-d2c2-4bc1-8592-379a21260596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5331
