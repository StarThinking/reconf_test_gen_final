reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086191519-172.17.0.18-1597054044310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-bd50cd48-d4c0-47eb-8ece-5870a6762970,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-b141fba8-2c97-4e36-af6d-dccaeb92c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-0429fa1b-774e-4cad-9e9b-b153169669a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-e9cfb591-8b85-4d6d-9b3b-2cfa69225e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-d00cffa1-28c3-4371-ba18-96b696dd1f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-ac52f45d-789a-4f77-9689-4c61a4501d01,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-cec82f4b-19a2-4428-aa08-f8e16179ed7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-2035dc7f-c2ce-4bbf-9510-2c2dbbb92b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086191519-172.17.0.18-1597054044310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39762,DS-bd50cd48-d4c0-47eb-8ece-5870a6762970,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-b141fba8-2c97-4e36-af6d-dccaeb92c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-0429fa1b-774e-4cad-9e9b-b153169669a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-e9cfb591-8b85-4d6d-9b3b-2cfa69225e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-d00cffa1-28c3-4371-ba18-96b696dd1f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-ac52f45d-789a-4f77-9689-4c61a4501d01,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-cec82f4b-19a2-4428-aa08-f8e16179ed7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-2035dc7f-c2ce-4bbf-9510-2c2dbbb92b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413075922-172.17.0.18-1597054147962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-69393b76-bd06-402d-bf4e-ce5e07d8b495,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-32305ec3-2edd-4c10-b3f0-609f35800519,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-cd11fd38-00ab-4255-959a-8e304361cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-57ee9ec4-784d-49fb-a6e2-a86d1918b5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-14e630fb-8589-4d39-a85a-3403eb7742df,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-37dfb401-368c-42ef-8f23-bfea1836ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-8c857fa5-3c6c-43ff-a0ce-fc36263d3776,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-861a6c39-ef98-4af1-ad8a-8e6e6d28c639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413075922-172.17.0.18-1597054147962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-69393b76-bd06-402d-bf4e-ce5e07d8b495,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-32305ec3-2edd-4c10-b3f0-609f35800519,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-cd11fd38-00ab-4255-959a-8e304361cc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-57ee9ec4-784d-49fb-a6e2-a86d1918b5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-14e630fb-8589-4d39-a85a-3403eb7742df,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-37dfb401-368c-42ef-8f23-bfea1836ad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-8c857fa5-3c6c-43ff-a0ce-fc36263d3776,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-861a6c39-ef98-4af1-ad8a-8e6e6d28c639,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373085784-172.17.0.18-1597054887263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-1383fc0e-61ad-4d9e-af5a-e6593913165a,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-699ceedf-cbed-4295-9822-efd9bdcec6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-8ecc2c26-b062-4bf4-84a9-11fb5a84982f,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-3dbb1177-480e-487b-8a53-18155a1a3eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-d0c95f43-3409-4f4a-962b-447bc42b5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-f40c075a-3355-4e4b-aa5f-86b671e504ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-95a4389a-8b79-4e33-bfe6-004e809c66d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-ad75e6c2-b4fc-4c34-bf18-89e74b84c8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1373085784-172.17.0.18-1597054887263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36470,DS-1383fc0e-61ad-4d9e-af5a-e6593913165a,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-699ceedf-cbed-4295-9822-efd9bdcec6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-8ecc2c26-b062-4bf4-84a9-11fb5a84982f,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-3dbb1177-480e-487b-8a53-18155a1a3eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-d0c95f43-3409-4f4a-962b-447bc42b5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-f40c075a-3355-4e4b-aa5f-86b671e504ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-95a4389a-8b79-4e33-bfe6-004e809c66d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-ad75e6c2-b4fc-4c34-bf18-89e74b84c8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688840446-172.17.0.18-1597056099434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42423,DS-03ffe1b9-73f0-468b-a046-e5094bbee6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-77fa47fc-8c0c-4542-9805-d92dc7f621e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-2bb86342-5347-41d9-bcf0-ad0e72693f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-e58fe7b2-8e19-4b64-aa85-f7df934df25f,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-65ad7ea2-8794-42cc-b96c-8cb02eaceb56,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-69b09fad-416e-4325-9dd1-1a787bffdf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-9e79b3a8-0d29-4f71-ada6-1bb7d2b5c8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-d4bc2cd9-655a-4a60-ace4-946b5f10567a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-688840446-172.17.0.18-1597056099434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42423,DS-03ffe1b9-73f0-468b-a046-e5094bbee6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-77fa47fc-8c0c-4542-9805-d92dc7f621e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-2bb86342-5347-41d9-bcf0-ad0e72693f17,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-e58fe7b2-8e19-4b64-aa85-f7df934df25f,DISK], DatanodeInfoWithStorage[127.0.0.1:36030,DS-65ad7ea2-8794-42cc-b96c-8cb02eaceb56,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-69b09fad-416e-4325-9dd1-1a787bffdf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-9e79b3a8-0d29-4f71-ada6-1bb7d2b5c8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-d4bc2cd9-655a-4a60-ace4-946b5f10567a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381158828-172.17.0.18-1597056179351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32972,DS-35b489ff-1f34-4afa-9044-f81a10e250d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-342be9ac-2789-4275-9d56-b467585627a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-1590e5bb-2a01-4eb1-ba51-a6afa638dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-b5f2cb4c-8319-4e20-8fae-018f4ee5d3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-6eba584a-182d-4d50-9b3c-cac38a3c6962,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-a5122a71-baa2-496a-b113-65becb06b147,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-bc9acd1d-38eb-4c43-818c-eec08f1e7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-97f9c969-90ef-4cff-a857-ea115a6a08e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-381158828-172.17.0.18-1597056179351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32972,DS-35b489ff-1f34-4afa-9044-f81a10e250d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-342be9ac-2789-4275-9d56-b467585627a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-1590e5bb-2a01-4eb1-ba51-a6afa638dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-b5f2cb4c-8319-4e20-8fae-018f4ee5d3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-6eba584a-182d-4d50-9b3c-cac38a3c6962,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-a5122a71-baa2-496a-b113-65becb06b147,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-bc9acd1d-38eb-4c43-818c-eec08f1e7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-97f9c969-90ef-4cff-a857-ea115a6a08e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836521367-172.17.0.18-1597056559570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-ddc74b74-0289-4938-9bd2-7ee5cfead39b,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-42230583-db2a-4d61-a09e-d469c3815a43,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-2c73df00-0d0b-48f6-8f94-ad79473af346,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-267921fd-9b89-4c7b-ae32-ea5d685cb024,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-71d5da36-6d9d-4614-a806-1ccc4055c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-7ad2004a-510e-4809-a8f2-97c3b7953a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-5bf75c60-da6f-4705-aff8-d9e517a3bd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-514da63b-e8d6-4942-aac1-3da04be06abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836521367-172.17.0.18-1597056559570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39435,DS-ddc74b74-0289-4938-9bd2-7ee5cfead39b,DISK], DatanodeInfoWithStorage[127.0.0.1:46365,DS-42230583-db2a-4d61-a09e-d469c3815a43,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-2c73df00-0d0b-48f6-8f94-ad79473af346,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-267921fd-9b89-4c7b-ae32-ea5d685cb024,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-71d5da36-6d9d-4614-a806-1ccc4055c50b,DISK], DatanodeInfoWithStorage[127.0.0.1:35140,DS-7ad2004a-510e-4809-a8f2-97c3b7953a08,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-5bf75c60-da6f-4705-aff8-d9e517a3bd3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38900,DS-514da63b-e8d6-4942-aac1-3da04be06abb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030864791-172.17.0.18-1597056742230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38012,DS-f1c67fb1-814e-40c8-9d00-ef4037d2082e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-0f05cfbd-5f54-4567-aa5e-1cc36b0d39eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-379ef7e9-b3f6-4d3b-a819-b8c875617554,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-4669f950-45f5-4b1a-b14b-3f388e4540b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-f1084135-975d-4eba-9d86-7fc03a66d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-b17d51d1-bbe5-404c-92be-4ce2b8dc4c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-418c8c3a-7314-4135-8441-362a2c92c6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-548002a5-30d1-43e8-bde5-68a0c58031dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030864791-172.17.0.18-1597056742230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38012,DS-f1c67fb1-814e-40c8-9d00-ef4037d2082e,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-0f05cfbd-5f54-4567-aa5e-1cc36b0d39eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-379ef7e9-b3f6-4d3b-a819-b8c875617554,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-4669f950-45f5-4b1a-b14b-3f388e4540b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-f1084135-975d-4eba-9d86-7fc03a66d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-b17d51d1-bbe5-404c-92be-4ce2b8dc4c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-418c8c3a-7314-4135-8441-362a2c92c6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-548002a5-30d1-43e8-bde5-68a0c58031dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978819309-172.17.0.18-1597056937623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37855,DS-f70228f1-0f96-470b-8658-df14e0bea485,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-72869a6d-4f9a-454b-ad1d-811f8bfec1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-eb5ed5be-03b3-47d5-8ad1-10dabf731d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-60644675-7475-4b55-b077-25f43a257b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-2fee302e-b525-4cc3-ad71-fbf63546d2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-53e7c4f3-176e-4c86-9641-d2a31b25e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-63859623-0285-4444-a4a1-515f53a59488,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-54e310f0-9d2e-4248-b140-8d48a2d4e868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978819309-172.17.0.18-1597056937623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37855,DS-f70228f1-0f96-470b-8658-df14e0bea485,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-72869a6d-4f9a-454b-ad1d-811f8bfec1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-eb5ed5be-03b3-47d5-8ad1-10dabf731d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43776,DS-60644675-7475-4b55-b077-25f43a257b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-2fee302e-b525-4cc3-ad71-fbf63546d2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-53e7c4f3-176e-4c86-9641-d2a31b25e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:40121,DS-63859623-0285-4444-a4a1-515f53a59488,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-54e310f0-9d2e-4248-b140-8d48a2d4e868,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2939954-172.17.0.18-1597057087082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-2438cfb2-aa72-42e2-aeb4-a9d312515110,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-d285f4ee-464e-48e6-b3ae-3ae3d03bce98,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-ef59d46f-8bb0-49f4-95de-439e1ef8f58d,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-371165d9-1309-4e46-ada5-3301b87b367e,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-74006098-14cc-497c-ae6d-37808683a1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-3aaa5fa9-7600-4fa7-99e8-ba39b6b6b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-cc191a04-a3f0-4122-9625-68779775ba10,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-d01a63b0-95db-4c00-8de3-6782ca38c1da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2939954-172.17.0.18-1597057087082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38733,DS-2438cfb2-aa72-42e2-aeb4-a9d312515110,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-d285f4ee-464e-48e6-b3ae-3ae3d03bce98,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-ef59d46f-8bb0-49f4-95de-439e1ef8f58d,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-371165d9-1309-4e46-ada5-3301b87b367e,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-74006098-14cc-497c-ae6d-37808683a1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-3aaa5fa9-7600-4fa7-99e8-ba39b6b6b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-cc191a04-a3f0-4122-9625-68779775ba10,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-d01a63b0-95db-4c00-8de3-6782ca38c1da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493206132-172.17.0.18-1597057239808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44510,DS-047a6f36-c066-4fc8-b12d-78326bab5c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-10b195b7-66e5-4deb-a767-ab43adccc984,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-1fb8b113-6871-48dd-90bb-d076cba70bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-92e5eeac-8a3b-40d1-a885-e661933b3959,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-73127c2f-c4b2-4d99-9748-300cfd88e992,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-6722fbd5-deb5-405c-a534-7e616b7c6b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-5f01be33-d249-4b8d-95b5-413121ae6860,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-c8896cd1-a11e-4cb4-8503-1ddd0e734dc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1493206132-172.17.0.18-1597057239808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44510,DS-047a6f36-c066-4fc8-b12d-78326bab5c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-10b195b7-66e5-4deb-a767-ab43adccc984,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-1fb8b113-6871-48dd-90bb-d076cba70bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-92e5eeac-8a3b-40d1-a885-e661933b3959,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-73127c2f-c4b2-4d99-9748-300cfd88e992,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-6722fbd5-deb5-405c-a534-7e616b7c6b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-5f01be33-d249-4b8d-95b5-413121ae6860,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-c8896cd1-a11e-4cb4-8503-1ddd0e734dc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005007346-172.17.0.18-1597057391669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34286,DS-200c0422-e441-4dea-85cd-2bdb22d05f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-8c2823a1-7ab0-4380-be63-2ffc6f5fc1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-0b329f60-42a7-4f88-9663-42671871b4da,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-1815cc5b-d7a1-47de-9aa3-56a48a98a2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-8a83e754-7883-49b6-85f1-ae1e9009fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-9b8f9116-d5a8-41d9-b894-a3e54141dd61,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-767cbe4b-2df0-45d6-b234-2b7b74115947,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-7260548e-ebd7-4d8e-a219-7118ea905a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005007346-172.17.0.18-1597057391669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34286,DS-200c0422-e441-4dea-85cd-2bdb22d05f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-8c2823a1-7ab0-4380-be63-2ffc6f5fc1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-0b329f60-42a7-4f88-9663-42671871b4da,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-1815cc5b-d7a1-47de-9aa3-56a48a98a2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-8a83e754-7883-49b6-85f1-ae1e9009fd6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-9b8f9116-d5a8-41d9-b894-a3e54141dd61,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-767cbe4b-2df0-45d6-b234-2b7b74115947,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-7260548e-ebd7-4d8e-a219-7118ea905a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163653581-172.17.0.18-1597057922286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-47078450-a941-4dbb-88f4-f765cbe75bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-9968c6af-5d94-450f-bc09-1b7b283f9759,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-05e673d6-1281-4d49-bf63-bdec5aa15c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-3522d7ce-bc41-4d51-8207-4663f85dec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-5f63d741-cae1-4c24-b651-6bd4a3ae67f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-5bf15a6b-54d0-4209-92e7-8ae3c75dff6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-754f9670-ae0e-464e-9159-7af8065e0c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-81754a81-00f2-4010-95c4-7903e0c3cb86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163653581-172.17.0.18-1597057922286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-47078450-a941-4dbb-88f4-f765cbe75bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-9968c6af-5d94-450f-bc09-1b7b283f9759,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-05e673d6-1281-4d49-bf63-bdec5aa15c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-3522d7ce-bc41-4d51-8207-4663f85dec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-5f63d741-cae1-4c24-b651-6bd4a3ae67f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-5bf15a6b-54d0-4209-92e7-8ae3c75dff6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-754f9670-ae0e-464e-9159-7af8065e0c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-81754a81-00f2-4010-95c4-7903e0c3cb86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585770600-172.17.0.18-1597058104862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46758,DS-292161fc-61ce-41cb-a7fb-83e344b1f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-1c45ff33-68b6-4eb8-971f-5ea94e4ad3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e7aaa38f-6704-4cd2-8762-df2f2a6deb43,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-d36d5060-b815-4691-91b3-9396b543f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-730cf0a1-05b2-40ae-a600-16d3f2bac277,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-3cd0e7b6-ee25-47fe-af2d-30faf435220a,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-181eecdb-70ad-4093-b523-2f58198e57aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-782c7289-0c41-4c28-99b3-3dfcd46d82ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585770600-172.17.0.18-1597058104862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46758,DS-292161fc-61ce-41cb-a7fb-83e344b1f96b,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-1c45ff33-68b6-4eb8-971f-5ea94e4ad3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e7aaa38f-6704-4cd2-8762-df2f2a6deb43,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-d36d5060-b815-4691-91b3-9396b543f88d,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-730cf0a1-05b2-40ae-a600-16d3f2bac277,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-3cd0e7b6-ee25-47fe-af2d-30faf435220a,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-181eecdb-70ad-4093-b523-2f58198e57aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-782c7289-0c41-4c28-99b3-3dfcd46d82ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034091471-172.17.0.18-1597058395486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33175,DS-0ea5ed2a-6e7a-43f1-9d06-20793c1573d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-d1f2e775-42bb-49eb-be89-81e91a1384ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-1381c473-eb17-4386-ba87-d3bc57c4203d,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-c75f97f2-03d9-4989-9579-a577199685ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-776e37fd-006a-4c87-8d51-bd13780981e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-6b27d100-56f4-4e71-b1db-5f8064656055,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-2ea582c2-0c48-482d-93d1-878c60c8607e,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-dfa6cb23-8f45-493d-ae8b-e4e0a827fd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034091471-172.17.0.18-1597058395486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33175,DS-0ea5ed2a-6e7a-43f1-9d06-20793c1573d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43326,DS-d1f2e775-42bb-49eb-be89-81e91a1384ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-1381c473-eb17-4386-ba87-d3bc57c4203d,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-c75f97f2-03d9-4989-9579-a577199685ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-776e37fd-006a-4c87-8d51-bd13780981e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-6b27d100-56f4-4e71-b1db-5f8064656055,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-2ea582c2-0c48-482d-93d1-878c60c8607e,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-dfa6cb23-8f45-493d-ae8b-e4e0a827fd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225377994-172.17.0.18-1597058503829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41314,DS-b8fb3524-e75a-441f-9cdf-8dae2485c636,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-e3cf4009-5e8a-482c-bfa7-bbb22ff66404,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-ed5507db-6fb0-497d-81fc-03a4fcb4ca62,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-5a5b02b0-bfee-4b50-ad68-655946541ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-2f193147-fad3-4688-9273-8f425af7efa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-96b541e8-a1a3-45bd-baf7-0c4fb59d45b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-4009f14f-b180-4f5a-8037-08d0e0f23c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-dfbb1902-fbb0-4e5b-b47e-fb1f0f70deff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225377994-172.17.0.18-1597058503829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41314,DS-b8fb3524-e75a-441f-9cdf-8dae2485c636,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-e3cf4009-5e8a-482c-bfa7-bbb22ff66404,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-ed5507db-6fb0-497d-81fc-03a4fcb4ca62,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-5a5b02b0-bfee-4b50-ad68-655946541ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-2f193147-fad3-4688-9273-8f425af7efa1,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-96b541e8-a1a3-45bd-baf7-0c4fb59d45b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-4009f14f-b180-4f5a-8037-08d0e0f23c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-dfbb1902-fbb0-4e5b-b47e-fb1f0f70deff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286444451-172.17.0.18-1597059041141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-9e215452-da1d-46ad-b22c-9e8572afb3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-18fa48c0-4b9f-4e3c-9b5c-d440fe401f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-0833b673-6b2e-45ad-86b1-252ebe44e939,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-14fdb04c-e66d-4256-9977-fba06f890ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-1a6cc2f7-599d-4779-8101-c77cfd2bbe58,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-faa63a6b-1bc2-4eb7-b47e-6b6bd04a57a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-cdc4c3db-7ab9-42f2-9126-da7c382177d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-3758f092-b058-4f20-b2d0-6f22adb7f9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1286444451-172.17.0.18-1597059041141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41694,DS-9e215452-da1d-46ad-b22c-9e8572afb3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-18fa48c0-4b9f-4e3c-9b5c-d440fe401f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-0833b673-6b2e-45ad-86b1-252ebe44e939,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-14fdb04c-e66d-4256-9977-fba06f890ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-1a6cc2f7-599d-4779-8101-c77cfd2bbe58,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-faa63a6b-1bc2-4eb7-b47e-6b6bd04a57a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-cdc4c3db-7ab9-42f2-9126-da7c382177d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-3758f092-b058-4f20-b2d0-6f22adb7f9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.rpc-timeout.ms
component: hdfs:DataNode
v1: 600000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602886208-172.17.0.18-1597059173753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-b4aee15e-8b3b-40d2-9a21-23f5d588879d,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-cf363c72-c8d0-4782-8984-641c968515b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-ec047e89-db6f-4d6c-b4f6-355262a664a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-0b113439-c2ce-4de1-9670-fb60d41eda76,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-fe441962-474d-4471-8fff-879f4993b908,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-a9c83ae3-f20a-414a-9e6e-8dc1ad55a748,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-bff6a42d-04fa-432d-a581-3decb4c9b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-671d6d50-063e-46f1-9bdf-6265debed4c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602886208-172.17.0.18-1597059173753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-b4aee15e-8b3b-40d2-9a21-23f5d588879d,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-cf363c72-c8d0-4782-8984-641c968515b1,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-ec047e89-db6f-4d6c-b4f6-355262a664a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-0b113439-c2ce-4de1-9670-fb60d41eda76,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-fe441962-474d-4471-8fff-879f4993b908,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-a9c83ae3-f20a-414a-9e6e-8dc1ad55a748,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-bff6a42d-04fa-432d-a581-3decb4c9b8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40037,DS-671d6d50-063e-46f1-9bdf-6265debed4c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5487
