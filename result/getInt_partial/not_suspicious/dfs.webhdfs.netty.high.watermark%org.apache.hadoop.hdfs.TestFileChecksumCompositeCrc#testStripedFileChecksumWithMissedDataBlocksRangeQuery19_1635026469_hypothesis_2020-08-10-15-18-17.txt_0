reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575544809-172.17.0.8-1597073152829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-2bece0ea-546b-47bb-b130-8b8a8187c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-70a550f6-cd32-4c05-a487-10da82876032,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-7b3ef03b-1758-4014-9447-62d4781bd3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-d70cd266-703c-40fd-af76-b6a46bb0c5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-b595bd9a-0287-4bb0-ae16-1069f74ba128,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-7b908555-0eba-47e7-8fd3-ea6467cef6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-c37fc7ad-29d1-40f7-970d-ded330ed11a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-f9b68ae1-caf8-409a-9410-fa52182512c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575544809-172.17.0.8-1597073152829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-2bece0ea-546b-47bb-b130-8b8a8187c7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-70a550f6-cd32-4c05-a487-10da82876032,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-7b3ef03b-1758-4014-9447-62d4781bd3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-d70cd266-703c-40fd-af76-b6a46bb0c5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-b595bd9a-0287-4bb0-ae16-1069f74ba128,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-7b908555-0eba-47e7-8fd3-ea6467cef6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-c37fc7ad-29d1-40f7-970d-ded330ed11a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-f9b68ae1-caf8-409a-9410-fa52182512c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295111696-172.17.0.8-1597073254016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-c9bccc46-0a6f-4d76-a957-c7e03d0e851f,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-1f0da719-28ef-4e04-a1f9-ac854b4fb32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-dc8c79e8-379a-4f48-b4e6-4047bda177e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-58bce59a-841f-477a-9172-84e14e9c3fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-9229b08b-f131-458f-bdee-1c04e021466e,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-91875411-ac8f-4841-8690-e9173aaebe87,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-268ea95e-3251-48d0-b629-8a18ebb7212b,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-2e38669d-41f2-4ad4-9c75-b02e35c0857a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1295111696-172.17.0.8-1597073254016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-c9bccc46-0a6f-4d76-a957-c7e03d0e851f,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-1f0da719-28ef-4e04-a1f9-ac854b4fb32a,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-dc8c79e8-379a-4f48-b4e6-4047bda177e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-58bce59a-841f-477a-9172-84e14e9c3fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-9229b08b-f131-458f-bdee-1c04e021466e,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-91875411-ac8f-4841-8690-e9173aaebe87,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-268ea95e-3251-48d0-b629-8a18ebb7212b,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-2e38669d-41f2-4ad4-9c75-b02e35c0857a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293462684-172.17.0.8-1597073495928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43617,DS-c1f75fb5-0491-452d-9e58-4084104c31e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-c497e9fb-d6b0-4e15-9184-397fd17e179f,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-679a2164-6a5b-4e0e-be92-9bd1b0184b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-d967d0c1-1b75-4edc-83c2-97953910614f,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-071653fe-ef1b-42f9-a0fd-6e4dd568d364,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-92581f99-38d3-4450-9019-18d02e9022b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-5d2493f0-5e19-44e6-af2f-b9c840e78319,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-60319562-a5a4-4f7e-854e-202f358bfc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-293462684-172.17.0.8-1597073495928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43617,DS-c1f75fb5-0491-452d-9e58-4084104c31e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-c497e9fb-d6b0-4e15-9184-397fd17e179f,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-679a2164-6a5b-4e0e-be92-9bd1b0184b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-d967d0c1-1b75-4edc-83c2-97953910614f,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-071653fe-ef1b-42f9-a0fd-6e4dd568d364,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-92581f99-38d3-4450-9019-18d02e9022b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46424,DS-5d2493f0-5e19-44e6-af2f-b9c840e78319,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-60319562-a5a4-4f7e-854e-202f358bfc36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33715160-172.17.0.8-1597073759752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-5dc636c8-30f6-4254-adff-12139dfc3214,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-e75d7f00-e144-43b6-9026-b1a6ac6b859e,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-1315da44-38eb-4963-93a8-4fbe64d09d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-1aaaef97-506a-4845-9637-f964ffbcd5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-42d5d6e5-510a-4a8b-93f7-61a71421fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-37703c63-54ba-4c14-a6d7-4faef355ff5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-3cbcd6b4-decc-41b0-9d8c-4e2ecd50cf31,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-ac9f33c4-a4f3-4015-b87c-e96edeeac364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33715160-172.17.0.8-1597073759752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-5dc636c8-30f6-4254-adff-12139dfc3214,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-e75d7f00-e144-43b6-9026-b1a6ac6b859e,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-1315da44-38eb-4963-93a8-4fbe64d09d11,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-1aaaef97-506a-4845-9637-f964ffbcd5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-42d5d6e5-510a-4a8b-93f7-61a71421fd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-37703c63-54ba-4c14-a6d7-4faef355ff5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-3cbcd6b4-decc-41b0-9d8c-4e2ecd50cf31,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-ac9f33c4-a4f3-4015-b87c-e96edeeac364,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274772500-172.17.0.8-1597073818677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-35f695ff-36ba-4710-a0f4-122d18b4c797,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-0560a7e5-8ee4-400b-9b3c-89026cac032d,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-e587ba76-4289-47a5-acc2-21e9b0b91daf,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-ab59b590-dae5-4309-9425-ad6310cb4404,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-5263f23f-5368-4164-9f05-118a19f540e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-5da2aa97-4cbe-44fc-8894-593438d07b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-c86e6f67-e7d1-40ea-9969-bdf4238670db,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-c9d63741-c11b-4f68-a357-8a7e9b0baa0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274772500-172.17.0.8-1597073818677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45794,DS-35f695ff-36ba-4710-a0f4-122d18b4c797,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-0560a7e5-8ee4-400b-9b3c-89026cac032d,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-e587ba76-4289-47a5-acc2-21e9b0b91daf,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-ab59b590-dae5-4309-9425-ad6310cb4404,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-5263f23f-5368-4164-9f05-118a19f540e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-5da2aa97-4cbe-44fc-8894-593438d07b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-c86e6f67-e7d1-40ea-9969-bdf4238670db,DISK], DatanodeInfoWithStorage[127.0.0.1:43544,DS-c9d63741-c11b-4f68-a357-8a7e9b0baa0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555243618-172.17.0.8-1597073891843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-c7a5c7e7-6718-4d06-a7ff-c8818a409a40,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-eb249664-5323-490f-ae8a-ffc199790ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-9465afef-372b-4f1f-a57e-6594cc16773a,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-ecc2dd02-3cd9-4dfb-8db9-b9b7190e25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-df8c4cb6-2456-4ed7-a2d0-98c31d8dc357,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-6f72f66b-fbcd-43a1-860f-86d8a6ec1cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-b6ca7554-9d10-4302-9fb0-f841e7b924be,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-e03f5925-eb6d-464a-b3fe-0915fbb63be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555243618-172.17.0.8-1597073891843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33930,DS-c7a5c7e7-6718-4d06-a7ff-c8818a409a40,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-eb249664-5323-490f-ae8a-ffc199790ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-9465afef-372b-4f1f-a57e-6594cc16773a,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-ecc2dd02-3cd9-4dfb-8db9-b9b7190e25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-df8c4cb6-2456-4ed7-a2d0-98c31d8dc357,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-6f72f66b-fbcd-43a1-860f-86d8a6ec1cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-b6ca7554-9d10-4302-9fb0-f841e7b924be,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-e03f5925-eb6d-464a-b3fe-0915fbb63be7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132156015-172.17.0.8-1597074208009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-33a44b4d-deef-4aa6-8b9e-bc77abf353b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-945e506d-5fa8-47ab-88e7-2fb0ee0b87b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-1b61b438-edea-460d-b5a8-ef4d230db897,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-8ddf77e9-3cc7-43f1-afa8-8060cf5af67d,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-57d55e60-a167-4d11-81b9-2192e70a0626,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-b8ad38b2-afbf-4229-9dd5-15713dcfce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-e7604195-04c2-41f4-83fe-6cc1ea876eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-5aeabde8-86bf-451d-b5a0-436d3fc559b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132156015-172.17.0.8-1597074208009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44301,DS-33a44b4d-deef-4aa6-8b9e-bc77abf353b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-945e506d-5fa8-47ab-88e7-2fb0ee0b87b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-1b61b438-edea-460d-b5a8-ef4d230db897,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-8ddf77e9-3cc7-43f1-afa8-8060cf5af67d,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-57d55e60-a167-4d11-81b9-2192e70a0626,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-b8ad38b2-afbf-4229-9dd5-15713dcfce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-e7604195-04c2-41f4-83fe-6cc1ea876eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-5aeabde8-86bf-451d-b5a0-436d3fc559b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236762821-172.17.0.8-1597074691125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-a7afd7d8-5e0c-4496-a815-c0cc1c616c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-23f3af2c-feb1-4e40-97e1-cd3d0cb07625,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-341dfb2e-7149-4a0c-bc84-61349a906cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-3cbdeb40-97f2-42d2-972a-b1c52a93710e,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-572cd23d-9cdb-42af-809a-3ddde5b55d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-d25a6e7b-24fe-4d60-86ed-03fea99a3cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-7d80e887-0143-4610-9bb3-5d80a104368a,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-a51d853a-f6e8-441b-8ace-2b198d797b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1236762821-172.17.0.8-1597074691125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41968,DS-a7afd7d8-5e0c-4496-a815-c0cc1c616c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-23f3af2c-feb1-4e40-97e1-cd3d0cb07625,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-341dfb2e-7149-4a0c-bc84-61349a906cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-3cbdeb40-97f2-42d2-972a-b1c52a93710e,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-572cd23d-9cdb-42af-809a-3ddde5b55d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-d25a6e7b-24fe-4d60-86ed-03fea99a3cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-7d80e887-0143-4610-9bb3-5d80a104368a,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-a51d853a-f6e8-441b-8ace-2b198d797b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811485018-172.17.0.8-1597074724806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37840,DS-b6bce495-66d7-4132-8834-28438a5b22f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-282a49a9-e173-4a3c-8a03-8df69f280a42,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-961422fc-5b27-4e9e-85d4-ab4a6a914cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-8ad0f711-0837-4db9-9257-c4aae5ad409a,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-b940927b-1af3-4d6c-b971-db217c93fbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-2f83a885-362d-41ab-84a8-f2eb3ab90734,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-4b085c0b-8850-4caa-a253-3f4ad7353bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-2131b24c-247c-4698-8ebc-49d9a6dfe752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1811485018-172.17.0.8-1597074724806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37840,DS-b6bce495-66d7-4132-8834-28438a5b22f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35669,DS-282a49a9-e173-4a3c-8a03-8df69f280a42,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-961422fc-5b27-4e9e-85d4-ab4a6a914cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-8ad0f711-0837-4db9-9257-c4aae5ad409a,DISK], DatanodeInfoWithStorage[127.0.0.1:38967,DS-b940927b-1af3-4d6c-b971-db217c93fbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-2f83a885-362d-41ab-84a8-f2eb3ab90734,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-4b085c0b-8850-4caa-a253-3f4ad7353bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-2131b24c-247c-4698-8ebc-49d9a6dfe752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237538754-172.17.0.8-1597075525678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-60caaab0-a424-4b6d-a48c-e8d446ee6bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-08e68343-d2c1-42e3-8d78-c634af00d814,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-ee0257cb-f790-4fdd-8fef-192efd37ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-ae9eb7c5-7dea-4ce3-894f-1e579533fd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-e38edcf1-ec77-4faa-ab57-92dc6aa52435,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-bf04c63d-fdd1-468d-a6a6-64058bda9064,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-912a2901-c196-43fc-98af-2d2524ebdd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-7f427930-5f96-4125-99e0-e2f48bffc2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237538754-172.17.0.8-1597075525678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46078,DS-60caaab0-a424-4b6d-a48c-e8d446ee6bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-08e68343-d2c1-42e3-8d78-c634af00d814,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-ee0257cb-f790-4fdd-8fef-192efd37ba07,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-ae9eb7c5-7dea-4ce3-894f-1e579533fd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-e38edcf1-ec77-4faa-ab57-92dc6aa52435,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-bf04c63d-fdd1-468d-a6a6-64058bda9064,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-912a2901-c196-43fc-98af-2d2524ebdd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-7f427930-5f96-4125-99e0-e2f48bffc2cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578494939-172.17.0.8-1597076136214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-d081d308-0cb6-4a54-952c-9d7e70a9f2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-bb48afb9-e9b3-4b9c-a215-e3bcc1592af7,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-8b05ad90-488e-4031-aedd-17597f396b99,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-86500c40-81b1-4dd6-a8f6-4f2287461c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-f6b803c4-5b46-40b3-b54d-f69e6a9b8de2,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-a2be6f2b-7acb-404f-b898-9e97575060fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-0809f21f-315d-4454-934e-7b775fe50cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-82d81309-fe16-464c-abd6-c9f3aa5543fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578494939-172.17.0.8-1597076136214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-d081d308-0cb6-4a54-952c-9d7e70a9f2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-bb48afb9-e9b3-4b9c-a215-e3bcc1592af7,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-8b05ad90-488e-4031-aedd-17597f396b99,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-86500c40-81b1-4dd6-a8f6-4f2287461c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-f6b803c4-5b46-40b3-b54d-f69e6a9b8de2,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-a2be6f2b-7acb-404f-b898-9e97575060fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-0809f21f-315d-4454-934e-7b775fe50cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-82d81309-fe16-464c-abd6-c9f3aa5543fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870722617-172.17.0.8-1597076446906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43844,DS-d43534e8-1546-4ecb-87b3-b6a4c51e4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-b7e1f987-6f9e-4131-a2fc-dd10da40ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-b062ce4d-7f4f-4cd1-93e6-f4b05796f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-9bcc5477-def1-4ce9-b2ba-1b6dab75efec,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-f13b54a0-5c5d-462f-ba95-1187d015a23b,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-e9275196-3db3-4fb8-afce-24fdacd88bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-a68de3ad-64e3-4d85-adb6-3d39e866f317,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-265f3513-3ff7-40e5-9ac1-54330c00f7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870722617-172.17.0.8-1597076446906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43844,DS-d43534e8-1546-4ecb-87b3-b6a4c51e4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-b7e1f987-6f9e-4131-a2fc-dd10da40ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-b062ce4d-7f4f-4cd1-93e6-f4b05796f6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-9bcc5477-def1-4ce9-b2ba-1b6dab75efec,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-f13b54a0-5c5d-462f-ba95-1187d015a23b,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-e9275196-3db3-4fb8-afce-24fdacd88bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-a68de3ad-64e3-4d85-adb6-3d39e866f317,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-265f3513-3ff7-40e5-9ac1-54330c00f7e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000308396-172.17.0.8-1597076739297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36646,DS-7d586dfe-dcae-4983-8eb7-ebf39d6943f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-94783d02-a90d-4e70-8d01-300a287b8c42,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-133449ba-775e-4ab6-8824-d0432798bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-0d78e210-a3fc-4a4e-a86c-0e71e74c8881,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-1e00695c-9bdf-4e9f-bf2c-f7d0f1054513,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-7c8bd4d2-97db-4006-b21d-99d743438eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-9b62e27a-b671-499a-978f-d66621521673,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-c46cfeb3-b429-4464-aa60-cf00f361db34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2000308396-172.17.0.8-1597076739297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36646,DS-7d586dfe-dcae-4983-8eb7-ebf39d6943f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-94783d02-a90d-4e70-8d01-300a287b8c42,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-133449ba-775e-4ab6-8824-d0432798bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-0d78e210-a3fc-4a4e-a86c-0e71e74c8881,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-1e00695c-9bdf-4e9f-bf2c-f7d0f1054513,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-7c8bd4d2-97db-4006-b21d-99d743438eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-9b62e27a-b671-499a-978f-d66621521673,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-c46cfeb3-b429-4464-aa60-cf00f361db34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722748028-172.17.0.8-1597077151677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-524570bc-9c89-4098-8aca-05070857afff,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-30f45afd-5c51-440a-8e40-01008883df68,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-fc1e9daa-0297-481e-bcd6-b25a1f880786,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-ac07f67b-cdae-413c-af49-cf31d4b569da,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-7c8d7b06-bd23-4c61-91b1-76fca67908ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-0ea2ee4b-c74c-4f7a-a61c-0dda8ff77c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-662e96e7-5e65-4ef0-b52b-5d1cfaefb893,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-90a58c23-aef8-4ced-91ad-e39c45e2ebeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722748028-172.17.0.8-1597077151677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33331,DS-524570bc-9c89-4098-8aca-05070857afff,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-30f45afd-5c51-440a-8e40-01008883df68,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-fc1e9daa-0297-481e-bcd6-b25a1f880786,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-ac07f67b-cdae-413c-af49-cf31d4b569da,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-7c8d7b06-bd23-4c61-91b1-76fca67908ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-0ea2ee4b-c74c-4f7a-a61c-0dda8ff77c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-662e96e7-5e65-4ef0-b52b-5d1cfaefb893,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-90a58c23-aef8-4ced-91ad-e39c45e2ebeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698397074-172.17.0.8-1597077189507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33545,DS-13325a73-a9a7-4c53-acff-820c3ebbc5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-5a65f0e4-df43-40a0-9619-a91123666ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-2927a24c-774a-4b66-97f7-b3b131193856,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-0e0acbee-a474-4940-b00e-1c1ec134a848,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-b59826cb-d747-441f-b084-87ce63e00aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-3391c6ca-57f7-4942-9105-8f8d473473ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-4de43776-38bd-432c-8ba3-84c692a4f6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-cc4766a2-1cd3-4d01-872a-f8db771a079e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698397074-172.17.0.8-1597077189507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33545,DS-13325a73-a9a7-4c53-acff-820c3ebbc5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-5a65f0e4-df43-40a0-9619-a91123666ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-2927a24c-774a-4b66-97f7-b3b131193856,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-0e0acbee-a474-4940-b00e-1c1ec134a848,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-b59826cb-d747-441f-b084-87ce63e00aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-3391c6ca-57f7-4942-9105-8f8d473473ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44243,DS-4de43776-38bd-432c-8ba3-84c692a4f6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-cc4766a2-1cd3-4d01-872a-f8db771a079e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.high.watermark
component: hdfs:DataNode
v1: 65535
v2: 2097152
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805275123-172.17.0.8-1597077298123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34340,DS-4c953fb4-25e1-4604-91fd-ce095dead3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-8e2444d7-c82b-49b9-be94-9601b3bc8138,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-2ce1cc66-3135-4dda-b079-f2f758d2ead5,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-fcab4af6-6c49-4ee4-b97e-8437efef5406,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-36e2a742-eae4-478f-bb44-4aa0e3ae8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-9252937f-126f-4acc-9dd5-81b48c16107f,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-ead6a584-25a8-42dc-ad97-4d66f37cb55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-368ce7a9-df79-48d8-aa60-26dc606efe17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1805275123-172.17.0.8-1597077298123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34340,DS-4c953fb4-25e1-4604-91fd-ce095dead3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-8e2444d7-c82b-49b9-be94-9601b3bc8138,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-2ce1cc66-3135-4dda-b079-f2f758d2ead5,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-fcab4af6-6c49-4ee4-b97e-8437efef5406,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-36e2a742-eae4-478f-bb44-4aa0e3ae8bec,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-9252937f-126f-4acc-9dd5-81b48c16107f,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-ead6a584-25a8-42dc-ad97-4d66f37cb55d,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-368ce7a9-df79-48d8-aa60-26dc606efe17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5069
