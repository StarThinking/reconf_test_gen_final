reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078895505-172.17.0.19-1597103339461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33321,DS-d1d26919-54d1-4151-93c6-5d46c6c04025,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-b6237ad1-6e66-4a10-96c3-09bf314ba240,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-186bf221-c185-456e-89d6-5a51acdcb87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-3b2d626c-acaf-44e3-8b3b-1c0b92ea5f13,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-7aff90a5-fce6-49f6-89d2-22e941ce1cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-7fd56fd2-58a6-49de-896e-f39f148b711f,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-b285ab36-bd67-4922-9f6f-f406dad545af,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-73ea0358-17e4-4d7c-92e4-925c26390ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078895505-172.17.0.19-1597103339461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33321,DS-d1d26919-54d1-4151-93c6-5d46c6c04025,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-b6237ad1-6e66-4a10-96c3-09bf314ba240,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-186bf221-c185-456e-89d6-5a51acdcb87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-3b2d626c-acaf-44e3-8b3b-1c0b92ea5f13,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-7aff90a5-fce6-49f6-89d2-22e941ce1cff,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-7fd56fd2-58a6-49de-896e-f39f148b711f,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-b285ab36-bd67-4922-9f6f-f406dad545af,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-73ea0358-17e4-4d7c-92e4-925c26390ded,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339108664-172.17.0.19-1597103947143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34181,DS-82f0ca94-ab07-4ad3-ae1b-99f093073802,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-f4362522-9926-488a-83e1-8e05d0f72979,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-dfbfc258-b114-4e88-b756-bfd7a0051272,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-a69899af-20e2-4dc9-91ca-5979a39428d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-293dfd17-5914-4e38-bc13-46a2bc7078e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-e06d21de-dc1d-4b7a-ae13-c36b0b6ad4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-8ea5a3d2-8ac1-4621-8a3a-86aa81518e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-7ea23d4e-bc8a-4e03-ae60-56319af53698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339108664-172.17.0.19-1597103947143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34181,DS-82f0ca94-ab07-4ad3-ae1b-99f093073802,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-f4362522-9926-488a-83e1-8e05d0f72979,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-dfbfc258-b114-4e88-b756-bfd7a0051272,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-a69899af-20e2-4dc9-91ca-5979a39428d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-293dfd17-5914-4e38-bc13-46a2bc7078e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-e06d21de-dc1d-4b7a-ae13-c36b0b6ad4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-8ea5a3d2-8ac1-4621-8a3a-86aa81518e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-7ea23d4e-bc8a-4e03-ae60-56319af53698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922941662-172.17.0.19-1597104076135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36838,DS-727bb51c-6525-4400-a5ef-b0c8d0260a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-283af7fc-7513-48a1-846a-f10c96b1cbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-85718641-05df-49e4-982b-52cfad6017b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-0ccc718b-58db-4011-8ccd-9737f1eced27,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-d3115106-39d5-42d4-9308-4c4fe5f2ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-06efb39b-9a91-4ea8-a59d-6bb1c39aaf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-142885f0-b469-4a3c-bcdd-b7e4d5240210,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-5cfdb991-e977-4d8e-b2e7-c44c89e51c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922941662-172.17.0.19-1597104076135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36838,DS-727bb51c-6525-4400-a5ef-b0c8d0260a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-283af7fc-7513-48a1-846a-f10c96b1cbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-85718641-05df-49e4-982b-52cfad6017b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-0ccc718b-58db-4011-8ccd-9737f1eced27,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-d3115106-39d5-42d4-9308-4c4fe5f2ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-06efb39b-9a91-4ea8-a59d-6bb1c39aaf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-142885f0-b469-4a3c-bcdd-b7e4d5240210,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-5cfdb991-e977-4d8e-b2e7-c44c89e51c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495386627-172.17.0.19-1597104215620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-1b3c5a16-530f-4712-a124-4129ac4b4590,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-29636f85-7918-487e-b96f-d3fc9e1cbad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-6cb5ebb9-6781-4fc8-add1-9d9f7ac45bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-e8eb044d-bdbe-438e-9d5e-78786fe70614,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-8fa1dba7-10f4-4de9-907e-1f5ed94d1670,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-751040f9-cb1a-4f40-ad56-1fada9d12142,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-30b98f89-6ca1-40bd-9855-ac685167428b,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-6a5fff93-700c-44d6-bf56-126b43668f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495386627-172.17.0.19-1597104215620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-1b3c5a16-530f-4712-a124-4129ac4b4590,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-29636f85-7918-487e-b96f-d3fc9e1cbad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-6cb5ebb9-6781-4fc8-add1-9d9f7ac45bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-e8eb044d-bdbe-438e-9d5e-78786fe70614,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-8fa1dba7-10f4-4de9-907e-1f5ed94d1670,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-751040f9-cb1a-4f40-ad56-1fada9d12142,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-30b98f89-6ca1-40bd-9855-ac685167428b,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-6a5fff93-700c-44d6-bf56-126b43668f39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831483254-172.17.0.19-1597104621569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33636,DS-db75a647-0b67-486f-8817-dd09ce8f2f98,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-acfc40db-f774-4e96-8810-f59247479c84,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-fea0ff11-2587-40fd-a3f9-066da91d512f,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-c61000fe-29ba-416a-9972-5ae9c29df756,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-edb16c9c-eecc-4900-ad58-1e26bda3f3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-7cc417a8-8c1b-4488-8aa7-b1680d394614,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-85bfcb81-a852-4ab3-974e-fc3180b9bf61,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-809fcadf-3fd6-4d24-87a6-e66e3df218fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831483254-172.17.0.19-1597104621569:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33636,DS-db75a647-0b67-486f-8817-dd09ce8f2f98,DISK], DatanodeInfoWithStorage[127.0.0.1:36449,DS-acfc40db-f774-4e96-8810-f59247479c84,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-fea0ff11-2587-40fd-a3f9-066da91d512f,DISK], DatanodeInfoWithStorage[127.0.0.1:35821,DS-c61000fe-29ba-416a-9972-5ae9c29df756,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-edb16c9c-eecc-4900-ad58-1e26bda3f3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41873,DS-7cc417a8-8c1b-4488-8aa7-b1680d394614,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-85bfcb81-a852-4ab3-974e-fc3180b9bf61,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-809fcadf-3fd6-4d24-87a6-e66e3df218fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484651131-172.17.0.19-1597104796289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45647,DS-23c1bfd3-0e6c-4a33-919c-b6cdacb28cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-3aacac77-4c8e-4e3e-b340-e3baec0f8db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-efe25f92-3858-4576-b841-85f7d6045776,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-8cfc8e60-7e5a-4af2-9ddf-ad235afdf3be,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-20638a12-2f3d-4f00-bba7-b03020e34781,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-c65ffd2b-6cdc-4737-9993-31fca73e7da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-c61573f7-5067-4f1b-b7dc-587c5255b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-e12b1f01-6e83-4d3e-bca2-59f53fb1c21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1484651131-172.17.0.19-1597104796289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45647,DS-23c1bfd3-0e6c-4a33-919c-b6cdacb28cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-3aacac77-4c8e-4e3e-b340-e3baec0f8db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34196,DS-efe25f92-3858-4576-b841-85f7d6045776,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-8cfc8e60-7e5a-4af2-9ddf-ad235afdf3be,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-20638a12-2f3d-4f00-bba7-b03020e34781,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-c65ffd2b-6cdc-4737-9993-31fca73e7da3,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-c61573f7-5067-4f1b-b7dc-587c5255b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-e12b1f01-6e83-4d3e-bca2-59f53fb1c21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770699009-172.17.0.19-1597104833900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-3f070803-d8e4-466a-8575-93069ad314d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-94f5b4ef-c44c-4b1e-a1f7-53ce788ac54d,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-18e5d577-8e4f-4c6b-b468-e7a497e1b6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-63eb77dd-af95-4e9d-b7de-f5dd50cd88ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-cda0d211-a985-47cc-9553-88f510ac3490,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-002a5497-edaf-4fda-986c-3df9b74d0428,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-48db86f6-668f-4f81-bc1b-eec7b257378a,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-da8aa366-bb5b-45c1-8039-3e3cf3310d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-770699009-172.17.0.19-1597104833900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-3f070803-d8e4-466a-8575-93069ad314d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-94f5b4ef-c44c-4b1e-a1f7-53ce788ac54d,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-18e5d577-8e4f-4c6b-b468-e7a497e1b6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-63eb77dd-af95-4e9d-b7de-f5dd50cd88ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-cda0d211-a985-47cc-9553-88f510ac3490,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-002a5497-edaf-4fda-986c-3df9b74d0428,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-48db86f6-668f-4f81-bc1b-eec7b257378a,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-da8aa366-bb5b-45c1-8039-3e3cf3310d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140487060-172.17.0.19-1597105053961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-67c3077e-58fc-4aa9-a09c-38349aaf7b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-3abadf5a-94cd-4199-bda0-95bd254ca1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-f6975112-39b4-4ce4-81f3-59eb5c91d42e,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-43166fdc-c84d-41c4-974d-b3bc33eb82f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-fc87b85b-9b9d-4061-b81a-8aa21cd7e642,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-f1a77777-72ae-47ca-a566-944e2268131c,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-22a74a3e-526a-4ebd-88a1-058118f36a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-bde40e5a-c860-4e1c-9837-84daa3666235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140487060-172.17.0.19-1597105053961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35185,DS-67c3077e-58fc-4aa9-a09c-38349aaf7b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-3abadf5a-94cd-4199-bda0-95bd254ca1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38930,DS-f6975112-39b4-4ce4-81f3-59eb5c91d42e,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-43166fdc-c84d-41c4-974d-b3bc33eb82f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-fc87b85b-9b9d-4061-b81a-8aa21cd7e642,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-f1a77777-72ae-47ca-a566-944e2268131c,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-22a74a3e-526a-4ebd-88a1-058118f36a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-bde40e5a-c860-4e1c-9837-84daa3666235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585157726-172.17.0.19-1597105322604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43379,DS-030d73af-a9fb-4388-b836-e410872761f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-8c704bf6-cd0e-4c74-9f87-7c7e6c1737e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-9de409b2-3545-4267-a355-69537cc1c089,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-3682204e-dd6f-42f3-a7f1-9971d87c79c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-4a08477a-29ca-4f29-8a90-1e635574c115,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-72badecb-823b-4f55-b98d-9ae9c40c4933,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-42fa777f-8fe0-4309-8d26-57ff63f74a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-ae243ca7-24fe-4eca-a669-7675757820df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1585157726-172.17.0.19-1597105322604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43379,DS-030d73af-a9fb-4388-b836-e410872761f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-8c704bf6-cd0e-4c74-9f87-7c7e6c1737e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-9de409b2-3545-4267-a355-69537cc1c089,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-3682204e-dd6f-42f3-a7f1-9971d87c79c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-4a08477a-29ca-4f29-8a90-1e635574c115,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-72badecb-823b-4f55-b98d-9ae9c40c4933,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-42fa777f-8fe0-4309-8d26-57ff63f74a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-ae243ca7-24fe-4eca-a669-7675757820df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43180841-172.17.0.19-1597105712960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35804,DS-75aeaf04-683a-47b7-9f0f-6f065442bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-84693880-4d9c-47fb-a70b-a0920f4e14e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-33baad59-617e-4b40-8692-2e69708d3d57,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-667f1f7e-0899-407c-abbd-50c867a6caec,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-8a3c6394-3aaa-4c38-8851-42707a8ea5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-d554156d-43a6-4006-afe4-ff13f1b89135,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-7fa389f3-2d40-4722-9b0b-f7378b3532d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-09515a5a-eb5c-4dfc-9973-84946e470ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43180841-172.17.0.19-1597105712960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35804,DS-75aeaf04-683a-47b7-9f0f-6f065442bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-84693880-4d9c-47fb-a70b-a0920f4e14e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-33baad59-617e-4b40-8692-2e69708d3d57,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-667f1f7e-0899-407c-abbd-50c867a6caec,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-8a3c6394-3aaa-4c38-8851-42707a8ea5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-d554156d-43a6-4006-afe4-ff13f1b89135,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-7fa389f3-2d40-4722-9b0b-f7378b3532d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-09515a5a-eb5c-4dfc-9973-84946e470ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193790308-172.17.0.19-1597106169319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36691,DS-315c3871-4b0a-4988-9205-b9717416b626,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-f52e22a8-2f76-4f73-bf1a-b9f3a89bb869,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-20a4533b-3d9e-4c4b-af58-3fd45386c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-533ccad9-f26a-4766-b858-98c8706ab06d,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-b82fdd62-4aa9-49a5-8b48-3b978b316fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-282a8ca9-ec97-45b4-986e-f30a5a2d901f,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-5a37f5b1-6bc8-4520-a6c5-a37a6c3f9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-87c1c577-d457-4573-881a-6a92c1db7142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193790308-172.17.0.19-1597106169319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36691,DS-315c3871-4b0a-4988-9205-b9717416b626,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-f52e22a8-2f76-4f73-bf1a-b9f3a89bb869,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-20a4533b-3d9e-4c4b-af58-3fd45386c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-533ccad9-f26a-4766-b858-98c8706ab06d,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-b82fdd62-4aa9-49a5-8b48-3b978b316fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-282a8ca9-ec97-45b4-986e-f30a5a2d901f,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-5a37f5b1-6bc8-4520-a6c5-a37a6c3f9a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33875,DS-87c1c577-d457-4573-881a-6a92c1db7142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022716218-172.17.0.19-1597106257611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40549,DS-5aa1ad8b-6e5f-4e38-a458-d07051ab7c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-1bc74267-ecbb-42ac-b90a-deef7f11eb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-48d38100-8efd-4727-becb-5de1a501977c,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-fceca398-d709-4907-a03c-93773ff51219,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-ac4d0fe1-dd3d-4af3-b9ec-9412b8f294bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-5bce0604-5311-4b22-a4ab-de70decdb44f,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-b943d655-ea6b-4a8b-8286-d362433b0c47,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-00a5e748-0aca-43d5-ad72-de7017f6e018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022716218-172.17.0.19-1597106257611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40549,DS-5aa1ad8b-6e5f-4e38-a458-d07051ab7c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-1bc74267-ecbb-42ac-b90a-deef7f11eb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-48d38100-8efd-4727-becb-5de1a501977c,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-fceca398-d709-4907-a03c-93773ff51219,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-ac4d0fe1-dd3d-4af3-b9ec-9412b8f294bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-5bce0604-5311-4b22-a4ab-de70decdb44f,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-b943d655-ea6b-4a8b-8286-d362433b0c47,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-00a5e748-0aca-43d5-ad72-de7017f6e018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596065810-172.17.0.19-1597106427791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-98892642-f88c-46c1-9020-11f3aeac2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-f3863aa2-247b-40f9-ba43-c0755f55b477,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-91380ef4-835d-47b9-a87e-867a1d38e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-dd369084-5ae9-48e1-bf32-ce61f6feef31,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-463dd0aa-31a4-464f-816a-3a887692234c,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-70ccedb3-f4dd-4534-bf61-19adaf553049,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-538a3656-d0b3-456f-9160-13aa825ec34b,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-2eea0c9a-7ea6-4f45-bb91-c94440c38f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1596065810-172.17.0.19-1597106427791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-98892642-f88c-46c1-9020-11f3aeac2cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-f3863aa2-247b-40f9-ba43-c0755f55b477,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-91380ef4-835d-47b9-a87e-867a1d38e5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-dd369084-5ae9-48e1-bf32-ce61f6feef31,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-463dd0aa-31a4-464f-816a-3a887692234c,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-70ccedb3-f4dd-4534-bf61-19adaf553049,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-538a3656-d0b3-456f-9160-13aa825ec34b,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-2eea0c9a-7ea6-4f45-bb91-c94440c38f92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31410241-172.17.0.19-1597106638402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37235,DS-257edceb-eb60-4e67-a3cd-1b8e309a91f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-e2e1cdfb-ab56-49c7-9ca2-9e0457ea4cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-65683517-6edc-49dd-a3bb-3f2465eb7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-1fd20d96-f261-4dcb-b57c-09af1d72b869,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-e68b0913-5c4a-448d-8dc4-a094db83d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-c567e380-e4a8-49cc-b7b7-63f6f5e3ccd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-f852fda3-3098-4888-b809-14dc8316996c,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-4787b752-7845-4b24-9ad2-6311cf8dae3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-31410241-172.17.0.19-1597106638402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37235,DS-257edceb-eb60-4e67-a3cd-1b8e309a91f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-e2e1cdfb-ab56-49c7-9ca2-9e0457ea4cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-65683517-6edc-49dd-a3bb-3f2465eb7fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-1fd20d96-f261-4dcb-b57c-09af1d72b869,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-e68b0913-5c4a-448d-8dc4-a094db83d4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-c567e380-e4a8-49cc-b7b7-63f6f5e3ccd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-f852fda3-3098-4888-b809-14dc8316996c,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-4787b752-7845-4b24-9ad2-6311cf8dae3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797166307-172.17.0.19-1597106996012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-733db924-dd3a-40c7-93c3-57c11e64ea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-50547e13-a159-4c38-9f3e-ab978fe40002,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-1384b8dc-4303-414a-8fd4-7ad92d791060,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-7923108d-6f02-40b6-a440-4e2a40775a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-e4742493-37a2-4172-ba92-64ca955acac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-d77de703-a104-4243-9dcf-2cee0f4c2816,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-444ce436-46b3-42b9-bf88-d182cfb3a168,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-88ac3859-2ebb-4a6e-8abc-da1de8128fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797166307-172.17.0.19-1597106996012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-733db924-dd3a-40c7-93c3-57c11e64ea7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-50547e13-a159-4c38-9f3e-ab978fe40002,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-1384b8dc-4303-414a-8fd4-7ad92d791060,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-7923108d-6f02-40b6-a440-4e2a40775a57,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-e4742493-37a2-4172-ba92-64ca955acac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-d77de703-a104-4243-9dcf-2cee0f4c2816,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-444ce436-46b3-42b9-bf88-d182cfb3a168,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-88ac3859-2ebb-4a6e-8abc-da1de8128fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-389540880-172.17.0.19-1597107461145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-0978a296-cad0-4d20-a2a7-c8e708a0acf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-a2146f96-98d9-4038-8056-113e6351e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-f3d57065-80bc-45be-aabd-f05e2cc8a4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-e9542ad0-f842-43ce-b5e2-6a7d86f08566,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-b3ab90fa-887c-4f72-a7ee-ba742ad7af70,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-aac92e44-ae1d-438b-b011-6516cb4e502c,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-977403c4-69fe-4548-99f6-bd39ea46a122,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-c586379b-42a8-4f39-ad45-343731fe0b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-389540880-172.17.0.19-1597107461145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-0978a296-cad0-4d20-a2a7-c8e708a0acf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-a2146f96-98d9-4038-8056-113e6351e7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-f3d57065-80bc-45be-aabd-f05e2cc8a4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-e9542ad0-f842-43ce-b5e2-6a7d86f08566,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-b3ab90fa-887c-4f72-a7ee-ba742ad7af70,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-aac92e44-ae1d-438b-b011-6516cb4e502c,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-977403c4-69fe-4548-99f6-bd39ea46a122,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-c586379b-42a8-4f39-ad45-343731fe0b58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706640117-172.17.0.19-1597107588868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-63f0a378-22b5-4d99-8789-71393505ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-dceae9f7-a178-4421-8f48-1d4c901c87be,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-2792ef94-9f87-4e1f-945e-14b29f68f6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-5718e7d3-6449-4e81-bb88-bf04133ec0af,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-400ab131-a1ab-493a-952e-247c39a53c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-a7fc6bb3-caa9-4e3f-adf0-136b64253002,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-5abc5d02-4a78-4367-9ef9-00c9dc613cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-d4c2308a-4b8f-41ce-b80f-18db8424e550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706640117-172.17.0.19-1597107588868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-63f0a378-22b5-4d99-8789-71393505ca72,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-dceae9f7-a178-4421-8f48-1d4c901c87be,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-2792ef94-9f87-4e1f-945e-14b29f68f6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-5718e7d3-6449-4e81-bb88-bf04133ec0af,DISK], DatanodeInfoWithStorage[127.0.0.1:38233,DS-400ab131-a1ab-493a-952e-247c39a53c72,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-a7fc6bb3-caa9-4e3f-adf0-136b64253002,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-5abc5d02-4a78-4367-9ef9-00c9dc613cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-d4c2308a-4b8f-41ce-b80f-18db8424e550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920226686-172.17.0.19-1597107814452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-f914ba57-d645-49bc-935a-9961839329df,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-4f59fc53-74fb-437f-81f2-32776184e63e,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-734c9486-8cf7-406e-a75e-54ad9336944c,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-b1e92f0d-70be-408c-9d36-dd0a5d749cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-dc751a32-ce5b-4884-87f1-3f5f9ebf0509,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-25eb16d8-6a31-4601-965d-310d75caae51,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-17a01b78-54ab-4d54-9f01-1fae63409496,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-0dde3f39-a6dc-4525-b12e-076215c7e328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920226686-172.17.0.19-1597107814452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39931,DS-f914ba57-d645-49bc-935a-9961839329df,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-4f59fc53-74fb-437f-81f2-32776184e63e,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-734c9486-8cf7-406e-a75e-54ad9336944c,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-b1e92f0d-70be-408c-9d36-dd0a5d749cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-dc751a32-ce5b-4884-87f1-3f5f9ebf0509,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-25eb16d8-6a31-4601-965d-310d75caae51,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-17a01b78-54ab-4d54-9f01-1fae63409496,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-0dde3f39-a6dc-4525-b12e-076215c7e328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275968684-172.17.0.19-1597107864949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41535,DS-884c8cf3-6026-44d1-9e83-2df695dd4106,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-21da2fdf-94ca-4a33-b5af-1ddb3403fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-ddcc6f41-10b6-4b33-bb3b-7c166967c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-cfbcf0b5-f5aa-4f15-b68b-2f9411585c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-caf630f8-ceb7-4cec-8613-4e5ba6518e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-1dde6629-1378-4483-bc9a-c5e17de33c00,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-147b89a3-30d9-4fd2-9b84-6fb2b7f83dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-82f53447-cd01-4347-985b-b1987b0bb73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1275968684-172.17.0.19-1597107864949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41535,DS-884c8cf3-6026-44d1-9e83-2df695dd4106,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-21da2fdf-94ca-4a33-b5af-1ddb3403fa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-ddcc6f41-10b6-4b33-bb3b-7c166967c83f,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-cfbcf0b5-f5aa-4f15-b68b-2f9411585c87,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-caf630f8-ceb7-4cec-8613-4e5ba6518e47,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-1dde6629-1378-4483-bc9a-c5e17de33c00,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-147b89a3-30d9-4fd2-9b84-6fb2b7f83dfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-82f53447-cd01-4347-985b-b1987b0bb73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168192510-172.17.0.19-1597107957837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37020,DS-b6cec5dc-3114-42df-af58-393f488d4b53,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-e4b70243-0bc1-4848-a511-9b8e95a17342,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-24dc12d9-06eb-46de-925a-6a4322957d01,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-bf973cf8-68c6-4ccf-821d-9ea0e1a88caf,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-c5fb0494-08db-4857-ae10-493612fb7a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-e0c8d588-427f-4536-9aeb-4fa0cd151e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-1d75f1ec-fc28-4bb4-98a8-b8e5700182fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-89e20bc4-9ac2-434c-ad5d-e5ceb9b11432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168192510-172.17.0.19-1597107957837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37020,DS-b6cec5dc-3114-42df-af58-393f488d4b53,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-e4b70243-0bc1-4848-a511-9b8e95a17342,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-24dc12d9-06eb-46de-925a-6a4322957d01,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-bf973cf8-68c6-4ccf-821d-9ea0e1a88caf,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-c5fb0494-08db-4857-ae10-493612fb7a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-e0c8d588-427f-4536-9aeb-4fa0cd151e89,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-1d75f1ec-fc28-4bb4-98a8-b8e5700182fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-89e20bc4-9ac2-434c-ad5d-e5ceb9b11432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6670
