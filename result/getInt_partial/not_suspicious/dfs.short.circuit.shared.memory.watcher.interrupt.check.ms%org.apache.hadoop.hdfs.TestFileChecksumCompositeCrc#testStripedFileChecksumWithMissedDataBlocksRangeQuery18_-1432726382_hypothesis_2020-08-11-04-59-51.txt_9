reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578603446-172.17.0.20-1597122256336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-62415344-2464-4c85-954d-56da147b1ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-3b557f68-70c1-4f74-bd63-955a7a3aaf58,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-b72358c3-23d9-4911-af3c-8b276b18641d,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-10c846f5-8882-4a99-95b1-4955871e541e,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-04473074-8c41-4c3e-be65-d55bf6ea7cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-f644b5c0-d6e6-4f70-bbf8-9d604af7b109,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-bdec4489-46c3-446e-bfd5-8265b2cf0285,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-d69a7a5a-658a-4bbb-bc4a-afb27d95219c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1578603446-172.17.0.20-1597122256336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37069,DS-62415344-2464-4c85-954d-56da147b1ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-3b557f68-70c1-4f74-bd63-955a7a3aaf58,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-b72358c3-23d9-4911-af3c-8b276b18641d,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-10c846f5-8882-4a99-95b1-4955871e541e,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-04473074-8c41-4c3e-be65-d55bf6ea7cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-f644b5c0-d6e6-4f70-bbf8-9d604af7b109,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-bdec4489-46c3-446e-bfd5-8265b2cf0285,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-d69a7a5a-658a-4bbb-bc4a-afb27d95219c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316452649-172.17.0.20-1597122683996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-4f97fb47-ab61-45a0-a948-85e70a717fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-490c36c8-caaf-41b2-a051-722db0af6b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-23627887-21ad-4b69-99d1-90eeab0be48c,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-c044404e-4f2f-4e27-bd36-b61f6e1d7671,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-b0527b07-256d-4852-b92b-6acf8b9b9bee,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-3a231e61-e6f0-412c-a107-705f9494e260,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-3aec80f4-8532-4116-a5d4-6ad14b5c6a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-17fb1ebf-f44e-4e09-b4af-32a728741d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316452649-172.17.0.20-1597122683996:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33553,DS-4f97fb47-ab61-45a0-a948-85e70a717fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-490c36c8-caaf-41b2-a051-722db0af6b08,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-23627887-21ad-4b69-99d1-90eeab0be48c,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-c044404e-4f2f-4e27-bd36-b61f6e1d7671,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-b0527b07-256d-4852-b92b-6acf8b9b9bee,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-3a231e61-e6f0-412c-a107-705f9494e260,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-3aec80f4-8532-4116-a5d4-6ad14b5c6a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-17fb1ebf-f44e-4e09-b4af-32a728741d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548207090-172.17.0.20-1597123599511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40963,DS-ac27fd22-485a-4df3-af9b-003449f63d52,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-9ff2cc81-ede6-418d-8d02-c8b686cdf8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-911aef0e-0c60-47ea-9697-d27db84e9ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-cf6b919a-320e-4fd8-a9b7-e3229ed84d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-c8607ace-1623-4334-b469-9305cbc30777,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-7945c884-d1aa-403d-8ce0-1524df5d4f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-1379065e-3bbc-4337-b111-d3073f99f8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-af9221b4-c57c-47c9-a49f-272b41a1aa1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548207090-172.17.0.20-1597123599511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40963,DS-ac27fd22-485a-4df3-af9b-003449f63d52,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-9ff2cc81-ede6-418d-8d02-c8b686cdf8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-911aef0e-0c60-47ea-9697-d27db84e9ece,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-cf6b919a-320e-4fd8-a9b7-e3229ed84d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-c8607ace-1623-4334-b469-9305cbc30777,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-7945c884-d1aa-403d-8ce0-1524df5d4f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-1379065e-3bbc-4337-b111-d3073f99f8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-af9221b4-c57c-47c9-a49f-272b41a1aa1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940096819-172.17.0.20-1597123952035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-41c296fa-f838-4a36-a286-a1ebdeb34d87,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-cc955a86-b866-4e3e-b2ca-d1ba3a808223,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-d6e38fd8-2878-4584-8ece-78fc3eff5432,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-70ed119d-3bcf-497a-bcfc-9fe08438c949,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-abcd963c-b95b-4ea0-bd99-134d650211d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-c5b3077f-94ae-4f14-a9ad-10078a4d9e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-5e461fb4-46f0-4633-9833-81c609fd32ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-2133112c-6283-49b7-a03b-a0b3601b6281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1940096819-172.17.0.20-1597123952035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-41c296fa-f838-4a36-a286-a1ebdeb34d87,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-cc955a86-b866-4e3e-b2ca-d1ba3a808223,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-d6e38fd8-2878-4584-8ece-78fc3eff5432,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-70ed119d-3bcf-497a-bcfc-9fe08438c949,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-abcd963c-b95b-4ea0-bd99-134d650211d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-c5b3077f-94ae-4f14-a9ad-10078a4d9e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-5e461fb4-46f0-4633-9833-81c609fd32ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-2133112c-6283-49b7-a03b-a0b3601b6281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227372690-172.17.0.20-1597124735998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41238,DS-72a28679-ae25-4a7d-b5c3-053add71ab0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-01a0a70d-4e45-4796-93d9-f4ca47c0db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-61e4b60c-662a-42d7-a69c-e3e998f14a29,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-2f540a07-bc0d-4d7c-8522-73b4207174eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-19528e95-f97c-4100-9802-da3993b9c706,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-1f68dfa8-d31d-491c-89f9-5179b91102fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-7d0621f9-72ab-4361-a3da-2a6e9d9b89d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-ad0f9fc7-c48e-4bbb-ab87-f88d846669b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227372690-172.17.0.20-1597124735998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41238,DS-72a28679-ae25-4a7d-b5c3-053add71ab0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-01a0a70d-4e45-4796-93d9-f4ca47c0db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-61e4b60c-662a-42d7-a69c-e3e998f14a29,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-2f540a07-bc0d-4d7c-8522-73b4207174eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-19528e95-f97c-4100-9802-da3993b9c706,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-1f68dfa8-d31d-491c-89f9-5179b91102fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-7d0621f9-72ab-4361-a3da-2a6e9d9b89d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-ad0f9fc7-c48e-4bbb-ab87-f88d846669b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412417183-172.17.0.20-1597125075738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-62acaa1b-c0ec-436d-a809-b02778b31420,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-1c6aaa74-1f86-4fde-bc46-f18a8c0e157a,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-1ed7a27f-a75e-49db-a7e7-122dbd55edc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-0f88e805-160d-4f98-8d73-c7c20854be76,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-1d79e1f3-5f10-4dcd-abd5-ec3aff67946d,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-a1898248-77b2-42f6-9178-b4fbf2bdde70,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-b1e9be96-e5e0-4729-bc1d-377db6f8d6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-06dda8fd-fbe5-4e81-aa7c-b182f9318260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412417183-172.17.0.20-1597125075738:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-62acaa1b-c0ec-436d-a809-b02778b31420,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-1c6aaa74-1f86-4fde-bc46-f18a8c0e157a,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-1ed7a27f-a75e-49db-a7e7-122dbd55edc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-0f88e805-160d-4f98-8d73-c7c20854be76,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-1d79e1f3-5f10-4dcd-abd5-ec3aff67946d,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-a1898248-77b2-42f6-9178-b4fbf2bdde70,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-b1e9be96-e5e0-4729-bc1d-377db6f8d6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-06dda8fd-fbe5-4e81-aa7c-b182f9318260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450546987-172.17.0.20-1597125178865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-cf1323d3-52c2-4adf-ab3e-fe7674c8a40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-c67094e8-12ce-45e9-ac60-ed124a1d351b,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-4e2fe4ec-77b1-4ef7-88c3-31096b14a3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-0ead227b-ae41-4d1f-b8bb-d659963cee9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-d33fb657-87ee-4353-8aa4-58b825c6229d,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-3510b400-f353-4c5b-9e1b-0de6d6d8958d,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-7c10a3d6-2f58-4af3-9eb9-7b55402c20d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-6d8d16d8-a949-41fc-a57b-f815b52716e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-450546987-172.17.0.20-1597125178865:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46059,DS-cf1323d3-52c2-4adf-ab3e-fe7674c8a40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-c67094e8-12ce-45e9-ac60-ed124a1d351b,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-4e2fe4ec-77b1-4ef7-88c3-31096b14a3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-0ead227b-ae41-4d1f-b8bb-d659963cee9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-d33fb657-87ee-4353-8aa4-58b825c6229d,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-3510b400-f353-4c5b-9e1b-0de6d6d8958d,DISK], DatanodeInfoWithStorage[127.0.0.1:45589,DS-7c10a3d6-2f58-4af3-9eb9-7b55402c20d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-6d8d16d8-a949-41fc-a57b-f815b52716e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970081602-172.17.0.20-1597125213341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-67a9f61b-243a-4601-96b5-d8ff07b16d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-df7ad9d4-1ad1-4e94-b4c8-db6883a62799,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-c5fa931b-e8a3-4607-a594-979a05b439e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-f974dd04-6a1c-4664-bb92-78e1c8ed4667,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-f91dc5fc-5234-47e5-a9ef-e36a35fc2ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-066e4f01-69d5-4515-b1f7-fb94edfafa84,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-a8efbc29-9f9a-4f9b-8c68-ff6997c7fc12,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-9f747da1-f7a1-4e4a-a655-81c57a7fc6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970081602-172.17.0.20-1597125213341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-67a9f61b-243a-4601-96b5-d8ff07b16d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-df7ad9d4-1ad1-4e94-b4c8-db6883a62799,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-c5fa931b-e8a3-4607-a594-979a05b439e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-f974dd04-6a1c-4664-bb92-78e1c8ed4667,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-f91dc5fc-5234-47e5-a9ef-e36a35fc2ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-066e4f01-69d5-4515-b1f7-fb94edfafa84,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-a8efbc29-9f9a-4f9b-8c68-ff6997c7fc12,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-9f747da1-f7a1-4e4a-a655-81c57a7fc6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442306819-172.17.0.20-1597125737499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37104,DS-b4319be7-f503-4e94-8abf-eed49ca16c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-945b8a23-03f2-45d7-a829-225d50732b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-825176e1-0e87-4c84-b431-e36fce41af89,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-58f767ec-8377-4f3c-8399-dec4b9aac450,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-582fb617-dfb3-44eb-8074-f47911e14df6,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-70bf9378-a07d-48a9-8e3e-126ae0ec642b,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-c60661ad-6925-4ed4-9c6f-dd7a6ba57b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-5862234e-cca1-4f64-a083-9e6f0ead717b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-442306819-172.17.0.20-1597125737499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37104,DS-b4319be7-f503-4e94-8abf-eed49ca16c72,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-945b8a23-03f2-45d7-a829-225d50732b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-825176e1-0e87-4c84-b431-e36fce41af89,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-58f767ec-8377-4f3c-8399-dec4b9aac450,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-582fb617-dfb3-44eb-8074-f47911e14df6,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-70bf9378-a07d-48a9-8e3e-126ae0ec642b,DISK], DatanodeInfoWithStorage[127.0.0.1:40195,DS-c60661ad-6925-4ed4-9c6f-dd7a6ba57b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-5862234e-cca1-4f64-a083-9e6f0ead717b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631288310-172.17.0.20-1597126065167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41786,DS-8521b3ae-3137-4c3d-aa45-8790703743ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-ca0acfc8-459f-4001-adaa-fbde699ad920,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-d7e96ad3-c578-48d7-9489-e4633dee908a,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-02753444-5651-478c-b162-072bad55308d,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-b0cb0c3a-d109-47a9-9cc4-0a9ed442eb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-c6badca2-0e21-48c2-a6b4-bb7284855f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-8049162e-00ed-4fc3-8857-c0daeeca6bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-a6cf87a5-9fbe-4992-814b-a66782760ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631288310-172.17.0.20-1597126065167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41786,DS-8521b3ae-3137-4c3d-aa45-8790703743ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-ca0acfc8-459f-4001-adaa-fbde699ad920,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-d7e96ad3-c578-48d7-9489-e4633dee908a,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-02753444-5651-478c-b162-072bad55308d,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-b0cb0c3a-d109-47a9-9cc4-0a9ed442eb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-c6badca2-0e21-48c2-a6b4-bb7284855f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-8049162e-00ed-4fc3-8857-c0daeeca6bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-a6cf87a5-9fbe-4992-814b-a66782760ea2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581893482-172.17.0.20-1597126527429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-84723624-9308-420e-a6e8-df1659380417,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-ebc82a8d-0936-4e21-aef0-63682bf13895,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-b3ec52f5-c22a-40a0-a76a-bd32e6f19928,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-e012e1e9-dd7b-4cea-ba0d-74e66b573aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-592f30e2-582a-48f9-a29b-fed4f546e571,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-16f0fb06-cfc5-4010-9a24-000948d6f86c,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-b86d906e-fbb2-4708-bb38-3302421db578,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-027051e4-b9e3-4a2e-bf71-0397cad0da96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581893482-172.17.0.20-1597126527429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35380,DS-84723624-9308-420e-a6e8-df1659380417,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-ebc82a8d-0936-4e21-aef0-63682bf13895,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-b3ec52f5-c22a-40a0-a76a-bd32e6f19928,DISK], DatanodeInfoWithStorage[127.0.0.1:36673,DS-e012e1e9-dd7b-4cea-ba0d-74e66b573aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-592f30e2-582a-48f9-a29b-fed4f546e571,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-16f0fb06-cfc5-4010-9a24-000948d6f86c,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-b86d906e-fbb2-4708-bb38-3302421db578,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-027051e4-b9e3-4a2e-bf71-0397cad0da96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312085767-172.17.0.20-1597126667269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-db5a069a-a9ef-4af9-921c-aebad2ec3cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-b61c311f-d02f-4dcf-82ba-b354e5dc5c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-128c9eac-258f-46b0-92c7-fe1ad2e3dd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-1338bb49-76c3-4e3b-ba27-19cd3dd59825,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-0674ea0c-a60b-43d4-9659-14d575057881,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-b28c7103-b2d2-4dd6-bd4a-507115b7d4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-70fff6da-3b1a-4bae-9d57-c5325776cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-520e5b49-2272-459f-9812-51b19e4fc0f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312085767-172.17.0.20-1597126667269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36083,DS-db5a069a-a9ef-4af9-921c-aebad2ec3cee,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-b61c311f-d02f-4dcf-82ba-b354e5dc5c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-128c9eac-258f-46b0-92c7-fe1ad2e3dd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-1338bb49-76c3-4e3b-ba27-19cd3dd59825,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-0674ea0c-a60b-43d4-9659-14d575057881,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-b28c7103-b2d2-4dd6-bd4a-507115b7d4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-70fff6da-3b1a-4bae-9d57-c5325776cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-520e5b49-2272-459f-9812-51b19e4fc0f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984141496-172.17.0.20-1597126896456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-84add6b9-d032-471c-9121-b530afc39277,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-e3d09092-dbae-4253-b8d2-014250fd2203,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-6219606d-ef49-4b52-8700-4609508bb014,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-7539dbfe-b245-4de7-a64c-a99c4d83f318,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-7ac2561c-ec54-4b6d-9766-7c3a2e1975db,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-7aa3f520-9e8e-49c6-a7b2-63426f1cf9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-b0b3225e-df75-4349-9f2f-fb22aedb04c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-bf589b2b-96f6-436c-8001-6ab072ee3b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1984141496-172.17.0.20-1597126896456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42762,DS-84add6b9-d032-471c-9121-b530afc39277,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-e3d09092-dbae-4253-b8d2-014250fd2203,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-6219606d-ef49-4b52-8700-4609508bb014,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-7539dbfe-b245-4de7-a64c-a99c4d83f318,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-7ac2561c-ec54-4b6d-9766-7c3a2e1975db,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-7aa3f520-9e8e-49c6-a7b2-63426f1cf9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-b0b3225e-df75-4349-9f2f-fb22aedb04c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-bf589b2b-96f6-436c-8001-6ab072ee3b52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.short.circuit.shared.memory.watcher.interrupt.check.ms
component: hdfs:NameNode
v1: 60000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255429814-172.17.0.20-1597127003135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-3cfc6125-9f4d-402e-8771-29f7b91cb094,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-2cb6643d-681f-4aec-a88a-8895e8df681f,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-8491c401-a513-4101-b9d9-aca914545823,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-9a475921-d660-40c4-a467-7aa2f5acc3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-4bb8db4d-6995-44f2-8885-d6cc1dd9439e,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-51a799fc-3e32-4187-b171-97a52db104e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-46d2cb0d-8b56-4a97-90a7-712b38b17c59,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-d4df49b2-eb7f-4c87-95da-a2b0e34d9573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255429814-172.17.0.20-1597127003135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41109,DS-3cfc6125-9f4d-402e-8771-29f7b91cb094,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-2cb6643d-681f-4aec-a88a-8895e8df681f,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-8491c401-a513-4101-b9d9-aca914545823,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-9a475921-d660-40c4-a467-7aa2f5acc3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-4bb8db4d-6995-44f2-8885-d6cc1dd9439e,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-51a799fc-3e32-4187-b171-97a52db104e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-46d2cb0d-8b56-4a97-90a7-712b38b17c59,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-d4df49b2-eb7f-4c87-95da-a2b0e34d9573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5176
