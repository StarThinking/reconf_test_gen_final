reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799877219-172.17.0.13-1597128152423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-69498a31-399f-4ea1-8c10-45fabdbc2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-a6678f6d-7e60-4bd0-b85f-5c93fb4d4289,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-c6973a48-f9e2-4cf6-838b-0c0617467c91,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-16a1d2c8-c075-4e42-b6f7-8f31235edd41,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-b47eb43d-c404-4358-9ddf-0c3f7944c377,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-0e961ac1-aa7a-4539-9ef7-4f7268025240,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-ea88c312-6d93-4467-9391-e3e3bebdf29d,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-2833d872-887d-4116-8929-ea7c30b8e24c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-799877219-172.17.0.13-1597128152423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38444,DS-69498a31-399f-4ea1-8c10-45fabdbc2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-a6678f6d-7e60-4bd0-b85f-5c93fb4d4289,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-c6973a48-f9e2-4cf6-838b-0c0617467c91,DISK], DatanodeInfoWithStorage[127.0.0.1:43537,DS-16a1d2c8-c075-4e42-b6f7-8f31235edd41,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-b47eb43d-c404-4358-9ddf-0c3f7944c377,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-0e961ac1-aa7a-4539-9ef7-4f7268025240,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-ea88c312-6d93-4467-9391-e3e3bebdf29d,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-2833d872-887d-4116-8929-ea7c30b8e24c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319575652-172.17.0.13-1597128532630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42551,DS-cc15a29e-78da-4fdf-af61-6d70bf5e44b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-60a8430d-69be-4502-9458-8945879cf038,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-6c864efa-00c5-4b44-9378-1c37b53fb231,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-1efee492-b7bc-4ca5-9cbd-86351c73be52,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-83501c73-a7bb-4c26-82e8-44d5095f4c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-9505b90f-431b-455f-8fed-644de47f4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-2d15e94f-0efa-45b6-baa9-2d3ed33f5175,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-af0ef8fc-be4b-4792-8078-49e604f8af43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-319575652-172.17.0.13-1597128532630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42551,DS-cc15a29e-78da-4fdf-af61-6d70bf5e44b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-60a8430d-69be-4502-9458-8945879cf038,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-6c864efa-00c5-4b44-9378-1c37b53fb231,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-1efee492-b7bc-4ca5-9cbd-86351c73be52,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-83501c73-a7bb-4c26-82e8-44d5095f4c32,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-9505b90f-431b-455f-8fed-644de47f4fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-2d15e94f-0efa-45b6-baa9-2d3ed33f5175,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-af0ef8fc-be4b-4792-8078-49e604f8af43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654382900-172.17.0.13-1597128815981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37379,DS-c22dfff1-9ba7-47d7-b728-821c90c781e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-762f4204-504c-43b1-b7a2-1adc76126d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-0bd5e174-7322-42ba-b6ae-db469f696bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-829795f6-c1f6-477d-ac22-e740f71b5937,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-567c5e7a-1beb-4166-acb0-e64613d6926f,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-b617cfa0-915d-4a18-b436-8bc16cc1007f,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-8d2a8663-9140-4de4-8d62-cd1e74ad938c,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-17269ce4-11f5-4f85-9b98-2c88c627cfd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654382900-172.17.0.13-1597128815981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37379,DS-c22dfff1-9ba7-47d7-b728-821c90c781e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-762f4204-504c-43b1-b7a2-1adc76126d48,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-0bd5e174-7322-42ba-b6ae-db469f696bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-829795f6-c1f6-477d-ac22-e740f71b5937,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-567c5e7a-1beb-4166-acb0-e64613d6926f,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-b617cfa0-915d-4a18-b436-8bc16cc1007f,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-8d2a8663-9140-4de4-8d62-cd1e74ad938c,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-17269ce4-11f5-4f85-9b98-2c88c627cfd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597196173-172.17.0.13-1597129967790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-f4a58e48-2568-4184-998b-9e39068c4285,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-2d7b140e-eb41-46c5-b31f-d0745e76d8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-6e4daae4-d91f-44c6-9a1c-210f1005458e,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-b872641f-1d38-4dd0-9ac8-8b76bcfd3221,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-1f378f86-f4e8-4ca2-b1f5-b03028ad4327,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-0692bced-a7a4-4ddb-97a5-ce024c9dc216,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-34b39786-394b-4063-a77b-09135f361297,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-366b9910-5427-4e9c-9636-5c7db619c489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597196173-172.17.0.13-1597129967790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-f4a58e48-2568-4184-998b-9e39068c4285,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-2d7b140e-eb41-46c5-b31f-d0745e76d8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-6e4daae4-d91f-44c6-9a1c-210f1005458e,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-b872641f-1d38-4dd0-9ac8-8b76bcfd3221,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-1f378f86-f4e8-4ca2-b1f5-b03028ad4327,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-0692bced-a7a4-4ddb-97a5-ce024c9dc216,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-34b39786-394b-4063-a77b-09135f361297,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-366b9910-5427-4e9c-9636-5c7db619c489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750220673-172.17.0.13-1597130063341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39604,DS-d9e0d458-8ffe-46b9-ba23-ce539724eabf,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-240aa1f8-6691-4d10-b07f-331f1315478c,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-159e60c5-8fb1-493e-b92f-2d9836c64ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-f4f63739-0544-4f46-9050-7e1fe064c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-03b8083b-d428-4457-bfd3-4ce3b26f3517,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-6114df4e-19ff-4a89-bfcc-c382336d8c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-e2ffb608-f634-4668-b076-5caa48c7f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-a4bfa284-8590-4fda-9371-f917ab8da2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1750220673-172.17.0.13-1597130063341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39604,DS-d9e0d458-8ffe-46b9-ba23-ce539724eabf,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-240aa1f8-6691-4d10-b07f-331f1315478c,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-159e60c5-8fb1-493e-b92f-2d9836c64ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-f4f63739-0544-4f46-9050-7e1fe064c92b,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-03b8083b-d428-4457-bfd3-4ce3b26f3517,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-6114df4e-19ff-4a89-bfcc-c382336d8c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-e2ffb608-f634-4668-b076-5caa48c7f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-a4bfa284-8590-4fda-9371-f917ab8da2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18822129-172.17.0.13-1597130484309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-ddd315fd-2be6-4051-a45f-89446adc8005,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-f6220588-ff71-4306-8937-f138a6ffdefc,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-da307706-e9fd-40c8-b3c1-00ec3b71d1de,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-f0774b4d-52dd-4ab6-94fd-1268e8eb00ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-e6a837b1-42f7-4c31-a9cb-d380f523eb76,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-9aab6e13-323e-43c8-83fa-9f9cc896d177,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-31f3f697-ce2d-4798-9035-5376c69900a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-b938a356-95a3-4b18-8a7f-ab06589eec87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-18822129-172.17.0.13-1597130484309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38648,DS-ddd315fd-2be6-4051-a45f-89446adc8005,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-f6220588-ff71-4306-8937-f138a6ffdefc,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-da307706-e9fd-40c8-b3c1-00ec3b71d1de,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-f0774b4d-52dd-4ab6-94fd-1268e8eb00ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-e6a837b1-42f7-4c31-a9cb-d380f523eb76,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-9aab6e13-323e-43c8-83fa-9f9cc896d177,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-31f3f697-ce2d-4798-9035-5376c69900a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-b938a356-95a3-4b18-8a7f-ab06589eec87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125413248-172.17.0.13-1597130616316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-37c55338-80d8-4d1f-9ece-d583783160b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-956fb67a-0fee-4aa9-a7d1-11ce1d3f8d88,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-041c4d2c-4e0d-498a-9344-573232ddb01e,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-ee73b91a-9210-4b0f-b2ef-37ac95cb912a,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-0446ed61-903d-401b-8b0f-aa268a87a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-3e521fe1-6517-4e44-aa98-c9aa1015c308,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-bf43be81-6274-4ec1-a9d8-4f21e0d8cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-de06a30f-795e-4613-a4e1-12d089dde13c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125413248-172.17.0.13-1597130616316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-37c55338-80d8-4d1f-9ece-d583783160b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-956fb67a-0fee-4aa9-a7d1-11ce1d3f8d88,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-041c4d2c-4e0d-498a-9344-573232ddb01e,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-ee73b91a-9210-4b0f-b2ef-37ac95cb912a,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-0446ed61-903d-401b-8b0f-aa268a87a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-3e521fe1-6517-4e44-aa98-c9aa1015c308,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-bf43be81-6274-4ec1-a9d8-4f21e0d8cd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-de06a30f-795e-4613-a4e1-12d089dde13c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642331021-172.17.0.13-1597131340231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-332291e4-5b29-4294-b712-7ea7eaae07e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-313d83fc-6788-4074-9113-e9f9a1d74af3,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-1e6fa3a9-2a7c-4763-8152-a197814929cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-d6f05c80-6ef7-42c4-8d24-434e4d53cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-b65de6d1-7f77-46b9-8825-b498f9fa3529,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-76d86fc4-79f1-4be2-9ddc-f9ca0d4ce678,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-81824c27-8ec3-4f5c-9866-e0f5d732d8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-9ed5c588-c9e9-4fd5-be13-f1950942209f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-642331021-172.17.0.13-1597131340231:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-332291e4-5b29-4294-b712-7ea7eaae07e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-313d83fc-6788-4074-9113-e9f9a1d74af3,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-1e6fa3a9-2a7c-4763-8152-a197814929cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-d6f05c80-6ef7-42c4-8d24-434e4d53cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-b65de6d1-7f77-46b9-8825-b498f9fa3529,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-76d86fc4-79f1-4be2-9ddc-f9ca0d4ce678,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-81824c27-8ec3-4f5c-9866-e0f5d732d8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-9ed5c588-c9e9-4fd5-be13-f1950942209f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090586272-172.17.0.13-1597132127660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44934,DS-c7b73b8e-dd4a-411a-966c-e4408ec42d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-68c0d360-0666-4175-85f8-924afe5656fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-490978ef-6a7c-40cf-a8f9-b3f1357734e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-a9ceb8ce-daa5-4405-927b-8c1e1e42f50a,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-dc4a2c48-e5cf-41b2-9b5c-5c01c16776d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-8d37c635-2d7e-4037-ad5f-a33a04f7d49b,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-9f04643e-96b0-4650-800b-087ac5012b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-5bcac18b-cc7c-4720-b793-91abc04394a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1090586272-172.17.0.13-1597132127660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44934,DS-c7b73b8e-dd4a-411a-966c-e4408ec42d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-68c0d360-0666-4175-85f8-924afe5656fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-490978ef-6a7c-40cf-a8f9-b3f1357734e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-a9ceb8ce-daa5-4405-927b-8c1e1e42f50a,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-dc4a2c48-e5cf-41b2-9b5c-5c01c16776d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-8d37c635-2d7e-4037-ad5f-a33a04f7d49b,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-9f04643e-96b0-4650-800b-087ac5012b28,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-5bcac18b-cc7c-4720-b793-91abc04394a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 8000
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514013579-172.17.0.13-1597132617248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-497639b5-8328-4796-bd00-acdc01396ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-be1b8466-d488-45a1-b1c5-281059ea873e,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-278a7896-3ad2-4987-a142-50cb05a5b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-f77468ea-b920-417f-8384-b4bc1a3f8668,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-70f0340a-d899-4928-a541-c863cda39115,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-11a8d13b-2c63-43f5-8321-ca57bbd4e586,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-77d3d161-ceef-474a-8e6d-3f08ba5f1551,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-7b2f1619-6538-43d1-a499-58a429996366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514013579-172.17.0.13-1597132617248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-497639b5-8328-4796-bd00-acdc01396ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-be1b8466-d488-45a1-b1c5-281059ea873e,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-278a7896-3ad2-4987-a142-50cb05a5b8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-f77468ea-b920-417f-8384-b4bc1a3f8668,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-70f0340a-d899-4928-a541-c863cda39115,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-11a8d13b-2c63-43f5-8321-ca57bbd4e586,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-77d3d161-ceef-474a-8e6d-3f08ba5f1551,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-7b2f1619-6538-43d1-a499-58a429996366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5227
