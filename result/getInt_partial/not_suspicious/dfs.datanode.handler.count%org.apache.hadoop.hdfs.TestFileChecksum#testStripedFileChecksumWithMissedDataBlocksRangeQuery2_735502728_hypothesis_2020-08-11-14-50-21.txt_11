reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472313000-172.17.0.2-1597157477202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-f70eaf5f-5be7-45fa-b6f4-d6ff92598180,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-9487414e-fa96-4e31-a23c-11dc45e25f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-14b0ed1b-cb1f-4577-aa9b-c461a8cb6d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-07e5651f-7482-4c0f-84f9-5452e373d913,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-0a216538-a44f-4de4-bb93-3ecd85f4d60c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-fcfe648e-af93-4e26-9348-f2e05fcfd2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-77b2de38-5ff7-47b8-aa45-f717892b0034,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-e43c8ac8-2149-4e14-b9b2-f4b94d09358a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472313000-172.17.0.2-1597157477202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-f70eaf5f-5be7-45fa-b6f4-d6ff92598180,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-9487414e-fa96-4e31-a23c-11dc45e25f30,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-14b0ed1b-cb1f-4577-aa9b-c461a8cb6d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-07e5651f-7482-4c0f-84f9-5452e373d913,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-0a216538-a44f-4de4-bb93-3ecd85f4d60c,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-fcfe648e-af93-4e26-9348-f2e05fcfd2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-77b2de38-5ff7-47b8-aa45-f717892b0034,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-e43c8ac8-2149-4e14-b9b2-f4b94d09358a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991474485-172.17.0.2-1597157752495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-fe5954b6-526f-4ec9-9e5e-af4eba95151a,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-05b3fa29-9f77-4d4b-bb5d-09daafc62e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-fc59ff90-8580-492e-a36b-06357a3f08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-de71b810-e38c-43c3-9b46-9d808a91e778,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-2bf80da7-72e7-49f7-b8f6-3558ab41fafe,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-37742cd8-291b-44a0-b535-36ca84e98a34,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-6848bfad-58d9-48b7-aa96-eb4e21178cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-510a403e-c968-46ba-8f9e-42df24319dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1991474485-172.17.0.2-1597157752495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-fe5954b6-526f-4ec9-9e5e-af4eba95151a,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-05b3fa29-9f77-4d4b-bb5d-09daafc62e80,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-fc59ff90-8580-492e-a36b-06357a3f08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-de71b810-e38c-43c3-9b46-9d808a91e778,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-2bf80da7-72e7-49f7-b8f6-3558ab41fafe,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-37742cd8-291b-44a0-b535-36ca84e98a34,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-6848bfad-58d9-48b7-aa96-eb4e21178cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-510a403e-c968-46ba-8f9e-42df24319dfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126023603-172.17.0.2-1597158075040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-965a9775-bd0a-4fb3-932c-2e671b6ec418,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-ae45e9a2-5a2c-4545-854a-684c77042aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-ac52f367-2443-4541-953c-db67e7b0b716,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-db9994d6-4067-4969-939d-c23d743d1c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-5490fef7-2380-4d9f-afea-b5b72a0ae3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-1e32287f-8995-4ddb-9088-ddcf5554ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-3ec5efdd-ba54-4a85-abe8-a2448f15ed1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-34101795-a799-4b77-a468-cae23fe29407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126023603-172.17.0.2-1597158075040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46663,DS-965a9775-bd0a-4fb3-932c-2e671b6ec418,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-ae45e9a2-5a2c-4545-854a-684c77042aec,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-ac52f367-2443-4541-953c-db67e7b0b716,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-db9994d6-4067-4969-939d-c23d743d1c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-5490fef7-2380-4d9f-afea-b5b72a0ae3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-1e32287f-8995-4ddb-9088-ddcf5554ad37,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-3ec5efdd-ba54-4a85-abe8-a2448f15ed1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-34101795-a799-4b77-a468-cae23fe29407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524308846-172.17.0.2-1597158167761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33960,DS-2bfd79fc-0bd2-4a94-9803-79bdb682b65a,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-94c016ee-24d8-4b06-adea-91b988194377,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-e20cf31a-875a-46ac-ad83-32945a2dcca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-960fa4c8-9766-44e0-b361-b11248ecffe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-8c897817-de02-4009-a3ec-e9a4a60a7709,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-0c6eaae1-c3f8-460c-9f81-2c8e805a2530,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-962d1350-6cb2-477b-ad25-a4d3a47e1b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-98908c09-2530-4ea1-b61b-fdd6a05dccde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524308846-172.17.0.2-1597158167761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33960,DS-2bfd79fc-0bd2-4a94-9803-79bdb682b65a,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-94c016ee-24d8-4b06-adea-91b988194377,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-e20cf31a-875a-46ac-ad83-32945a2dcca6,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-960fa4c8-9766-44e0-b361-b11248ecffe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-8c897817-de02-4009-a3ec-e9a4a60a7709,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-0c6eaae1-c3f8-460c-9f81-2c8e805a2530,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-962d1350-6cb2-477b-ad25-a4d3a47e1b31,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-98908c09-2530-4ea1-b61b-fdd6a05dccde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868532497-172.17.0.2-1597158791332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38322,DS-314aa5dd-b02e-461f-8393-e356d56b28e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-29de4f5c-0f00-4d1f-aa31-a084ea1a8077,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-30a48225-e36f-4ed8-8be3-f0a449a10123,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-6fdf29d2-ae5e-479a-8b72-63037fc54a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-85bd43b9-de4e-4c74-ae0c-674a42228635,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-3793b889-6034-4e6d-80c3-352659c56d31,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-7059393e-42ed-464d-936e-dbb1e22ebab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-e514c12b-23d7-4729-b948-7b2739b8c390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868532497-172.17.0.2-1597158791332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38322,DS-314aa5dd-b02e-461f-8393-e356d56b28e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42858,DS-29de4f5c-0f00-4d1f-aa31-a084ea1a8077,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-30a48225-e36f-4ed8-8be3-f0a449a10123,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-6fdf29d2-ae5e-479a-8b72-63037fc54a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-85bd43b9-de4e-4c74-ae0c-674a42228635,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-3793b889-6034-4e6d-80c3-352659c56d31,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-7059393e-42ed-464d-936e-dbb1e22ebab9,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-e514c12b-23d7-4729-b948-7b2739b8c390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568717783-172.17.0.2-1597159109414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43552,DS-f2568e2f-d8e5-4a87-b942-132672bbf9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-461501a8-2390-4869-930b-1659ad694233,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-5c8607a8-3707-41d1-88db-44238022a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-46cd0d13-bfc0-4558-bdbc-cf427dbbb33e,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-65623f3a-f473-4384-b091-c9c6e89633d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-8b25bdd5-0c68-4ac3-bf54-e15aefa36890,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-fb0fd3c4-b138-4c6b-bdc3-222c0503d774,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-2ae1184b-4cad-4cfe-bdaf-912e450c25b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568717783-172.17.0.2-1597159109414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43552,DS-f2568e2f-d8e5-4a87-b942-132672bbf9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-461501a8-2390-4869-930b-1659ad694233,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-5c8607a8-3707-41d1-88db-44238022a9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-46cd0d13-bfc0-4558-bdbc-cf427dbbb33e,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-65623f3a-f473-4384-b091-c9c6e89633d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-8b25bdd5-0c68-4ac3-bf54-e15aefa36890,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-fb0fd3c4-b138-4c6b-bdc3-222c0503d774,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-2ae1184b-4cad-4cfe-bdaf-912e450c25b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083082921-172.17.0.2-1597159618657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-47a8be81-7780-4bf1-9244-9f672c1cb8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-602e47c3-f699-4ba9-a972-398714cc8aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-21734147-ead5-48dd-b7d8-9db0e39c6493,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-8322a711-5cd2-4532-a920-2ebe682b14d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-de351e10-9491-445b-a2ba-8c00cdc3e932,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-fe13795f-ceca-4a57-a883-0873bb17b70b,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-c935edab-09ab-483b-97ae-edabc6fcafb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-60a0787f-d3a4-4319-822b-c09fdb9c138a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1083082921-172.17.0.2-1597159618657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-47a8be81-7780-4bf1-9244-9f672c1cb8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-602e47c3-f699-4ba9-a972-398714cc8aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-21734147-ead5-48dd-b7d8-9db0e39c6493,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-8322a711-5cd2-4532-a920-2ebe682b14d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-de351e10-9491-445b-a2ba-8c00cdc3e932,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-fe13795f-ceca-4a57-a883-0873bb17b70b,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-c935edab-09ab-483b-97ae-edabc6fcafb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-60a0787f-d3a4-4319-822b-c09fdb9c138a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537676275-172.17.0.2-1597159953530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44722,DS-8f970ae3-13f9-4df2-9022-3e2900c6838d,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-3e06ebfe-d38c-4cbe-87c6-6a88bebc4765,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-cb915437-4d5f-4bca-9318-26403cc8f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-603c7c4b-93db-4fba-98c8-044fd5a290de,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-083afc4a-8448-4714-9d29-ac0b5f0ec46e,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-3632ce9a-bf1d-42d1-a8b3-c0fa2b4096f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-e7b30a1b-3aa9-4c1d-9dc7-b0e5a38ff275,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-142569aa-e23f-4fe7-8d21-84018030b7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537676275-172.17.0.2-1597159953530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44722,DS-8f970ae3-13f9-4df2-9022-3e2900c6838d,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-3e06ebfe-d38c-4cbe-87c6-6a88bebc4765,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-cb915437-4d5f-4bca-9318-26403cc8f9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-603c7c4b-93db-4fba-98c8-044fd5a290de,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-083afc4a-8448-4714-9d29-ac0b5f0ec46e,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-3632ce9a-bf1d-42d1-a8b3-c0fa2b4096f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-e7b30a1b-3aa9-4c1d-9dc7-b0e5a38ff275,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-142569aa-e23f-4fe7-8d21-84018030b7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379364815-172.17.0.2-1597160718984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42621,DS-87212a2d-d69c-4c00-9e47-08df0d6d8b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-57509eba-c994-4b1f-9c3c-4f496df6247e,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-afed466d-699a-4e06-8793-0eda8bdff560,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-514df3bb-6df5-4eb9-a958-95663e7f1544,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-48284b93-b20c-414d-bae9-5377f0e8d038,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-04725fb8-e83d-4114-afb5-669f4ee7416b,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-6ff0c636-ca5a-456e-8b56-d1dcf068692b,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-f4623f94-6965-4502-9570-09026988e1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-379364815-172.17.0.2-1597160718984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42621,DS-87212a2d-d69c-4c00-9e47-08df0d6d8b33,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-57509eba-c994-4b1f-9c3c-4f496df6247e,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-afed466d-699a-4e06-8793-0eda8bdff560,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-514df3bb-6df5-4eb9-a958-95663e7f1544,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-48284b93-b20c-414d-bae9-5377f0e8d038,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-04725fb8-e83d-4114-afb5-669f4ee7416b,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-6ff0c636-ca5a-456e-8b56-d1dcf068692b,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-f4623f94-6965-4502-9570-09026988e1a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716425090-172.17.0.2-1597160954666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46845,DS-95365a28-25d2-47d8-9924-a92a7366c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-4be75f63-b7be-45ef-b146-5d200dd2027a,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-5a64b1bb-f6c2-4aa0-9fa5-c7db2ac9cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-407a7ea8-92ed-4e0c-9e52-80a982c7dac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-3897298e-4c12-47b0-ac33-e96b831ca8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-e7f3d96e-cf33-4235-b934-154007c220e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-3a3320f7-c4d2-4db2-a244-a88b5f2a77a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-f2aa62ea-7968-49c0-8fca-63b66353882e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716425090-172.17.0.2-1597160954666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46845,DS-95365a28-25d2-47d8-9924-a92a7366c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-4be75f63-b7be-45ef-b146-5d200dd2027a,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-5a64b1bb-f6c2-4aa0-9fa5-c7db2ac9cc06,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-407a7ea8-92ed-4e0c-9e52-80a982c7dac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-3897298e-4c12-47b0-ac33-e96b831ca8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-e7f3d96e-cf33-4235-b934-154007c220e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-3a3320f7-c4d2-4db2-a244-a88b5f2a77a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-f2aa62ea-7968-49c0-8fca-63b66353882e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469248980-172.17.0.2-1597161214140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39410,DS-7d4e8641-3794-456e-ace3-185abdc94eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-9426d6a3-6ffb-4f6a-8931-6699cd64fc58,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-d67152c1-a964-4c4a-b617-d7753286142f,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-ce65f24a-2deb-4ce3-befb-90ddb508fa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-7c98894d-7a5c-431e-9a7e-4fd9a3b610be,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-47db7c22-f3fb-46e7-a95e-0e3302c50e25,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-af2567e4-e037-4615-aa16-41e1d832b071,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-74490ed9-1345-4ed3-8db1-53a4751929ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469248980-172.17.0.2-1597161214140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39410,DS-7d4e8641-3794-456e-ace3-185abdc94eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-9426d6a3-6ffb-4f6a-8931-6699cd64fc58,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-d67152c1-a964-4c4a-b617-d7753286142f,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-ce65f24a-2deb-4ce3-befb-90ddb508fa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-7c98894d-7a5c-431e-9a7e-4fd9a3b610be,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-47db7c22-f3fb-46e7-a95e-0e3302c50e25,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-af2567e4-e037-4615-aa16-41e1d832b071,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-74490ed9-1345-4ed3-8db1-53a4751929ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880996832-172.17.0.2-1597161335220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35073,DS-45593d62-0b06-4ee6-a2ec-72344377eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-9f14ea53-5475-483c-b0ee-99e45eda3e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-53075623-5b70-4988-806d-99cb16b8562b,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-8ba5ce4c-2935-41c5-83a4-d997462b045a,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-8a91db95-34ff-40e8-b564-46c24433c72c,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-747a6fca-c109-4b79-8a18-7883e31dc616,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-e8a88d26-fa48-4c67-b665-345d2e03564d,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-abb792a6-ddac-43b4-b201-2d5965e63390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1880996832-172.17.0.2-1597161335220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35073,DS-45593d62-0b06-4ee6-a2ec-72344377eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-9f14ea53-5475-483c-b0ee-99e45eda3e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-53075623-5b70-4988-806d-99cb16b8562b,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-8ba5ce4c-2935-41c5-83a4-d997462b045a,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-8a91db95-34ff-40e8-b564-46c24433c72c,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-747a6fca-c109-4b79-8a18-7883e31dc616,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-e8a88d26-fa48-4c67-b665-345d2e03564d,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-abb792a6-ddac-43b4-b201-2d5965e63390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598031341-172.17.0.2-1597162716449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40615,DS-f18c5f02-1d7e-4aaa-99a2-6734728f2207,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-6d24f107-5b67-43b7-a67b-7f2e9ec28add,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-88118fd1-3a71-4cf4-b1e5-a2fa59e4d326,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-41bc5880-e296-4597-af73-c16ba80d02b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-8d84788d-cafe-45d8-8a05-c4935afd6aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-cfaf8acf-7318-4037-b270-033597164dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-9d9e93ef-7ea4-4928-864d-aeb7aa2c1b51,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-91cc381f-c6df-4289-afb0-424157e4e64b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-598031341-172.17.0.2-1597162716449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40615,DS-f18c5f02-1d7e-4aaa-99a2-6734728f2207,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-6d24f107-5b67-43b7-a67b-7f2e9ec28add,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-88118fd1-3a71-4cf4-b1e5-a2fa59e4d326,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-41bc5880-e296-4597-af73-c16ba80d02b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46216,DS-8d84788d-cafe-45d8-8a05-c4935afd6aae,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-cfaf8acf-7318-4037-b270-033597164dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43454,DS-9d9e93ef-7ea4-4928-864d-aeb7aa2c1b51,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-91cc381f-c6df-4289-afb0-424157e4e64b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912280480-172.17.0.2-1597163006434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-4db3986f-b5bb-45f3-8da2-725d75a4e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-09d90129-7c48-4b3e-ab88-ea5a439df84b,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-e6e1839d-9c95-499b-9e1d-04adfc63125f,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-9ba81ea8-f4ed-4fd3-8e1a-abc13b9cb242,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-02821196-988c-45ca-a1fb-a9983d10f040,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-87dad9ea-dcfb-49de-8497-4266e06d2d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-a3ca3fc2-4053-4a5f-9f30-e215aa776af7,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-be497827-70a7-4e9d-a867-1d22e1be088c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912280480-172.17.0.2-1597163006434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-4db3986f-b5bb-45f3-8da2-725d75a4e02a,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-09d90129-7c48-4b3e-ab88-ea5a439df84b,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-e6e1839d-9c95-499b-9e1d-04adfc63125f,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-9ba81ea8-f4ed-4fd3-8e1a-abc13b9cb242,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-02821196-988c-45ca-a1fb-a9983d10f040,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-87dad9ea-dcfb-49de-8497-4266e06d2d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41719,DS-a3ca3fc2-4053-4a5f-9f30-e215aa776af7,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-be497827-70a7-4e9d-a867-1d22e1be088c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338990269-172.17.0.2-1597163063615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38888,DS-2d3ada07-0eb5-4967-ac93-7f88eaff12d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-cb846062-ee79-4e3a-9fee-bc31e3a1d59f,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-0fe25b94-a697-4597-9dc3-68771cc2cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-59fcbd95-8565-4cde-a13b-cf162e4796d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-73c79158-8791-41dd-acff-f4f34f9d1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-8d4d65ba-7a21-4904-8816-f357e6fc97b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-3ac9608e-67da-4a0c-8d96-8621c696ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-9302d504-e40c-48a0-813c-56f57545a98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338990269-172.17.0.2-1597163063615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38888,DS-2d3ada07-0eb5-4967-ac93-7f88eaff12d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-cb846062-ee79-4e3a-9fee-bc31e3a1d59f,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-0fe25b94-a697-4597-9dc3-68771cc2cb32,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-59fcbd95-8565-4cde-a13b-cf162e4796d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-73c79158-8791-41dd-acff-f4f34f9d1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-8d4d65ba-7a21-4904-8816-f357e6fc97b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-3ac9608e-67da-4a0c-8d96-8621c696ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-9302d504-e40c-48a0-813c-56f57545a98a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023603225-172.17.0.2-1597163237087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40585,DS-df40d49b-60bd-4e10-8c6f-c18e3c0d4adc,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-9229b293-d66a-45c3-b12f-c9f0e7e2e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-e7203a1e-e8d6-4f04-b00c-d7790ab7ba66,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-3caa4463-845e-4ac1-9350-a6b599615a50,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-4a4b9dd2-d666-4bf5-adcd-8fff1799069f,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-c3a198e1-386d-4e19-89d4-7f8164373a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-8e45f717-f6be-47b3-a82c-86d0e32fbc95,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-842a9684-6118-4495-9f18-f5605a0cb21d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2023603225-172.17.0.2-1597163237087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40585,DS-df40d49b-60bd-4e10-8c6f-c18e3c0d4adc,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-9229b293-d66a-45c3-b12f-c9f0e7e2e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-e7203a1e-e8d6-4f04-b00c-d7790ab7ba66,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-3caa4463-845e-4ac1-9350-a6b599615a50,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-4a4b9dd2-d666-4bf5-adcd-8fff1799069f,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-c3a198e1-386d-4e19-89d4-7f8164373a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-8e45f717-f6be-47b3-a82c-86d0e32fbc95,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-842a9684-6118-4495-9f18-f5605a0cb21d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 10
v2: 15
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350458848-172.17.0.2-1597163647347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46790,DS-d046521c-19d3-4682-936f-32a9f627aa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a813d623-6114-44a3-a72c-d092c3f023e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-70ed93a8-e6e7-45dd-97a0-4041552b4a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-12325050-a77c-4759-be40-ea1cfa157322,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-954bbb29-b8da-4321-8e3e-c5fa2eb21474,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-5fe64979-f7fc-49cc-b1a7-32b76854d2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-6e4b184b-a3ab-48b9-b946-b3caa0fe0fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-7df8f87a-42e5-4da1-a1f1-38ee97bf709c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350458848-172.17.0.2-1597163647347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46790,DS-d046521c-19d3-4682-936f-32a9f627aa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a813d623-6114-44a3-a72c-d092c3f023e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-70ed93a8-e6e7-45dd-97a0-4041552b4a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-12325050-a77c-4759-be40-ea1cfa157322,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-954bbb29-b8da-4321-8e3e-c5fa2eb21474,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-5fe64979-f7fc-49cc-b1a7-32b76854d2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-6e4b184b-a3ab-48b9-b946-b3caa0fe0fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-7df8f87a-42e5-4da1-a1f1-38ee97bf709c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6383
