reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926373757-172.17.0.21-1597061551330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-4e7d5bae-8136-4d60-957b-298be89c96ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-c1a447b7-0219-465d-b5b6-492554548d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-dd0431bb-ead2-4afa-bdd7-c5ea36b881f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-0485342f-b401-4bf7-8846-6f7fffdb23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-2f454bf1-99a5-443d-988b-14872d93d608,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-cea9ec06-8929-4727-b7e2-50654d3a3e57,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-e5f7c478-f1db-4467-9cc4-b9ddd180d5df,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-c1ea2a86-1c74-480d-837e-54136b4b4d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926373757-172.17.0.21-1597061551330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-4e7d5bae-8136-4d60-957b-298be89c96ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-c1a447b7-0219-465d-b5b6-492554548d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-dd0431bb-ead2-4afa-bdd7-c5ea36b881f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-0485342f-b401-4bf7-8846-6f7fffdb23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42808,DS-2f454bf1-99a5-443d-988b-14872d93d608,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-cea9ec06-8929-4727-b7e2-50654d3a3e57,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-e5f7c478-f1db-4467-9cc4-b9ddd180d5df,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-c1ea2a86-1c74-480d-837e-54136b4b4d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811532862-172.17.0.21-1597061588989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34608,DS-13ef23e6-3c6a-4628-9217-3eaa9fd87581,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-7461513f-6787-4020-861c-df2a75dd459a,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-bc83ea4c-900f-4b29-9734-9ec4bd5b523d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-69bbbeaa-034d-4e8c-a5bb-f71ae3575603,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-c6455007-fa9b-4362-b243-150e396c5d98,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-9275151f-17a8-4a3c-8889-0aacda9bda01,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-2484a094-f390-44b9-8abd-c27cc56881c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-1b981453-86c5-4762-95eb-757277932b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811532862-172.17.0.21-1597061588989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34608,DS-13ef23e6-3c6a-4628-9217-3eaa9fd87581,DISK], DatanodeInfoWithStorage[127.0.0.1:43149,DS-7461513f-6787-4020-861c-df2a75dd459a,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-bc83ea4c-900f-4b29-9734-9ec4bd5b523d,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-69bbbeaa-034d-4e8c-a5bb-f71ae3575603,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-c6455007-fa9b-4362-b243-150e396c5d98,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-9275151f-17a8-4a3c-8889-0aacda9bda01,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-2484a094-f390-44b9-8abd-c27cc56881c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-1b981453-86c5-4762-95eb-757277932b0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700282158-172.17.0.21-1597062482031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44003,DS-ee43cd0c-a5a8-4f2c-844e-f9b47f6c0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-318160bb-0a5f-412a-84c8-019fbc1cf639,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-393af658-638e-4734-94d1-aeaa9fd3469a,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-b8b86e83-01f0-4055-8340-43b81be6f97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-31ddcca2-3c7b-4118-8bb2-80f2df6308ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-3c5a5c61-42e4-4ce4-ac0e-93bbd4a79b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-bc6d3868-149a-4ca1-ad45-7fc150890ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-fc41c646-c628-4186-a771-067c86d8227a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700282158-172.17.0.21-1597062482031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44003,DS-ee43cd0c-a5a8-4f2c-844e-f9b47f6c0fff,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-318160bb-0a5f-412a-84c8-019fbc1cf639,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-393af658-638e-4734-94d1-aeaa9fd3469a,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-b8b86e83-01f0-4055-8340-43b81be6f97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-31ddcca2-3c7b-4118-8bb2-80f2df6308ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-3c5a5c61-42e4-4ce4-ac0e-93bbd4a79b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38003,DS-bc6d3868-149a-4ca1-ad45-7fc150890ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-fc41c646-c628-4186-a771-067c86d8227a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964258199-172.17.0.21-1597063262570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-274608cf-c839-48d2-9650-a164818e18ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-cd2fa405-4349-4cfb-932e-06f22798191b,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-6b017ec2-6b48-4bf8-91c4-07873079415f,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-3940f500-d320-4934-8494-355fd4a54f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-dd30010a-bedb-444c-9ec0-acefce26e642,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-5c0370cd-b9c1-4216-85fe-b0b1d2930449,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-c666c1f4-4b56-478a-ab6a-aa2d1f42160f,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-136e2a5b-7d42-4bb3-803f-2a3b24649a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-964258199-172.17.0.21-1597063262570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-274608cf-c839-48d2-9650-a164818e18ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-cd2fa405-4349-4cfb-932e-06f22798191b,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-6b017ec2-6b48-4bf8-91c4-07873079415f,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-3940f500-d320-4934-8494-355fd4a54f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-dd30010a-bedb-444c-9ec0-acefce26e642,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-5c0370cd-b9c1-4216-85fe-b0b1d2930449,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-c666c1f4-4b56-478a-ab6a-aa2d1f42160f,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-136e2a5b-7d42-4bb3-803f-2a3b24649a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065732522-172.17.0.21-1597064237579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34447,DS-957a85b5-eea2-47d1-9bda-af4899461ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-8fdc0216-8e94-4552-8502-e8e9d912cf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-989f5744-930d-433f-ada4-fce946fd2476,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-11158807-4a4a-415f-8602-9684aef70ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-aa0abaab-abe2-4265-8c7f-16f0a46ce60f,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-33f61c84-6940-4c18-bc66-201755e3bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-3afa33eb-b4d8-4110-bb04-2d0117d82105,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-0ce6f4c4-d2c4-4e20-b91f-d26256c35f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065732522-172.17.0.21-1597064237579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34447,DS-957a85b5-eea2-47d1-9bda-af4899461ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-8fdc0216-8e94-4552-8502-e8e9d912cf3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-989f5744-930d-433f-ada4-fce946fd2476,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-11158807-4a4a-415f-8602-9684aef70ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-aa0abaab-abe2-4265-8c7f-16f0a46ce60f,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-33f61c84-6940-4c18-bc66-201755e3bfcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-3afa33eb-b4d8-4110-bb04-2d0117d82105,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-0ce6f4c4-d2c4-4e20-b91f-d26256c35f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564319786-172.17.0.21-1597064729526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-0d9a79bd-67bd-4369-ac16-d08841ff0650,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-4163bf73-2d97-48f8-840a-a18f398ed893,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-3f21dd6a-c15c-46ce-8f54-2f931daba513,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-11dec519-43fc-4192-b560-bc062f2fc1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-1213ba56-aa14-4423-b7ed-dafefdced592,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-827de20e-b9aa-443b-a9cc-1ec0ecf9a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-c6dd7ad8-9783-42cf-aaa7-198af3fb3fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-632feebc-4084-4e4e-baae-388b85e7eacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564319786-172.17.0.21-1597064729526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45254,DS-0d9a79bd-67bd-4369-ac16-d08841ff0650,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-4163bf73-2d97-48f8-840a-a18f398ed893,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-3f21dd6a-c15c-46ce-8f54-2f931daba513,DISK], DatanodeInfoWithStorage[127.0.0.1:39919,DS-11dec519-43fc-4192-b560-bc062f2fc1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-1213ba56-aa14-4423-b7ed-dafefdced592,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-827de20e-b9aa-443b-a9cc-1ec0ecf9a46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-c6dd7ad8-9783-42cf-aaa7-198af3fb3fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-632feebc-4084-4e4e-baae-388b85e7eacc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930111335-172.17.0.21-1597065114273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-2f091e4c-9a2b-4ae4-a92b-76df3be883dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-a44aa1d8-7fbb-4c0b-90a4-dcae88b853dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-45ef2e22-582f-479e-b153-ccc23b309cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-2cc67c09-3be2-44aa-bea0-b49d131bb389,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-11c41a67-0cee-4d21-9bd6-506eb20db264,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-068e8117-6348-41a3-bc1d-2b9a185ea597,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-4bacdc67-1d10-4400-aa1a-44c11afaf0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-fa03bee1-952a-4989-9222-43843a7f1a58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930111335-172.17.0.21-1597065114273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38828,DS-2f091e4c-9a2b-4ae4-a92b-76df3be883dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-a44aa1d8-7fbb-4c0b-90a4-dcae88b853dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-45ef2e22-582f-479e-b153-ccc23b309cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-2cc67c09-3be2-44aa-bea0-b49d131bb389,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-11c41a67-0cee-4d21-9bd6-506eb20db264,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-068e8117-6348-41a3-bc1d-2b9a185ea597,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-4bacdc67-1d10-4400-aa1a-44c11afaf0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-fa03bee1-952a-4989-9222-43843a7f1a58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748595088-172.17.0.21-1597065477590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-8cd588ba-3925-4f31-8f36-c46b2b60f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-c469de0f-a996-4053-aeef-f1ece84d1719,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-af92bdda-17f4-4405-9a5e-610d305c6081,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-161946ae-05ed-488e-af5e-b66f1b7429e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-bb1cb3f0-7e50-4d5b-ba6e-7679abb9706e,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-1c9ff06f-b750-4bad-b787-92d521ddb77f,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-5efa28c9-59c3-4aba-b575-e7591d8dbdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-66c55c33-a690-47f3-8e54-742053b066c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748595088-172.17.0.21-1597065477590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46720,DS-8cd588ba-3925-4f31-8f36-c46b2b60f0bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-c469de0f-a996-4053-aeef-f1ece84d1719,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-af92bdda-17f4-4405-9a5e-610d305c6081,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-161946ae-05ed-488e-af5e-b66f1b7429e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-bb1cb3f0-7e50-4d5b-ba6e-7679abb9706e,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-1c9ff06f-b750-4bad-b787-92d521ddb77f,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-5efa28c9-59c3-4aba-b575-e7591d8dbdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-66c55c33-a690-47f3-8e54-742053b066c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281563616-172.17.0.21-1597066284549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-2808c11f-bfba-4a93-ac4e-eae9828a114d,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-fa531a55-9c1e-4d88-b41e-a9a8d70ff677,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-7564cd82-cb9c-413e-a434-b9ec3891a045,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-bdec4ca7-70f5-40e0-8645-c1f7fcc814a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-33d8d95f-1669-4a3a-99d7-95324b4273c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-64cceded-5d59-44ad-a0b8-cb1fd7718014,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-4bc2e149-10f9-42ab-b961-ebd6d5437a15,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-30f63715-ea3c-4799-b7f2-5be85d9982c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281563616-172.17.0.21-1597066284549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41856,DS-2808c11f-bfba-4a93-ac4e-eae9828a114d,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-fa531a55-9c1e-4d88-b41e-a9a8d70ff677,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-7564cd82-cb9c-413e-a434-b9ec3891a045,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-bdec4ca7-70f5-40e0-8645-c1f7fcc814a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-33d8d95f-1669-4a3a-99d7-95324b4273c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-64cceded-5d59-44ad-a0b8-cb1fd7718014,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-4bc2e149-10f9-42ab-b961-ebd6d5437a15,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-30f63715-ea3c-4799-b7f2-5be85d9982c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498259611-172.17.0.21-1597066457654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36959,DS-4580729e-21f6-47f9-81fb-cce36a4e3845,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-42c69d7b-d1e7-4653-b296-1d60530cf149,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-e52c8135-2492-48cf-89b9-f74d9a592242,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-1965a0b2-9853-4042-a737-f1fc8c812ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-557ee893-6051-4dd6-99f2-e9367695bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-793f9d68-1927-4d9d-a327-875e616ed520,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-4bfe873e-60d8-4558-93e1-62c88631576e,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-2035251f-9eca-4265-9647-64e7eebbe9a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498259611-172.17.0.21-1597066457654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36959,DS-4580729e-21f6-47f9-81fb-cce36a4e3845,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-42c69d7b-d1e7-4653-b296-1d60530cf149,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-e52c8135-2492-48cf-89b9-f74d9a592242,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-1965a0b2-9853-4042-a737-f1fc8c812ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-557ee893-6051-4dd6-99f2-e9367695bc33,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-793f9d68-1927-4d9d-a327-875e616ed520,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-4bfe873e-60d8-4558-93e1-62c88631576e,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-2035251f-9eca-4265-9647-64e7eebbe9a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678045344-172.17.0.21-1597066547013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40161,DS-c662c96f-a53d-436b-b624-f75ee8ccbc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-78220f22-8c69-405b-adb5-55971e159cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-0cf72acc-365e-4f8f-abd3-088600ec189d,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-3bf67d24-ecbc-463b-82e5-be1ff21ab51b,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f905d7ad-9124-408a-855f-c49485af6438,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-e51aa882-24bc-4742-bf68-25ede7d909ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-d69e8ebc-c3a1-4e69-82c0-76e360494263,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-4569d8b7-5fde-435e-b6a1-32f55f934fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678045344-172.17.0.21-1597066547013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40161,DS-c662c96f-a53d-436b-b624-f75ee8ccbc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-78220f22-8c69-405b-adb5-55971e159cde,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-0cf72acc-365e-4f8f-abd3-088600ec189d,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-3bf67d24-ecbc-463b-82e5-be1ff21ab51b,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-f905d7ad-9124-408a-855f-c49485af6438,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-e51aa882-24bc-4742-bf68-25ede7d909ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-d69e8ebc-c3a1-4e69-82c0-76e360494263,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-4569d8b7-5fde-435e-b6a1-32f55f934fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980645004-172.17.0.21-1597066673531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-4c09faed-4b09-4802-b24b-6a7daab1972d,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-83764916-beb3-4ad9-8515-10c1c355c822,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-344fd3ab-0e1c-479f-85b1-35d68bb7a52e,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-e195d1ea-c611-411a-8a46-ea88129f8dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-8d65ad82-d641-4689-95ac-93215516cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-b09a920e-785c-4869-96ff-e505fcb8191a,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-928b6f72-19bb-497b-94fe-99dcd797de4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-e8813559-faf4-428d-b5dd-ddbba878e6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980645004-172.17.0.21-1597066673531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-4c09faed-4b09-4802-b24b-6a7daab1972d,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-83764916-beb3-4ad9-8515-10c1c355c822,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-344fd3ab-0e1c-479f-85b1-35d68bb7a52e,DISK], DatanodeInfoWithStorage[127.0.0.1:36851,DS-e195d1ea-c611-411a-8a46-ea88129f8dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-8d65ad82-d641-4689-95ac-93215516cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-b09a920e-785c-4869-96ff-e505fcb8191a,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-928b6f72-19bb-497b-94fe-99dcd797de4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-e8813559-faf4-428d-b5dd-ddbba878e6ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40237374-172.17.0.21-1597066949528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-98f36ac9-daf2-4073-a24c-edd27e3f8f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-0e50e9c3-1138-49a2-85a2-ab7cf39f2678,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-eade6f09-31cc-4b87-bbb2-09f24646f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-4ee124ee-a23d-4f40-b57d-d0504cf16782,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-8f53f9c7-a0bc-4d9a-9009-a89e361d4433,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-d6424ae8-e50a-44fc-99b7-d3c8c11403fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-1fcc47ef-ae53-404f-8fa9-06fdda6567e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-6a012ce7-4e5f-4751-b60c-e38b2037bf63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40237374-172.17.0.21-1597066949528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-98f36ac9-daf2-4073-a24c-edd27e3f8f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-0e50e9c3-1138-49a2-85a2-ab7cf39f2678,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-eade6f09-31cc-4b87-bbb2-09f24646f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-4ee124ee-a23d-4f40-b57d-d0504cf16782,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-8f53f9c7-a0bc-4d9a-9009-a89e361d4433,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-d6424ae8-e50a-44fc-99b7-d3c8c11403fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-1fcc47ef-ae53-404f-8fa9-06fdda6567e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-6a012ce7-4e5f-4751-b60c-e38b2037bf63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045547233-172.17.0.21-1597067534091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45066,DS-66945bd8-4efc-4a1e-961b-04336f93e907,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-db459568-9082-4c90-91d4-6a7010c3ab15,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-e4877414-6452-4cb1-8a6d-0d5cb8106beb,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-e3763608-a690-4030-9e02-ad5e45ee2389,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-4a0c857e-a1d1-4f7e-9899-27e5cff3e297,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-1a329dd2-1102-4904-9bf4-6fa8f353c197,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-f395f44e-ad43-4908-b246-ae886ab4e805,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-67c33578-64fa-4db2-ab66-b6420481b8b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045547233-172.17.0.21-1597067534091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45066,DS-66945bd8-4efc-4a1e-961b-04336f93e907,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-db459568-9082-4c90-91d4-6a7010c3ab15,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-e4877414-6452-4cb1-8a6d-0d5cb8106beb,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-e3763608-a690-4030-9e02-ad5e45ee2389,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-4a0c857e-a1d1-4f7e-9899-27e5cff3e297,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-1a329dd2-1102-4904-9bf4-6fa8f353c197,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-f395f44e-ad43-4908-b246-ae886ab4e805,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-67c33578-64fa-4db2-ab66-b6420481b8b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6425
