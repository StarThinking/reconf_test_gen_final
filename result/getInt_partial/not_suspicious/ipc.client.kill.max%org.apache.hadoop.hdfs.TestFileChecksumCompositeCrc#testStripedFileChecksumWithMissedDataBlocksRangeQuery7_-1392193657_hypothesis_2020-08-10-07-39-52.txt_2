reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411223198-172.17.0.9-1597045237804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-5f10b655-b5a3-4545-9a96-321ffbed1f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-48eb270a-5c4e-4399-82bd-d507fa87cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-78cbe709-fb5e-49bf-a9b7-b06ed7820d87,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-58adbcc0-58b3-4def-b967-c48a5726e338,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-908db37a-b47c-4ab7-9de1-6d1c55f3e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-f8405692-92ab-412f-9f9a-64c34c33d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-9e11fc05-4349-487f-9b87-a31f7fc4529e,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-c267d5cf-ab02-4e6b-977f-91bd360db9a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411223198-172.17.0.9-1597045237804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38679,DS-5f10b655-b5a3-4545-9a96-321ffbed1f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-48eb270a-5c4e-4399-82bd-d507fa87cd19,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-78cbe709-fb5e-49bf-a9b7-b06ed7820d87,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-58adbcc0-58b3-4def-b967-c48a5726e338,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-908db37a-b47c-4ab7-9de1-6d1c55f3e8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-f8405692-92ab-412f-9f9a-64c34c33d57d,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-9e11fc05-4349-487f-9b87-a31f7fc4529e,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-c267d5cf-ab02-4e6b-977f-91bd360db9a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548923168-172.17.0.9-1597045372607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37256,DS-cb62bbe6-2b92-4439-8bbf-874cad3a98a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-c29aed7e-73d6-4038-8318-111dab597408,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-779a83f2-ecc9-4af1-9446-62b1831d4e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-4768218b-8117-43be-8dcb-ecd457c9c92e,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-a0121a48-603f-41cc-8f96-6ee622e4ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-70684c91-1e3b-4746-a309-33eca8d2fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-7dcd1ab3-82bc-468d-8aa1-07942a373b91,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-f1c658d6-2fdf-4810-8cb5-3121e03cc0c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548923168-172.17.0.9-1597045372607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37256,DS-cb62bbe6-2b92-4439-8bbf-874cad3a98a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-c29aed7e-73d6-4038-8318-111dab597408,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-779a83f2-ecc9-4af1-9446-62b1831d4e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-4768218b-8117-43be-8dcb-ecd457c9c92e,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-a0121a48-603f-41cc-8f96-6ee622e4ec0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-70684c91-1e3b-4746-a309-33eca8d2fc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-7dcd1ab3-82bc-468d-8aa1-07942a373b91,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-f1c658d6-2fdf-4810-8cb5-3121e03cc0c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124634472-172.17.0.9-1597045583890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42966,DS-c6e8458c-8068-4f20-b018-6c4c26f2da15,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-9dfd2e94-2a68-43cb-ae3e-2ac18ab54975,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-36b2fe00-2aed-414c-a662-55eecddf522f,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-156f1074-52d0-4852-afa8-e588f54a9ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-8e63975f-2b34-46bd-a4e9-5ab72ed2900f,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-91c2baf1-166d-47e5-8756-ce223682294a,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-2b0e9a9e-d118-4c7d-bb05-a018fdbf0521,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-64453e28-7db1-4ddb-b44c-4a187544d782,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124634472-172.17.0.9-1597045583890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42966,DS-c6e8458c-8068-4f20-b018-6c4c26f2da15,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-9dfd2e94-2a68-43cb-ae3e-2ac18ab54975,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-36b2fe00-2aed-414c-a662-55eecddf522f,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-156f1074-52d0-4852-afa8-e588f54a9ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-8e63975f-2b34-46bd-a4e9-5ab72ed2900f,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-91c2baf1-166d-47e5-8756-ce223682294a,DISK], DatanodeInfoWithStorage[127.0.0.1:34250,DS-2b0e9a9e-d118-4c7d-bb05-a018fdbf0521,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-64453e28-7db1-4ddb-b44c-4a187544d782,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919416986-172.17.0.9-1597045657866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36596,DS-cded60d0-bf6b-4012-a468-dbc7f86d4eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-f0277262-063c-4c96-af44-c2c994c7e8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-9769729d-2b71-48c7-ab4c-80623b44d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-8d6f8229-a7e0-4660-8f1e-b336e183e819,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-870bd527-3031-49c2-b0eb-cb6f2e291190,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-663b198e-f91d-42f5-af6e-c918e91bbf63,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-0b83b7de-bda8-4dbb-bc38-ca6e04a5021f,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-ada859e3-002d-4adb-8590-1d4cddbc108a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919416986-172.17.0.9-1597045657866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36596,DS-cded60d0-bf6b-4012-a468-dbc7f86d4eba,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-f0277262-063c-4c96-af44-c2c994c7e8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-9769729d-2b71-48c7-ab4c-80623b44d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-8d6f8229-a7e0-4660-8f1e-b336e183e819,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-870bd527-3031-49c2-b0eb-cb6f2e291190,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-663b198e-f91d-42f5-af6e-c918e91bbf63,DISK], DatanodeInfoWithStorage[127.0.0.1:43513,DS-0b83b7de-bda8-4dbb-bc38-ca6e04a5021f,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-ada859e3-002d-4adb-8590-1d4cddbc108a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592722249-172.17.0.9-1597045697064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42669,DS-b33d49a6-9acc-4c6c-bbfb-c72e5e1b56a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-b38e2e4f-48d4-48c5-bd86-ad7c863303a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-555096c8-8117-446e-9456-4f1cb443cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-b316e25c-44f5-4ec8-bae4-82ff15fce948,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-b5f11d5b-6ab0-4993-bc38-6f580e7fad00,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-653241d8-2500-4e9f-884b-ec275039aa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-103c1b67-70e7-4ea2-a4f1-9802db5f81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-d83ca75e-3a89-4824-b190-3e43a3ce8d9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1592722249-172.17.0.9-1597045697064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42669,DS-b33d49a6-9acc-4c6c-bbfb-c72e5e1b56a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-b38e2e4f-48d4-48c5-bd86-ad7c863303a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-555096c8-8117-446e-9456-4f1cb443cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-b316e25c-44f5-4ec8-bae4-82ff15fce948,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-b5f11d5b-6ab0-4993-bc38-6f580e7fad00,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-653241d8-2500-4e9f-884b-ec275039aa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-103c1b67-70e7-4ea2-a4f1-9802db5f81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-d83ca75e-3a89-4824-b190-3e43a3ce8d9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688247554-172.17.0.9-1597045988871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46005,DS-3c414c13-04dd-437c-8a99-16b46a98b290,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-2bfaf10c-2d81-4acc-9bb0-0203932d9fea,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-81eda23a-f08a-4904-afcb-eee15d139d98,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-746eabdc-71f4-423b-92aa-31a35307a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-094c18cb-d4d3-4b95-8657-c21c29589f00,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-b9f13bc6-1395-4459-8d73-89395040df2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-a3b60651-dfb2-4bf7-9ffe-179031d34391,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-fed26e6f-8ff8-4a55-ba6b-a9f456f517b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688247554-172.17.0.9-1597045988871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46005,DS-3c414c13-04dd-437c-8a99-16b46a98b290,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-2bfaf10c-2d81-4acc-9bb0-0203932d9fea,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-81eda23a-f08a-4904-afcb-eee15d139d98,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-746eabdc-71f4-423b-92aa-31a35307a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-094c18cb-d4d3-4b95-8657-c21c29589f00,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-b9f13bc6-1395-4459-8d73-89395040df2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-a3b60651-dfb2-4bf7-9ffe-179031d34391,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-fed26e6f-8ff8-4a55-ba6b-a9f456f517b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264629097-172.17.0.9-1597046213293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33453,DS-504159fd-7444-4e8c-942f-d714e79565d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-10d5461d-515b-4d3c-a190-949390fa91ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-0e39a500-1d75-4ba8-818a-a9261a60c330,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-ec7edbae-12a1-4f68-9767-fe97b2bf3828,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-55fcd75e-2cc6-400c-9af8-b4413becd2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-d358e8d0-d2c7-490d-b3f1-6e72ce9dee90,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-fe4be4c9-1cfe-4c3c-abb1-4428e46dee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-75c1e12d-8b31-4f80-b053-83d947ef892f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264629097-172.17.0.9-1597046213293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33453,DS-504159fd-7444-4e8c-942f-d714e79565d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-10d5461d-515b-4d3c-a190-949390fa91ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-0e39a500-1d75-4ba8-818a-a9261a60c330,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-ec7edbae-12a1-4f68-9767-fe97b2bf3828,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-55fcd75e-2cc6-400c-9af8-b4413becd2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-d358e8d0-d2c7-490d-b3f1-6e72ce9dee90,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-fe4be4c9-1cfe-4c3c-abb1-4428e46dee4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-75c1e12d-8b31-4f80-b053-83d947ef892f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28670433-172.17.0.9-1597046244818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36514,DS-f45daaa9-2935-424a-a00a-2acab9a4ceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-946e53ef-e120-405c-8c5c-be4b2dadf69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-5ed62f10-57db-4d7c-baa2-f18a43fc83cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-2d54ff9b-17d5-41a0-af1b-198e12c8f788,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-a63351a1-e104-4769-911e-393d706360eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-c51d42d1-7842-4373-a964-27b17fe0f333,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-15ec5b13-79a2-4222-a88f-d37af99dc2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-075e7bfb-24b9-43c5-b097-5dd5caaa70e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28670433-172.17.0.9-1597046244818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36514,DS-f45daaa9-2935-424a-a00a-2acab9a4ceb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-946e53ef-e120-405c-8c5c-be4b2dadf69c,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-5ed62f10-57db-4d7c-baa2-f18a43fc83cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-2d54ff9b-17d5-41a0-af1b-198e12c8f788,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-a63351a1-e104-4769-911e-393d706360eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-c51d42d1-7842-4373-a964-27b17fe0f333,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-15ec5b13-79a2-4222-a88f-d37af99dc2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46020,DS-075e7bfb-24b9-43c5-b097-5dd5caaa70e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836047259-172.17.0.9-1597046316139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-d067cbb0-9dcf-4379-a8a4-4b257426c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-d0e59c4d-9f28-4f0e-807f-7470223c4ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-323b64f4-267e-4f4f-a1be-a40117642442,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-decfafbe-ae08-4dac-81e7-f3d925b3a2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-32a88eff-77cd-4f46-b079-b21b0e93007d,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-b34986dc-322f-4836-9c40-b1b5b8f0abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-5585d0fb-e88a-4038-911c-794ed34154c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-56af46d4-6da7-4a90-8302-4ccc67732fe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1836047259-172.17.0.9-1597046316139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34299,DS-d067cbb0-9dcf-4379-a8a4-4b257426c1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-d0e59c4d-9f28-4f0e-807f-7470223c4ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-323b64f4-267e-4f4f-a1be-a40117642442,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-decfafbe-ae08-4dac-81e7-f3d925b3a2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-32a88eff-77cd-4f46-b079-b21b0e93007d,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-b34986dc-322f-4836-9c40-b1b5b8f0abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-5585d0fb-e88a-4038-911c-794ed34154c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-56af46d4-6da7-4a90-8302-4ccc67732fe9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865368467-172.17.0.9-1597046386937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41876,DS-3821310f-e0d1-44ad-8763-1e5363732221,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-1b21b65c-2bf2-4052-b661-7d111f3c3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-02475786-5d91-4edb-bccf-a5d6f959684d,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-a985f808-93e9-4d18-8925-db51a38830b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-e13d832c-a1df-4528-8249-1f5ac4b90348,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-ca90851b-0749-4583-ada6-3e56adcca614,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-23066aba-e9ca-42c6-977d-269228e0f295,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-7085f391-36aa-4f84-9228-924c178fa5fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865368467-172.17.0.9-1597046386937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41876,DS-3821310f-e0d1-44ad-8763-1e5363732221,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-1b21b65c-2bf2-4052-b661-7d111f3c3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-02475786-5d91-4edb-bccf-a5d6f959684d,DISK], DatanodeInfoWithStorage[127.0.0.1:35827,DS-a985f808-93e9-4d18-8925-db51a38830b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-e13d832c-a1df-4528-8249-1f5ac4b90348,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-ca90851b-0749-4583-ada6-3e56adcca614,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-23066aba-e9ca-42c6-977d-269228e0f295,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-7085f391-36aa-4f84-9228-924c178fa5fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197492507-172.17.0.9-1597046563039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-9ff03ee8-b449-4481-8b15-a4ab8918036c,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-2cf831c3-de4b-4335-8729-5f6ae398362e,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-9c7f3e4b-99f1-4780-bb71-3c7d0a2f6720,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-81c1c5b7-5c96-41a1-ba77-925ef4625185,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-95b6db90-af1d-474f-ad1b-6189a89fe855,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-4fc3ec86-61ad-4e19-8c7c-d9aa12fdd7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-9fcfb09d-711c-4d15-93e1-a2fadfca5f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-48ec5050-1ead-45f7-a5b6-9dc3fe5135cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-197492507-172.17.0.9-1597046563039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-9ff03ee8-b449-4481-8b15-a4ab8918036c,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-2cf831c3-de4b-4335-8729-5f6ae398362e,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-9c7f3e4b-99f1-4780-bb71-3c7d0a2f6720,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-81c1c5b7-5c96-41a1-ba77-925ef4625185,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-95b6db90-af1d-474f-ad1b-6189a89fe855,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-4fc3ec86-61ad-4e19-8c7c-d9aa12fdd7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-9fcfb09d-711c-4d15-93e1-a2fadfca5f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-48ec5050-1ead-45f7-a5b6-9dc3fe5135cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192974960-172.17.0.9-1597046825259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40298,DS-e6948abf-0222-40a4-81f6-288b9124ab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-4a952ca2-4f01-4b6f-b41d-e4500d100ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-c739fff3-4421-4559-a11c-ff881ca9402b,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-d2a1889f-6b6a-461f-9cd4-8d9678ddc5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-46a0b674-b25f-4551-b0f5-a484a2af64d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-57420236-aff7-48a2-a010-69744ff96f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-1a1f90d4-096b-44ae-b5bc-01902f72c508,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-6b05dc2b-8308-4644-8d72-10bf12751e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192974960-172.17.0.9-1597046825259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40298,DS-e6948abf-0222-40a4-81f6-288b9124ab0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-4a952ca2-4f01-4b6f-b41d-e4500d100ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-c739fff3-4421-4559-a11c-ff881ca9402b,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-d2a1889f-6b6a-461f-9cd4-8d9678ddc5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-46a0b674-b25f-4551-b0f5-a484a2af64d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-57420236-aff7-48a2-a010-69744ff96f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-1a1f90d4-096b-44ae-b5bc-01902f72c508,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-6b05dc2b-8308-4644-8d72-10bf12751e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716407235-172.17.0.9-1597046945270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-010e419c-2772-48b6-bee8-7eace073bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-6f05f63a-53c3-411e-8284-b81f55cfe773,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-416f387e-c704-4f73-b4ac-cbbe6e2b19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-14770040-24b3-432e-8d39-971b207319f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-e88ce77c-2eca-4caa-8e0d-c71da4934592,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-873a8061-e144-44ba-a342-a028a5b06708,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-4722a123-b332-44a5-8ad2-cfae1d1ce40a,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-738cd3d5-d17a-41d7-b0b5-40ece30d6f96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716407235-172.17.0.9-1597046945270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-010e419c-2772-48b6-bee8-7eace073bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-6f05f63a-53c3-411e-8284-b81f55cfe773,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-416f387e-c704-4f73-b4ac-cbbe6e2b19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-14770040-24b3-432e-8d39-971b207319f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-e88ce77c-2eca-4caa-8e0d-c71da4934592,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-873a8061-e144-44ba-a342-a028a5b06708,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-4722a123-b332-44a5-8ad2-cfae1d1ce40a,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-738cd3d5-d17a-41d7-b0b5-40ece30d6f96,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185985689-172.17.0.9-1597047020638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-ae00fe81-e744-4b60-bcba-48d2acabe483,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-d2e77b93-4e4f-4c98-8f72-892d59066862,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-a4a508d0-0a23-438b-a50f-21d3353a43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-e78f528e-bde3-4190-9988-f2ce9962ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-196986d4-79d5-4b77-b2a8-f9321261fcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-2aaaec03-9efe-4dc7-a247-a403563662dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-459a0794-d3d7-4ad3-8811-ae6fd0f36e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-694921f2-1816-446c-b392-19a38e9ad32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185985689-172.17.0.9-1597047020638:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-ae00fe81-e744-4b60-bcba-48d2acabe483,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-d2e77b93-4e4f-4c98-8f72-892d59066862,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-a4a508d0-0a23-438b-a50f-21d3353a43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-e78f528e-bde3-4190-9988-f2ce9962ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-196986d4-79d5-4b77-b2a8-f9321261fcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-2aaaec03-9efe-4dc7-a247-a403563662dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-459a0794-d3d7-4ad3-8811-ae6fd0f36e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33888,DS-694921f2-1816-446c-b392-19a38e9ad32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617282954-172.17.0.9-1597047064078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-1c456eae-f42b-4ce4-a0c6-9d74908cfbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-b053d4eb-1590-45aa-816d-ab81a2c0d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-4c1a30fa-7970-4506-a2ad-e3cb30c4c5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-d269b3ad-1d08-4d53-a040-657761e16434,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-79a8aed0-8f5b-41b4-b595-7193b20d498f,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-a2dceac9-b804-4285-81d1-88a3248fab95,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-0e6b2614-c8c6-4275-a0c1-52d79b9ada62,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-fd0ee5af-7e06-44c7-bc5b-41bd1d25ce98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617282954-172.17.0.9-1597047064078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45931,DS-1c456eae-f42b-4ce4-a0c6-9d74908cfbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-b053d4eb-1590-45aa-816d-ab81a2c0d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-4c1a30fa-7970-4506-a2ad-e3cb30c4c5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-d269b3ad-1d08-4d53-a040-657761e16434,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-79a8aed0-8f5b-41b4-b595-7193b20d498f,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-a2dceac9-b804-4285-81d1-88a3248fab95,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-0e6b2614-c8c6-4275-a0c1-52d79b9ada62,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-fd0ee5af-7e06-44c7-bc5b-41bd1d25ce98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454247908-172.17.0.9-1597047100116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44677,DS-4f3afa8d-2815-4a06-bc68-d82e13d6fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-88185252-146b-4215-9668-6b3e3675d35c,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-7c01d459-5190-44d1-aa2a-5bbfdcdadbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-ca06b603-9c67-46d2-88fa-f1074a9fdac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-db302367-babd-4341-b61d-b17f31c5bb19,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-00894af4-508e-4962-8b8b-33acbdcc55e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-64f59ab5-4ec7-4ff6-ae7f-0309a650f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-b303bfdf-101d-4ecb-b6ba-92d264040df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454247908-172.17.0.9-1597047100116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44677,DS-4f3afa8d-2815-4a06-bc68-d82e13d6fe63,DISK], DatanodeInfoWithStorage[127.0.0.1:41486,DS-88185252-146b-4215-9668-6b3e3675d35c,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-7c01d459-5190-44d1-aa2a-5bbfdcdadbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-ca06b603-9c67-46d2-88fa-f1074a9fdac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-db302367-babd-4341-b61d-b17f31c5bb19,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-00894af4-508e-4962-8b8b-33acbdcc55e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-64f59ab5-4ec7-4ff6-ae7f-0309a650f48f,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-b303bfdf-101d-4ecb-b6ba-92d264040df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542332068-172.17.0.9-1597047361389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-34bb8139-8013-4246-b184-8edf39e9eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-737f25a4-2e59-4ff1-8e2d-3c95dc24f474,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-70316b4c-bf50-41f4-978d-2b938b9a016c,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-c7ca76c2-64b8-4219-a211-1e895f4151a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-20016e0d-7f36-46e4-a297-549660e4afea,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-f8868ac2-0900-42a8-975a-5b9f4434b5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-57af63f9-97c6-4e3d-ac13-45516d114a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-89f9bdd7-411d-493a-aa96-2cb2e82ada7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542332068-172.17.0.9-1597047361389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-34bb8139-8013-4246-b184-8edf39e9eaae,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-737f25a4-2e59-4ff1-8e2d-3c95dc24f474,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-70316b4c-bf50-41f4-978d-2b938b9a016c,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-c7ca76c2-64b8-4219-a211-1e895f4151a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40454,DS-20016e0d-7f36-46e4-a297-549660e4afea,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-f8868ac2-0900-42a8-975a-5b9f4434b5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-57af63f9-97c6-4e3d-ac13-45516d114a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-89f9bdd7-411d-493a-aa96-2cb2e82ada7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487752902-172.17.0.9-1597047590006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-049263da-6a37-40d4-877d-02112f26e714,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-7133cc3d-7598-4b86-ae48-2307cdd73eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-f28afa2e-4582-490c-9836-16aa7518f884,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-7f2eaf20-4ff1-4ff4-b60d-e243bcba8f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-5dd6b789-936b-4519-9539-b0d39ea7b555,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-661416a5-aca9-4a06-bd56-5868be8eb46c,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-9e702ba6-35cd-45c4-896a-91e907326cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-8c9bd982-c5d7-404d-b949-eafe5dc91b4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487752902-172.17.0.9-1597047590006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34573,DS-049263da-6a37-40d4-877d-02112f26e714,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-7133cc3d-7598-4b86-ae48-2307cdd73eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-f28afa2e-4582-490c-9836-16aa7518f884,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-7f2eaf20-4ff1-4ff4-b60d-e243bcba8f78,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-5dd6b789-936b-4519-9539-b0d39ea7b555,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-661416a5-aca9-4a06-bd56-5868be8eb46c,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-9e702ba6-35cd-45c4-896a-91e907326cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-8c9bd982-c5d7-404d-b949-eafe5dc91b4e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790570597-172.17.0.9-1597047690787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-9b545ebb-7929-4fd6-96cc-4dc1626b84cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-fdf37cf5-3bd1-4d7e-a647-92c0852a7f10,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-a78cb2b3-4284-4f5a-869b-0ffadba71fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-bfc49560-e141-486b-bf4d-830fde322412,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-dcc08340-b8bc-4d98-b930-c597efff0cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-79d9cf28-e5e1-47fd-ba99-632ed6ee96bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-873c62d5-db13-4473-b76b-18cfdb1fa45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-831af37c-8fd9-496a-9ffd-ade5e934ef2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790570597-172.17.0.9-1597047690787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41297,DS-9b545ebb-7929-4fd6-96cc-4dc1626b84cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-fdf37cf5-3bd1-4d7e-a647-92c0852a7f10,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-a78cb2b3-4284-4f5a-869b-0ffadba71fba,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-bfc49560-e141-486b-bf4d-830fde322412,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-dcc08340-b8bc-4d98-b930-c597efff0cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-79d9cf28-e5e1-47fd-ba99-632ed6ee96bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-873c62d5-db13-4473-b76b-18cfdb1fa45c,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-831af37c-8fd9-496a-9ffd-ade5e934ef2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291361398-172.17.0.9-1597047721573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-1af71932-7af8-428b-9c0f-489f381e02df,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-2fe27b2f-af47-4322-9af3-c751045b136a,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-895b0e7c-2bac-475c-be69-4376106c7f99,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-5a62c186-8d65-4203-a9f7-c9371cddb2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c9f2bd31-63d9-425c-b62f-74884cb282f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-1db12e16-0a4d-40ea-b2e8-d8c712ae7ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-f8d814d9-89a3-40c2-995b-cae543374df6,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-9468b616-27b2-4500-b79f-cc8ec300d52b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291361398-172.17.0.9-1597047721573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34871,DS-1af71932-7af8-428b-9c0f-489f381e02df,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-2fe27b2f-af47-4322-9af3-c751045b136a,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-895b0e7c-2bac-475c-be69-4376106c7f99,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-5a62c186-8d65-4203-a9f7-c9371cddb2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c9f2bd31-63d9-425c-b62f-74884cb282f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-1db12e16-0a4d-40ea-b2e8-d8c712ae7ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-f8d814d9-89a3-40c2-995b-cae543374df6,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-9468b616-27b2-4500-b79f-cc8ec300d52b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43707375-172.17.0.9-1597047922649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33189,DS-7cbed28c-3963-45a7-992d-a650b74fe212,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-4f28b5bf-ef5c-40ff-9bd9-dba46a24aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-edc636e3-6798-4122-91c7-7dc7d758f3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-474c7252-ee5e-4e14-a0de-881f617de4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-8b7936dd-6027-4aaa-a328-89cb86d5a850,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-fb26b9a9-8caa-4ebf-bc65-701ff3f2114c,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-f10b63a8-d511-4c56-9515-551b8b7a50e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-cfb7e116-307d-4fe4-8492-1ea38f3b4809,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-43707375-172.17.0.9-1597047922649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33189,DS-7cbed28c-3963-45a7-992d-a650b74fe212,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-4f28b5bf-ef5c-40ff-9bd9-dba46a24aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-edc636e3-6798-4122-91c7-7dc7d758f3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-474c7252-ee5e-4e14-a0de-881f617de4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-8b7936dd-6027-4aaa-a328-89cb86d5a850,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-fb26b9a9-8caa-4ebf-bc65-701ff3f2114c,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-f10b63a8-d511-4c56-9515-551b8b7a50e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-cfb7e116-307d-4fe4-8492-1ea38f3b4809,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842411623-172.17.0.9-1597047955877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45690,DS-7142044e-8e14-46a2-bb53-0545b8261da4,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-e56d5266-7a8a-44b4-bd13-d2dd1d419d67,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-ebc83b31-b7eb-46c5-bfd1-d09b2c5bc941,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-1f1cc99f-8e57-4868-92d1-5da7294356dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-d282ce77-3c51-4d72-b45e-3e2167778d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-1e079d72-ce0a-49de-a44b-ff3030a69978,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-51529249-eb55-410a-a35d-89c48c2c1ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-1941bfff-1c4d-4f0c-8949-fdb6020a99b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842411623-172.17.0.9-1597047955877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45690,DS-7142044e-8e14-46a2-bb53-0545b8261da4,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-e56d5266-7a8a-44b4-bd13-d2dd1d419d67,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-ebc83b31-b7eb-46c5-bfd1-d09b2c5bc941,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-1f1cc99f-8e57-4868-92d1-5da7294356dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-d282ce77-3c51-4d72-b45e-3e2167778d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-1e079d72-ce0a-49de-a44b-ff3030a69978,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-51529249-eb55-410a-a35d-89c48c2c1ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-1941bfff-1c4d-4f0c-8949-fdb6020a99b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656583846-172.17.0.9-1597048056869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-e495d00a-0e5b-4dc7-b36b-50b07e205769,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-e75c50d7-0a55-446c-965b-2ff62b9a912f,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-de11a269-f292-4fce-bf39-ed994452ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2e3a1ce2-a5e8-4ad0-a1b5-815f546904b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-794adff3-e22f-465d-b144-bc13f8127a81,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-8aaddd48-cf24-4f19-9845-201fca79fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-b4140def-dcc2-4bff-9fe1-fb5223947ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-3bfbd0ae-ab71-404f-ba99-c30170aa8afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656583846-172.17.0.9-1597048056869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-e495d00a-0e5b-4dc7-b36b-50b07e205769,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-e75c50d7-0a55-446c-965b-2ff62b9a912f,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-de11a269-f292-4fce-bf39-ed994452ee16,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-2e3a1ce2-a5e8-4ad0-a1b5-815f546904b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-794adff3-e22f-465d-b144-bc13f8127a81,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-8aaddd48-cf24-4f19-9845-201fca79fb39,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-b4140def-dcc2-4bff-9fe1-fb5223947ead,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-3bfbd0ae-ab71-404f-ba99-c30170aa8afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972085945-172.17.0.9-1597048095915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-a68000a9-f202-4834-a2c8-289682748bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-99f704b4-9cd4-45b4-9708-5525833f37b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-e770540c-dbb0-4018-847b-e7dfb354f35a,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-c2a42c51-c050-4d82-b918-bb9592aba358,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-fc5288ab-1775-4fec-9894-f2a215ed154a,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-6dea3b55-87d4-47ce-baad-baf890aece97,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-fef996f4-65cf-41a2-bc0f-42942e4e2160,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-755dfbc3-5d90-4b8d-aded-212cbc20943b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972085945-172.17.0.9-1597048095915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39034,DS-a68000a9-f202-4834-a2c8-289682748bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-99f704b4-9cd4-45b4-9708-5525833f37b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-e770540c-dbb0-4018-847b-e7dfb354f35a,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-c2a42c51-c050-4d82-b918-bb9592aba358,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-fc5288ab-1775-4fec-9894-f2a215ed154a,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-6dea3b55-87d4-47ce-baad-baf890aece97,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-fef996f4-65cf-41a2-bc0f-42942e4e2160,DISK], DatanodeInfoWithStorage[127.0.0.1:45280,DS-755dfbc3-5d90-4b8d-aded-212cbc20943b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437754876-172.17.0.9-1597048191110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36508,DS-023c60e8-8b64-4fa7-89ad-334a86053e11,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-9d4a0238-c44d-4f33-8e89-dd20cf367714,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-ceccf698-bc98-422e-8c6a-d5688e5e4ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-a665b798-4572-4368-93c6-819ae85d2266,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-7371b609-798e-4d8b-a679-ad971180aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-d7590e5d-df8d-49ca-842f-dbde73e22023,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-85820ce6-77a0-4a37-8f4d-40d8c618a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-2c60744b-8762-4987-9a82-b9fadcd0144f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437754876-172.17.0.9-1597048191110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36508,DS-023c60e8-8b64-4fa7-89ad-334a86053e11,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-9d4a0238-c44d-4f33-8e89-dd20cf367714,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-ceccf698-bc98-422e-8c6a-d5688e5e4ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-a665b798-4572-4368-93c6-819ae85d2266,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-7371b609-798e-4d8b-a679-ad971180aa94,DISK], DatanodeInfoWithStorage[127.0.0.1:41447,DS-d7590e5d-df8d-49ca-842f-dbde73e22023,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-85820ce6-77a0-4a37-8f4d-40d8c618a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-2c60744b-8762-4987-9a82-b9fadcd0144f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532684727-172.17.0.9-1597048299583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-6bbae693-975d-4583-85ef-f492fafde7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-25d671de-f846-4f1c-9d76-b4fc372a43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-34452671-a3be-4936-85b5-b09ad974f88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-fae45449-26b8-43dd-8259-239c94026717,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-89568311-9993-4862-8ec3-34aee989fecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-7bba03de-0370-47bc-a6fa-d369796112ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-a8b00b07-d48f-4ebf-a216-8eed707f6120,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-36cfe58f-bd8b-4330-8e46-23334e193863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532684727-172.17.0.9-1597048299583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-6bbae693-975d-4583-85ef-f492fafde7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-25d671de-f846-4f1c-9d76-b4fc372a43e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-34452671-a3be-4936-85b5-b09ad974f88b,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-fae45449-26b8-43dd-8259-239c94026717,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-89568311-9993-4862-8ec3-34aee989fecf,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-7bba03de-0370-47bc-a6fa-d369796112ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-a8b00b07-d48f-4ebf-a216-8eed707f6120,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-36cfe58f-bd8b-4330-8e46-23334e193863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724320862-172.17.0.9-1597048611622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-055bea6c-4105-496c-aabb-22fce821667e,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-22c08d02-8890-403c-9397-9128b7f70dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-ac3d1894-6b71-4dc3-b69f-3f673d5a9347,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-a64cb315-d8ae-45eb-a26c-c85af5fd9fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-0b1d5893-4fc0-47ae-a621-0b70588c720c,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-9af66f33-7012-42a7-97d2-91f98f0f672d,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-4cb48fd3-787f-444c-9174-9b04983e6acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-e2ec94a9-68ed-4c0b-8555-e5277c95f1ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724320862-172.17.0.9-1597048611622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-055bea6c-4105-496c-aabb-22fce821667e,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-22c08d02-8890-403c-9397-9128b7f70dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-ac3d1894-6b71-4dc3-b69f-3f673d5a9347,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-a64cb315-d8ae-45eb-a26c-c85af5fd9fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-0b1d5893-4fc0-47ae-a621-0b70588c720c,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-9af66f33-7012-42a7-97d2-91f98f0f672d,DISK], DatanodeInfoWithStorage[127.0.0.1:38458,DS-4cb48fd3-787f-444c-9174-9b04983e6acb,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-e2ec94a9-68ed-4c0b-8555-e5277c95f1ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117753133-172.17.0.9-1597048711469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41704,DS-c5eb7edd-0a9f-4dbd-9e9f-2e532e681165,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-581a6b88-49fd-4fc8-91d0-176af1f68156,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-c9f4dd0e-ddc7-4ba6-90b7-745876d95d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-951a1942-a3df-49b6-b8d1-43c74c098742,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-98e86c0d-1b5e-4a38-bb97-26050a96eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-19aae599-d847-4e18-bd2c-7554e3684b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-58727be4-6061-4969-ac54-f2905ae60cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-47366f5a-ccd7-4e49-b72f-ff71ef4b20b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117753133-172.17.0.9-1597048711469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41704,DS-c5eb7edd-0a9f-4dbd-9e9f-2e532e681165,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-581a6b88-49fd-4fc8-91d0-176af1f68156,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-c9f4dd0e-ddc7-4ba6-90b7-745876d95d47,DISK], DatanodeInfoWithStorage[127.0.0.1:41665,DS-951a1942-a3df-49b6-b8d1-43c74c098742,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-98e86c0d-1b5e-4a38-bb97-26050a96eb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-19aae599-d847-4e18-bd2c-7554e3684b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-58727be4-6061-4969-ac54-f2905ae60cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-47366f5a-ccd7-4e49-b72f-ff71ef4b20b5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509237065-172.17.0.9-1597048781770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-06ba615e-ab03-4abb-b243-6f0068db054b,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-0f603040-1bad-4d14-83f4-dd1a5110c169,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-d5dc99ac-788f-44d4-aa7f-116adae796a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-528512b0-404d-48a0-b71e-018e67900f91,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-958e34a1-092e-45f7-ac1f-b666c45bd7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-67aa63ac-43bc-4090-b031-2802e31105ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-ddb9d50c-5dbe-4e20-9703-a90beb72fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-3283521f-85b3-4045-ad7b-6b37c2cc95ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509237065-172.17.0.9-1597048781770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38874,DS-06ba615e-ab03-4abb-b243-6f0068db054b,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-0f603040-1bad-4d14-83f4-dd1a5110c169,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-d5dc99ac-788f-44d4-aa7f-116adae796a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-528512b0-404d-48a0-b71e-018e67900f91,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-958e34a1-092e-45f7-ac1f-b666c45bd7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-67aa63ac-43bc-4090-b031-2802e31105ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-ddb9d50c-5dbe-4e20-9703-a90beb72fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-3283521f-85b3-4045-ad7b-6b37c2cc95ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358685794-172.17.0.9-1597048889271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-a6ef6661-0080-4e0a-9f5a-2ddb6002f2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-01655477-dc9a-4a54-9d46-c00684f819c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-87e02224-f389-4fa3-a91e-2c2b5120e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-f5a5fb83-9ac5-4e98-8c20-dc96504571c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a7345d72-cde7-4d35-8559-2a22251b2955,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-e90958a1-bb31-4e47-aaf3-4727be8c4131,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-0034730a-768b-4cdc-ae02-eebef17fc6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-7837e709-9cb1-4bcc-9020-dcad2d51cfc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358685794-172.17.0.9-1597048889271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34442,DS-a6ef6661-0080-4e0a-9f5a-2ddb6002f2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-01655477-dc9a-4a54-9d46-c00684f819c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-87e02224-f389-4fa3-a91e-2c2b5120e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-f5a5fb83-9ac5-4e98-8c20-dc96504571c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a7345d72-cde7-4d35-8559-2a22251b2955,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-e90958a1-bb31-4e47-aaf3-4727be8c4131,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-0034730a-768b-4cdc-ae02-eebef17fc6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-7837e709-9cb1-4bcc-9020-dcad2d51cfc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947127740-172.17.0.9-1597049127296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-67c87144-16de-4dee-87f2-1d3e68c2d31b,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-7f05ebc2-fbe1-46f9-b046-9eeac52ddb02,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-3df411ce-47fa-46da-8634-103459b549f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-9859f99a-b2a6-4b93-b17e-214ceaeaf926,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-164158e4-4071-407c-80f7-471516e2d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-ff7c4cc6-894b-40c4-b6bf-c9e5744e7d28,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-84365ab4-4e59-46f0-add3-5bf0f09d4f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-bb18c8fc-574c-4325-8851-cd105ded8d4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947127740-172.17.0.9-1597049127296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-67c87144-16de-4dee-87f2-1d3e68c2d31b,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-7f05ebc2-fbe1-46f9-b046-9eeac52ddb02,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-3df411ce-47fa-46da-8634-103459b549f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-9859f99a-b2a6-4b93-b17e-214ceaeaf926,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-164158e4-4071-407c-80f7-471516e2d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-ff7c4cc6-894b-40c4-b6bf-c9e5744e7d28,DISK], DatanodeInfoWithStorage[127.0.0.1:40803,DS-84365ab4-4e59-46f0-add3-5bf0f09d4f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-bb18c8fc-574c-4325-8851-cd105ded8d4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421659662-172.17.0.9-1597049172222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39220,DS-d0142d2d-bcd2-49da-8e51-84135bc871e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-d41f37a2-0473-48fa-96f2-80671e35a1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-e1c9e968-edaa-4a42-83f6-87fd434780c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-04850e0b-ff12-4e21-8a23-f191e21f59f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-e8a6c6c0-1f97-41ee-8a49-2e0cf409d7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-bf1229d6-8c5d-4084-96fe-c77155c7e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-09b069ed-3726-482e-a33c-57044cb27ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-25ead5e5-c18a-439f-93d5-a74d3f71ddc7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421659662-172.17.0.9-1597049172222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39220,DS-d0142d2d-bcd2-49da-8e51-84135bc871e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-d41f37a2-0473-48fa-96f2-80671e35a1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-e1c9e968-edaa-4a42-83f6-87fd434780c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-04850e0b-ff12-4e21-8a23-f191e21f59f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-e8a6c6c0-1f97-41ee-8a49-2e0cf409d7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-bf1229d6-8c5d-4084-96fe-c77155c7e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-09b069ed-3726-482e-a33c-57044cb27ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-25ead5e5-c18a-439f-93d5-a74d3f71ddc7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198058134-172.17.0.9-1597049416418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43026,DS-f6a2660d-d3d2-4e54-a2a0-9927640e151f,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-e86ef615-569c-4fb5-9306-9bf58f4dfb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-a6549dcb-8d38-4afc-a0f5-e8d13dab2a78,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-097ffb76-1188-4a94-bf9e-bbdb4462937e,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-4dce86dd-85d4-4c89-b8e4-274141110d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-5ffef8eb-19bc-438f-a99b-51e168429057,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-a3ed1c32-21ee-4a21-b24f-212ba962175d,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-351aa883-0db0-4132-9833-281b90bea920,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-198058134-172.17.0.9-1597049416418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43026,DS-f6a2660d-d3d2-4e54-a2a0-9927640e151f,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-e86ef615-569c-4fb5-9306-9bf58f4dfb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-a6549dcb-8d38-4afc-a0f5-e8d13dab2a78,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-097ffb76-1188-4a94-bf9e-bbdb4462937e,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-4dce86dd-85d4-4c89-b8e4-274141110d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-5ffef8eb-19bc-438f-a99b-51e168429057,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-a3ed1c32-21ee-4a21-b24f-212ba962175d,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-351aa883-0db0-4132-9833-281b90bea920,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275218364-172.17.0.9-1597049674515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-90bf4ed0-9d3e-46ab-8165-030f1e7e5119,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-e0ed6e81-fe8a-4a3d-8311-2e344af4f929,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-b27659e2-912c-46e0-9a06-c208118051ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-ce398429-0844-4341-ab1c-40c519260329,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-c7d519e8-30dc-43db-9cc7-b10412a4c774,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-3ffee9bf-da28-4efc-978f-ebe0013f28f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-f01049f7-93c0-46b7-88d6-db104209b184,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-9a9177b0-634b-4aa4-b42e-b4fda24e9ed3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275218364-172.17.0.9-1597049674515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45566,DS-90bf4ed0-9d3e-46ab-8165-030f1e7e5119,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-e0ed6e81-fe8a-4a3d-8311-2e344af4f929,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-b27659e2-912c-46e0-9a06-c208118051ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-ce398429-0844-4341-ab1c-40c519260329,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-c7d519e8-30dc-43db-9cc7-b10412a4c774,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-3ffee9bf-da28-4efc-978f-ebe0013f28f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-f01049f7-93c0-46b7-88d6-db104209b184,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-9a9177b0-634b-4aa4-b42e-b4fda24e9ed3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945908432-172.17.0.9-1597050152294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36688,DS-06dfb456-e4b5-4db6-8169-608156adb6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-53a38896-ab35-46c4-854f-9915c6cf67de,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-901909a5-97fb-4dae-8640-a6bc07cd6c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-72a110bd-3720-464c-93fb-04cda7487b63,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-9add10cd-497a-4ba3-89d8-4a4c6d835501,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-7d1ff570-5cd0-4215-be92-39a70fd19276,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-daf26aaa-9ba8-4ba0-a3f6-f17cc845e4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-05f47f2b-8454-4a71-8cce-c93bfabe8516,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945908432-172.17.0.9-1597050152294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36688,DS-06dfb456-e4b5-4db6-8169-608156adb6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-53a38896-ab35-46c4-854f-9915c6cf67de,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-901909a5-97fb-4dae-8640-a6bc07cd6c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-72a110bd-3720-464c-93fb-04cda7487b63,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-9add10cd-497a-4ba3-89d8-4a4c6d835501,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-7d1ff570-5cd0-4215-be92-39a70fd19276,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-daf26aaa-9ba8-4ba0-a3f6-f17cc845e4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-05f47f2b-8454-4a71-8cce-c93bfabe8516,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380396821-172.17.0.9-1597050298177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-06cb5276-21f1-4a13-a701-80ed2ea24110,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-a6cd1fc7-129b-4339-8039-0b7dda268dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-8b923579-dd01-4219-8926-a35f1d846f74,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-dc75a762-4d02-41f8-8df8-782c336566fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-d5703d3a-ecdc-40d9-a378-64b6e63c6d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-29ac5466-70a7-4322-9c97-86fc42d85d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-93d40131-1e8d-4ccf-a4ad-1c00e094ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-c7c13bdb-67f4-4b45-9fe1-44f85fd0eca7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380396821-172.17.0.9-1597050298177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-06cb5276-21f1-4a13-a701-80ed2ea24110,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-a6cd1fc7-129b-4339-8039-0b7dda268dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-8b923579-dd01-4219-8926-a35f1d846f74,DISK], DatanodeInfoWithStorage[127.0.0.1:39156,DS-dc75a762-4d02-41f8-8df8-782c336566fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-d5703d3a-ecdc-40d9-a378-64b6e63c6d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-29ac5466-70a7-4322-9c97-86fc42d85d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-93d40131-1e8d-4ccf-a4ad-1c00e094ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-c7c13bdb-67f4-4b45-9fe1-44f85fd0eca7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5344
