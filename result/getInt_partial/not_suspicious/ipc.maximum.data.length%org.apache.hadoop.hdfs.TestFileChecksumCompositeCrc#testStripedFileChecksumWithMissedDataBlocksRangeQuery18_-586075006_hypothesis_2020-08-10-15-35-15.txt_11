reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410352498-172.17.0.3-1597073729920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33471,DS-621ef5e8-c9fa-4a98-b3dd-fd7029efba88,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-f994ac3e-c29b-4a88-a1b4-60302786f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-57663303-682c-418c-8b9f-ec08cb8f1b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-c6d414b6-84a0-4c89-9d7d-8182780f8254,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-d1f43245-6090-4059-b8e2-379b20b8177c,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-2431f751-cccd-4957-bfa8-57cf8d9358d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-1dacc47a-775b-4757-a405-3af382b945ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-1c6f0f58-a38d-40ff-afc1-4db84eb1ccdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1410352498-172.17.0.3-1597073729920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33471,DS-621ef5e8-c9fa-4a98-b3dd-fd7029efba88,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-f994ac3e-c29b-4a88-a1b4-60302786f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-57663303-682c-418c-8b9f-ec08cb8f1b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-c6d414b6-84a0-4c89-9d7d-8182780f8254,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-d1f43245-6090-4059-b8e2-379b20b8177c,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-2431f751-cccd-4957-bfa8-57cf8d9358d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-1dacc47a-775b-4757-a405-3af382b945ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-1c6f0f58-a38d-40ff-afc1-4db84eb1ccdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601604547-172.17.0.3-1597073813476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35323,DS-d1e93567-1083-4498-9e45-dbd30b745a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-2662047e-e61a-4400-b5cb-002151a89bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-fa649b72-985d-43a9-b1d2-eb2194e2b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-706efbf1-a703-479e-aecd-c86d6c4db4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-d0df4d36-49a1-4f48-a4e1-75ea38670265,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-9a3a60c6-831c-48ca-9d2d-1875dd347733,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-267daef2-3624-400e-af7f-1ab5b3580df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-d0862aa4-b799-4f07-9d81-d2064cba29dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601604547-172.17.0.3-1597073813476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35323,DS-d1e93567-1083-4498-9e45-dbd30b745a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-2662047e-e61a-4400-b5cb-002151a89bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-fa649b72-985d-43a9-b1d2-eb2194e2b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-706efbf1-a703-479e-aecd-c86d6c4db4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34081,DS-d0df4d36-49a1-4f48-a4e1-75ea38670265,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-9a3a60c6-831c-48ca-9d2d-1875dd347733,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-267daef2-3624-400e-af7f-1ab5b3580df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-d0862aa4-b799-4f07-9d81-d2064cba29dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993951960-172.17.0.3-1597074117240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44649,DS-c8e07c10-9925-4f94-a6c6-91d99ec325ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-245a65be-aeae-46fa-b7e6-6af48164ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-3db7f569-aa7d-4d63-8571-f0afffc870bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-7e06278c-d0ba-47d6-8b43-3c5f8694ef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-d90ffe95-5822-4e5c-809c-f6db7777e1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-fdc0b7b8-b7df-4875-bd17-2c4f455fd31a,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-1f03fc22-05e0-4e6b-b90d-8fa3cf602c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-f453f747-8a23-49ea-8960-b776f9c34d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993951960-172.17.0.3-1597074117240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44649,DS-c8e07c10-9925-4f94-a6c6-91d99ec325ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-245a65be-aeae-46fa-b7e6-6af48164ccd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-3db7f569-aa7d-4d63-8571-f0afffc870bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-7e06278c-d0ba-47d6-8b43-3c5f8694ef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-d90ffe95-5822-4e5c-809c-f6db7777e1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-fdc0b7b8-b7df-4875-bd17-2c4f455fd31a,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-1f03fc22-05e0-4e6b-b90d-8fa3cf602c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-f453f747-8a23-49ea-8960-b776f9c34d98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756243242-172.17.0.3-1597074698793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-2a3af238-14f2-4f74-b28b-fe9385caac8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-bd0edb9a-0bfe-498e-bf87-64350808e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-08d3b1d1-ab0e-4add-bc16-b6a00a32b83a,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-75ef40ce-3aff-4a8f-ac25-140d02fc782c,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-aeb16c3e-f8d8-4b0a-8aae-90000f48994f,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-bda3ef4f-8210-4712-a2b2-d636e07135da,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-28fe1a4d-a476-43a8-bf08-3204dc79e09d,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-cf8266d8-b7b5-4532-8244-07096e9b0ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756243242-172.17.0.3-1597074698793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36208,DS-2a3af238-14f2-4f74-b28b-fe9385caac8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-bd0edb9a-0bfe-498e-bf87-64350808e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-08d3b1d1-ab0e-4add-bc16-b6a00a32b83a,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-75ef40ce-3aff-4a8f-ac25-140d02fc782c,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-aeb16c3e-f8d8-4b0a-8aae-90000f48994f,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-bda3ef4f-8210-4712-a2b2-d636e07135da,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-28fe1a4d-a476-43a8-bf08-3204dc79e09d,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-cf8266d8-b7b5-4532-8244-07096e9b0ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056302138-172.17.0.3-1597075337049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-9436b1a9-5946-420d-b335-8c1f3cfe967b,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-9b27f3e8-089b-439c-8601-3ec7dd90c106,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-82648eb9-c135-4ea8-9cca-2963e2d8afb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-a94adf03-995d-412b-bcc8-ec0fd9624e40,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-ada3b125-520f-496c-97ca-4d2b817ccd88,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-d2935402-8800-49db-94f7-3601a3c609ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-540ba05b-a2bb-4a93-8db8-6e583b26858a,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-67dfc008-45a2-4db5-ba06-ee53c0dd0b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2056302138-172.17.0.3-1597075337049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-9436b1a9-5946-420d-b335-8c1f3cfe967b,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-9b27f3e8-089b-439c-8601-3ec7dd90c106,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-82648eb9-c135-4ea8-9cca-2963e2d8afb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-a94adf03-995d-412b-bcc8-ec0fd9624e40,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-ada3b125-520f-496c-97ca-4d2b817ccd88,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-d2935402-8800-49db-94f7-3601a3c609ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-540ba05b-a2bb-4a93-8db8-6e583b26858a,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-67dfc008-45a2-4db5-ba06-ee53c0dd0b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912814363-172.17.0.3-1597075596582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-8f980532-48b2-4449-b92e-3961222352d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-ecc0d475-681f-47cf-861e-adfb16aa477c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-5f4ef1e0-a486-4208-8fe5-c3b8ad683ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-e8536e13-9d28-4731-904f-39d3ad324cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-1bf621a4-0d53-498c-8c45-e574c242daba,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-151e67ab-3f20-415d-9e56-e4d7512094be,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-9c3f872a-8094-46cb-a31c-706b772c6e07,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-be6e79b5-f0d5-4d54-b16c-c479bbe61966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912814363-172.17.0.3-1597075596582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-8f980532-48b2-4449-b92e-3961222352d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-ecc0d475-681f-47cf-861e-adfb16aa477c,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-5f4ef1e0-a486-4208-8fe5-c3b8ad683ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-e8536e13-9d28-4731-904f-39d3ad324cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-1bf621a4-0d53-498c-8c45-e574c242daba,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-151e67ab-3f20-415d-9e56-e4d7512094be,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-9c3f872a-8094-46cb-a31c-706b772c6e07,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-be6e79b5-f0d5-4d54-b16c-c479bbe61966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864434687-172.17.0.3-1597075638866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39859,DS-6d7aaf71-bd93-406c-b579-76bc85f1769b,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-16627dad-16cd-405f-8fa4-671176a1b321,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-7f603f5a-c7cc-415d-98b1-0412c7814782,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-319b2b55-09e1-40d7-9217-6e9ea74ec348,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-0988fc29-37b5-4fd7-90ea-8b5a7bd27977,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-3ad915d7-285b-4731-a6ca-c802c341ae55,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-b5eb61d0-d0aa-4a27-93e2-ab89cb5733c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-418a9a39-6863-45fd-b7f3-8d011da4da28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-864434687-172.17.0.3-1597075638866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39859,DS-6d7aaf71-bd93-406c-b579-76bc85f1769b,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-16627dad-16cd-405f-8fa4-671176a1b321,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-7f603f5a-c7cc-415d-98b1-0412c7814782,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-319b2b55-09e1-40d7-9217-6e9ea74ec348,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-0988fc29-37b5-4fd7-90ea-8b5a7bd27977,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-3ad915d7-285b-4731-a6ca-c802c341ae55,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-b5eb61d0-d0aa-4a27-93e2-ab89cb5733c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37498,DS-418a9a39-6863-45fd-b7f3-8d011da4da28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130312798-172.17.0.3-1597075738120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42491,DS-654c8483-1414-485c-adec-9f9ec456caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-8a31f263-db9e-4d83-8c08-0d0fc721ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-9ed74f5f-21e0-4b4e-af0f-e379531e49ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-f901cc52-3168-4169-98b4-4b72aeb5e3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-aef0aa8e-7ebf-4b47-9131-621be07d8306,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-e3694ca7-717e-4f50-a7e1-e72a132d9d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-6cee13b3-0852-49cc-9c78-df661dc27f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-87dcb312-336b-4f5e-b546-09545bf5f6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130312798-172.17.0.3-1597075738120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42491,DS-654c8483-1414-485c-adec-9f9ec456caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-8a31f263-db9e-4d83-8c08-0d0fc721ab0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-9ed74f5f-21e0-4b4e-af0f-e379531e49ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-f901cc52-3168-4169-98b4-4b72aeb5e3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-aef0aa8e-7ebf-4b47-9131-621be07d8306,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-e3694ca7-717e-4f50-a7e1-e72a132d9d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-6cee13b3-0852-49cc-9c78-df661dc27f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43128,DS-87dcb312-336b-4f5e-b546-09545bf5f6b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138781804-172.17.0.3-1597076002562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-c52e8eaa-108e-4efa-af7e-19a8ed5ec837,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-55682e61-f910-40da-af43-7e243854699d,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-0b9e0cfd-22cd-468d-805c-2a9fd213fcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-049a7cf2-c598-4020-a149-f20a3fbc442d,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-f420bd47-4fb0-4b9b-840e-6eca948f8f60,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-76faf64c-1221-4dac-9eb4-d459cd3ded2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-9fd81148-dd18-4d83-b034-b86c4aa752f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-a9c1c265-efb2-4d39-902e-d53d6af3a23d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138781804-172.17.0.3-1597076002562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44415,DS-c52e8eaa-108e-4efa-af7e-19a8ed5ec837,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-55682e61-f910-40da-af43-7e243854699d,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-0b9e0cfd-22cd-468d-805c-2a9fd213fcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-049a7cf2-c598-4020-a149-f20a3fbc442d,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-f420bd47-4fb0-4b9b-840e-6eca948f8f60,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-76faf64c-1221-4dac-9eb4-d459cd3ded2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-9fd81148-dd18-4d83-b034-b86c4aa752f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-a9c1c265-efb2-4d39-902e-d53d6af3a23d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151257585-172.17.0.3-1597076038731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-5bce401e-7b8a-4c69-bfd3-6a4290aa6749,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-0c65ecf6-222b-4d4e-8e7e-908a926e74ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-50d2e973-0b89-4b37-9d80-299ae075bb98,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-6c496801-547d-42a2-8d53-cdd63e841b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-ad948f5f-d49a-4c90-be9c-b6f0340d1a66,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-31f5b424-8ba6-40ee-89a4-37ab9d6c7eab,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-f0cecf38-3c19-4dd0-b3b7-759c4de03632,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ed49b851-ed0d-40a9-89cd-672495c35dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151257585-172.17.0.3-1597076038731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44230,DS-5bce401e-7b8a-4c69-bfd3-6a4290aa6749,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-0c65ecf6-222b-4d4e-8e7e-908a926e74ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-50d2e973-0b89-4b37-9d80-299ae075bb98,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-6c496801-547d-42a2-8d53-cdd63e841b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-ad948f5f-d49a-4c90-be9c-b6f0340d1a66,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-31f5b424-8ba6-40ee-89a4-37ab9d6c7eab,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-f0cecf38-3c19-4dd0-b3b7-759c4de03632,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-ed49b851-ed0d-40a9-89cd-672495c35dcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217910620-172.17.0.3-1597076801783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-dea3b261-f348-4f03-9aa9-a5dc254fd03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-c5fc3a04-2761-4d77-8e35-423cb82ea3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-42f78156-6690-4633-b0ce-3d3033aeb196,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-ba144873-f865-4471-ab16-dc0e2e2a5680,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-cbe0765c-6d43-4a61-958c-68613fad73ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-7d988090-137c-4d83-8fb7-f6741799b6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-1094aab7-b7bf-4828-89af-388ffc3f370c,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-512bd9c5-3492-4c05-98b0-312d26fad08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217910620-172.17.0.3-1597076801783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46737,DS-dea3b261-f348-4f03-9aa9-a5dc254fd03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-c5fc3a04-2761-4d77-8e35-423cb82ea3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-42f78156-6690-4633-b0ce-3d3033aeb196,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-ba144873-f865-4471-ab16-dc0e2e2a5680,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-cbe0765c-6d43-4a61-958c-68613fad73ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-7d988090-137c-4d83-8fb7-f6741799b6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-1094aab7-b7bf-4828-89af-388ffc3f370c,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-512bd9c5-3492-4c05-98b0-312d26fad08e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126891779-172.17.0.3-1597077066850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36450,DS-80eb3bc4-d90c-42e5-bd18-86336a1ea2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-3f55a2f5-1941-4995-baed-4e7984fe674a,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-fb03ade1-936c-4fae-ad02-74ee2466ce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-334b251d-67fd-408b-9bf4-793d47a25f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-283787f5-f181-4f64-81b5-79b322d6d823,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-3f5a768a-987b-4175-91b4-3474066be26d,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-e0927962-87c6-40c4-97db-272fbb51e78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-37b3a095-89d5-4a58-83a9-e6b3bc66cba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-126891779-172.17.0.3-1597077066850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36450,DS-80eb3bc4-d90c-42e5-bd18-86336a1ea2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37017,DS-3f55a2f5-1941-4995-baed-4e7984fe674a,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-fb03ade1-936c-4fae-ad02-74ee2466ce4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-334b251d-67fd-408b-9bf4-793d47a25f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-283787f5-f181-4f64-81b5-79b322d6d823,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-3f5a768a-987b-4175-91b4-3474066be26d,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-e0927962-87c6-40c4-97db-272fbb51e78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-37b3a095-89d5-4a58-83a9-e6b3bc66cba9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968516599-172.17.0.3-1597077339843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-a524648f-fecd-4d34-8095-944482cb5ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-8a2f4a78-287e-4ae6-9252-01053d680df7,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-a943b714-6265-4dd1-bbe3-a2ff147d1bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-458c76de-140e-489f-9a46-8f772d6b5c36,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-cfba007e-c8ed-478b-bd30-cd9b59ba3926,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-2105591a-9ee5-437a-88a2-017ec50e64ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-66d26db2-f182-4b87-9083-a6626cac9879,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-097b5d13-e848-491c-8812-b944f445fde8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968516599-172.17.0.3-1597077339843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-a524648f-fecd-4d34-8095-944482cb5ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-8a2f4a78-287e-4ae6-9252-01053d680df7,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-a943b714-6265-4dd1-bbe3-a2ff147d1bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-458c76de-140e-489f-9a46-8f772d6b5c36,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-cfba007e-c8ed-478b-bd30-cd9b59ba3926,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-2105591a-9ee5-437a-88a2-017ec50e64ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-66d26db2-f182-4b87-9083-a6626cac9879,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-097b5d13-e848-491c-8812-b944f445fde8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619037157-172.17.0.3-1597077545301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-594fd481-1f59-48f5-9136-611ca4e8ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-307584fe-85e9-41fc-a673-e3a3eabc4e16,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-505c30be-d358-4d8c-863d-60832935dade,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-966596e9-4074-4c05-b99e-47a00b87db12,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-9dd26ec9-38c2-495f-841a-9ac5684c334c,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-ee8d7738-7902-4094-98be-048de80d0224,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-24f359a6-20fe-4893-853e-f5de9e896c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-911b833a-ba44-458a-aa13-a572f6417e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1619037157-172.17.0.3-1597077545301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-594fd481-1f59-48f5-9136-611ca4e8ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-307584fe-85e9-41fc-a673-e3a3eabc4e16,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-505c30be-d358-4d8c-863d-60832935dade,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-966596e9-4074-4c05-b99e-47a00b87db12,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-9dd26ec9-38c2-495f-841a-9ac5684c334c,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-ee8d7738-7902-4094-98be-048de80d0224,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-24f359a6-20fe-4893-853e-f5de9e896c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-911b833a-ba44-458a-aa13-a572f6417e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435848333-172.17.0.3-1597077841118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-cc372644-c74c-4284-96c5-12ef612e083a,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-ea4d9097-a3e3-4a62-af8f-9e76d54dc9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-af09a891-3290-4722-9628-fb82a8e5e6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-54682acb-130e-4d7c-946e-9ef2eb2c4663,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-d0d02cc7-94b2-40ae-9649-d717cd182725,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-585cc560-60ea-401d-af20-6e68b3299c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-10e68597-ef5b-4a19-a0dc-7ab5bd1b2816,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-51d15e36-79c8-4337-91a8-ac7921f70b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435848333-172.17.0.3-1597077841118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-cc372644-c74c-4284-96c5-12ef612e083a,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-ea4d9097-a3e3-4a62-af8f-9e76d54dc9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-af09a891-3290-4722-9628-fb82a8e5e6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-54682acb-130e-4d7c-946e-9ef2eb2c4663,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-d0d02cc7-94b2-40ae-9649-d717cd182725,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-585cc560-60ea-401d-af20-6e68b3299c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-10e68597-ef5b-4a19-a0dc-7ab5bd1b2816,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-51d15e36-79c8-4337-91a8-ac7921f70b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991116191-172.17.0.3-1597078224497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-86d35dcc-2e4f-4cbc-b170-2dc512453d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-782857fa-f4f2-4ad2-b845-0e3b3b652a21,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-3e8fbc51-a8cb-4ef9-a47d-733094b0bc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-4d3ad029-33f2-4b8d-80c7-535c740a1795,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-977f6f77-1a8b-4ec2-9388-297fe9a055ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-65999484-222c-4307-9e38-3770b82feaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-13f35471-ec30-4878-b61f-9eb251f815df,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-26d8fb66-8417-4672-9ef1-fc509f43665c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-991116191-172.17.0.3-1597078224497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38100,DS-86d35dcc-2e4f-4cbc-b170-2dc512453d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-782857fa-f4f2-4ad2-b845-0e3b3b652a21,DISK], DatanodeInfoWithStorage[127.0.0.1:45909,DS-3e8fbc51-a8cb-4ef9-a47d-733094b0bc28,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-4d3ad029-33f2-4b8d-80c7-535c740a1795,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-977f6f77-1a8b-4ec2-9388-297fe9a055ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-65999484-222c-4307-9e38-3770b82feaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-13f35471-ec30-4878-b61f-9eb251f815df,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-26d8fb66-8417-4672-9ef1-fc509f43665c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615655962-172.17.0.3-1597078280658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44293,DS-6458d993-d43f-4cac-82b7-d6f69be79b14,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-a6d0910c-e871-4191-a31a-112b9eda0b75,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-9f3d284b-97c1-49ca-942f-7bf08dd40b74,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-f8ed08a6-e1a9-4e5e-b016-1e20f16f300f,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-0361eab8-5997-45de-b7cf-2af39e880a02,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-21c0ffeb-e85c-4512-b6a0-5ef8408612a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-ec77ec08-736b-4565-be1a-d613801178d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-7d10eee1-4bce-4bf8-aca7-8cc39bfef49e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1615655962-172.17.0.3-1597078280658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44293,DS-6458d993-d43f-4cac-82b7-d6f69be79b14,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-a6d0910c-e871-4191-a31a-112b9eda0b75,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-9f3d284b-97c1-49ca-942f-7bf08dd40b74,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-f8ed08a6-e1a9-4e5e-b016-1e20f16f300f,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-0361eab8-5997-45de-b7cf-2af39e880a02,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-21c0ffeb-e85c-4512-b6a0-5ef8408612a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-ec77ec08-736b-4565-be1a-d613801178d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-7d10eee1-4bce-4bf8-aca7-8cc39bfef49e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321674773-172.17.0.3-1597078555804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40441,DS-24683159-bd56-45d0-a7b3-0a809f607b19,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-7b2b473c-efd6-47ed-9d30-45fa3b156793,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-8ca70182-c636-4e95-b52a-2c5bf55c8570,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-1f04fe0a-9c32-4b21-99fc-29494c2e1d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-835bc4cf-62ed-4957-9224-27dc030ceaca,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-9642d71e-add8-4903-b3c8-c9248ffccf49,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-194e2b4b-bd4c-4dc7-92ae-18cf923e052f,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-e56c9090-73cb-4cad-ac89-e0e4492d028f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321674773-172.17.0.3-1597078555804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40441,DS-24683159-bd56-45d0-a7b3-0a809f607b19,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-7b2b473c-efd6-47ed-9d30-45fa3b156793,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-8ca70182-c636-4e95-b52a-2c5bf55c8570,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-1f04fe0a-9c32-4b21-99fc-29494c2e1d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-835bc4cf-62ed-4957-9224-27dc030ceaca,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-9642d71e-add8-4903-b3c8-c9248ffccf49,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-194e2b4b-bd4c-4dc7-92ae-18cf923e052f,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-e56c9090-73cb-4cad-ac89-e0e4492d028f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841966962-172.17.0.3-1597079166362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43456,DS-0332f97c-f593-4893-b373-ad9add1f07b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-44771a21-df4a-4cd4-a8ad-9857036bb5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-1d038f25-7c62-43dc-a6be-8450c7ca6c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-1ce079d6-35d7-433d-b3e1-1a419924cd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-6417abc0-5736-4010-b85d-89ac95e40528,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-0aba252d-caa4-482b-95ad-d6c4cbb40ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-227f5b0e-e7a1-4d44-a8a6-84d81570d433,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-21de55bd-db8a-4dd5-877c-c05af056d8e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-841966962-172.17.0.3-1597079166362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43456,DS-0332f97c-f593-4893-b373-ad9add1f07b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-44771a21-df4a-4cd4-a8ad-9857036bb5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-1d038f25-7c62-43dc-a6be-8450c7ca6c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-1ce079d6-35d7-433d-b3e1-1a419924cd02,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-6417abc0-5736-4010-b85d-89ac95e40528,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-0aba252d-caa4-482b-95ad-d6c4cbb40ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-227f5b0e-e7a1-4d44-a8a6-84d81570d433,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-21de55bd-db8a-4dd5-877c-c05af056d8e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666116346-172.17.0.3-1597079420322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-71b90488-48b8-47a3-9efd-22cdf4c8c43f,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-695c3b69-6c69-4bb4-93ad-ed9cdfef471f,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-52ec40ff-e642-4f6f-a6dd-e14206e57c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-74170c67-9bed-4f11-bc53-a1eb98e39e59,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-320958e8-5dfa-4f82-ac6f-90221bd9b139,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-c333e97d-5f9e-4006-8ec7-98c869aff1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-0e87ef6b-5072-48eb-8aeb-3081d37365bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-4e0553d3-8740-4aee-bd59-bedeb436e870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1666116346-172.17.0.3-1597079420322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40808,DS-71b90488-48b8-47a3-9efd-22cdf4c8c43f,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-695c3b69-6c69-4bb4-93ad-ed9cdfef471f,DISK], DatanodeInfoWithStorage[127.0.0.1:35645,DS-52ec40ff-e642-4f6f-a6dd-e14206e57c16,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-74170c67-9bed-4f11-bc53-a1eb98e39e59,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-320958e8-5dfa-4f82-ac6f-90221bd9b139,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-c333e97d-5f9e-4006-8ec7-98c869aff1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-0e87ef6b-5072-48eb-8aeb-3081d37365bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-4e0553d3-8740-4aee-bd59-bedeb436e870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850098923-172.17.0.3-1597079834441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-a6548988-d909-42db-9095-3a8b52d0f58c,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-5fe3a347-6dc2-4b07-8058-c8c216032d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-02928bec-68b6-4c4a-93b0-1a8e9d8727dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-d130b110-df4f-4157-b633-13255002431a,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-168d38be-af0a-49ec-8593-d0fb17089a81,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-128b1b41-357a-46ca-ac82-16ecc727f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-0e8cbdf1-711d-4058-8783-d52d9d51c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-ff4d03cc-8483-4c79-9558-fdaf001e32e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850098923-172.17.0.3-1597079834441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-a6548988-d909-42db-9095-3a8b52d0f58c,DISK], DatanodeInfoWithStorage[127.0.0.1:32827,DS-5fe3a347-6dc2-4b07-8058-c8c216032d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-02928bec-68b6-4c4a-93b0-1a8e9d8727dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-d130b110-df4f-4157-b633-13255002431a,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-168d38be-af0a-49ec-8593-d0fb17089a81,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-128b1b41-357a-46ca-ac82-16ecc727f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-0e8cbdf1-711d-4058-8783-d52d9d51c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-ff4d03cc-8483-4c79-9558-fdaf001e32e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.data.length
component: hdfs:DataNode
v1: 67108864
v2: 8388608
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143461941-172.17.0.3-1597080355711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33356,DS-fe169514-d274-476c-8808-40431c692081,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-c640e009-6082-4a48-a2a7-dd99c60e0739,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-2e2fbd86-d667-4853-b50f-800403b296b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-769f3edd-df0b-4313-afa3-364de2077dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-8bab25d6-8985-4be5-81f9-742db9b48b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-5e9b0527-3c6d-407b-827e-0d7d6cdf2fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-e8dc5c2d-19fa-4814-96f8-6db6cb88e59c,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-120560f9-df31-4d63-b2ed-e2ee31b4e472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143461941-172.17.0.3-1597080355711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33356,DS-fe169514-d274-476c-8808-40431c692081,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-c640e009-6082-4a48-a2a7-dd99c60e0739,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-2e2fbd86-d667-4853-b50f-800403b296b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-769f3edd-df0b-4313-afa3-364de2077dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-8bab25d6-8985-4be5-81f9-742db9b48b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-5e9b0527-3c6d-407b-827e-0d7d6cdf2fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-e8dc5c2d-19fa-4814-96f8-6db6cb88e59c,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-120560f9-df31-4d63-b2ed-e2ee31b4e472,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6809
