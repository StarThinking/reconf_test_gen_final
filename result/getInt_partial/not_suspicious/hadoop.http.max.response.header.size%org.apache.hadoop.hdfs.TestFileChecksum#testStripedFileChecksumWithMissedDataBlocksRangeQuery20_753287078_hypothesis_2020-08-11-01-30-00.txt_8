reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438343201-172.17.0.8-1597109451379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35606,DS-b043b398-8dcf-4632-a362-67153c04c3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-ab37af80-cebe-4112-a476-daa9a46c7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-a975bf93-5d42-47f5-b632-b92d7ed70738,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-be6f73e3-c5c0-46de-854b-b0450a045f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-b39073b5-dc47-431f-bcba-824a9d6dc4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-a22e167c-71c8-437f-a588-8f8710b60613,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-ea89ebfc-3846-4678-8fa5-16a697a6ba51,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-0535f4ea-694f-415a-b298-dfa17654bc61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438343201-172.17.0.8-1597109451379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35606,DS-b043b398-8dcf-4632-a362-67153c04c3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-ab37af80-cebe-4112-a476-daa9a46c7fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-a975bf93-5d42-47f5-b632-b92d7ed70738,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-be6f73e3-c5c0-46de-854b-b0450a045f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37566,DS-b39073b5-dc47-431f-bcba-824a9d6dc4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-a22e167c-71c8-437f-a588-8f8710b60613,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-ea89ebfc-3846-4678-8fa5-16a697a6ba51,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-0535f4ea-694f-415a-b298-dfa17654bc61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693285368-172.17.0.8-1597109620872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-dc4f355b-8391-45cf-9095-b1dc18a4f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-f2d13363-eb20-41c9-9d81-b4cfdb5bcf12,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-3688d959-2dce-46e5-9468-3686e3ae8e67,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-236bf5d5-1f2b-463b-9c43-d2169a65a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-b570c4e5-9c1b-490c-a027-20344fb681b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-4ac406b4-b363-46c1-8923-9088c7e959e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-b422091b-c34e-4c79-b6bd-b6aabaaf080b,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a866c790-2696-4bea-9346-dbab109b0a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1693285368-172.17.0.8-1597109620872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-dc4f355b-8391-45cf-9095-b1dc18a4f1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-f2d13363-eb20-41c9-9d81-b4cfdb5bcf12,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-3688d959-2dce-46e5-9468-3686e3ae8e67,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-236bf5d5-1f2b-463b-9c43-d2169a65a82e,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-b570c4e5-9c1b-490c-a027-20344fb681b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-4ac406b4-b363-46c1-8923-9088c7e959e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-b422091b-c34e-4c79-b6bd-b6aabaaf080b,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-a866c790-2696-4bea-9346-dbab109b0a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439512643-172.17.0.8-1597109691323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45495,DS-ab5eca55-c5ca-4aa8-8491-1365c8d47cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-f7b3266b-1214-4c5e-8827-6191fdefe89c,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-a0aa12ec-a20d-44d4-a992-bcfe2b443408,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-78eea3a4-467f-482e-859a-8941b295aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-f9856a7a-1dad-47fb-80cb-88d20ab32b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-b5f4ac40-861b-43a1-977a-5dc137a796d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-99553d5f-ad93-47b9-9dce-c4b2d0c7e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-879cff3b-de90-402f-be57-961083a08358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1439512643-172.17.0.8-1597109691323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45495,DS-ab5eca55-c5ca-4aa8-8491-1365c8d47cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39763,DS-f7b3266b-1214-4c5e-8827-6191fdefe89c,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-a0aa12ec-a20d-44d4-a992-bcfe2b443408,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-78eea3a4-467f-482e-859a-8941b295aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-f9856a7a-1dad-47fb-80cb-88d20ab32b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-b5f4ac40-861b-43a1-977a-5dc137a796d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-99553d5f-ad93-47b9-9dce-c4b2d0c7e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-879cff3b-de90-402f-be57-961083a08358,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080524932-172.17.0.8-1597109975844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-7517fa9f-e79f-4c1e-9bdd-038d6556f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-8e07e0c1-8e92-49b4-9ffd-d4c77503d497,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-f2177b5c-f8fd-4ca0-a673-7bb7b6d8a884,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-7506a159-06f5-4715-a9e1-521426c7ba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-ad9923e0-e6ee-406c-81b3-46695d54edde,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-3c5d8d0f-e380-4235-a26a-3013ed5dc7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-8297bf06-3944-4e5b-b2dc-2df88925aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-54762eb6-590a-4074-b70e-41700bceefc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080524932-172.17.0.8-1597109975844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-7517fa9f-e79f-4c1e-9bdd-038d6556f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-8e07e0c1-8e92-49b4-9ffd-d4c77503d497,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-f2177b5c-f8fd-4ca0-a673-7bb7b6d8a884,DISK], DatanodeInfoWithStorage[127.0.0.1:36921,DS-7506a159-06f5-4715-a9e1-521426c7ba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-ad9923e0-e6ee-406c-81b3-46695d54edde,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-3c5d8d0f-e380-4235-a26a-3013ed5dc7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-8297bf06-3944-4e5b-b2dc-2df88925aaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-54762eb6-590a-4074-b70e-41700bceefc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459346050-172.17.0.8-1597110853327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-71324e06-6864-4226-8cd5-ffa04681fb93,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-6f0ed617-538a-47a4-8d6a-eeebd9e9c675,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-7ea85c9a-9304-4bc3-8c57-3ac2e6d2f3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-2e544286-10e1-4d74-816e-6de8f7583c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-436b0564-cef3-47ee-964a-ab9b090d26d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-afb9cb3e-e953-4f8e-865b-6734bd6559b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-7fd27ece-8dee-41d0-a6c1-f48918b01f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-444fe8ea-410a-45b6-b76d-bf8c9220a18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1459346050-172.17.0.8-1597110853327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-71324e06-6864-4226-8cd5-ffa04681fb93,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-6f0ed617-538a-47a4-8d6a-eeebd9e9c675,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-7ea85c9a-9304-4bc3-8c57-3ac2e6d2f3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-2e544286-10e1-4d74-816e-6de8f7583c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-436b0564-cef3-47ee-964a-ab9b090d26d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-afb9cb3e-e953-4f8e-865b-6734bd6559b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-7fd27ece-8dee-41d0-a6c1-f48918b01f77,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-444fe8ea-410a-45b6-b76d-bf8c9220a18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054134635-172.17.0.8-1597111030367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-949581bb-1628-41d0-83a0-0cbc7b413192,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-07ca53ee-720d-4c0e-b0b7-ccdc2064c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-49fcd409-ec1f-4b9c-aa0f-f1c3f1233cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-b52eb8d9-e9c0-476e-9ac8-f97ac01eecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-aeeecdef-f117-43e1-b6d9-4d2c2a8179aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-4db9723c-9467-43cc-a658-48f3b7d7155a,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-b3554549-f42d-40a0-8612-7dde17475874,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-6721b745-a0ee-4705-a655-6ff94249249e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054134635-172.17.0.8-1597111030367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-949581bb-1628-41d0-83a0-0cbc7b413192,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-07ca53ee-720d-4c0e-b0b7-ccdc2064c0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-49fcd409-ec1f-4b9c-aa0f-f1c3f1233cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-b52eb8d9-e9c0-476e-9ac8-f97ac01eecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-aeeecdef-f117-43e1-b6d9-4d2c2a8179aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-4db9723c-9467-43cc-a658-48f3b7d7155a,DISK], DatanodeInfoWithStorage[127.0.0.1:33091,DS-b3554549-f42d-40a0-8612-7dde17475874,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-6721b745-a0ee-4705-a655-6ff94249249e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815376076-172.17.0.8-1597111194246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-6e38c9a3-6591-4ce3-919a-789bc6b27558,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-130ee453-a1b3-4360-bed7-00ad4e1b6b68,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-77ed4edc-785a-47c5-824a-fc5aa18ca9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-e0b6457c-58ce-4146-a00b-6b1341c78262,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-0db59ff6-f8f1-4dc8-a495-05e616d25c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-1b5919b3-52c0-4f41-a799-5ed516d0fe77,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-ab93bf8a-39e5-4c9e-bc6d-bd14be243ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-8cbc68a2-b651-49da-80cf-07c0ba9df188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815376076-172.17.0.8-1597111194246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-6e38c9a3-6591-4ce3-919a-789bc6b27558,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-130ee453-a1b3-4360-bed7-00ad4e1b6b68,DISK], DatanodeInfoWithStorage[127.0.0.1:45087,DS-77ed4edc-785a-47c5-824a-fc5aa18ca9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-e0b6457c-58ce-4146-a00b-6b1341c78262,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-0db59ff6-f8f1-4dc8-a495-05e616d25c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-1b5919b3-52c0-4f41-a799-5ed516d0fe77,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-ab93bf8a-39e5-4c9e-bc6d-bd14be243ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-8cbc68a2-b651-49da-80cf-07c0ba9df188,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586021633-172.17.0.8-1597111788064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35918,DS-772dada3-2578-498d-a087-567cf3737ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-b98957cf-39e1-4d42-b442-25d3a335e850,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-86d76849-c205-4696-b510-57594bf2fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-a1d077ee-8f6e-4567-9bb2-ade7dc7685a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-aaf91542-9a64-47ac-ab3b-04aaa29e8dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-efbc7c80-5294-40cf-82b8-16b1c4dad256,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-7a2109bd-a55b-400a-9312-a1d80868ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-e4235f31-bba4-4a43-86fb-4d3161a57828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586021633-172.17.0.8-1597111788064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35918,DS-772dada3-2578-498d-a087-567cf3737ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-b98957cf-39e1-4d42-b442-25d3a335e850,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-86d76849-c205-4696-b510-57594bf2fcae,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-a1d077ee-8f6e-4567-9bb2-ade7dc7685a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-aaf91542-9a64-47ac-ab3b-04aaa29e8dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-efbc7c80-5294-40cf-82b8-16b1c4dad256,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-7a2109bd-a55b-400a-9312-a1d80868ab34,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-e4235f31-bba4-4a43-86fb-4d3161a57828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082283265-172.17.0.8-1597111826367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43331,DS-526d5b79-b86d-4ef8-9b85-191ad59b450b,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-663ce8f3-e65f-4e16-8030-f0d4202102ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-a8a77629-abcc-45ec-9d97-bfffc5c3f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-d3fae571-7975-47bb-9434-66689672e149,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-750ac126-b4cb-4fe7-80b5-a44aa73be3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-bfce1aa0-fa1d-4233-8cf7-f39b6fdb57f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-d7eebe1d-66e1-42e6-a46e-470528e9b0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-92ec9bf2-b5ba-4ee2-b7b2-b983b3675a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2082283265-172.17.0.8-1597111826367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43331,DS-526d5b79-b86d-4ef8-9b85-191ad59b450b,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-663ce8f3-e65f-4e16-8030-f0d4202102ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-a8a77629-abcc-45ec-9d97-bfffc5c3f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-d3fae571-7975-47bb-9434-66689672e149,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-750ac126-b4cb-4fe7-80b5-a44aa73be3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-bfce1aa0-fa1d-4233-8cf7-f39b6fdb57f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-d7eebe1d-66e1-42e6-a46e-470528e9b0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-92ec9bf2-b5ba-4ee2-b7b2-b983b3675a85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984122495-172.17.0.8-1597112051424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33435,DS-4645a713-d15a-4528-9fdb-55662c83cbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-6dcef378-4446-4f7c-ac5c-275de3e1a015,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-a08a88da-39db-48b5-9c80-9c46209249f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-7c76b76f-1181-4787-aa1d-152116920be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-55ec61c4-aa0f-4c1e-9b0b-c15db80d1b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-b8389e86-d1e0-4a46-85e1-005903514f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-5786d177-ca28-4c86-8a10-220aea0eda81,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-f1edb219-0be5-44c4-9d73-ae1a735d5ee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984122495-172.17.0.8-1597112051424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33435,DS-4645a713-d15a-4528-9fdb-55662c83cbfc,DISK], DatanodeInfoWithStorage[127.0.0.1:44210,DS-6dcef378-4446-4f7c-ac5c-275de3e1a015,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-a08a88da-39db-48b5-9c80-9c46209249f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-7c76b76f-1181-4787-aa1d-152116920be8,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-55ec61c4-aa0f-4c1e-9b0b-c15db80d1b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-b8389e86-d1e0-4a46-85e1-005903514f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-5786d177-ca28-4c86-8a10-220aea0eda81,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-f1edb219-0be5-44c4-9d73-ae1a735d5ee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988084878-172.17.0.8-1597112184510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-0bc5b85f-0076-4f4a-ab2f-32a1a8071a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-96711768-a8c0-4326-88e0-95bd61c5236c,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-b6d3725f-a5bf-4db8-bd72-48daae5fb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-8787eb92-c8d3-4daf-9a05-8bc07eacc896,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-cf97eef8-603d-46fa-b5ca-7c597e2f9b87,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-b4e27be0-17c1-40a0-bda0-9615e78ddb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-b1072fcf-4c5c-4dec-80b3-db789dd10e10,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-85980f1a-0319-4bf2-800b-78a6412cd10c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988084878-172.17.0.8-1597112184510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44738,DS-0bc5b85f-0076-4f4a-ab2f-32a1a8071a13,DISK], DatanodeInfoWithStorage[127.0.0.1:38339,DS-96711768-a8c0-4326-88e0-95bd61c5236c,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-b6d3725f-a5bf-4db8-bd72-48daae5fb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-8787eb92-c8d3-4daf-9a05-8bc07eacc896,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-cf97eef8-603d-46fa-b5ca-7c597e2f9b87,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-b4e27be0-17c1-40a0-bda0-9615e78ddb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-b1072fcf-4c5c-4dec-80b3-db789dd10e10,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-85980f1a-0319-4bf2-800b-78a6412cd10c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562734112-172.17.0.8-1597112216310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35653,DS-01d9f0ea-6b8e-43a5-837d-4812de9d9681,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-cee3196f-b7bf-44ab-8ccb-c2922798f80e,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-3440bdb3-a751-4e26-aee4-0bb90e2278da,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-b9496726-5800-4de1-948e-e89a49f54105,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-b08d49f1-f528-4018-a297-caa6bcd768aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-d65eb40f-2464-4fb7-8bfe-898940d68701,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-0255e63e-7eea-4e65-8ba9-11f36e71feba,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-a3d51a67-21e5-4b86-a6ac-9875e8e3e23a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562734112-172.17.0.8-1597112216310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35653,DS-01d9f0ea-6b8e-43a5-837d-4812de9d9681,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-cee3196f-b7bf-44ab-8ccb-c2922798f80e,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-3440bdb3-a751-4e26-aee4-0bb90e2278da,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-b9496726-5800-4de1-948e-e89a49f54105,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-b08d49f1-f528-4018-a297-caa6bcd768aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-d65eb40f-2464-4fb7-8bfe-898940d68701,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-0255e63e-7eea-4e65-8ba9-11f36e71feba,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-a3d51a67-21e5-4b86-a6ac-9875e8e3e23a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363515944-172.17.0.8-1597112486426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-e6237e8d-3fb6-44c3-a7f7-cf0efa9553cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-66b4eba1-f92a-41b7-9ada-e142e5249483,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-f17f6a1b-ca6d-4fd2-8d63-cc5802cb8812,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-ccae12a6-b76f-421d-90c0-ad33cb6d1e93,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-d8fae537-236f-4332-8459-54fe269906d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-c5886457-fee2-4be8-a6a2-c2991d390273,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-4dae22cd-8a8f-4cc7-948c-1c5fd86b9b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-fd87c1f2-417d-4fc2-90a2-a5bf9eab20df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363515944-172.17.0.8-1597112486426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45773,DS-e6237e8d-3fb6-44c3-a7f7-cf0efa9553cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-66b4eba1-f92a-41b7-9ada-e142e5249483,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-f17f6a1b-ca6d-4fd2-8d63-cc5802cb8812,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-ccae12a6-b76f-421d-90c0-ad33cb6d1e93,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-d8fae537-236f-4332-8459-54fe269906d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-c5886457-fee2-4be8-a6a2-c2991d390273,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-4dae22cd-8a8f-4cc7-948c-1c5fd86b9b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-fd87c1f2-417d-4fc2-90a2-a5bf9eab20df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332110466-172.17.0.8-1597112519969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-42d8c8b9-bb51-45e3-b78b-4d3442b585f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-c1721378-2e15-4604-b7fa-e7176d911ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-329a9e31-4e04-40fd-b057-7065055b9582,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-20d055a2-8220-4bbd-bdca-5eeb6373d707,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-0420ad6d-a9df-4a28-af1d-b01d407a8b31,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-bdf4fbf0-f9fe-4dc1-ba60-b6379ff576f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-b7333e12-2fe4-483d-a314-1b34749a07d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-31eba3f8-752d-4893-a70e-0c5e0b57dc46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-332110466-172.17.0.8-1597112519969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42785,DS-42d8c8b9-bb51-45e3-b78b-4d3442b585f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-c1721378-2e15-4604-b7fa-e7176d911ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-329a9e31-4e04-40fd-b057-7065055b9582,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-20d055a2-8220-4bbd-bdca-5eeb6373d707,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-0420ad6d-a9df-4a28-af1d-b01d407a8b31,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-bdf4fbf0-f9fe-4dc1-ba60-b6379ff576f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-b7333e12-2fe4-483d-a314-1b34749a07d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-31eba3f8-752d-4893-a70e-0c5e0b57dc46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458788013-172.17.0.8-1597112724279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41291,DS-9ec78531-6ce7-4aa1-9785-a7cbefee3501,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-2529496c-cdbc-4201-98bc-bc85a676ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-83ff5b96-e622-471c-86f2-a5852cd96694,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-764f35c2-38d9-431b-a44d-1b72a0bb481d,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-e269814c-2928-4cac-9672-b32bf1a8ce31,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-a300d594-a000-4fae-9673-46acc55c3134,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-f044b19f-1f88-40de-88d5-2019e2eb8f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-9060077b-6d54-4bb8-b1a7-76871ccb0a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458788013-172.17.0.8-1597112724279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41291,DS-9ec78531-6ce7-4aa1-9785-a7cbefee3501,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-2529496c-cdbc-4201-98bc-bc85a676ff96,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-83ff5b96-e622-471c-86f2-a5852cd96694,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-764f35c2-38d9-431b-a44d-1b72a0bb481d,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-e269814c-2928-4cac-9672-b32bf1a8ce31,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-a300d594-a000-4fae-9673-46acc55c3134,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-f044b19f-1f88-40de-88d5-2019e2eb8f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-9060077b-6d54-4bb8-b1a7-76871ccb0a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840300941-172.17.0.8-1597112762782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45726,DS-aa8863c0-ca15-4068-af7a-04ae4b46ffcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-8a8a8f90-af26-4e8c-bb83-38ec02e64c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-dd84f778-2526-4a0c-924d-6e1355b2e141,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-c24b0904-235c-41ac-8f82-d9dfd3e4ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-1e50cbf4-246e-4887-b50a-b66f23b6e951,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-e63dd0b9-5ed0-4dad-94fd-4b8b54215532,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-c27d39c2-7d50-4725-a778-24cc0acd75c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-51b2dd4a-08f8-45b8-80a2-1580133a75dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1840300941-172.17.0.8-1597112762782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45726,DS-aa8863c0-ca15-4068-af7a-04ae4b46ffcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-8a8a8f90-af26-4e8c-bb83-38ec02e64c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-dd84f778-2526-4a0c-924d-6e1355b2e141,DISK], DatanodeInfoWithStorage[127.0.0.1:43563,DS-c24b0904-235c-41ac-8f82-d9dfd3e4ed4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-1e50cbf4-246e-4887-b50a-b66f23b6e951,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-e63dd0b9-5ed0-4dad-94fd-4b8b54215532,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-c27d39c2-7d50-4725-a778-24cc0acd75c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41123,DS-51b2dd4a-08f8-45b8-80a2-1580133a75dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575917387-172.17.0.8-1597112865876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-51cbccde-defb-4a73-8f84-59969e114df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-92715848-0445-4a9e-a381-6131d3a845b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-d012fb56-5bdd-4b4b-836d-afe7331ca02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-2e11500a-ad94-4be8-ba10-7a78fa550739,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-781e14c9-e624-4f27-a060-364194962604,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-602fc9df-df05-403d-b065-c0899efd9331,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-6b09fbb2-f931-462b-9705-722711ac1fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-c20ce454-af63-4593-b99f-2728868fc279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-575917387-172.17.0.8-1597112865876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40932,DS-51cbccde-defb-4a73-8f84-59969e114df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-92715848-0445-4a9e-a381-6131d3a845b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-d012fb56-5bdd-4b4b-836d-afe7331ca02a,DISK], DatanodeInfoWithStorage[127.0.0.1:45714,DS-2e11500a-ad94-4be8-ba10-7a78fa550739,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-781e14c9-e624-4f27-a060-364194962604,DISK], DatanodeInfoWithStorage[127.0.0.1:39399,DS-602fc9df-df05-403d-b065-c0899efd9331,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-6b09fbb2-f931-462b-9705-722711ac1fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36519,DS-c20ce454-af63-4593-b99f-2728868fc279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669056080-172.17.0.8-1597112930527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33566,DS-02e40693-4f86-471f-b8bc-270443deb649,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-0287f859-5d50-4f9f-9ddc-d1d4faecfdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-6b29ebee-da79-4b5b-896a-53eb42ab1726,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-9b64a109-2950-4e2a-a897-8f124b68b83b,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-22c2cc31-a9dd-47fa-8123-374d8000d902,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-27a702f5-f541-4c84-a448-e31361c5fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-34273f13-1f1a-497f-b0ad-e012752f3f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-aebfa1a4-1e52-4102-a0cd-1d68837ec736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669056080-172.17.0.8-1597112930527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33566,DS-02e40693-4f86-471f-b8bc-270443deb649,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-0287f859-5d50-4f9f-9ddc-d1d4faecfdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-6b29ebee-da79-4b5b-896a-53eb42ab1726,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-9b64a109-2950-4e2a-a897-8f124b68b83b,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-22c2cc31-a9dd-47fa-8123-374d8000d902,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-27a702f5-f541-4c84-a448-e31361c5fe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-34273f13-1f1a-497f-b0ad-e012752f3f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-aebfa1a4-1e52-4102-a0cd-1d68837ec736,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618725387-172.17.0.8-1597112997166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37677,DS-df10a6e1-ba7b-4426-a162-0676e44b0c85,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-4e47a8de-b681-404c-ada2-22295a35da24,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-40095b3f-4ef7-40f6-ae52-abab904e555e,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-63dc5197-af18-41f3-8b6b-13309c1521ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-c4a963b0-9ae0-4b38-9479-872d0774468d,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-cfe87981-46ad-42a5-b1c4-f314f31f28f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-be4dfe53-9bd6-4b99-af9f-5a92e5613993,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-9bcbb803-06bb-47cc-a6bf-7ef441bbdd88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1618725387-172.17.0.8-1597112997166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37677,DS-df10a6e1-ba7b-4426-a162-0676e44b0c85,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-4e47a8de-b681-404c-ada2-22295a35da24,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-40095b3f-4ef7-40f6-ae52-abab904e555e,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-63dc5197-af18-41f3-8b6b-13309c1521ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-c4a963b0-9ae0-4b38-9479-872d0774468d,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-cfe87981-46ad-42a5-b1c4-f314f31f28f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-be4dfe53-9bd6-4b99-af9f-5a92e5613993,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-9bcbb803-06bb-47cc-a6bf-7ef441bbdd88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552153636-172.17.0.8-1597113285057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36026,DS-10b62397-43cc-44de-8b74-58fdf1101e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-fea6ba42-f125-4b0e-be3b-3658fcc8ba90,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-64081201-fc1b-4813-af47-1fe2b6540a85,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-c68c9eac-bed3-4f45-9b77-9a8a4b0e0a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-78cb2d47-1c72-48a7-8b3b-b0a997930f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-dd4108a5-20d9-4d92-bac9-963b98a5fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-01c6499c-62af-42a6-a2f6-74d83588aefe,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-e0b4eb19-2cea-4fc7-9900-1b4939705036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552153636-172.17.0.8-1597113285057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36026,DS-10b62397-43cc-44de-8b74-58fdf1101e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-fea6ba42-f125-4b0e-be3b-3658fcc8ba90,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-64081201-fc1b-4813-af47-1fe2b6540a85,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-c68c9eac-bed3-4f45-9b77-9a8a4b0e0a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-78cb2d47-1c72-48a7-8b3b-b0a997930f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-dd4108a5-20d9-4d92-bac9-963b98a5fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-01c6499c-62af-42a6-a2f6-74d83588aefe,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-e0b4eb19-2cea-4fc7-9900-1b4939705036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146405282-172.17.0.8-1597113384394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-98b43d62-478d-4c33-b71a-b10cd2488c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-58612bce-4741-48a1-b575-ccfc3c4ebcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-674a3f52-4ce8-4a33-8701-4b35d1ecffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-f1e27645-045d-4c5a-8783-6bf46de3aeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-66e640a4-34a2-456a-9f63-c1bd7ea15ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-8df84416-0dfe-4adc-acee-49bd5fa2b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-d4737703-1268-4eac-844c-f0d4043190f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-8a604808-de71-4760-b6b0-44c4b5ac5086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146405282-172.17.0.8-1597113384394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-98b43d62-478d-4c33-b71a-b10cd2488c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-58612bce-4741-48a1-b575-ccfc3c4ebcf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-674a3f52-4ce8-4a33-8701-4b35d1ecffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-f1e27645-045d-4c5a-8783-6bf46de3aeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-66e640a4-34a2-456a-9f63-c1bd7ea15ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-8df84416-0dfe-4adc-acee-49bd5fa2b5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-d4737703-1268-4eac-844c-f0d4043190f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-8a604808-de71-4760-b6b0-44c4b5ac5086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656400899-172.17.0.8-1597113485440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-178b0bac-bc71-44de-8651-da281bcd1672,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-74c0fe34-ed4e-4c4a-9beb-9d42440ade62,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-8d81a0fc-f1ae-4e2a-a8c4-522ba311d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-01b841cc-00f5-45b2-88bd-09ffae0297df,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-64dc129a-2e3d-4302-b2c4-0db15a6cb477,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-adef4440-71f9-4630-8c9b-9377c05e2941,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-a8847202-01b1-480c-9f02-2e777c61502a,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-d4f09932-c4b6-4d6c-8fad-f7369c283834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656400899-172.17.0.8-1597113485440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43156,DS-178b0bac-bc71-44de-8651-da281bcd1672,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-74c0fe34-ed4e-4c4a-9beb-9d42440ade62,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-8d81a0fc-f1ae-4e2a-a8c4-522ba311d13a,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-01b841cc-00f5-45b2-88bd-09ffae0297df,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-64dc129a-2e3d-4302-b2c4-0db15a6cb477,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-adef4440-71f9-4630-8c9b-9377c05e2941,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-a8847202-01b1-480c-9f02-2e777c61502a,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-d4f09932-c4b6-4d6c-8fad-f7369c283834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303337067-172.17.0.8-1597114342598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44937,DS-d6f650f7-1da2-4a82-82f8-dde35dfea395,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-9f461c3a-8b24-4da4-bd22-3c4e988e70fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-b6689584-2db4-48d1-9165-9b08956b4405,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-bbc0edb3-34c0-4f66-aa4f-c340f74f7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-d49378c8-6a0c-4724-8c93-5db7f86c9f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-bf12d2ab-d6d8-4716-b5c9-d000f79ec5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-e0b4f876-d3fb-4658-bae4-f95e4cfa22f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-0758d4fb-c478-4e05-9249-4a5675f44a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1303337067-172.17.0.8-1597114342598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44937,DS-d6f650f7-1da2-4a82-82f8-dde35dfea395,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-9f461c3a-8b24-4da4-bd22-3c4e988e70fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-b6689584-2db4-48d1-9165-9b08956b4405,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-bbc0edb3-34c0-4f66-aa4f-c340f74f7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-d49378c8-6a0c-4724-8c93-5db7f86c9f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-bf12d2ab-d6d8-4716-b5c9-d000f79ec5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-e0b4f876-d3fb-4658-bae4-f95e4cfa22f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-0758d4fb-c478-4e05-9249-4a5675f44a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.response.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224754042-172.17.0.8-1597114374206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-3daf6159-66d1-4278-981a-09a03c3a2c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-80bcb469-da8a-4243-bb3e-c80af87e2cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-18ad491c-8c3d-498b-88e6-598db441f44d,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-3e9e2dd5-6b9e-447e-8af1-74a11d70d670,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-35c987eb-2c00-47ef-95c2-36f0e5053ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-a32d4302-9c33-4998-9201-bf30e2b58ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-614cfafe-cbb9-468a-9d11-8685fd6d8fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-adf78ca5-637d-4a81-9c3a-fe1544800a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224754042-172.17.0.8-1597114374206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-3daf6159-66d1-4278-981a-09a03c3a2c13,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-80bcb469-da8a-4243-bb3e-c80af87e2cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-18ad491c-8c3d-498b-88e6-598db441f44d,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-3e9e2dd5-6b9e-447e-8af1-74a11d70d670,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-35c987eb-2c00-47ef-95c2-36f0e5053ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33685,DS-a32d4302-9c33-4998-9201-bf30e2b58ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-614cfafe-cbb9-468a-9d11-8685fd6d8fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-adf78ca5-637d-4a81-9c3a-fe1544800a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5082
