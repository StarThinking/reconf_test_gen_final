reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613535572-172.17.0.8-1597103619762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-2b075c72-d0c0-4522-a0ae-813af19cec71,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-876b445f-b8b1-4327-9f0a-a9378031ce48,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-7e36d018-f552-419f-9505-01ee90021309,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-204fa8aa-1335-48ac-8573-4243b6d57784,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-781ac709-4309-4415-9fae-5054860e30e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-2bc9d0d9-e75d-4ada-bdb9-ce265635ecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-c6a2fc01-76d5-4876-ae65-98352b1cb369,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-79e7ddce-9487-4573-b8bb-f54b415f5c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613535572-172.17.0.8-1597103619762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-2b075c72-d0c0-4522-a0ae-813af19cec71,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-876b445f-b8b1-4327-9f0a-a9378031ce48,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-7e36d018-f552-419f-9505-01ee90021309,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-204fa8aa-1335-48ac-8573-4243b6d57784,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-781ac709-4309-4415-9fae-5054860e30e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-2bc9d0d9-e75d-4ada-bdb9-ce265635ecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-c6a2fc01-76d5-4876-ae65-98352b1cb369,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-79e7ddce-9487-4573-b8bb-f54b415f5c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209248531-172.17.0.8-1597103703234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-87cd2697-a2c9-4b10-b14f-6de0a333b871,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-ccb96368-9544-4074-9cec-46ba5345d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-89ca36d6-ab9b-4c2d-818e-3a5c7a24bf33,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-5802bd26-f9d0-49f4-843e-a332886998e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-101169f5-a44c-4b1b-a475-5a7af69f0bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-c2e6db22-887e-412c-a2c9-5116da50d311,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-01103f38-f639-4c26-bf6e-fdb04f5146ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-1fc5aad4-2f91-4698-883d-281577557f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209248531-172.17.0.8-1597103703234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36376,DS-87cd2697-a2c9-4b10-b14f-6de0a333b871,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-ccb96368-9544-4074-9cec-46ba5345d98e,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-89ca36d6-ab9b-4c2d-818e-3a5c7a24bf33,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-5802bd26-f9d0-49f4-843e-a332886998e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-101169f5-a44c-4b1b-a475-5a7af69f0bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-c2e6db22-887e-412c-a2c9-5116da50d311,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-01103f38-f639-4c26-bf6e-fdb04f5146ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-1fc5aad4-2f91-4698-883d-281577557f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877852614-172.17.0.8-1597104358799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-84c22cac-fac2-4aee-9f86-d2cc9b608242,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-543c9570-fb2f-40f3-a7b7-5bd639876dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-15a0a8d0-58b1-4e27-b80a-e499c3459fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-cf987fca-bd26-4bf0-9542-907310075b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-d5dce3b0-7bd8-4999-80d7-0a4bbb983256,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-cd6179a2-568f-4d36-8e0b-014de4741f83,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-8bff9095-44ea-4b04-967f-1f29316ccf97,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-988c9de0-bc78-45a2-a21e-40a5b1e4ed0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877852614-172.17.0.8-1597104358799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38801,DS-84c22cac-fac2-4aee-9f86-d2cc9b608242,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-543c9570-fb2f-40f3-a7b7-5bd639876dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-15a0a8d0-58b1-4e27-b80a-e499c3459fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-cf987fca-bd26-4bf0-9542-907310075b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43803,DS-d5dce3b0-7bd8-4999-80d7-0a4bbb983256,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-cd6179a2-568f-4d36-8e0b-014de4741f83,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-8bff9095-44ea-4b04-967f-1f29316ccf97,DISK], DatanodeInfoWithStorage[127.0.0.1:42570,DS-988c9de0-bc78-45a2-a21e-40a5b1e4ed0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774770670-172.17.0.8-1597104480387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-6e3e3414-0a52-4d96-ba1d-1ff7088c6487,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-480836d2-12f5-40e9-acde-71008d66b2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-7989bc63-01fe-451f-a241-458870cfa502,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-90daeebc-4544-4b4f-88ce-8ec07aef6aed,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-5be239f7-7ade-4bd0-adfb-2740d22f6a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-bf267602-1e00-420d-ab4a-e965c7eb46ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-5219a412-5cdf-470e-80f0-aae6498f23f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-f6a67fa0-b2e7-4a44-98e7-bee3319aaa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774770670-172.17.0.8-1597104480387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36368,DS-6e3e3414-0a52-4d96-ba1d-1ff7088c6487,DISK], DatanodeInfoWithStorage[127.0.0.1:42791,DS-480836d2-12f5-40e9-acde-71008d66b2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-7989bc63-01fe-451f-a241-458870cfa502,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-90daeebc-4544-4b4f-88ce-8ec07aef6aed,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-5be239f7-7ade-4bd0-adfb-2740d22f6a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-bf267602-1e00-420d-ab4a-e965c7eb46ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-5219a412-5cdf-470e-80f0-aae6498f23f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-f6a67fa0-b2e7-4a44-98e7-bee3319aaa66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617876823-172.17.0.8-1597105345481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-33643e2a-06de-4171-9353-e131b088b092,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-94d71eb6-57cf-40be-8e2b-034df64fec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-593631da-55ec-42a0-a591-207538525581,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-a27761e8-59cf-4352-925d-43588e22edb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-f0e513e8-f565-4c80-b04f-ff02d1596732,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-445946f1-5bd6-4c59-bdc7-f09f9c9a6ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-483ae758-8084-4b55-9e72-55c31a14e0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-86571017-ad6f-4a53-95b8-5b78e8957f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617876823-172.17.0.8-1597105345481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37592,DS-33643e2a-06de-4171-9353-e131b088b092,DISK], DatanodeInfoWithStorage[127.0.0.1:42192,DS-94d71eb6-57cf-40be-8e2b-034df64fec4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-593631da-55ec-42a0-a591-207538525581,DISK], DatanodeInfoWithStorage[127.0.0.1:35834,DS-a27761e8-59cf-4352-925d-43588e22edb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-f0e513e8-f565-4c80-b04f-ff02d1596732,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-445946f1-5bd6-4c59-bdc7-f09f9c9a6ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-483ae758-8084-4b55-9e72-55c31a14e0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-86571017-ad6f-4a53-95b8-5b78e8957f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450213550-172.17.0.8-1597105382631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-fdaca1bc-53f5-4228-be08-0b32addd3066,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-fe2b2967-9abd-44e0-a10a-c37946701489,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-098c403c-823f-4389-a8e9-3ab0365c5a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-45a4739a-89c3-4252-9644-9e22ff3cd319,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-f51a0dd1-55a2-429d-8921-e8144a9e1a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-ed7a1e2d-3ecc-45fa-b895-e53e50f75a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-9de7590b-fe3d-477b-9505-2c6f3662d683,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-f8b80184-c639-4bcb-9ef9-902f2102a51d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450213550-172.17.0.8-1597105382631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34344,DS-fdaca1bc-53f5-4228-be08-0b32addd3066,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-fe2b2967-9abd-44e0-a10a-c37946701489,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-098c403c-823f-4389-a8e9-3ab0365c5a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-45a4739a-89c3-4252-9644-9e22ff3cd319,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-f51a0dd1-55a2-429d-8921-e8144a9e1a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-ed7a1e2d-3ecc-45fa-b895-e53e50f75a16,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-9de7590b-fe3d-477b-9505-2c6f3662d683,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-f8b80184-c639-4bcb-9ef9-902f2102a51d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950314187-172.17.0.8-1597105461963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-0d42b387-207d-436d-b2d7-a2c66fd125e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-ea92b2d0-8d3e-4c9c-bbee-eaa07718a474,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-3bd3b075-a11c-457a-b4c0-0ea8eaede9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-53f95202-1d1a-48a0-bf40-1c2115025f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-980408d5-2848-4afe-aeff-8214d2e13d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-49f19e08-1550-46cc-b772-3f0ac6bc1b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-09398f36-0146-4a69-984e-3db5e707d228,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-0310d859-b6f1-4f99-b790-4b58fef38b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950314187-172.17.0.8-1597105461963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-0d42b387-207d-436d-b2d7-a2c66fd125e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-ea92b2d0-8d3e-4c9c-bbee-eaa07718a474,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-3bd3b075-a11c-457a-b4c0-0ea8eaede9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-53f95202-1d1a-48a0-bf40-1c2115025f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-980408d5-2848-4afe-aeff-8214d2e13d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-49f19e08-1550-46cc-b772-3f0ac6bc1b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-09398f36-0146-4a69-984e-3db5e707d228,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-0310d859-b6f1-4f99-b790-4b58fef38b9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431546618-172.17.0.8-1597106055455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-2118e77b-9d9c-4eb9-8a43-0e97ca689e12,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-4e9f2a1c-5ec0-4b4d-8fff-4a16ecb508e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-82bc405a-a4bd-4dad-b34e-1ff5ac039fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-cbfa6149-2776-4f7f-b7da-49848349c719,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-70d9ea14-dea2-4d42-a74d-576ea50dd078,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-d7e6f2da-4bee-4ff6-97a7-48fe4ec6a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-5d84c13d-7bee-4cff-a40d-cf6d26b61c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-bf6f3c1d-c712-44c0-806b-c5a0422b361c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431546618-172.17.0.8-1597106055455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45946,DS-2118e77b-9d9c-4eb9-8a43-0e97ca689e12,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-4e9f2a1c-5ec0-4b4d-8fff-4a16ecb508e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-82bc405a-a4bd-4dad-b34e-1ff5ac039fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-cbfa6149-2776-4f7f-b7da-49848349c719,DISK], DatanodeInfoWithStorage[127.0.0.1:44796,DS-70d9ea14-dea2-4d42-a74d-576ea50dd078,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-d7e6f2da-4bee-4ff6-97a7-48fe4ec6a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-5d84c13d-7bee-4cff-a40d-cf6d26b61c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-bf6f3c1d-c712-44c0-806b-c5a0422b361c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065576575-172.17.0.8-1597106547052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38016,DS-b411db3c-2a8f-488f-a156-36cfc4922118,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-0aff2b02-185b-434d-92a3-8d44262eb1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-78d93742-ead7-4095-85ab-1b229fc70baa,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-53a78260-40a3-40a0-9560-1f8c86baaa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-4bfb5eab-d0fa-40e7-b3aa-dad69adae419,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-7bdfafa4-7196-41cc-ae0d-8582d1975912,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-3948bf35-6c3b-4b9b-8929-41b71a03fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-297126ab-4797-4697-b9bf-bed86d15cae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065576575-172.17.0.8-1597106547052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38016,DS-b411db3c-2a8f-488f-a156-36cfc4922118,DISK], DatanodeInfoWithStorage[127.0.0.1:41796,DS-0aff2b02-185b-434d-92a3-8d44262eb1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-78d93742-ead7-4095-85ab-1b229fc70baa,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-53a78260-40a3-40a0-9560-1f8c86baaa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-4bfb5eab-d0fa-40e7-b3aa-dad69adae419,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-7bdfafa4-7196-41cc-ae0d-8582d1975912,DISK], DatanodeInfoWithStorage[127.0.0.1:39731,DS-3948bf35-6c3b-4b9b-8929-41b71a03fb27,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-297126ab-4797-4697-b9bf-bed86d15cae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580427474-172.17.0.8-1597107790314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-a6ab7c75-0a82-47c7-aa93-3644e0eefe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-1c8af395-39ca-4e62-b187-5f5442fae795,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-bb99b0f1-4af5-41b4-8386-b8c1c9e80421,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-05da2539-f4e6-4d1e-a5b6-9f982be6b6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-6c6f4500-f7fa-4baa-bbaa-8574dad99d70,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-13f658f9-1017-4365-a5f1-e5492da75089,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-acaa55ad-7185-4832-a5a6-3b02fe502f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-6f8da825-8d11-49ef-a6bc-13ce55d327c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580427474-172.17.0.8-1597107790314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33159,DS-a6ab7c75-0a82-47c7-aa93-3644e0eefe9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-1c8af395-39ca-4e62-b187-5f5442fae795,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-bb99b0f1-4af5-41b4-8386-b8c1c9e80421,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-05da2539-f4e6-4d1e-a5b6-9f982be6b6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-6c6f4500-f7fa-4baa-bbaa-8574dad99d70,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-13f658f9-1017-4365-a5f1-e5492da75089,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-acaa55ad-7185-4832-a5a6-3b02fe502f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-6f8da825-8d11-49ef-a6bc-13ce55d327c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768593253-172.17.0.8-1597107933757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-e6dea0ed-d140-4e45-8714-5572d642e15b,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-ff95b1e1-beb9-4651-9edd-f2c7c1ab2b97,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-b7b7901a-42f9-41a8-a7b1-cee24413f778,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-856ecd29-84b1-4597-920d-5777672624fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-08934400-067e-42dc-b1cd-2749eab2fbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-3cc0c6a3-b604-4d55-a9f6-9e67f938455e,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-0f0bd23b-d025-448e-984f-e677dc33a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-ab1739c1-fd2e-43b6-ac10-abfa459445f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768593253-172.17.0.8-1597107933757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-e6dea0ed-d140-4e45-8714-5572d642e15b,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-ff95b1e1-beb9-4651-9edd-f2c7c1ab2b97,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-b7b7901a-42f9-41a8-a7b1-cee24413f778,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-856ecd29-84b1-4597-920d-5777672624fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-08934400-067e-42dc-b1cd-2749eab2fbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-3cc0c6a3-b604-4d55-a9f6-9e67f938455e,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-0f0bd23b-d025-448e-984f-e677dc33a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-ab1739c1-fd2e-43b6-ac10-abfa459445f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579891635-172.17.0.8-1597108161615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46542,DS-ece6b4a3-b5a4-487d-b432-a7dace0a38ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-6355c086-7393-4454-96ce-7640e0ed888f,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-a57d8b76-62f7-43bf-941e-600c9efc0ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-1aecdf2f-e78d-435a-b6ba-5755fe40d1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-bffe7fda-5021-4b35-bb2c-c07cb9fd86a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-aea5d7bf-abbf-43b0-8405-b2852ce4af9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-88d9dc12-0173-4fe3-8c60-d7952e86327e,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-fe38af49-55b8-4bba-b8f3-bf273675614d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579891635-172.17.0.8-1597108161615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46542,DS-ece6b4a3-b5a4-487d-b432-a7dace0a38ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-6355c086-7393-4454-96ce-7640e0ed888f,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-a57d8b76-62f7-43bf-941e-600c9efc0ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-1aecdf2f-e78d-435a-b6ba-5755fe40d1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-bffe7fda-5021-4b35-bb2c-c07cb9fd86a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-aea5d7bf-abbf-43b0-8405-b2852ce4af9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34190,DS-88d9dc12-0173-4fe3-8c60-d7952e86327e,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-fe38af49-55b8-4bba-b8f3-bf273675614d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769542775-172.17.0.8-1597108435848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-46430bdb-7b7c-4407-985e-79f7cea97cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-c325bf90-40bb-4099-b63b-957d6f6ffe40,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-b6b5f2c7-55e2-446d-8bae-c5e0fd28b357,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-ea4c2c72-6ac9-494b-8dd0-b70769dbec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-1ae5ceb3-f883-4d31-ae4e-b47497100aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-9952d7a6-b618-4406-930b-04fe7a5a7d53,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-997e351c-55f9-48bb-a972-a19d789b8841,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-d4527468-78aa-4bc9-8450-2ecaee73db86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769542775-172.17.0.8-1597108435848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46290,DS-46430bdb-7b7c-4407-985e-79f7cea97cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-c325bf90-40bb-4099-b63b-957d6f6ffe40,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-b6b5f2c7-55e2-446d-8bae-c5e0fd28b357,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-ea4c2c72-6ac9-494b-8dd0-b70769dbec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-1ae5ceb3-f883-4d31-ae4e-b47497100aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-9952d7a6-b618-4406-930b-04fe7a5a7d53,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-997e351c-55f9-48bb-a972-a19d789b8841,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-d4527468-78aa-4bc9-8450-2ecaee73db86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.buffer.size
component: hdfs:NameNode
v1: 8192
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662909225-172.17.0.8-1597109270711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-10fae7e0-4f78-4555-b131-289bec7bc802,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-d129cfd0-1b7b-490f-85fc-36aa71788b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-cd0c6f05-17ad-42d5-a280-e405b170e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-1998f902-bb77-4c95-9e7a-b68d37aca18c,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-f1e8b781-5149-496c-be7c-ad02a49980a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-d4d65088-0bd3-40d3-a883-20893670fbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-371d918d-294b-48e4-8625-e188a3ad8285,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-027dda07-befa-4cd4-b9d1-9f5ad12979c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-662909225-172.17.0.8-1597109270711:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34391,DS-10fae7e0-4f78-4555-b131-289bec7bc802,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-d129cfd0-1b7b-490f-85fc-36aa71788b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-cd0c6f05-17ad-42d5-a280-e405b170e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-1998f902-bb77-4c95-9e7a-b68d37aca18c,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-f1e8b781-5149-496c-be7c-ad02a49980a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-d4d65088-0bd3-40d3-a883-20893670fbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-371d918d-294b-48e4-8625-e188a3ad8285,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-027dda07-befa-4cd4-b9d1-9f5ad12979c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6675
