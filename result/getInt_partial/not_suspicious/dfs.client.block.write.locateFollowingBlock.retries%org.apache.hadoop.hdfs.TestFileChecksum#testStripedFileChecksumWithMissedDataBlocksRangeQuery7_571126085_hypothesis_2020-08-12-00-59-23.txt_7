reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864413833-172.17.0.12-1597194429141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-0b3110b2-2ac8-422e-83ff-7f8dc602e143,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-0e9c98a1-8e93-4072-a56c-408ed20e5453,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-71de09d1-c650-4d80-9ec3-b9dada7376c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-a5f8d563-2584-4b5d-8d63-f07a907ee8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-1943070b-b5da-4f22-b107-2221144fad62,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-8f342c03-f177-4b41-a55d-75c3c0e26f90,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-d7724167-7c57-4804-adaa-a4210ae60f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-233340a7-7539-4655-a92d-0a20ca6d0ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864413833-172.17.0.12-1597194429141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-0b3110b2-2ac8-422e-83ff-7f8dc602e143,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-0e9c98a1-8e93-4072-a56c-408ed20e5453,DISK], DatanodeInfoWithStorage[127.0.0.1:40324,DS-71de09d1-c650-4d80-9ec3-b9dada7376c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-a5f8d563-2584-4b5d-8d63-f07a907ee8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-1943070b-b5da-4f22-b107-2221144fad62,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-8f342c03-f177-4b41-a55d-75c3c0e26f90,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-d7724167-7c57-4804-adaa-a4210ae60f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35148,DS-233340a7-7539-4655-a92d-0a20ca6d0ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643927779-172.17.0.12-1597194540876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33549,DS-89002d22-b6f0-4dd9-970e-10ab9e49237f,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-23db7331-20c2-4a87-83c6-7b86eaf4c23c,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-56bc2aa7-7a3f-4da2-ae7d-3b8fa1070ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-2a135eff-de94-4d06-b6ea-92123e2862bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-20400d2e-a5eb-4887-b7d3-c2011926fd72,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-b8c519ab-e297-46f3-8dd1-8ac3e999fda2,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-d603e68a-21b5-4d24-97e1-e79e838d179a,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-1ec434af-338c-41d4-84a0-1be5301fdf34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1643927779-172.17.0.12-1597194540876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33549,DS-89002d22-b6f0-4dd9-970e-10ab9e49237f,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-23db7331-20c2-4a87-83c6-7b86eaf4c23c,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-56bc2aa7-7a3f-4da2-ae7d-3b8fa1070ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-2a135eff-de94-4d06-b6ea-92123e2862bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-20400d2e-a5eb-4887-b7d3-c2011926fd72,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-b8c519ab-e297-46f3-8dd1-8ac3e999fda2,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-d603e68a-21b5-4d24-97e1-e79e838d179a,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-1ec434af-338c-41d4-84a0-1be5301fdf34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815836274-172.17.0.12-1597194607324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-6fb334d6-1653-40e0-bbc3-81ebabc6e610,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-e99e1117-5ea5-4833-9b1a-0425c94e9264,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-17b3a130-c06a-41f1-a430-3e22fb6a2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-b966d2ed-d4a7-4cb8-a284-4bee3afec2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-ca5c1015-61e2-4f33-a899-09f5fefdd263,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-67fd3d99-f1ed-4f2a-9d35-c4c85ea3b657,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-501624bf-4fcc-43f7-9c88-345bf20cb661,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-6027f02e-e6d1-465b-b80e-0b5d7059a640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815836274-172.17.0.12-1597194607324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45043,DS-6fb334d6-1653-40e0-bbc3-81ebabc6e610,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-e99e1117-5ea5-4833-9b1a-0425c94e9264,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-17b3a130-c06a-41f1-a430-3e22fb6a2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-b966d2ed-d4a7-4cb8-a284-4bee3afec2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-ca5c1015-61e2-4f33-a899-09f5fefdd263,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-67fd3d99-f1ed-4f2a-9d35-c4c85ea3b657,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-501624bf-4fcc-43f7-9c88-345bf20cb661,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-6027f02e-e6d1-465b-b80e-0b5d7059a640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748263504-172.17.0.12-1597194715407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42647,DS-ab5e2b96-27e4-4fa9-963e-9c0e93c490de,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-4993a365-cefc-43ee-af5a-652e77aaa66f,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-6649fb9e-b884-4b81-8857-304fc28fb1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-c05ce089-8743-4850-a918-78f4c4ac9ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-5ef56b8a-27a0-4273-82af-8e347d0eb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-1193c1e5-e006-4c88-9a98-9d6066c21353,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-08e8faa9-67ce-4ed7-beb7-8ab4fcbad1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-3d27980a-e82a-496a-9758-b216fe7321fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748263504-172.17.0.12-1597194715407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42647,DS-ab5e2b96-27e4-4fa9-963e-9c0e93c490de,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-4993a365-cefc-43ee-af5a-652e77aaa66f,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-6649fb9e-b884-4b81-8857-304fc28fb1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-c05ce089-8743-4850-a918-78f4c4ac9ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:37503,DS-5ef56b8a-27a0-4273-82af-8e347d0eb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-1193c1e5-e006-4c88-9a98-9d6066c21353,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-08e8faa9-67ce-4ed7-beb7-8ab4fcbad1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-3d27980a-e82a-496a-9758-b216fe7321fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424043821-172.17.0.12-1597194787589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-ce85b406-f53a-409c-9a1e-87cad1016801,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-6511a3e4-fb4f-4ba7-a4b6-2541a150cd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-a84cc8a9-4486-47ee-b166-2421fbd51a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-ac80d3cf-90ec-472b-8acf-4a8b1d8907ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-b2945e8e-e5a9-4fbb-8905-aef1a50e4e06,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-915ba4c3-21a5-4a59-ad3d-84008fb765a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-58cfaaaf-93a0-414d-96e7-ada2f0bd02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-d91b72fb-f1ae-44d2-92b0-0a4dd79decee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424043821-172.17.0.12-1597194787589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44218,DS-ce85b406-f53a-409c-9a1e-87cad1016801,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-6511a3e4-fb4f-4ba7-a4b6-2541a150cd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-a84cc8a9-4486-47ee-b166-2421fbd51a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-ac80d3cf-90ec-472b-8acf-4a8b1d8907ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35748,DS-b2945e8e-e5a9-4fbb-8905-aef1a50e4e06,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-915ba4c3-21a5-4a59-ad3d-84008fb765a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42941,DS-58cfaaaf-93a0-414d-96e7-ada2f0bd02b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-d91b72fb-f1ae-44d2-92b0-0a4dd79decee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285601176-172.17.0.12-1597194828919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-6293e854-e781-4554-b13b-45cf1bdd1a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-a821d528-139b-44be-8a23-b3781d5f8293,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-345309d6-c429-4d80-b721-a603756cbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-77ffd00b-5310-473d-98dc-931790907123,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-143e168d-05e8-49c4-916a-117907dde6df,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-4cebf4da-c232-4f21-a702-b83b4c1d73f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-3e2c0afa-5d7a-4543-ae18-7852a404b425,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-46fd0a44-be34-42fe-a409-a8784f7b8323,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285601176-172.17.0.12-1597194828919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-6293e854-e781-4554-b13b-45cf1bdd1a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-a821d528-139b-44be-8a23-b3781d5f8293,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-345309d6-c429-4d80-b721-a603756cbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-77ffd00b-5310-473d-98dc-931790907123,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-143e168d-05e8-49c4-916a-117907dde6df,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-4cebf4da-c232-4f21-a702-b83b4c1d73f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-3e2c0afa-5d7a-4543-ae18-7852a404b425,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-46fd0a44-be34-42fe-a409-a8784f7b8323,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728311547-172.17.0.12-1597194962546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-bc9e4bf2-71c5-4f2d-9fc2-26a87d195507,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-29859768-5cb2-4fb8-ab63-8ef13241a3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-bca90885-2805-42f7-8148-1eb7d6afad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-5fad3415-052e-44f6-82ef-ca13861b3e87,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-5b5f3ee1-4eea-4600-90b7-aa60d8a2f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-0465b6cf-2e6a-4aad-b049-2d70068da4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-ff1cc4dd-2d95-400d-a777-5113521ba148,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-2437c31a-7114-48f8-8e64-93cb9dbde2ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728311547-172.17.0.12-1597194962546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43618,DS-bc9e4bf2-71c5-4f2d-9fc2-26a87d195507,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-29859768-5cb2-4fb8-ab63-8ef13241a3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-bca90885-2805-42f7-8148-1eb7d6afad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-5fad3415-052e-44f6-82ef-ca13861b3e87,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-5b5f3ee1-4eea-4600-90b7-aa60d8a2f4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38813,DS-0465b6cf-2e6a-4aad-b049-2d70068da4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-ff1cc4dd-2d95-400d-a777-5113521ba148,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-2437c31a-7114-48f8-8e64-93cb9dbde2ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571091450-172.17.0.12-1597195075590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-a2f4f938-adb4-4f2b-a053-aae95086a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-3600bd77-23a9-4e06-8269-4ab8948f5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-3844ed74-b832-4068-a211-f195a54c7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-d3ef2450-85ee-403d-9fee-f6a9e38da12a,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-ca8df2aa-1336-46f2-854a-eef74a59ec25,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-47f875e8-294e-4f13-b29b-76fb519c4c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-5ae52529-0b16-4457-acc3-10d0191f7157,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-bea448ab-c239-41e0-ac26-f8d10cdca36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571091450-172.17.0.12-1597195075590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-a2f4f938-adb4-4f2b-a053-aae95086a3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-3600bd77-23a9-4e06-8269-4ab8948f5bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-3844ed74-b832-4068-a211-f195a54c7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-d3ef2450-85ee-403d-9fee-f6a9e38da12a,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-ca8df2aa-1336-46f2-854a-eef74a59ec25,DISK], DatanodeInfoWithStorage[127.0.0.1:42022,DS-47f875e8-294e-4f13-b29b-76fb519c4c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-5ae52529-0b16-4457-acc3-10d0191f7157,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-bea448ab-c239-41e0-ac26-f8d10cdca36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063267541-172.17.0.12-1597195449861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-9216bc0c-2ff8-4223-b9ca-3aa02fbd06a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-de697492-6f2a-429d-9b28-17e87cd82eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-af6a57ce-2429-4d19-af57-8770ec3a8522,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-acb3ea62-9c6f-4e1a-906d-c8a04b27ef96,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-fd95547f-0480-4db3-b21b-9b8033b462d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-f8fe8d3b-1593-4d8c-9b6a-11750b44b89a,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-6e53ce95-772a-4c63-ad9d-675ff6867609,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-fdd991ec-3c20-451d-b3bd-9ed562139573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2063267541-172.17.0.12-1597195449861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-9216bc0c-2ff8-4223-b9ca-3aa02fbd06a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-de697492-6f2a-429d-9b28-17e87cd82eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-af6a57ce-2429-4d19-af57-8770ec3a8522,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-acb3ea62-9c6f-4e1a-906d-c8a04b27ef96,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-fd95547f-0480-4db3-b21b-9b8033b462d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-f8fe8d3b-1593-4d8c-9b6a-11750b44b89a,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-6e53ce95-772a-4c63-ad9d-675ff6867609,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-fdd991ec-3c20-451d-b3bd-9ed562139573,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978904749-172.17.0.12-1597195483394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35398,DS-e020af99-0003-4a2e-b637-9a88084627a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-ae67448a-7639-4230-8d2e-ece53a6ff0af,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-ac65e5ba-e397-4a92-999d-6e5240c225d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-04970029-97ec-4325-a3ba-6da60cfabead,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-606759fa-0ed9-4ade-998f-5dd018735445,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-be352b69-5a42-4fe2-8dc9-f81a143965b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-fc161ac9-ec48-42c8-8aa6-a82043f2010b,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-293d0701-c558-4c55-9338-0c6760d77e40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978904749-172.17.0.12-1597195483394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35398,DS-e020af99-0003-4a2e-b637-9a88084627a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-ae67448a-7639-4230-8d2e-ece53a6ff0af,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-ac65e5ba-e397-4a92-999d-6e5240c225d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-04970029-97ec-4325-a3ba-6da60cfabead,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-606759fa-0ed9-4ade-998f-5dd018735445,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-be352b69-5a42-4fe2-8dc9-f81a143965b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-fc161ac9-ec48-42c8-8aa6-a82043f2010b,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-293d0701-c558-4c55-9338-0c6760d77e40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747832021-172.17.0.12-1597195548030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-edace3b6-b92f-47c6-995f-5032911a6869,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-0b3fd57e-885c-40d5-8c83-eef898265608,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-a4361ed8-ced3-45ec-a770-dd915108b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-5accd2d7-c0c4-4273-9bf2-eb083a182424,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-2e9968aa-1020-47fd-a479-d9065053b292,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-57ec5608-0e5e-40d4-a917-5971b41d7683,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-bee87344-a3f1-4791-bcc3-3199bd277a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-22ca50a2-260a-4bc8-9588-9423a53a10e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747832021-172.17.0.12-1597195548030:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42117,DS-edace3b6-b92f-47c6-995f-5032911a6869,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-0b3fd57e-885c-40d5-8c83-eef898265608,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-a4361ed8-ced3-45ec-a770-dd915108b2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-5accd2d7-c0c4-4273-9bf2-eb083a182424,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-2e9968aa-1020-47fd-a479-d9065053b292,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-57ec5608-0e5e-40d4-a917-5971b41d7683,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-bee87344-a3f1-4791-bcc3-3199bd277a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-22ca50a2-260a-4bc8-9588-9423a53a10e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197747817-172.17.0.12-1597195811880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35907,DS-1a3ca049-371e-4d46-b0ef-ca6e6ed65618,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-79e682e3-f1cc-4d84-864f-b40dbdc46a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-f7dbb6a5-ca99-4890-a1f8-8132496ac012,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-4156ddff-12f2-4caa-b9ed-ee43311c2a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-94605483-9d38-4d29-a49d-b11df306d8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-ad2e3841-79a7-4488-bc3d-173e2e5b3c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-82576aaa-6eb0-4a86-8d5a-5a53a5d1b5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-1be7972c-a459-4008-950c-81e020f060bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1197747817-172.17.0.12-1597195811880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35907,DS-1a3ca049-371e-4d46-b0ef-ca6e6ed65618,DISK], DatanodeInfoWithStorage[127.0.0.1:35428,DS-79e682e3-f1cc-4d84-864f-b40dbdc46a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-f7dbb6a5-ca99-4890-a1f8-8132496ac012,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-4156ddff-12f2-4caa-b9ed-ee43311c2a13,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-94605483-9d38-4d29-a49d-b11df306d8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-ad2e3841-79a7-4488-bc3d-173e2e5b3c61,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-82576aaa-6eb0-4a86-8d5a-5a53a5d1b5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-1be7972c-a459-4008-950c-81e020f060bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543828482-172.17.0.12-1597196052523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-433a0945-7735-4f33-b10b-aa73d280fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-4c3f224f-0c56-4dcf-b63a-3e149357eb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-708fb8fc-4aff-4e40-8ebd-80755d9ce53d,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-df12be58-356d-4d36-aec7-7eb336fefd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-82a73d40-ad83-4f6b-96ac-a4daa865bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-513d1bb7-db53-48b1-a035-95407ba8da3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-aa0841a3-631a-40e1-9ca5-b22c80e0d553,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-5d712344-eb02-4d40-a3d3-ed7ce88f4dbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543828482-172.17.0.12-1597196052523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39870,DS-433a0945-7735-4f33-b10b-aa73d280fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-4c3f224f-0c56-4dcf-b63a-3e149357eb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-708fb8fc-4aff-4e40-8ebd-80755d9ce53d,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-df12be58-356d-4d36-aec7-7eb336fefd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-82a73d40-ad83-4f6b-96ac-a4daa865bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-513d1bb7-db53-48b1-a035-95407ba8da3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-aa0841a3-631a-40e1-9ca5-b22c80e0d553,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-5d712344-eb02-4d40-a3d3-ed7ce88f4dbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120555032-172.17.0.12-1597196136811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42862,DS-6e245b73-d9da-47c2-ad08-3e4a20704229,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-89e9904a-3ba8-4ae9-bce2-47c656392639,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-2d7a47a7-39da-4680-b50e-ab2ace58836b,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-91ced378-0945-41d7-84b6-72981189b186,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-01896834-50e3-4f86-8ff1-2decd74ef092,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-ba335971-95d9-42a7-9247-12ef46c6d999,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-4bb30b74-95d2-4e27-9b50-6a7889356221,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-2bebdea5-e8a8-49df-bed6-96d39e224d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120555032-172.17.0.12-1597196136811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42862,DS-6e245b73-d9da-47c2-ad08-3e4a20704229,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-89e9904a-3ba8-4ae9-bce2-47c656392639,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-2d7a47a7-39da-4680-b50e-ab2ace58836b,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-91ced378-0945-41d7-84b6-72981189b186,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-01896834-50e3-4f86-8ff1-2decd74ef092,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-ba335971-95d9-42a7-9247-12ef46c6d999,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-4bb30b74-95d2-4e27-9b50-6a7889356221,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-2bebdea5-e8a8-49df-bed6-96d39e224d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110343428-172.17.0.12-1597196204989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44928,DS-6c53c109-9460-4de4-9882-56ddaa6e40c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-7a609a06-57c9-4223-a6a9-059054e75b60,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-c79aaadb-f3a8-483a-9793-7b0c32121707,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-1a644904-aaf5-43dc-968d-a45861a56966,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-e55396dc-2014-4b1d-9435-4e7dfe284322,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-2f641185-6328-44cb-96ed-7bc519addfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-b562fb1a-1902-4562-85ee-968c51d069c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-993c5507-b274-4c85-9460-67362f3cbaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110343428-172.17.0.12-1597196204989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44928,DS-6c53c109-9460-4de4-9882-56ddaa6e40c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-7a609a06-57c9-4223-a6a9-059054e75b60,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-c79aaadb-f3a8-483a-9793-7b0c32121707,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-1a644904-aaf5-43dc-968d-a45861a56966,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-e55396dc-2014-4b1d-9435-4e7dfe284322,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-2f641185-6328-44cb-96ed-7bc519addfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-b562fb1a-1902-4562-85ee-968c51d069c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-993c5507-b274-4c85-9460-67362f3cbaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677085496-172.17.0.12-1597196460320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-087aaade-1ce4-4c92-ae51-33b10efc9439,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-2698e206-e7af-442d-8e48-67e4c58b48cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-bc3206c7-dd4a-42ed-82fe-2e9127e847f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-dd586883-d38b-400e-a522-ff5735dbe93f,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-7b481aa4-b2c8-4086-949c-b7e30ba54c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-fa998eac-4bb4-45de-bed7-8aa9d11385ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-faa444be-3c27-440d-aeba-82963b3c8e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-e5d31a04-0c89-40e3-9528-2572bc5d799a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677085496-172.17.0.12-1597196460320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-087aaade-1ce4-4c92-ae51-33b10efc9439,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-2698e206-e7af-442d-8e48-67e4c58b48cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-bc3206c7-dd4a-42ed-82fe-2e9127e847f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-dd586883-d38b-400e-a522-ff5735dbe93f,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-7b481aa4-b2c8-4086-949c-b7e30ba54c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-fa998eac-4bb4-45de-bed7-8aa9d11385ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-faa444be-3c27-440d-aeba-82963b3c8e93,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-e5d31a04-0c89-40e3-9528-2572bc5d799a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169954905-172.17.0.12-1597196494107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-8fc6f1be-ad9a-4975-9b1c-6b8102016170,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-59c16149-536d-4900-8b2b-6a4cec1c7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-43467180-fb43-43f3-b967-806462fda70f,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-06f5129e-afcc-4ebf-9779-0d679ce50c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-f17d4bf1-eb09-4712-9f49-0436d1e4ff7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-4ce7d553-7b2f-42e4-a849-837a8a299a18,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-45b5f50f-b6a9-4873-8726-e010528c5694,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-67b769a9-0bd7-463a-b2e7-7e9c3a2cf5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169954905-172.17.0.12-1597196494107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34375,DS-8fc6f1be-ad9a-4975-9b1c-6b8102016170,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-59c16149-536d-4900-8b2b-6a4cec1c7fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-43467180-fb43-43f3-b967-806462fda70f,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-06f5129e-afcc-4ebf-9779-0d679ce50c35,DISK], DatanodeInfoWithStorage[127.0.0.1:36044,DS-f17d4bf1-eb09-4712-9f49-0436d1e4ff7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-4ce7d553-7b2f-42e4-a849-837a8a299a18,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-45b5f50f-b6a9-4873-8726-e010528c5694,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-67b769a9-0bd7-463a-b2e7-7e9c3a2cf5cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915636584-172.17.0.12-1597196726497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-af649108-21c9-497a-b3aa-372d83c6cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-38a5c661-42c1-4e94-892a-ee42d860edb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-1872b2b4-b6a7-4bda-8eb7-cf09f2ba489c,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-bb8d995a-9661-470c-966a-ab14599871d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-28ab2e71-acc8-4823-91e7-bb0398a1fe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-013a252c-14f3-4064-bba3-4a160f592e51,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-65635db1-10e1-4f7b-af48-9cf635a1cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-19440313-10d8-4231-922d-4c82b9a68b0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915636584-172.17.0.12-1597196726497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44630,DS-af649108-21c9-497a-b3aa-372d83c6cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-38a5c661-42c1-4e94-892a-ee42d860edb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-1872b2b4-b6a7-4bda-8eb7-cf09f2ba489c,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-bb8d995a-9661-470c-966a-ab14599871d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-28ab2e71-acc8-4823-91e7-bb0398a1fe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-013a252c-14f3-4064-bba3-4a160f592e51,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-65635db1-10e1-4f7b-af48-9cf635a1cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-19440313-10d8-4231-922d-4c82b9a68b0b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564368307-172.17.0.12-1597197065009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35042,DS-c79faa33-c18c-4402-8d72-fba9164ae780,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-d7b4b4c4-c394-48c2-9755-3637ee9559d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-aa3a2817-80e6-4e9b-853b-7dea51bb5640,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-5a659d01-2143-4eeb-bedd-3f04d2841570,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-313b9ad3-286e-4054-b610-fea4d396df80,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-fd70646f-41ac-40ff-b787-deb348beba94,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-fc4d965a-edd0-4daf-bc26-a00c889fb887,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-ef2313bf-8565-48e0-8b21-1cd864462af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564368307-172.17.0.12-1597197065009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35042,DS-c79faa33-c18c-4402-8d72-fba9164ae780,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-d7b4b4c4-c394-48c2-9755-3637ee9559d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-aa3a2817-80e6-4e9b-853b-7dea51bb5640,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-5a659d01-2143-4eeb-bedd-3f04d2841570,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-313b9ad3-286e-4054-b610-fea4d396df80,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-fd70646f-41ac-40ff-b787-deb348beba94,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-fc4d965a-edd0-4daf-bc26-a00c889fb887,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-ef2313bf-8565-48e0-8b21-1cd864462af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226244623-172.17.0.12-1597197182130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41482,DS-1e6e2ff1-b7a5-4f3f-8a1e-815517e31167,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-45ce392e-45fb-4f9f-bfb9-37bd455cac70,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-748c4184-0d2b-45e9-89ce-440103ff7ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-77878bc4-e13c-4db6-81d8-9c2bfb7d86f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-39c67af2-076d-4c4b-bb72-ccb75f091340,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-f3d3abe4-1329-498a-ab12-b22ec1d189b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-52d299df-e895-4beb-b2be-e0b58fa357f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-17fb07a5-442c-47c9-aa39-b8a17ea1588c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-226244623-172.17.0.12-1597197182130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41482,DS-1e6e2ff1-b7a5-4f3f-8a1e-815517e31167,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-45ce392e-45fb-4f9f-bfb9-37bd455cac70,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-748c4184-0d2b-45e9-89ce-440103ff7ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38455,DS-77878bc4-e13c-4db6-81d8-9c2bfb7d86f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-39c67af2-076d-4c4b-bb72-ccb75f091340,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-f3d3abe4-1329-498a-ab12-b22ec1d189b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-52d299df-e895-4beb-b2be-e0b58fa357f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-17fb07a5-442c-47c9-aa39-b8a17ea1588c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222528324-172.17.0.12-1597197287532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-187ed63b-a697-4a87-a950-cab5ba01e586,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-b263c50f-fe74-4048-95b9-26cb0ade38d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-26dbe093-37d9-41c7-ba08-4c1790614d24,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-8407c437-6510-404a-b89c-9675f8bc6981,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-32812d2b-4ee5-4908-91ee-22ffd961b7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-9e0cb4e9-1167-472c-9487-8bd11dd2d64e,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-7b28539c-b01f-4429-afca-fd262f0d3db3,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-59f4a836-c161-4e47-b5f1-b83feed97fc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222528324-172.17.0.12-1597197287532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37522,DS-187ed63b-a697-4a87-a950-cab5ba01e586,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-b263c50f-fe74-4048-95b9-26cb0ade38d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-26dbe093-37d9-41c7-ba08-4c1790614d24,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-8407c437-6510-404a-b89c-9675f8bc6981,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-32812d2b-4ee5-4908-91ee-22ffd961b7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-9e0cb4e9-1167-472c-9487-8bd11dd2d64e,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-7b28539c-b01f-4429-afca-fd262f0d3db3,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-59f4a836-c161-4e47-b5f1-b83feed97fc9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512316232-172.17.0.12-1597197512529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-df8d218c-07f6-4c18-b917-abb32eb8f16d,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-c1c0950e-cdb1-4780-8131-bb27d8ba1f03,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-0f63d126-95b5-4f1c-a3e0-664f7d2e868f,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-7b6e9731-ec4b-4e1d-98e4-55c60192fc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-8accff11-9f9b-465f-81dc-421ea912236b,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-e885d15c-5c2e-491f-a61c-e1bd92d3b035,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-a29b6280-5ccb-499c-a06a-2b2ce94bc186,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-283589ac-6204-42ad-91ac-0c5aedf05b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512316232-172.17.0.12-1597197512529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44617,DS-df8d218c-07f6-4c18-b917-abb32eb8f16d,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-c1c0950e-cdb1-4780-8131-bb27d8ba1f03,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-0f63d126-95b5-4f1c-a3e0-664f7d2e868f,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-7b6e9731-ec4b-4e1d-98e4-55c60192fc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-8accff11-9f9b-465f-81dc-421ea912236b,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-e885d15c-5c2e-491f-a61c-e1bd92d3b035,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-a29b6280-5ccb-499c-a06a-2b2ce94bc186,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-283589ac-6204-42ad-91ac-0c5aedf05b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390010359-172.17.0.12-1597197553216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35070,DS-05a595e0-5de0-4106-8cfb-ab8edbde0267,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-622bbedc-1e16-4106-b35e-1fe7c6fcea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-c893f314-1a84-45ba-9305-d015fbfddd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-1b3d0cee-42b0-4d7c-a264-558fd4bd6b98,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-fe40b535-c1bc-438c-9a09-ff01e1afeaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-761214a7-34b9-4601-97e2-1434eb7c6567,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-ac883066-09f3-4020-a1c2-0d3583308f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-92a03a4c-3b59-461c-ac75-5741dd850f50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390010359-172.17.0.12-1597197553216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35070,DS-05a595e0-5de0-4106-8cfb-ab8edbde0267,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-622bbedc-1e16-4106-b35e-1fe7c6fcea4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-c893f314-1a84-45ba-9305-d015fbfddd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-1b3d0cee-42b0-4d7c-a264-558fd4bd6b98,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-fe40b535-c1bc-438c-9a09-ff01e1afeaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-761214a7-34b9-4601-97e2-1434eb7c6567,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-ac883066-09f3-4020-a1c2-0d3583308f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-92a03a4c-3b59-461c-ac75-5741dd850f50,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514146865-172.17.0.12-1597197673592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-7e891a6b-cab9-4bff-a74e-663037562d65,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-8c14d863-c49d-492c-a802-35be4bbe2fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-351f952d-0c8e-44c1-8d09-e2296be0e279,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-e2635187-c02d-4841-b3bf-3f76dbdd6b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-ddf28218-8ada-4f7a-993f-5dc703de38b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-8e30be7c-4456-415f-804d-4a3673f65ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-90754392-c56f-4e4c-af1d-851609ada864,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-f9c7e1e7-c5d1-4248-9058-24a2d07a5a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514146865-172.17.0.12-1597197673592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-7e891a6b-cab9-4bff-a74e-663037562d65,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-8c14d863-c49d-492c-a802-35be4bbe2fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-351f952d-0c8e-44c1-8d09-e2296be0e279,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-e2635187-c02d-4841-b3bf-3f76dbdd6b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-ddf28218-8ada-4f7a-993f-5dc703de38b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-8e30be7c-4456-415f-804d-4a3673f65ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-90754392-c56f-4e4c-af1d-851609ada864,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-f9c7e1e7-c5d1-4248-9058-24a2d07a5a97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828123411-172.17.0.12-1597197920223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38369,DS-8f878e8a-91c2-42dd-a217-096897987b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-ccf6bae7-2ef7-4878-a3b0-a81d957856a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-2b4e83aa-ce7a-49b2-8645-2036bb200256,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-542f94eb-70b0-4b22-85a7-9934d0cbeced,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-90a8769b-46a1-42c3-96a2-6a28d1a134fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-4c4da93d-a040-437d-a202-daa6e79c9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-a54422d5-258a-475a-b609-a98bb080f199,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-816d85e5-3554-4822-b7fc-87cf71f16957,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-828123411-172.17.0.12-1597197920223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38369,DS-8f878e8a-91c2-42dd-a217-096897987b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-ccf6bae7-2ef7-4878-a3b0-a81d957856a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-2b4e83aa-ce7a-49b2-8645-2036bb200256,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-542f94eb-70b0-4b22-85a7-9934d0cbeced,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-90a8769b-46a1-42c3-96a2-6a28d1a134fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-4c4da93d-a040-437d-a202-daa6e79c9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-a54422d5-258a-475a-b609-a98bb080f199,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-816d85e5-3554-4822-b7fc-87cf71f16957,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981776705-172.17.0.12-1597197963430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-8c092f84-7903-4cde-b357-78910c2547e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-2e0371f7-da83-4146-be64-24a2bcad5de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-704528fd-1a8f-4477-a324-2a4a3e7a9892,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-a2005ce3-9bb4-4c5b-8606-49a1f647bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-090fa227-e07b-4d66-8465-35e10e61bb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-3de1585b-147f-4221-a62d-7ba9d0a7f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-c50c6313-2a69-463c-9f8c-4765a31ba5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-22413241-c678-465d-a2b9-f237eee5f4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981776705-172.17.0.12-1597197963430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42553,DS-8c092f84-7903-4cde-b357-78910c2547e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-2e0371f7-da83-4146-be64-24a2bcad5de4,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-704528fd-1a8f-4477-a324-2a4a3e7a9892,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-a2005ce3-9bb4-4c5b-8606-49a1f647bf70,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-090fa227-e07b-4d66-8465-35e10e61bb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-3de1585b-147f-4221-a62d-7ba9d0a7f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-c50c6313-2a69-463c-9f8c-4765a31ba5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-22413241-c678-465d-a2b9-f237eee5f4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184386532-172.17.0.12-1597198325514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-0c6e627a-eecb-417f-b638-a2479641361d,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-32483b27-a21c-42a5-96c5-60090f734710,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-7c9328f1-c2c4-4cbf-86ce-4ce28196e313,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-7e0bb184-be9e-4ba0-ad50-71b0a71a233d,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-4c7e2cd4-1834-4237-9975-480266017b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-aed22a6f-ccd6-48ab-9169-254473586ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-2a5da927-4a95-4fe2-8c5f-40711871db92,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-77100a22-7fbc-46bd-996f-fb34f67a01df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184386532-172.17.0.12-1597198325514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-0c6e627a-eecb-417f-b638-a2479641361d,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-32483b27-a21c-42a5-96c5-60090f734710,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-7c9328f1-c2c4-4cbf-86ce-4ce28196e313,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-7e0bb184-be9e-4ba0-ad50-71b0a71a233d,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-4c7e2cd4-1834-4237-9975-480266017b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-aed22a6f-ccd6-48ab-9169-254473586ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-2a5da927-4a95-4fe2-8c5f-40711871db92,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-77100a22-7fbc-46bd-996f-fb34f67a01df,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636439517-172.17.0.12-1597198437417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45007,DS-31374387-bb29-4e66-ac16-c36e7b9db7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-6a76deb1-cbe3-4616-9a62-e629521749aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-803968e8-5f88-413e-ae2c-7de901631c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-1b28cce1-e33b-4510-b1c1-a6ec8d8db0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-76841b87-bea1-49ec-b566-de42485ac353,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-bfcf4296-838c-4aca-b3d5-a37342c65b49,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-539f63e1-0354-41ca-9b9a-9b62b04fe7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-b849b178-9d69-4956-a9ee-7aa78aef8ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636439517-172.17.0.12-1597198437417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45007,DS-31374387-bb29-4e66-ac16-c36e7b9db7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-6a76deb1-cbe3-4616-9a62-e629521749aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-803968e8-5f88-413e-ae2c-7de901631c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-1b28cce1-e33b-4510-b1c1-a6ec8d8db0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-76841b87-bea1-49ec-b566-de42485ac353,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-bfcf4296-838c-4aca-b3d5-a37342c65b49,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-539f63e1-0354-41ca-9b9a-9b62b04fe7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-b849b178-9d69-4956-a9ee-7aa78aef8ee5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869376278-172.17.0.12-1597198506902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-7b2f7e66-9f20-4a50-8a1f-439f0750c001,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-a50c0a6b-909e-45d3-8193-778692461e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-887fb8b3-ce1b-46df-a96b-94eee460d265,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-8d9ac778-34fb-43fd-bab3-84f8b94c8a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-70af9c7a-ad57-4896-bb31-5755927f474e,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-af272c1a-cd37-4f0e-8992-9506e74b7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-f5390572-22d7-47d1-9540-cd7742c19b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-d12aba78-d13a-4832-86e6-67dac5729c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869376278-172.17.0.12-1597198506902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37734,DS-7b2f7e66-9f20-4a50-8a1f-439f0750c001,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-a50c0a6b-909e-45d3-8193-778692461e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-887fb8b3-ce1b-46df-a96b-94eee460d265,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-8d9ac778-34fb-43fd-bab3-84f8b94c8a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-70af9c7a-ad57-4896-bb31-5755927f474e,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-af272c1a-cd37-4f0e-8992-9506e74b7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-f5390572-22d7-47d1-9540-cd7742c19b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-d12aba78-d13a-4832-86e6-67dac5729c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469121355-172.17.0.12-1597198834422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-05271e4f-d8f0-4aba-aa06-d99c4292e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-5f0baab1-2e62-4ee3-9820-9f8072ad972c,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-ad5d7186-2485-49f0-952e-dcc09cb000ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-83c00164-b342-4d62-b636-4a07611b21c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-e5df8261-4f03-4836-8d96-a07f9cb94da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-03ef53c1-aa11-4f09-b8e1-8f77150d7e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-740ee48d-2a9a-4988-b2cb-bf997f8b409d,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-c22cfef2-2627-416a-a97c-81297c778f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469121355-172.17.0.12-1597198834422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-05271e4f-d8f0-4aba-aa06-d99c4292e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-5f0baab1-2e62-4ee3-9820-9f8072ad972c,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-ad5d7186-2485-49f0-952e-dcc09cb000ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36838,DS-83c00164-b342-4d62-b636-4a07611b21c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-e5df8261-4f03-4836-8d96-a07f9cb94da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-03ef53c1-aa11-4f09-b8e1-8f77150d7e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-740ee48d-2a9a-4988-b2cb-bf997f8b409d,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-c22cfef2-2627-416a-a97c-81297c778f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132674143-172.17.0.12-1597198951225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40629,DS-47f61b14-774f-486d-acc1-e7c12a16b12e,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-b9f9dc71-974a-48fa-85f6-208b0152654e,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4c1aad11-9444-4e75-9378-8b469ae62160,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-ab51adcd-fe18-4ceb-83db-ae201b228ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-a85e1d7d-6d29-4e6a-af15-c5dd0e0e2e04,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-a4db0ec4-7b11-4e57-9ea6-8464f881cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-1a00cf75-9e52-42da-98ff-b6d432d91887,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-56436b1f-be3e-4f5c-948c-a72bc6f48f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1132674143-172.17.0.12-1597198951225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40629,DS-47f61b14-774f-486d-acc1-e7c12a16b12e,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-b9f9dc71-974a-48fa-85f6-208b0152654e,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-4c1aad11-9444-4e75-9378-8b469ae62160,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-ab51adcd-fe18-4ceb-83db-ae201b228ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-a85e1d7d-6d29-4e6a-af15-c5dd0e0e2e04,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-a4db0ec4-7b11-4e57-9ea6-8464f881cf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-1a00cf75-9e52-42da-98ff-b6d432d91887,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-56436b1f-be3e-4f5c-948c-a72bc6f48f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119450433-172.17.0.12-1597199070064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37043,DS-855305c6-9eff-4c68-839c-08f3ed4ce1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-c7c15770-2339-48af-b42d-dbb73e4dd72c,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-7b3545a5-44f1-44d6-a2e2-c949bf944884,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-8faa40ba-d6e1-4aff-b35f-f940353e74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-12bd84fb-bf07-409f-a6a4-f1958d995946,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-e98b3b77-7892-4aa8-86ba-70671420bc99,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-4e61cec7-5da1-450c-855e-5e9a14528e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-90e5e06a-8161-45b7-84ad-891c9dd78665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119450433-172.17.0.12-1597199070064:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37043,DS-855305c6-9eff-4c68-839c-08f3ed4ce1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-c7c15770-2339-48af-b42d-dbb73e4dd72c,DISK], DatanodeInfoWithStorage[127.0.0.1:42036,DS-7b3545a5-44f1-44d6-a2e2-c949bf944884,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-8faa40ba-d6e1-4aff-b35f-f940353e74ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-12bd84fb-bf07-409f-a6a4-f1958d995946,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-e98b3b77-7892-4aa8-86ba-70671420bc99,DISK], DatanodeInfoWithStorage[127.0.0.1:33895,DS-4e61cec7-5da1-450c-855e-5e9a14528e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-90e5e06a-8161-45b7-84ad-891c9dd78665,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489573278-172.17.0.12-1597199115196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-acd9348d-0039-4bf2-8856-911d70d1ec08,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-5055912c-ae35-419b-8f71-163d39be8433,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-c2c9e583-e792-4ff9-9a48-073eeb4ca1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-ed027504-b38e-4cc3-b27e-97abf4442e78,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-636b9fa7-c1f3-4853-9a6c-587b552f690d,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-6d73c11a-c1ac-48ee-bc83-ce634adb9703,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-0ed4d4c7-cc77-4b77-9037-1648016f7346,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-17c4401d-d9d9-4a12-a2db-a1d9d7c9c908,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1489573278-172.17.0.12-1597199115196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-acd9348d-0039-4bf2-8856-911d70d1ec08,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-5055912c-ae35-419b-8f71-163d39be8433,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-c2c9e583-e792-4ff9-9a48-073eeb4ca1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-ed027504-b38e-4cc3-b27e-97abf4442e78,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-636b9fa7-c1f3-4853-9a6c-587b552f690d,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-6d73c11a-c1ac-48ee-bc83-ce634adb9703,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-0ed4d4c7-cc77-4b77-9037-1648016f7346,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-17c4401d-d9d9-4a12-a2db-a1d9d7c9c908,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171777985-172.17.0.12-1597199146456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-048a0fa3-2854-4c50-b4f0-337dfc328645,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-6fd73125-43e0-4393-99c2-50fe47559dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-872a05dd-9ee8-4fe8-98a7-83faf5a81368,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-c579092c-2bc6-4747-a83a-1a4ea5aadc20,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-4722fea4-9201-4c82-b23c-c649a648d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-c1232033-1856-4a39-a48c-a56d2f73bce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-f7ac78c5-fc91-40bc-b452-de9fe4cf9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-aa5942a2-bc11-4a6f-9502-acf2aa23514b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171777985-172.17.0.12-1597199146456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37700,DS-048a0fa3-2854-4c50-b4f0-337dfc328645,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-6fd73125-43e0-4393-99c2-50fe47559dff,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-872a05dd-9ee8-4fe8-98a7-83faf5a81368,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-c579092c-2bc6-4747-a83a-1a4ea5aadc20,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-4722fea4-9201-4c82-b23c-c649a648d05d,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-c1232033-1856-4a39-a48c-a56d2f73bce6,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-f7ac78c5-fc91-40bc-b452-de9fe4cf9bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-aa5942a2-bc11-4a6f-9502-acf2aa23514b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106858448-172.17.0.12-1597199226726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42555,DS-11e78ee7-f3ac-435e-a2e9-ff3fa30ad8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-156a8fd9-8558-42fe-851b-660f39ed1f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-4aec9d74-4fd5-4af5-aa04-4fdeee00da9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-9e3d3bdc-a0b9-4912-8258-7dcd07e20e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-5e6d4502-14df-41ee-be4c-5089e85b1826,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-c7cff4f5-0cc4-403a-ab7f-53664aa4efa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-aca8fdda-ee06-4936-8c4b-5d8698010283,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-9bac966b-4597-4d52-91ba-aa41fd9f1fbd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106858448-172.17.0.12-1597199226726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42555,DS-11e78ee7-f3ac-435e-a2e9-ff3fa30ad8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-156a8fd9-8558-42fe-851b-660f39ed1f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-4aec9d74-4fd5-4af5-aa04-4fdeee00da9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-9e3d3bdc-a0b9-4912-8258-7dcd07e20e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-5e6d4502-14df-41ee-be4c-5089e85b1826,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-c7cff4f5-0cc4-403a-ab7f-53664aa4efa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-aca8fdda-ee06-4936-8c4b-5d8698010283,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-9bac966b-4597-4d52-91ba-aa41fd9f1fbd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.locateFollowingBlock.retries
component: hdfs:NameNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896584885-172.17.0.12-1597199267274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-5a415826-29f2-446f-8864-165f3769d3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-24fec41e-65bd-459b-8f03-8db838cb8761,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-4b677099-c68e-46fc-93a6-ecedfee7dda7,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-ac5ff4fc-ae98-464f-b758-3760664a6335,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-c8356353-2386-47cd-9d37-972e84ed9399,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-c10fbf81-4caa-4f7d-b411-4220bbe55129,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-324b52f2-170a-4777-8229-112fcd4b7799,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-2196fb4b-09de-4e7a-9f13-a1774b698155,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896584885-172.17.0.12-1597199267274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-5a415826-29f2-446f-8864-165f3769d3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-24fec41e-65bd-459b-8f03-8db838cb8761,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-4b677099-c68e-46fc-93a6-ecedfee7dda7,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-ac5ff4fc-ae98-464f-b758-3760664a6335,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-c8356353-2386-47cd-9d37-972e84ed9399,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-c10fbf81-4caa-4f7d-b411-4220bbe55129,DISK], DatanodeInfoWithStorage[127.0.0.1:42815,DS-324b52f2-170a-4777-8229-112fcd4b7799,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-2196fb4b-09de-4e7a-9f13-a1774b698155,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 17 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5601
