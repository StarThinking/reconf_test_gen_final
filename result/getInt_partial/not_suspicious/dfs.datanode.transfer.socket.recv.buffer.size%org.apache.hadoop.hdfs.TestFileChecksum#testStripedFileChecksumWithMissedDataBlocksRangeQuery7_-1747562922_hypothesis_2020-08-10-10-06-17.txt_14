reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446213182-172.17.0.9-1597054026436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44996,DS-31656a32-a034-455d-83ec-ba188f54bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-d62528b9-7db3-4d71-88fc-516e820b4629,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-e7b8623c-034d-4ed4-972e-2d4b1aed80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-2bf7a973-765c-411c-90b1-b5f51c2f8b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-2624ef0e-366c-4113-8411-56928acac86c,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-65351ba5-5924-4bf2-83f0-a8b29f04facd,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-fcef8820-97f1-4e48-9943-4fa913efb381,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-55b97af3-46e7-414a-b1af-e4910a9c0264,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446213182-172.17.0.9-1597054026436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44996,DS-31656a32-a034-455d-83ec-ba188f54bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-d62528b9-7db3-4d71-88fc-516e820b4629,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-e7b8623c-034d-4ed4-972e-2d4b1aed80f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-2bf7a973-765c-411c-90b1-b5f51c2f8b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-2624ef0e-366c-4113-8411-56928acac86c,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-65351ba5-5924-4bf2-83f0-a8b29f04facd,DISK], DatanodeInfoWithStorage[127.0.0.1:40985,DS-fcef8820-97f1-4e48-9943-4fa913efb381,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-55b97af3-46e7-414a-b1af-e4910a9c0264,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830433046-172.17.0.9-1597054318173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-964a0883-b6c0-40b5-b4f1-9076cf2dab63,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e522f8b4-be21-4b24-8eb9-7c33dc94f0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-227bb808-7425-474a-8abc-7a81d9e4339a,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-9b305d6c-79e2-4d7c-956c-f83279259fee,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-1b30c603-4ffa-42b9-9667-4bf4b7c71049,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-f9f4a631-a6bf-4089-a9bd-4cad570d1277,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-d7d58e04-03e2-4cc8-9b1f-6cc17459d212,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-04340dc5-efce-43cc-8254-5041a61ce02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-830433046-172.17.0.9-1597054318173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34961,DS-964a0883-b6c0-40b5-b4f1-9076cf2dab63,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e522f8b4-be21-4b24-8eb9-7c33dc94f0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43491,DS-227bb808-7425-474a-8abc-7a81d9e4339a,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-9b305d6c-79e2-4d7c-956c-f83279259fee,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-1b30c603-4ffa-42b9-9667-4bf4b7c71049,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-f9f4a631-a6bf-4089-a9bd-4cad570d1277,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-d7d58e04-03e2-4cc8-9b1f-6cc17459d212,DISK], DatanodeInfoWithStorage[127.0.0.1:42112,DS-04340dc5-efce-43cc-8254-5041a61ce02e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709235359-172.17.0.9-1597054399157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-07b551ca-9326-42c5-bdcf-444e5d6fcc97,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-215ade3d-509c-4e22-aae7-55edf8208eba,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-8d8f4749-ee9e-4ceb-afda-3f15f392c510,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-a759eb69-32cc-4c2b-a67e-f0ac5d4c4ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-35071c25-5670-4f0f-8639-87309ccedf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-4bdadc52-4d5b-470e-b830-cbe5d95308d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-92942305-49ee-4bd8-b95b-059f5a2c9573,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-83791caa-2293-47ec-9c26-a9017db6d414,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-709235359-172.17.0.9-1597054399157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-07b551ca-9326-42c5-bdcf-444e5d6fcc97,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-215ade3d-509c-4e22-aae7-55edf8208eba,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-8d8f4749-ee9e-4ceb-afda-3f15f392c510,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-a759eb69-32cc-4c2b-a67e-f0ac5d4c4ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-35071c25-5670-4f0f-8639-87309ccedf70,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-4bdadc52-4d5b-470e-b830-cbe5d95308d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-92942305-49ee-4bd8-b95b-059f5a2c9573,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-83791caa-2293-47ec-9c26-a9017db6d414,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13010797-172.17.0.9-1597054466919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44141,DS-aa73ca7a-595f-4c78-8332-e7c387325ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-83bfdb07-4f59-4b57-a357-429488976671,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-e02ffa5a-c28c-404c-9506-5f345d4c81da,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-dfe9920b-cd59-4372-a8dd-6030b9642f89,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-84a889c7-36cf-4a27-abd1-aabf80532a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-d62431ee-1098-4f13-8719-db145442d82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-8447c202-0d0b-4c19-8443-ece8326a0faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-e735d622-d576-4f5f-b479-d2c2f19b9b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13010797-172.17.0.9-1597054466919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44141,DS-aa73ca7a-595f-4c78-8332-e7c387325ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-83bfdb07-4f59-4b57-a357-429488976671,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-e02ffa5a-c28c-404c-9506-5f345d4c81da,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-dfe9920b-cd59-4372-a8dd-6030b9642f89,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-84a889c7-36cf-4a27-abd1-aabf80532a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-d62431ee-1098-4f13-8719-db145442d82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-8447c202-0d0b-4c19-8443-ece8326a0faa,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-e735d622-d576-4f5f-b479-d2c2f19b9b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559904347-172.17.0.9-1597054853154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41719,DS-6970efed-c47a-491e-bc71-f4fe1b3c12e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-f8050071-7595-473f-85e9-7cc30632c311,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-1763faba-35cb-40f8-a6e8-5199ccf6c8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-00e3f23f-6711-4f13-9192-75012406a2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-97f12a61-132c-42d9-a5b7-08e8af58a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-43104ebb-82f2-461e-b87d-4f12768f68a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-54a7e871-1d0e-40fe-81d9-2e89fa56bcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-f1c1d891-260c-4fcf-a1ef-63aa0cd3f0bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559904347-172.17.0.9-1597054853154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41719,DS-6970efed-c47a-491e-bc71-f4fe1b3c12e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-f8050071-7595-473f-85e9-7cc30632c311,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-1763faba-35cb-40f8-a6e8-5199ccf6c8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-00e3f23f-6711-4f13-9192-75012406a2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-97f12a61-132c-42d9-a5b7-08e8af58a5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-43104ebb-82f2-461e-b87d-4f12768f68a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-54a7e871-1d0e-40fe-81d9-2e89fa56bcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-f1c1d891-260c-4fcf-a1ef-63aa0cd3f0bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178394782-172.17.0.9-1597054972392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-21e89848-8100-4d9e-8ac5-68539c9461de,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-bb3f5ac1-ef76-4ba9-b8a1-4b905a3fc0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-a6852206-b613-4074-92d7-cc87df36d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-7f5f6bbf-781e-4ce0-919e-e632fe5f769d,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-f97f08b5-a547-439c-a0ec-572eada5b378,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-8160a685-9416-4a4a-857f-2c2fab001512,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-8ff899f8-d72f-4e00-a6a6-1353cfce78fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-2c233f29-7522-4d2c-be18-4ffb9f98c552,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178394782-172.17.0.9-1597054972392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-21e89848-8100-4d9e-8ac5-68539c9461de,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-bb3f5ac1-ef76-4ba9-b8a1-4b905a3fc0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-a6852206-b613-4074-92d7-cc87df36d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-7f5f6bbf-781e-4ce0-919e-e632fe5f769d,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-f97f08b5-a547-439c-a0ec-572eada5b378,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-8160a685-9416-4a4a-857f-2c2fab001512,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-8ff899f8-d72f-4e00-a6a6-1353cfce78fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-2c233f29-7522-4d2c-be18-4ffb9f98c552,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011344688-172.17.0.9-1597055115199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-13cec6e4-3635-4133-b70b-2443b24f0c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-1754a945-9731-4479-8837-d9cbcfcb4a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-f44523aa-5d57-4172-b765-3af22902464e,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-1dc57b2a-cbc9-4ff9-aeca-b816a20e9cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-43e720f7-6ecb-45c3-99cf-ca4c4f514bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-9e1130f6-e5c4-416a-94be-000b571d7472,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-a1c19368-7861-4b05-b1a3-7965aa4359a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-8eb2ad96-18d0-414e-bbf8-2eeb0d5c0328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011344688-172.17.0.9-1597055115199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-13cec6e4-3635-4133-b70b-2443b24f0c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-1754a945-9731-4479-8837-d9cbcfcb4a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-f44523aa-5d57-4172-b765-3af22902464e,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-1dc57b2a-cbc9-4ff9-aeca-b816a20e9cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-43e720f7-6ecb-45c3-99cf-ca4c4f514bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-9e1130f6-e5c4-416a-94be-000b571d7472,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-a1c19368-7861-4b05-b1a3-7965aa4359a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-8eb2ad96-18d0-414e-bbf8-2eeb0d5c0328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211148026-172.17.0.9-1597055157997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38124,DS-fe2ab04a-b857-46c1-9f96-3b811ee5ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-fdf30289-8c10-4d27-9b14-159e57f0d634,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-7634fafb-9c44-44aa-9f91-41a1cfef5a74,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-031a4da6-8d7a-434c-b3e8-4b66382907fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-95f26c63-0779-4d73-bd45-52db627b0793,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-e2987631-5f7b-4aee-8d33-86a25e0ed3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-122f3330-bcad-47f3-8a00-0bee0d95efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-04858ea1-cfc4-463e-a5b3-849490ad9a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211148026-172.17.0.9-1597055157997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38124,DS-fe2ab04a-b857-46c1-9f96-3b811ee5ab73,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-fdf30289-8c10-4d27-9b14-159e57f0d634,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-7634fafb-9c44-44aa-9f91-41a1cfef5a74,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-031a4da6-8d7a-434c-b3e8-4b66382907fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-95f26c63-0779-4d73-bd45-52db627b0793,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-e2987631-5f7b-4aee-8d33-86a25e0ed3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-122f3330-bcad-47f3-8a00-0bee0d95efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-04858ea1-cfc4-463e-a5b3-849490ad9a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111144813-172.17.0.9-1597055273720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38845,DS-09d5610a-d759-46a1-b8fb-69e02590c3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-7d3a9884-1c81-449a-864c-09da10ba6a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-1a23a928-a391-4aa7-8a9f-8039733e3b58,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-100b6dce-da12-474f-ae28-67d472c3723a,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-97f40bc0-d873-4ef6-b51e-1595b5e5ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-f24f7c96-6a47-45e3-841d-bc29551e91f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-cf44bfa1-86f8-40a3-8062-1032df9c0ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-762d649c-754a-4a19-bf37-b3eaf1c41a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111144813-172.17.0.9-1597055273720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38845,DS-09d5610a-d759-46a1-b8fb-69e02590c3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-7d3a9884-1c81-449a-864c-09da10ba6a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-1a23a928-a391-4aa7-8a9f-8039733e3b58,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-100b6dce-da12-474f-ae28-67d472c3723a,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-97f40bc0-d873-4ef6-b51e-1595b5e5ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-f24f7c96-6a47-45e3-841d-bc29551e91f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-cf44bfa1-86f8-40a3-8062-1032df9c0ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-762d649c-754a-4a19-bf37-b3eaf1c41a98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744229198-172.17.0.9-1597055678182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37024,DS-814167e2-7e82-443c-b33a-0aa039aabd16,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-c6477cca-503d-4ae8-bd0b-f5a058209a70,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-a147a947-5020-4b55-a4b1-6639c1cab615,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-0e1f20e8-cc16-4ef6-8964-19a9c283dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-4d71cc22-e056-4fde-9a11-f47c7e96dedd,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-f5402000-bee4-42c6-9011-1f5dc65ba3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-a36e9bb8-67f3-4205-ac14-a21fad430990,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-5642de84-1def-4877-897f-6db4c7e159ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744229198-172.17.0.9-1597055678182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37024,DS-814167e2-7e82-443c-b33a-0aa039aabd16,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-c6477cca-503d-4ae8-bd0b-f5a058209a70,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-a147a947-5020-4b55-a4b1-6639c1cab615,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-0e1f20e8-cc16-4ef6-8964-19a9c283dc90,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-4d71cc22-e056-4fde-9a11-f47c7e96dedd,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-f5402000-bee4-42c6-9011-1f5dc65ba3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-a36e9bb8-67f3-4205-ac14-a21fad430990,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-5642de84-1def-4877-897f-6db4c7e159ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055081587-172.17.0.9-1597055709453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37235,DS-047fe3fd-a3b4-4edf-8fb6-ce4a62084adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-06d1343a-a9c1-436f-ab89-ffacb03db91d,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-e85fc325-61a1-43be-b4de-256f8d5fe96b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-a22cce2e-4baa-4528-b915-e1291a6e6dff,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-e6ab73d1-7f9d-40e8-a3d3-982adc8bc70b,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-e20b049e-0be0-4dd2-89c7-966e99ff5a99,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-eb5ac63a-5a38-45dd-afd4-6a46970e2612,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-01de82bc-2beb-49af-a4f8-d11476116f2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055081587-172.17.0.9-1597055709453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37235,DS-047fe3fd-a3b4-4edf-8fb6-ce4a62084adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-06d1343a-a9c1-436f-ab89-ffacb03db91d,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-e85fc325-61a1-43be-b4de-256f8d5fe96b,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-a22cce2e-4baa-4528-b915-e1291a6e6dff,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-e6ab73d1-7f9d-40e8-a3d3-982adc8bc70b,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-e20b049e-0be0-4dd2-89c7-966e99ff5a99,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-eb5ac63a-5a38-45dd-afd4-6a46970e2612,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-01de82bc-2beb-49af-a4f8-d11476116f2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346453323-172.17.0.9-1597055777413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45015,DS-e0dfff0a-6f52-4e57-b583-2f30cae51741,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-8a92f380-620f-4c21-bda9-11b4d23110b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-f2f43ec8-3dde-41c4-a476-2c9e8df6199f,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-d004bdc5-29aa-404a-860e-e0145043dba3,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-2c18df5c-2abc-42c2-b989-327f7f10b78f,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-949cc2b7-3e50-43d8-a1ac-21bf2bfb1405,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-f46bbab2-23da-4581-bbdb-e78d5cce0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-26b52ea8-aa8c-4599-83bd-64198a9a260d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346453323-172.17.0.9-1597055777413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45015,DS-e0dfff0a-6f52-4e57-b583-2f30cae51741,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-8a92f380-620f-4c21-bda9-11b4d23110b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-f2f43ec8-3dde-41c4-a476-2c9e8df6199f,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-d004bdc5-29aa-404a-860e-e0145043dba3,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-2c18df5c-2abc-42c2-b989-327f7f10b78f,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-949cc2b7-3e50-43d8-a1ac-21bf2bfb1405,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-f46bbab2-23da-4581-bbdb-e78d5cce0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-26b52ea8-aa8c-4599-83bd-64198a9a260d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810242668-172.17.0.9-1597055920593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32941,DS-fda480d5-028e-495c-a778-8f0dfe4050c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-6e40c32c-5b3f-471e-89d0-8c9e90b2d223,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-49eefcc0-a0d3-4659-a92b-b716ba224f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-8ae5a658-a130-4144-be3b-04e449068bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-878921bb-9e3d-4a45-bb40-9aef2f4e2c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-3772964c-4106-4cde-b16b-eb28a3675c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-84f5b663-51e2-47f1-b13a-f86a6f1e3946,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-91e88a64-3ecc-4049-9ced-d21151d25113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810242668-172.17.0.9-1597055920593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32941,DS-fda480d5-028e-495c-a778-8f0dfe4050c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-6e40c32c-5b3f-471e-89d0-8c9e90b2d223,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-49eefcc0-a0d3-4659-a92b-b716ba224f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-8ae5a658-a130-4144-be3b-04e449068bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-878921bb-9e3d-4a45-bb40-9aef2f4e2c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-3772964c-4106-4cde-b16b-eb28a3675c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-84f5b663-51e2-47f1-b13a-f86a6f1e3946,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-91e88a64-3ecc-4049-9ced-d21151d25113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290677953-172.17.0.9-1597055992495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-aaa748b7-a4a6-437d-8983-02b9f3de188a,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-1da03ef2-f07a-4b08-a8af-a2fe286045ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-53181beb-1fec-4898-896d-ab34f82d55ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-b7e57b1d-ae73-4781-9855-4e631e95a158,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-b657d368-33c0-47a2-9adb-54b9ad33f7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-5d985e30-d74e-456a-82ae-3a7754a677fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-b9b53160-0cfb-4f12-bd40-1a3008a17a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-e5558255-1ed6-4e67-bf4c-6fadec71f183,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290677953-172.17.0.9-1597055992495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41848,DS-aaa748b7-a4a6-437d-8983-02b9f3de188a,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-1da03ef2-f07a-4b08-a8af-a2fe286045ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-53181beb-1fec-4898-896d-ab34f82d55ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-b7e57b1d-ae73-4781-9855-4e631e95a158,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-b657d368-33c0-47a2-9adb-54b9ad33f7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-5d985e30-d74e-456a-82ae-3a7754a677fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-b9b53160-0cfb-4f12-bd40-1a3008a17a39,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-e5558255-1ed6-4e67-bf4c-6fadec71f183,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54159429-172.17.0.9-1597056196824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-54b01555-0a74-431d-be83-115eccfef863,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-c03cba18-35c2-414a-adf3-46698fb37a92,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-9e931290-76ee-44e9-82e9-cf8f36b15b62,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-747957e7-514b-4114-9a6c-ba27a4a626c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5046aaab-4e9c-496f-9405-e5e0c9685bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-300961b9-98ec-4091-81d7-2d9201dfdedb,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-52fd2771-1978-43f9-830b-ff53b42a958c,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-8c04ae7a-e2cf-423d-b88a-4ee72f6d7a63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54159429-172.17.0.9-1597056196824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-54b01555-0a74-431d-be83-115eccfef863,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-c03cba18-35c2-414a-adf3-46698fb37a92,DISK], DatanodeInfoWithStorage[127.0.0.1:33296,DS-9e931290-76ee-44e9-82e9-cf8f36b15b62,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-747957e7-514b-4114-9a6c-ba27a4a626c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-5046aaab-4e9c-496f-9405-e5e0c9685bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-300961b9-98ec-4091-81d7-2d9201dfdedb,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-52fd2771-1978-43f9-830b-ff53b42a958c,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-8c04ae7a-e2cf-423d-b88a-4ee72f6d7a63,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290910201-172.17.0.9-1597056265509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46423,DS-3b79a499-2993-4ec4-938f-56400ba875e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-d9870f6a-9923-4413-8dfa-2cad5d3a6827,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-939e1041-7c5a-4d96-813e-e34da7bcaf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-fcb5f8ab-ded5-42a8-8417-494a0f7f85e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-4bc0cbbf-cc7e-424b-a51c-7c60327e7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-9e237386-7153-4648-9cd8-d452342df3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-ce288638-8bb2-4290-b82b-1ee594379121,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-75d385df-a2b9-4c21-86e6-bb699164d396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290910201-172.17.0.9-1597056265509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46423,DS-3b79a499-2993-4ec4-938f-56400ba875e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34769,DS-d9870f6a-9923-4413-8dfa-2cad5d3a6827,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-939e1041-7c5a-4d96-813e-e34da7bcaf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-fcb5f8ab-ded5-42a8-8417-494a0f7f85e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40659,DS-4bc0cbbf-cc7e-424b-a51c-7c60327e7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-9e237386-7153-4648-9cd8-d452342df3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-ce288638-8bb2-4290-b82b-1ee594379121,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-75d385df-a2b9-4c21-86e6-bb699164d396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100563831-172.17.0.9-1597056645686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34091,DS-8876d2b8-22a9-41e0-8b17-fd73ba7a4465,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-01848d48-75c6-44d5-9256-45a999736668,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-a407bb3b-cd75-4539-b325-3271ba351e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-20e9c94b-c368-4ac5-934b-eac1ad8c07bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-78b2c5f7-b2c3-433c-8b4f-ad3035f39903,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-5d346353-19e2-47a6-9b5e-fa0590d0fbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-9b52a4b0-3f73-4ca3-9d0a-128cdb15d566,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-000b0392-9cce-4265-8792-eddc5fc18c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100563831-172.17.0.9-1597056645686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34091,DS-8876d2b8-22a9-41e0-8b17-fd73ba7a4465,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-01848d48-75c6-44d5-9256-45a999736668,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-a407bb3b-cd75-4539-b325-3271ba351e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-20e9c94b-c368-4ac5-934b-eac1ad8c07bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-78b2c5f7-b2c3-433c-8b4f-ad3035f39903,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-5d346353-19e2-47a6-9b5e-fa0590d0fbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-9b52a4b0-3f73-4ca3-9d0a-128cdb15d566,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-000b0392-9cce-4265-8792-eddc5fc18c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993102485-172.17.0.9-1597057125522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45203,DS-24bfbc31-37ed-4ea6-a4a9-0e25b9be8079,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-46ae85e2-6a53-43f3-a52c-cca0def8522d,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-4cec4cef-1bec-404d-ada4-50f51c1b68e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-f41cb71b-7778-4db6-b05d-7459716b1907,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-593d4119-9914-4856-ad16-832d8099c285,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-3acb7ee9-f7a9-43fb-9bd5-3d26dfa9b6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-74b4e4cf-878e-460b-b304-4f5b30e19205,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-f2194b04-a345-4ecf-8093-c03be57a3527,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993102485-172.17.0.9-1597057125522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45203,DS-24bfbc31-37ed-4ea6-a4a9-0e25b9be8079,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-46ae85e2-6a53-43f3-a52c-cca0def8522d,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-4cec4cef-1bec-404d-ada4-50f51c1b68e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-f41cb71b-7778-4db6-b05d-7459716b1907,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-593d4119-9914-4856-ad16-832d8099c285,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-3acb7ee9-f7a9-43fb-9bd5-3d26dfa9b6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-74b4e4cf-878e-460b-b304-4f5b30e19205,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-f2194b04-a345-4ecf-8093-c03be57a3527,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001523522-172.17.0.9-1597057604263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-29369c8d-b099-422b-811c-6376a1c40cea,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-1854e759-8c0f-4cb0-ae3f-0aa66de93aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-13a0d981-0e68-4cba-97ed-b8b1e92b6459,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-33ce70ba-c58e-43c8-b156-732502cc23a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-d0d4967b-ac06-4dd1-a049-88ee73d268b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-d6f09d6f-4122-4d4d-b5d5-32ea96452f59,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-b18c9d26-ea4d-44b3-a61d-9ba3400a003a,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-88796467-5c31-4aac-838e-d6133e335fe9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001523522-172.17.0.9-1597057604263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38407,DS-29369c8d-b099-422b-811c-6376a1c40cea,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-1854e759-8c0f-4cb0-ae3f-0aa66de93aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-13a0d981-0e68-4cba-97ed-b8b1e92b6459,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-33ce70ba-c58e-43c8-b156-732502cc23a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-d0d4967b-ac06-4dd1-a049-88ee73d268b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-d6f09d6f-4122-4d4d-b5d5-32ea96452f59,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-b18c9d26-ea4d-44b3-a61d-9ba3400a003a,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-88796467-5c31-4aac-838e-d6133e335fe9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36574312-172.17.0.9-1597057717124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42076,DS-029cbb2d-57d4-48f9-9393-4574006ed44f,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-24100269-bb71-4410-a7d8-91eca37d7ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-31794321-3a60-40cc-b1fc-a98b28111fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-9dce921f-f4c4-4724-9692-3381cfd024db,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-d328829d-d2dc-4e50-9d20-a2edd69df517,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-39a7a96d-ab9b-4186-b2f9-111ea509f3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-9fa0c857-d8a1-48af-9f59-f1769a39e4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-a0cd730b-0b88-4fb6-bed9-0b7b17200487,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36574312-172.17.0.9-1597057717124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42076,DS-029cbb2d-57d4-48f9-9393-4574006ed44f,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-24100269-bb71-4410-a7d8-91eca37d7ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-31794321-3a60-40cc-b1fc-a98b28111fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-9dce921f-f4c4-4724-9692-3381cfd024db,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-d328829d-d2dc-4e50-9d20-a2edd69df517,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-39a7a96d-ab9b-4186-b2f9-111ea509f3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-9fa0c857-d8a1-48af-9f59-f1769a39e4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-a0cd730b-0b88-4fb6-bed9-0b7b17200487,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377905158-172.17.0.9-1597057862909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-e6d0533a-d6f4-4171-b735-a49e7bf5cc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-7146e170-c22b-4272-ba2b-377c43e9ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-06c67a9c-9d41-4b12-ac3c-3d5169575ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-4502ea30-b33e-43c2-a995-bf066e5b889e,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-93c6a0b8-d27f-4514-93b0-37a1e2ed7509,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-45118d81-799d-49cd-be8d-1e5774d67acc,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-d3404f16-472a-4d66-8e52-6eca35b13493,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-3767df5b-00dd-4051-91a0-9ff18d06ef80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1377905158-172.17.0.9-1597057862909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45281,DS-e6d0533a-d6f4-4171-b735-a49e7bf5cc45,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-7146e170-c22b-4272-ba2b-377c43e9ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-06c67a9c-9d41-4b12-ac3c-3d5169575ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-4502ea30-b33e-43c2-a995-bf066e5b889e,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-93c6a0b8-d27f-4514-93b0-37a1e2ed7509,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-45118d81-799d-49cd-be8d-1e5774d67acc,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-d3404f16-472a-4d66-8e52-6eca35b13493,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-3767df5b-00dd-4051-91a0-9ff18d06ef80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791964110-172.17.0.9-1597057980257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42870,DS-75a4afc9-1aa9-44c0-ac0d-07a7d78e951b,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-5e33a767-ded4-4427-a1dc-fb99781096d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-0b845524-d882-4c27-ac84-ce7b4d329d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-358458e0-a041-4c92-ab1e-734b55d640bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-cddfd338-d833-4c39-8b2a-f509d3884b23,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-b97a0a9a-95d7-44b6-8c27-99a190eabafb,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-2f2e513f-d1fb-455b-a30b-0485389f4c32,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-03094697-27b2-45e0-a30a-59233dcc901f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791964110-172.17.0.9-1597057980257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42870,DS-75a4afc9-1aa9-44c0-ac0d-07a7d78e951b,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-5e33a767-ded4-4427-a1dc-fb99781096d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-0b845524-d882-4c27-ac84-ce7b4d329d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-358458e0-a041-4c92-ab1e-734b55d640bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-cddfd338-d833-4c39-8b2a-f509d3884b23,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-b97a0a9a-95d7-44b6-8c27-99a190eabafb,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-2f2e513f-d1fb-455b-a30b-0485389f4c32,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-03094697-27b2-45e0-a30a-59233dcc901f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77200448-172.17.0.9-1597058206366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39247,DS-fda5e3ba-d153-4715-ba6a-60bf20d72fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-e3a97def-265e-439b-b2e2-e4b7cbe12458,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-ed94ebc7-fa1c-4f87-874d-43a0ab9b3067,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-8c464ac5-8dc8-4ba7-8f0c-a3198b4bf693,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-52a1eb98-3901-44db-be78-a321cc794bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-6a9b60df-daf2-4cd2-8f5c-15c54c2fd53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-dbd766ab-15ae-4d64-b509-0056f4df9a95,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-5320b8af-c2e2-4a38-ae43-fef5396d6972,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77200448-172.17.0.9-1597058206366:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39247,DS-fda5e3ba-d153-4715-ba6a-60bf20d72fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-e3a97def-265e-439b-b2e2-e4b7cbe12458,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-ed94ebc7-fa1c-4f87-874d-43a0ab9b3067,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-8c464ac5-8dc8-4ba7-8f0c-a3198b4bf693,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-52a1eb98-3901-44db-be78-a321cc794bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-6a9b60df-daf2-4cd2-8f5c-15c54c2fd53a,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-dbd766ab-15ae-4d64-b509-0056f4df9a95,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-5320b8af-c2e2-4a38-ae43-fef5396d6972,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745690280-172.17.0.9-1597058529878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-3ce245ac-a10f-4efe-8ef2-3b31f48264f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-538846bb-e84e-4430-8c49-800f4d56d31a,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-57be8446-fa6d-432d-b06f-2ea8a6a86cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-8fdec84f-da66-422a-a5bb-13e5f7540bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-0151fb4b-6eff-40a0-8b64-c09f9b8718ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-e574cdbd-090c-4ae2-802b-26af639b1633,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-d0eecd62-e06e-479e-a30a-d0108dc5d776,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-2797550f-d61b-4260-aa97-7823cbd92ef7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745690280-172.17.0.9-1597058529878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38466,DS-3ce245ac-a10f-4efe-8ef2-3b31f48264f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-538846bb-e84e-4430-8c49-800f4d56d31a,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-57be8446-fa6d-432d-b06f-2ea8a6a86cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-8fdec84f-da66-422a-a5bb-13e5f7540bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-0151fb4b-6eff-40a0-8b64-c09f9b8718ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-e574cdbd-090c-4ae2-802b-26af639b1633,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-d0eecd62-e06e-479e-a30a-d0108dc5d776,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-2797550f-d61b-4260-aa97-7823cbd92ef7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917482043-172.17.0.9-1597058566660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36444,DS-a3cf1fc8-e4f1-4083-baa4-c81cb0bebc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-ff560c52-77ef-4c91-b36b-f3849b3d40c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-562bf2fe-b958-44cf-a704-90d8575ab96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-e29c6c47-8a04-43d3-85f6-072f2dbeba46,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-b7c4fa48-021b-4844-a5d7-f246de9d5bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-6eb942a5-a737-46c1-ab9d-217ecb52b06b,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-020d2ad3-a29e-423d-bba6-3ff8ee61e65e,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-19918c79-d3d9-426c-a5ec-f522478aef21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917482043-172.17.0.9-1597058566660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36444,DS-a3cf1fc8-e4f1-4083-baa4-c81cb0bebc7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-ff560c52-77ef-4c91-b36b-f3849b3d40c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-562bf2fe-b958-44cf-a704-90d8575ab96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-e29c6c47-8a04-43d3-85f6-072f2dbeba46,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-b7c4fa48-021b-4844-a5d7-f246de9d5bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-6eb942a5-a737-46c1-ab9d-217ecb52b06b,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-020d2ad3-a29e-423d-bba6-3ff8ee61e65e,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-19918c79-d3d9-426c-a5ec-f522478aef21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865433050-172.17.0.9-1597058782533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33088,DS-5dc5071f-045a-45ec-944c-32cfe9540f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-347c2250-7b91-4cef-b218-919d5bd83901,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-91637cf3-dc3b-49c6-87e7-470143e180cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-85b172d8-8fa0-49fa-87b1-a0244ecf4bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-3f102b91-022b-4030-a7f3-ea1c4cbde27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-7c61bed9-7c36-4ff1-87b4-865d8e9803d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-7f1b4a4d-ee76-43c3-bc5c-240fc2553913,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-eed7cf0d-5d43-49c2-8a27-7635d748cb68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1865433050-172.17.0.9-1597058782533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33088,DS-5dc5071f-045a-45ec-944c-32cfe9540f89,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-347c2250-7b91-4cef-b218-919d5bd83901,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-91637cf3-dc3b-49c6-87e7-470143e180cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-85b172d8-8fa0-49fa-87b1-a0244ecf4bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-3f102b91-022b-4030-a7f3-ea1c4cbde27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42548,DS-7c61bed9-7c36-4ff1-87b4-865d8e9803d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38766,DS-7f1b4a4d-ee76-43c3-bc5c-240fc2553913,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-eed7cf0d-5d43-49c2-8a27-7635d748cb68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317437500-172.17.0.9-1597058978680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-02e556c8-e90c-4f3f-943a-eec44539f570,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-d95c9d54-7010-415e-91f9-0e4f3be1001a,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-0754ed93-fe33-4ef9-ab4c-cc740f3adb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-6ffcffe0-86d5-42f9-9eec-af0251b14b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-f6303a7a-e445-4ddb-88ef-57f2463e8afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-413c0752-96b2-49fd-a0ba-587eb8693ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-e566c9ac-d500-47cf-81e8-1ce9e1db86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-d859633d-f09c-4d19-ad14-1df09db460d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1317437500-172.17.0.9-1597058978680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43612,DS-02e556c8-e90c-4f3f-943a-eec44539f570,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-d95c9d54-7010-415e-91f9-0e4f3be1001a,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-0754ed93-fe33-4ef9-ab4c-cc740f3adb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-6ffcffe0-86d5-42f9-9eec-af0251b14b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-f6303a7a-e445-4ddb-88ef-57f2463e8afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-413c0752-96b2-49fd-a0ba-587eb8693ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-e566c9ac-d500-47cf-81e8-1ce9e1db86f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-d859633d-f09c-4d19-ad14-1df09db460d6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342910269-172.17.0.9-1597059201250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43430,DS-06e50a55-12cc-4247-9c84-d1bd6e7ebe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-fd0ab2aa-8bbb-42e1-821d-f588d02de771,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-e12f5572-181e-4386-8584-cf386668adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-cfac2c1a-f531-430d-89f8-5ccdad5e9ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-31927143-0370-4270-a7b3-60bbcc21990d,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-e8d6ad9b-c54c-494c-998e-1959df6022a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-96e88d42-9ce8-423c-92d4-42a293c805f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-2214abd8-9acc-4ca6-a9c0-5e547ba88b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342910269-172.17.0.9-1597059201250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43430,DS-06e50a55-12cc-4247-9c84-d1bd6e7ebe1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-fd0ab2aa-8bbb-42e1-821d-f588d02de771,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-e12f5572-181e-4386-8584-cf386668adfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-cfac2c1a-f531-430d-89f8-5ccdad5e9ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-31927143-0370-4270-a7b3-60bbcc21990d,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-e8d6ad9b-c54c-494c-998e-1959df6022a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-96e88d42-9ce8-423c-92d4-42a293c805f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-2214abd8-9acc-4ca6-a9c0-5e547ba88b34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5455
