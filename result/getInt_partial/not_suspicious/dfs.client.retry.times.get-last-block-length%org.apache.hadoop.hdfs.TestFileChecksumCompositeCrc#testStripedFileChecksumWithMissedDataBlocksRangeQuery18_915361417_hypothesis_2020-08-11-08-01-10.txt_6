reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203962748-172.17.0.12-1597133026388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-079bd631-0697-4d83-b11b-1204b88a31c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-5d6b6b26-c50f-4a8d-ac96-b9c31ebcc2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-f8ed8589-fc24-4b83-be73-6842e23a0404,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-5cb12647-5413-4317-9912-24843b1f6590,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-4afecd06-dda2-4426-b946-b00c4c51f619,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-7df692af-23f1-4998-b0e9-f93ef20118db,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-a66bd479-f29d-4be6-9722-787e4103ec70,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-af9a5029-cb2a-4096-b258-f8321afe3804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1203962748-172.17.0.12-1597133026388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-079bd631-0697-4d83-b11b-1204b88a31c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-5d6b6b26-c50f-4a8d-ac96-b9c31ebcc2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-f8ed8589-fc24-4b83-be73-6842e23a0404,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-5cb12647-5413-4317-9912-24843b1f6590,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-4afecd06-dda2-4426-b946-b00c4c51f619,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-7df692af-23f1-4998-b0e9-f93ef20118db,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-a66bd479-f29d-4be6-9722-787e4103ec70,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-af9a5029-cb2a-4096-b258-f8321afe3804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813773454-172.17.0.12-1597133178003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40945,DS-c938e07f-bb17-4189-9b9a-64453dfbbd61,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-6b096d7d-e7a4-417e-8f6b-5e2dc8161fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-20ce03b3-594b-47da-b92f-02131b97625a,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-19468ae6-4342-4449-aeec-0a69ed13a3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-1e8ea72e-79ad-4ce1-a9ba-f7810243b849,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-558659c5-feda-4c06-9e8e-e4a7b67b303c,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-3d9174ac-6270-42b2-b365-8dd59cb65b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-a45ff058-b622-474d-b12f-00ae99cf0090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1813773454-172.17.0.12-1597133178003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40945,DS-c938e07f-bb17-4189-9b9a-64453dfbbd61,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-6b096d7d-e7a4-417e-8f6b-5e2dc8161fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-20ce03b3-594b-47da-b92f-02131b97625a,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-19468ae6-4342-4449-aeec-0a69ed13a3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-1e8ea72e-79ad-4ce1-a9ba-f7810243b849,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-558659c5-feda-4c06-9e8e-e4a7b67b303c,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-3d9174ac-6270-42b2-b365-8dd59cb65b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-a45ff058-b622-474d-b12f-00ae99cf0090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064570149-172.17.0.12-1597133289312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-ccedf554-5e1c-41bc-bc51-8c035a7e32de,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-ff8e14ee-59bc-43a5-a4ba-5a2cc7ace7df,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-8dd8f287-29ca-497b-880b-ab6f52514dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-09d1d59d-4188-4805-95e4-4aa8df07264b,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-6e71e9b8-87d1-4d0a-8b94-e64515395bda,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-52cfce70-bbd1-404e-ae4b-6153dec7c888,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-0ae817c2-ecdf-47b5-a8fa-bc6a02c01de2,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-78c5df8c-fbb2-481f-8fd2-b161ff64fa2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064570149-172.17.0.12-1597133289312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-ccedf554-5e1c-41bc-bc51-8c035a7e32de,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-ff8e14ee-59bc-43a5-a4ba-5a2cc7ace7df,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-8dd8f287-29ca-497b-880b-ab6f52514dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-09d1d59d-4188-4805-95e4-4aa8df07264b,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-6e71e9b8-87d1-4d0a-8b94-e64515395bda,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-52cfce70-bbd1-404e-ae4b-6153dec7c888,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-0ae817c2-ecdf-47b5-a8fa-bc6a02c01de2,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-78c5df8c-fbb2-481f-8fd2-b161ff64fa2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162394569-172.17.0.12-1597134017728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-5756f02d-275b-422a-a95c-3ae7e12cb406,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-f73dcfa3-065e-4437-9725-dba8d7997a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-0cab29e8-4181-4a79-a896-23f0ccb6f876,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-90632aef-c055-42b9-8196-2ede3a9133c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-1145f424-7d42-4cfb-aab9-b756678bf74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-8a842c88-c1ac-4ee2-ba71-1804f45ac2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-664cacd0-8b98-4c74-882c-013f7e35e973,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-17622b86-7c22-4332-9458-ce75f6c3a3e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162394569-172.17.0.12-1597134017728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-5756f02d-275b-422a-a95c-3ae7e12cb406,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-f73dcfa3-065e-4437-9725-dba8d7997a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-0cab29e8-4181-4a79-a896-23f0ccb6f876,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-90632aef-c055-42b9-8196-2ede3a9133c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-1145f424-7d42-4cfb-aab9-b756678bf74e,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-8a842c88-c1ac-4ee2-ba71-1804f45ac2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-664cacd0-8b98-4c74-882c-013f7e35e973,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-17622b86-7c22-4332-9458-ce75f6c3a3e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847091562-172.17.0.12-1597134058916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42145,DS-5ba2bbd4-6b39-47e8-9c28-f7ce54082146,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-9cb1b856-e529-4f4a-8a0f-1285065326f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-f79642c3-06b1-4405-af4b-e4cd27d08083,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-e5522974-ba6a-4663-838a-7daceea8a604,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-bdb47bd0-8fd6-4b57-9734-cb7a54c4f388,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8f69498b-e1f5-4120-940b-3cc59b0592b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-007e89bd-9637-4ba0-83d0-5e81d64c62fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-62cf0960-27dd-4378-bd1f-56b379c66036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-847091562-172.17.0.12-1597134058916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42145,DS-5ba2bbd4-6b39-47e8-9c28-f7ce54082146,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-9cb1b856-e529-4f4a-8a0f-1285065326f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-f79642c3-06b1-4405-af4b-e4cd27d08083,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-e5522974-ba6a-4663-838a-7daceea8a604,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-bdb47bd0-8fd6-4b57-9734-cb7a54c4f388,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-8f69498b-e1f5-4120-940b-3cc59b0592b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-007e89bd-9637-4ba0-83d0-5e81d64c62fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-62cf0960-27dd-4378-bd1f-56b379c66036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323116174-172.17.0.12-1597134860003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34366,DS-7bf905f1-3a20-424b-a4bf-281cbf78fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-9e8dfdbc-3158-471a-8827-79755e18c207,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-f422d4eb-4945-42a5-a088-084dec0c8c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-bb34bbc6-7321-45b8-832d-324ddeb80b17,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-f06f6e0f-26b6-4fda-beff-c3b7426a6c37,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-24c472f7-d2ea-4f79-8729-4dc0e6bea41d,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-aaa2f333-7905-4892-9300-7a9b60979f23,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-f67c5e66-6bc4-44a5-a8c1-5a3d580f732d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323116174-172.17.0.12-1597134860003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34366,DS-7bf905f1-3a20-424b-a4bf-281cbf78fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-9e8dfdbc-3158-471a-8827-79755e18c207,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-f422d4eb-4945-42a5-a088-084dec0c8c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-bb34bbc6-7321-45b8-832d-324ddeb80b17,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-f06f6e0f-26b6-4fda-beff-c3b7426a6c37,DISK], DatanodeInfoWithStorage[127.0.0.1:46142,DS-24c472f7-d2ea-4f79-8729-4dc0e6bea41d,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-aaa2f333-7905-4892-9300-7a9b60979f23,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-f67c5e66-6bc4-44a5-a8c1-5a3d580f732d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426927991-172.17.0.12-1597135345290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40033,DS-ad33ef40-ea30-4e91-8c9d-35654a76848d,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-78508e09-df08-4cc2-8c46-c3a284b59637,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-1de90dfd-86fd-4117-946d-913a70f0d7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-3579ef1c-63e6-4478-8941-4d9e5f0fe9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-2b0a6a2b-55fb-4742-b35b-6253cd034e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-51e875c6-3e6b-4489-9002-cdd51d4c0cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-399dcc79-72e2-420a-b4cd-691676606cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-3d3f4fe3-7d8c-4872-b753-f70d681f2a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426927991-172.17.0.12-1597135345290:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40033,DS-ad33ef40-ea30-4e91-8c9d-35654a76848d,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-78508e09-df08-4cc2-8c46-c3a284b59637,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-1de90dfd-86fd-4117-946d-913a70f0d7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-3579ef1c-63e6-4478-8941-4d9e5f0fe9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-2b0a6a2b-55fb-4742-b35b-6253cd034e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-51e875c6-3e6b-4489-9002-cdd51d4c0cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-399dcc79-72e2-420a-b4cd-691676606cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-3d3f4fe3-7d8c-4872-b753-f70d681f2a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989701503-172.17.0.12-1597135521644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36815,DS-9048e5f8-1734-4f69-a330-3249254c79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-abdc8590-4bb7-4a8f-934d-7ef9096d1277,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-021ee23a-35b3-4155-9f64-a571579d05d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-4a69971a-a8db-48dd-b75d-a52a4333cec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-cd44a31a-801f-410e-bd13-9631a8d8db08,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-46717ec9-dd7c-4d25-be6c-abf7c29c99c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-006edd9f-16a3-40d6-b76e-04213cb54fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-331eec06-9772-4ca7-b1cb-f42c2a329965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-989701503-172.17.0.12-1597135521644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36815,DS-9048e5f8-1734-4f69-a330-3249254c79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-abdc8590-4bb7-4a8f-934d-7ef9096d1277,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-021ee23a-35b3-4155-9f64-a571579d05d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-4a69971a-a8db-48dd-b75d-a52a4333cec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-cd44a31a-801f-410e-bd13-9631a8d8db08,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-46717ec9-dd7c-4d25-be6c-abf7c29c99c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-006edd9f-16a3-40d6-b76e-04213cb54fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-331eec06-9772-4ca7-b1cb-f42c2a329965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747835208-172.17.0.12-1597135628152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37838,DS-fd3b41e9-5444-4cba-a852-f0267cfab131,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-f28896e4-03e3-4500-83e4-d3dfdf6abc74,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-810aae6a-ac16-40d0-83f0-d510fe56d1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-adf95178-fcba-42d3-a282-bf530166bf04,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-42ae2c6f-290f-46c9-b37a-a2cb9986cef1,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-888d8e80-ba62-48e1-81c8-1c2454fc2bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-b7bbda79-8ca8-4998-8e3d-f24ff78bb483,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-c161351c-d0d4-4d43-ba08-724da88ccbb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-747835208-172.17.0.12-1597135628152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37838,DS-fd3b41e9-5444-4cba-a852-f0267cfab131,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-f28896e4-03e3-4500-83e4-d3dfdf6abc74,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-810aae6a-ac16-40d0-83f0-d510fe56d1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-adf95178-fcba-42d3-a282-bf530166bf04,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-42ae2c6f-290f-46c9-b37a-a2cb9986cef1,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-888d8e80-ba62-48e1-81c8-1c2454fc2bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-b7bbda79-8ca8-4998-8e3d-f24ff78bb483,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-c161351c-d0d4-4d43-ba08-724da88ccbb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088852696-172.17.0.12-1597135734766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44809,DS-c50f0d99-1912-449e-ada9-7e2926268ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-c1c78456-217c-46cd-93f1-d58a0897872f,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-7fbada63-ed03-46b1-afbb-3a66ce53fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-5756afe9-eeaf-4912-9d8c-aa0cc0631efb,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-cb3358a0-cd69-4df4-821a-60f8962dce50,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-3dea2058-a9b4-4301-a125-a24367e2e37b,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-003406f8-63ef-4d54-a8f2-3b0166935b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-419eb9f0-0d37-4480-8ad5-903747f5de07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088852696-172.17.0.12-1597135734766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44809,DS-c50f0d99-1912-449e-ada9-7e2926268ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-c1c78456-217c-46cd-93f1-d58a0897872f,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-7fbada63-ed03-46b1-afbb-3a66ce53fb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-5756afe9-eeaf-4912-9d8c-aa0cc0631efb,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-cb3358a0-cd69-4df4-821a-60f8962dce50,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-3dea2058-a9b4-4301-a125-a24367e2e37b,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-003406f8-63ef-4d54-a8f2-3b0166935b30,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-419eb9f0-0d37-4480-8ad5-903747f5de07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: StopWatch is already running
stackTrace: java.lang.IllegalStateException: StopWatch is already running
	at org.apache.hadoop.util.StopWatch.start(StopWatch.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager.restartHeartbeatStopWatch(HeartbeatManager.java:317)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerTestUtil.checkHeartbeat(BlockManagerTestUtil.java:249)
	at org.apache.hadoop.hdfs.MiniDFSCluster.setDataNodeDead(MiniDFSCluster.java:2502)
	at org.apache.hadoop.hdfs.TestFileChecksum.shutdownDataNode(TestFileChecksum.java:613)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:577)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817881967-172.17.0.12-1597136224712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45325,DS-5b8fc888-fdcd-44f6-b514-ac2966b11385,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-33bfbcae-aec7-40d4-8c9d-6bca08757c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-0cb722dd-589a-46e6-a789-ae2f95164c98,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-7c04d5b9-5e73-4db9-8374-8fd59e2008a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-9b12f7e5-54ba-4440-99ba-b5397c520509,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-39cc599b-d827-4844-a134-ae46a2cde642,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-edf1d5ee-bf04-44e2-a27b-107b1907b119,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-979035fb-aba5-4493-b475-b8397aaae724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817881967-172.17.0.12-1597136224712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45325,DS-5b8fc888-fdcd-44f6-b514-ac2966b11385,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-33bfbcae-aec7-40d4-8c9d-6bca08757c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-0cb722dd-589a-46e6-a789-ae2f95164c98,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-7c04d5b9-5e73-4db9-8374-8fd59e2008a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-9b12f7e5-54ba-4440-99ba-b5397c520509,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-39cc599b-d827-4844-a134-ae46a2cde642,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-edf1d5ee-bf04-44e2-a27b-107b1907b119,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-979035fb-aba5-4493-b475-b8397aaae724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237442564-172.17.0.12-1597136741308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-48fbced1-9c50-4ffc-bb98-90d7fb88676e,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-e30fecf4-4815-4236-a748-f0bc241d4c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-ff794615-281b-45bb-937a-fa431de019a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-6fed39dd-00c0-4e9d-aab6-ac7c78ec3fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-fb12e328-149c-499a-be38-93c1b40d5785,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-5f4a5206-4ec0-49fa-a3fe-77de03fd8403,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-74e87069-6b93-405c-b697-a136d6697706,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-9af0ad42-d432-4c05-90bc-2cdf7c6c47ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237442564-172.17.0.12-1597136741308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-48fbced1-9c50-4ffc-bb98-90d7fb88676e,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-e30fecf4-4815-4236-a748-f0bc241d4c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-ff794615-281b-45bb-937a-fa431de019a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-6fed39dd-00c0-4e9d-aab6-ac7c78ec3fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-fb12e328-149c-499a-be38-93c1b40d5785,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-5f4a5206-4ec0-49fa-a3fe-77de03fd8403,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-74e87069-6b93-405c-b697-a136d6697706,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-9af0ad42-d432-4c05-90bc-2cdf7c6c47ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995266551-172.17.0.12-1597137496050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36255,DS-f4667882-5c40-41a3-bf66-d341ee220826,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-1972ace6-3cc1-4296-9758-05123819d3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-8162ed2d-2f3b-4f1e-862f-7c2e3d2b8625,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-d85e7ff7-300a-4021-81b7-d60b06fb8637,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-abac8be5-3306-4e8a-9181-209c73a7c717,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-d5c88cea-f7ee-42fe-addd-c9d4b925f410,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-c63a385d-e928-4a41-a41a-398f97abcd20,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-94f7c105-4ab9-45cc-801a-a15c356e1bea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-995266551-172.17.0.12-1597137496050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36255,DS-f4667882-5c40-41a3-bf66-d341ee220826,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-1972ace6-3cc1-4296-9758-05123819d3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-8162ed2d-2f3b-4f1e-862f-7c2e3d2b8625,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-d85e7ff7-300a-4021-81b7-d60b06fb8637,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-abac8be5-3306-4e8a-9181-209c73a7c717,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-d5c88cea-f7ee-42fe-addd-c9d4b925f410,DISK], DatanodeInfoWithStorage[127.0.0.1:37102,DS-c63a385d-e928-4a41-a41a-398f97abcd20,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-94f7c105-4ab9-45cc-801a-a15c356e1bea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703573020-172.17.0.12-1597137555816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-994d0ae0-e5a8-45ba-b85c-924ec83d313c,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-832764da-2cd7-4274-a266-6a1a6fcd630e,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-59beb73c-a047-46a9-be22-a19629a26a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-ce8e7266-c0ae-4a67-81e1-8f6d174c7a38,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-4487ac8e-da5a-4707-947c-debd4dfbcdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-a619f0fe-61dd-4877-af1f-4c815e913839,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-858692e8-70fb-425e-953e-7001b145ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-edddf493-e738-405d-95de-6cb142ec7215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703573020-172.17.0.12-1597137555816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33143,DS-994d0ae0-e5a8-45ba-b85c-924ec83d313c,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-832764da-2cd7-4274-a266-6a1a6fcd630e,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-59beb73c-a047-46a9-be22-a19629a26a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-ce8e7266-c0ae-4a67-81e1-8f6d174c7a38,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-4487ac8e-da5a-4707-947c-debd4dfbcdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-a619f0fe-61dd-4877-af1f-4c815e913839,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-858692e8-70fb-425e-953e-7001b145ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-edddf493-e738-405d-95de-6cb142ec7215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410906647-172.17.0.12-1597137907552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-a5511e56-207e-4d66-8e9c-a49ab761ae13,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-872033b9-6138-4a87-9265-d68e29faf90f,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-ef005b73-0d7e-4bd8-add3-4b3e639b4666,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-5f53380c-3306-46e3-97ec-6cea6198f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-10b1ae04-9468-490e-ba98-95c07e8783ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-b8f7d000-1c0d-4ade-96a7-58780e121131,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-7d7f5849-8f29-496c-9b6e-49fe7dc207f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-fa12fbc6-ba25-4c4a-8307-90778efc54d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410906647-172.17.0.12-1597137907552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-a5511e56-207e-4d66-8e9c-a49ab761ae13,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-872033b9-6138-4a87-9265-d68e29faf90f,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-ef005b73-0d7e-4bd8-add3-4b3e639b4666,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-5f53380c-3306-46e3-97ec-6cea6198f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-10b1ae04-9468-490e-ba98-95c07e8783ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-b8f7d000-1c0d-4ade-96a7-58780e121131,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-7d7f5849-8f29-496c-9b6e-49fe7dc207f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-fa12fbc6-ba25-4c4a-8307-90778efc54d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921481119-172.17.0.12-1597138044191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42405,DS-5643403e-607e-4e48-bdd2-e00bd099183b,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-e12898c1-a1f4-46e2-843d-782bd1d17104,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-470fc5ca-6959-4d47-8fe5-eb2070b7538e,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-4a829eb0-bc0d-48d5-8d85-91e4da343da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-ed93698d-7094-42c6-87ef-a65d4759d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-c354878f-2912-4f0b-b04e-36ce2bf95e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-a6efef5b-118a-4ecd-8c46-7854a6c096d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-3e24d9e5-106c-492f-ab91-10ce99ad7610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921481119-172.17.0.12-1597138044191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42405,DS-5643403e-607e-4e48-bdd2-e00bd099183b,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-e12898c1-a1f4-46e2-843d-782bd1d17104,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-470fc5ca-6959-4d47-8fe5-eb2070b7538e,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-4a829eb0-bc0d-48d5-8d85-91e4da343da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-ed93698d-7094-42c6-87ef-a65d4759d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-c354878f-2912-4f0b-b04e-36ce2bf95e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-a6efef5b-118a-4ecd-8c46-7854a6c096d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-3e24d9e5-106c-492f-ab91-10ce99ad7610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 0
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796400984-172.17.0.12-1597138110988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38232,DS-a54ee170-1b58-4d8e-a5e4-422ccc3fd954,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-2ed77a22-7b7f-4a8a-a987-039d340e470a,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-71d9c0ba-412a-4155-925e-9f82f15bffe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-ab2ef4c5-fd8f-419e-9734-28f7bd2b9201,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-545bdab4-b039-4dde-a1b3-4e74cbdcda38,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-a43c7b61-ea12-44e1-92aa-13e04d8cf408,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-a960e9fe-3fc2-475a-afd4-be7f666cc311,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-8386f535-55d1-430e-877d-0e6204951794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796400984-172.17.0.12-1597138110988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38232,DS-a54ee170-1b58-4d8e-a5e4-422ccc3fd954,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-2ed77a22-7b7f-4a8a-a987-039d340e470a,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-71d9c0ba-412a-4155-925e-9f82f15bffe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-ab2ef4c5-fd8f-419e-9734-28f7bd2b9201,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-545bdab4-b039-4dde-a1b3-4e74cbdcda38,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-a43c7b61-ea12-44e1-92aa-13e04d8cf408,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-a960e9fe-3fc2-475a-afd4-be7f666cc311,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-8386f535-55d1-430e-877d-0e6204951794,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5362
