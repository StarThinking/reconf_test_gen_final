reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271490734-172.17.0.19-1597096488243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34086,DS-3ddd8ee2-d44b-4e9d-b96f-25e1d673e7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-322d010d-c763-4543-ae2c-6cada63aefac,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-d9daf34a-8d8d-42d0-8263-6a99d1d64b96,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-f7f75d31-b5ef-4fc6-beb1-f04fd0836f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-7157b085-d19a-468b-abb9-a34e1b494c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-c7d1644f-6942-488f-ab3c-baec1dac6776,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-222abf22-f002-495a-8d3e-4e4a6c35a116,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-65b08abe-9c97-447c-9f05-0584d384c4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271490734-172.17.0.19-1597096488243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34086,DS-3ddd8ee2-d44b-4e9d-b96f-25e1d673e7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-322d010d-c763-4543-ae2c-6cada63aefac,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-d9daf34a-8d8d-42d0-8263-6a99d1d64b96,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-f7f75d31-b5ef-4fc6-beb1-f04fd0836f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-7157b085-d19a-468b-abb9-a34e1b494c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-c7d1644f-6942-488f-ab3c-baec1dac6776,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-222abf22-f002-495a-8d3e-4e4a6c35a116,DISK], DatanodeInfoWithStorage[127.0.0.1:43979,DS-65b08abe-9c97-447c-9f05-0584d384c4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209102175-172.17.0.19-1597096522789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44974,DS-321c45ba-dec7-4c19-a06f-c6ea73c71c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-82241e0f-abf6-485b-93d9-7b2dc52d5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-74602691-784c-4ef2-8b01-6d63c2e5f7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-95a38990-4354-49bc-86b9-6fe5ffde5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-d96eb40a-f7a5-4cdf-b42c-80c31e182a42,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-993f4b31-8e1d-439b-a16d-be72475e8910,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-3264f494-aa8a-4790-a1f9-e06190acad85,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-6feca347-9545-4360-ae48-756eed917a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209102175-172.17.0.19-1597096522789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44974,DS-321c45ba-dec7-4c19-a06f-c6ea73c71c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-82241e0f-abf6-485b-93d9-7b2dc52d5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-74602691-784c-4ef2-8b01-6d63c2e5f7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-95a38990-4354-49bc-86b9-6fe5ffde5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-d96eb40a-f7a5-4cdf-b42c-80c31e182a42,DISK], DatanodeInfoWithStorage[127.0.0.1:36281,DS-993f4b31-8e1d-439b-a16d-be72475e8910,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-3264f494-aa8a-4790-a1f9-e06190acad85,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-6feca347-9545-4360-ae48-756eed917a38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1113285105-172.17.0.19-1597096797121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-58458308-a5e1-49d9-93b0-649b46921936,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-691607a7-3ba1-4aad-b90e-c133ce2d5867,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-e590e412-b152-4546-92b8-165f3cb06e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-e971430d-4a86-4a9e-9721-7d43b7e430ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-5027c137-11ed-4205-af0f-2584ea05f715,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-ab6992fa-3fc7-4cb7-8048-2c65f7ddf981,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-92d3b5b0-a154-453d-b89f-61c6a5c82e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-ba9b7e63-5d11-49ec-8361-8d4607656148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1113285105-172.17.0.19-1597096797121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44104,DS-58458308-a5e1-49d9-93b0-649b46921936,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-691607a7-3ba1-4aad-b90e-c133ce2d5867,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-e590e412-b152-4546-92b8-165f3cb06e26,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-e971430d-4a86-4a9e-9721-7d43b7e430ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-5027c137-11ed-4205-af0f-2584ea05f715,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-ab6992fa-3fc7-4cb7-8048-2c65f7ddf981,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-92d3b5b0-a154-453d-b89f-61c6a5c82e53,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-ba9b7e63-5d11-49ec-8361-8d4607656148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029589861-172.17.0.19-1597096832437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42492,DS-3f0bee4c-c36e-47bf-be2e-12df3dfac279,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-19829758-f0b1-41d8-b8a1-8d99feca6171,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-39dadb59-ea69-49ef-a717-33347bd0f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-e3348345-5638-4901-a09e-e3c1e6d7e622,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-292af8d4-fbf9-4160-9a13-1e673387f130,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-e8603822-83bb-46b7-bd38-7f7dc359af7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-214d6012-8dd0-4949-b3d3-10663b48c9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-6e107a6e-69e4-48e4-8f8e-0996bbd37b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1029589861-172.17.0.19-1597096832437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42492,DS-3f0bee4c-c36e-47bf-be2e-12df3dfac279,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-19829758-f0b1-41d8-b8a1-8d99feca6171,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-39dadb59-ea69-49ef-a717-33347bd0f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-e3348345-5638-4901-a09e-e3c1e6d7e622,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-292af8d4-fbf9-4160-9a13-1e673387f130,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-e8603822-83bb-46b7-bd38-7f7dc359af7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-214d6012-8dd0-4949-b3d3-10663b48c9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-6e107a6e-69e4-48e4-8f8e-0996bbd37b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867941783-172.17.0.19-1597097257665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-090cc62c-621d-4444-98d2-735fbb63e834,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-fc31566b-2045-4519-ae2c-db4971e09f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-ae67e03f-c28c-4128-b220-6ef20667e94f,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-a1db09f2-084a-46f3-a41f-e2d0b96e34e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-e74e91ff-77df-4c68-86c3-ef9d7f2ae7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-0bffcc4c-4bac-4fad-9755-51936a2cce09,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-289359c5-2afd-4a7f-a30b-04041b40384a,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-0369d32d-afe4-4588-9c08-e3311a82ba5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1867941783-172.17.0.19-1597097257665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-090cc62c-621d-4444-98d2-735fbb63e834,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-fc31566b-2045-4519-ae2c-db4971e09f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-ae67e03f-c28c-4128-b220-6ef20667e94f,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-a1db09f2-084a-46f3-a41f-e2d0b96e34e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40599,DS-e74e91ff-77df-4c68-86c3-ef9d7f2ae7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-0bffcc4c-4bac-4fad-9755-51936a2cce09,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-289359c5-2afd-4a7f-a30b-04041b40384a,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-0369d32d-afe4-4588-9c08-e3311a82ba5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531849720-172.17.0.19-1597097363485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34542,DS-8c8d9754-49d9-4151-ae7f-f8f14b9d0fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-0eba5b29-199e-4bbc-b432-70fffe289ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-605bc471-3153-4fcf-be4d-1d3e7d6d63b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-c9ee0581-19a3-49db-9e21-52ecc2104195,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7c718014-93be-4c8b-b691-b5aa86a0f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-bf053bac-d6bd-484d-ae27-5572e026d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-7af6f7d6-308a-4357-95ea-6f78655698a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-dac6214e-ad7b-4615-bb66-65d646803d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1531849720-172.17.0.19-1597097363485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34542,DS-8c8d9754-49d9-4151-ae7f-f8f14b9d0fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:34471,DS-0eba5b29-199e-4bbc-b432-70fffe289ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-605bc471-3153-4fcf-be4d-1d3e7d6d63b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-c9ee0581-19a3-49db-9e21-52ecc2104195,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7c718014-93be-4c8b-b691-b5aa86a0f87e,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-bf053bac-d6bd-484d-ae27-5572e026d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-7af6f7d6-308a-4357-95ea-6f78655698a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-dac6214e-ad7b-4615-bb66-65d646803d14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371072591-172.17.0.19-1597098469385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36216,DS-1833323f-ce1e-444f-82bd-481ce0dc1bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-3a8ee487-3e38-4930-ae55-2a724202ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-7675b806-5952-4959-8f79-c80d37a13fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-a5fc39d9-c8a9-42ce-be87-c0f16616d147,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-949b6701-1855-4ae8-822b-f7e78a48142c,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-9015e281-16d0-47cc-8714-b3ac38199f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-e6bfaa58-45dc-43b4-8c3c-97600b7804fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-a33fd403-f306-43c7-ab83-864b273d4058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371072591-172.17.0.19-1597098469385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36216,DS-1833323f-ce1e-444f-82bd-481ce0dc1bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-3a8ee487-3e38-4930-ae55-2a724202ff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-7675b806-5952-4959-8f79-c80d37a13fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-a5fc39d9-c8a9-42ce-be87-c0f16616d147,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-949b6701-1855-4ae8-822b-f7e78a48142c,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-9015e281-16d0-47cc-8714-b3ac38199f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-e6bfaa58-45dc-43b4-8c3c-97600b7804fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-a33fd403-f306-43c7-ab83-864b273d4058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957110097-172.17.0.19-1597098930946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-a4bd8da7-5c03-4cbb-b205-0729aabf9898,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-fc54d9ab-9f6b-4c62-958d-38a688dc7ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-bb17d382-34ac-4608-b29b-39148ef6a1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-eff45445-36bd-424f-ad33-896c325d78d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-68e18f7d-f1c0-4c62-a5a8-6209572509d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-245b13c7-7b67-4f6a-a0e1-3747949ba857,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-6d8c0432-9515-45d1-86cf-95f5ac5e6bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-e451c8aa-d7ab-4d63-a6a1-fa1bd8367221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957110097-172.17.0.19-1597098930946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43259,DS-a4bd8da7-5c03-4cbb-b205-0729aabf9898,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-fc54d9ab-9f6b-4c62-958d-38a688dc7ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-bb17d382-34ac-4608-b29b-39148ef6a1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-eff45445-36bd-424f-ad33-896c325d78d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-68e18f7d-f1c0-4c62-a5a8-6209572509d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-245b13c7-7b67-4f6a-a0e1-3747949ba857,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-6d8c0432-9515-45d1-86cf-95f5ac5e6bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-e451c8aa-d7ab-4d63-a6a1-fa1bd8367221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324571888-172.17.0.19-1597098999589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-3f8390c9-9c33-4d33-a4f3-deb29f0fbf05,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-33dae756-238d-49f7-a9dc-d3db46d1d4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-0af72f5e-7a1a-4f52-89c1-2f4a29382293,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-6203ca3a-7311-4dc6-86b7-16792d0c38d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-09b22c68-c49f-43d5-b953-5aaf36c33504,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-78664bed-a99c-47e0-b63e-58ace7259d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-c8cf0815-4729-4d04-b750-e61383bf1690,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-7b61a6c6-5dca-41dd-b18d-ed121996ad9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1324571888-172.17.0.19-1597098999589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-3f8390c9-9c33-4d33-a4f3-deb29f0fbf05,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-33dae756-238d-49f7-a9dc-d3db46d1d4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-0af72f5e-7a1a-4f52-89c1-2f4a29382293,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-6203ca3a-7311-4dc6-86b7-16792d0c38d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-09b22c68-c49f-43d5-b953-5aaf36c33504,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-78664bed-a99c-47e0-b63e-58ace7259d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-c8cf0815-4729-4d04-b750-e61383bf1690,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-7b61a6c6-5dca-41dd-b18d-ed121996ad9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462725041-172.17.0.19-1597099036329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-d1dcaba8-355f-43e0-8431-4990d311dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-fc34125d-a12e-47eb-aa4e-d23bf0666f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-548f1d00-fb2c-44d5-8e9c-f6e31eff8350,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-6fd05ea9-9397-432c-b145-bb5495b67e05,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-c619e96b-c0e2-4343-8dae-946b1da7708b,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-cefdd404-d83b-4704-b291-d9372d1e5d15,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-07b6a1c0-033c-41a3-a9b3-17c3bf3fc6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-d33f048e-d7a7-4c5f-9850-2669bf02b8cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462725041-172.17.0.19-1597099036329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-d1dcaba8-355f-43e0-8431-4990d311dfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-fc34125d-a12e-47eb-aa4e-d23bf0666f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-548f1d00-fb2c-44d5-8e9c-f6e31eff8350,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-6fd05ea9-9397-432c-b145-bb5495b67e05,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-c619e96b-c0e2-4343-8dae-946b1da7708b,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-cefdd404-d83b-4704-b291-d9372d1e5d15,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-07b6a1c0-033c-41a3-a9b3-17c3bf3fc6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-d33f048e-d7a7-4c5f-9850-2669bf02b8cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740546281-172.17.0.19-1597099239218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-8e4a6ace-6804-4e06-ba29-42fa635dc845,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-8763605b-8280-4019-92cb-1d002bf00c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-c1b007b8-afe5-4fbb-803d-d0f6d3075b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-17a92835-ef66-4e34-94f1-cafb9ab88a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-5346826b-bbd7-4c0f-bf23-5861d73de932,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-ff4915f6-aed4-4ea4-9566-8a0c73a14d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-4d908023-31d2-4c2f-a69a-7eb70ff9dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-771e244d-c1f1-4af6-8f1f-15830810adda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740546281-172.17.0.19-1597099239218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-8e4a6ace-6804-4e06-ba29-42fa635dc845,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-8763605b-8280-4019-92cb-1d002bf00c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-c1b007b8-afe5-4fbb-803d-d0f6d3075b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-17a92835-ef66-4e34-94f1-cafb9ab88a00,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-5346826b-bbd7-4c0f-bf23-5861d73de932,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-ff4915f6-aed4-4ea4-9566-8a0c73a14d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-4d908023-31d2-4c2f-a69a-7eb70ff9dc76,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-771e244d-c1f1-4af6-8f1f-15830810adda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962735997-172.17.0.19-1597100064645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-93f02ef6-7ee7-45c1-9612-8b5fa31e8108,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-cd3a01fa-04d1-4f67-b672-e76f866d39ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-91c9f386-9605-4030-ab22-446c3afd728d,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-e06166c1-158b-48d3-a194-9eb474382113,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-bd26f2d3-b6b8-4df6-8857-365dfa051da7,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-b1c16ed1-6789-40c8-9bf6-b7e4db5a47b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-2e9926e8-c7f6-456e-9719-eb1ba8c2fc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-0d45bc5f-daa8-4262-87b5-8167d6aed763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962735997-172.17.0.19-1597100064645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-93f02ef6-7ee7-45c1-9612-8b5fa31e8108,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-cd3a01fa-04d1-4f67-b672-e76f866d39ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-91c9f386-9605-4030-ab22-446c3afd728d,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-e06166c1-158b-48d3-a194-9eb474382113,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-bd26f2d3-b6b8-4df6-8857-365dfa051da7,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-b1c16ed1-6789-40c8-9bf6-b7e4db5a47b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-2e9926e8-c7f6-456e-9719-eb1ba8c2fc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39007,DS-0d45bc5f-daa8-4262-87b5-8167d6aed763,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026834374-172.17.0.19-1597100663963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-d4d8f1fe-4a66-417a-a4ca-a755d05b1682,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-b62adbf7-47dc-441f-a7e2-f5b89e0ba661,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-f46dfaa8-3e81-4d39-bbc9-9f9b685e88c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-4f8751f6-a91b-4c3d-a483-48579d62b4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-dc7db457-68c7-4ba0-b108-05b6a92763d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-d11eb21c-1668-473c-84a2-eab0feb8c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-d813ad9a-ff56-402b-8cc0-dcc2184f1683,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-6b3b03bd-6736-497a-9689-29df9f7629f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026834374-172.17.0.19-1597100663963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43419,DS-d4d8f1fe-4a66-417a-a4ca-a755d05b1682,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-b62adbf7-47dc-441f-a7e2-f5b89e0ba661,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-f46dfaa8-3e81-4d39-bbc9-9f9b685e88c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-4f8751f6-a91b-4c3d-a483-48579d62b4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-dc7db457-68c7-4ba0-b108-05b6a92763d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-d11eb21c-1668-473c-84a2-eab0feb8c44b,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-d813ad9a-ff56-402b-8cc0-dcc2184f1683,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-6b3b03bd-6736-497a-9689-29df9f7629f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228183907-172.17.0.19-1597100861339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37638,DS-4cb05e7e-4696-42e3-ae0c-1b3ed39d23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-26905d75-ee36-4655-b7c3-939c45781b87,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-4df86a63-1886-4398-ab13-9b54e55baa08,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-f33415a5-c5a6-4d41-98e5-c6e6cf08e22c,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-adcb40da-3691-434e-870b-a5b663f5855d,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-da7fad54-d1fd-4213-b551-1ebba4f82b29,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-4a98b669-e2c8-4a8c-8512-483ec305ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-c0ca651d-ed8e-4de2-bce8-0edd8eba75a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228183907-172.17.0.19-1597100861339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37638,DS-4cb05e7e-4696-42e3-ae0c-1b3ed39d23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-26905d75-ee36-4655-b7c3-939c45781b87,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-4df86a63-1886-4398-ab13-9b54e55baa08,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-f33415a5-c5a6-4d41-98e5-c6e6cf08e22c,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-adcb40da-3691-434e-870b-a5b663f5855d,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-da7fad54-d1fd-4213-b551-1ebba4f82b29,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-4a98b669-e2c8-4a8c-8512-483ec305ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-c0ca651d-ed8e-4de2-bce8-0edd8eba75a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119765298-172.17.0.19-1597100933365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45920,DS-0d8affff-a45f-4b19-b27f-dfa8edfc353a,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-abf8c067-7267-4ca1-b2bb-21ceccadddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-f619e40f-2c3f-402b-b614-238fda9c9ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-9c939ace-fb0d-4ff1-8683-1435907fb5be,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-81314722-3208-4462-a5db-704dc0a5a0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-61d88364-d43d-4b43-b44c-7cd026de8df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-88aa0ba1-b25e-434f-b8d7-f2fe08395cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-2bf82520-44af-4606-8371-46ae09c3f422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119765298-172.17.0.19-1597100933365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45920,DS-0d8affff-a45f-4b19-b27f-dfa8edfc353a,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-abf8c067-7267-4ca1-b2bb-21ceccadddd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-f619e40f-2c3f-402b-b614-238fda9c9ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-9c939ace-fb0d-4ff1-8683-1435907fb5be,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-81314722-3208-4462-a5db-704dc0a5a0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-61d88364-d43d-4b43-b44c-7cd026de8df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-88aa0ba1-b25e-434f-b8d7-f2fe08395cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-2bf82520-44af-4606-8371-46ae09c3f422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274153038-172.17.0.19-1597101036832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33148,DS-d8bd628b-d0c2-46f3-9b3d-df04999722e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-4af90d56-dc66-451b-ba6d-cb6da008f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-b9277916-bd2f-40c6-899a-be6f2ce07595,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-772f4774-0001-4fec-820d-cd89b6206cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-8a241ecc-dac7-4611-8dcf-28b40507f909,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-1cbdca12-5209-4bbe-ba0c-d9fa70dc698f,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-96c45678-0b2e-401a-b4e6-8b3d07389874,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-b1358147-05a5-460b-9d8b-04517e29f5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274153038-172.17.0.19-1597101036832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33148,DS-d8bd628b-d0c2-46f3-9b3d-df04999722e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-4af90d56-dc66-451b-ba6d-cb6da008f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-b9277916-bd2f-40c6-899a-be6f2ce07595,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-772f4774-0001-4fec-820d-cd89b6206cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-8a241ecc-dac7-4611-8dcf-28b40507f909,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-1cbdca12-5209-4bbe-ba0c-d9fa70dc698f,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-96c45678-0b2e-401a-b4e6-8b3d07389874,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-b1358147-05a5-460b-9d8b-04517e29f5e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082222628-172.17.0.19-1597101078322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39278,DS-d9d9c879-ed38-4177-818e-e3e975a1a418,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-89aa769f-a998-4ccc-880f-b7778ba62f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-cdb30d49-c30f-4c1e-bcdc-d266da51c595,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-46fd7e79-18f4-4de7-babf-b99cbaaa2e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-4b80cb81-ac58-48f6-be48-45ab4d843291,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-b1461318-eedc-4c9e-8e8f-f5a0f3bb7aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-1bb1d8bf-9189-4fab-a67c-b79e7112ac63,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-6eccd092-fbe1-4d2b-8847-02b8a672a08b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1082222628-172.17.0.19-1597101078322:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39278,DS-d9d9c879-ed38-4177-818e-e3e975a1a418,DISK], DatanodeInfoWithStorage[127.0.0.1:45484,DS-89aa769f-a998-4ccc-880f-b7778ba62f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-cdb30d49-c30f-4c1e-bcdc-d266da51c595,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-46fd7e79-18f4-4de7-babf-b99cbaaa2e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-4b80cb81-ac58-48f6-be48-45ab4d843291,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-b1461318-eedc-4c9e-8e8f-f5a0f3bb7aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-1bb1d8bf-9189-4fab-a67c-b79e7112ac63,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-6eccd092-fbe1-4d2b-8847-02b8a672a08b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453242021-172.17.0.19-1597101359710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-68029ac1-fc4c-453c-9b13-cd6a93258225,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-2dc69d01-66b0-4624-b034-4474cc4e4204,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-37cb4875-ffea-40c2-a1f6-8ebd5a86a112,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-0d665ed0-aeab-454e-862a-caa03cc83713,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-035f9a4d-16b5-4b92-8d87-d0017bd3fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-b22de2db-3947-4b80-81ea-c4c096236414,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-1cb66c15-fb14-49a4-a60a-cd1e989b0d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-6036ad98-e93a-402c-b2cb-8f0e1de731f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1453242021-172.17.0.19-1597101359710:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-68029ac1-fc4c-453c-9b13-cd6a93258225,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-2dc69d01-66b0-4624-b034-4474cc4e4204,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-37cb4875-ffea-40c2-a1f6-8ebd5a86a112,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-0d665ed0-aeab-454e-862a-caa03cc83713,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-035f9a4d-16b5-4b92-8d87-d0017bd3fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-b22de2db-3947-4b80-81ea-c4c096236414,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-1cb66c15-fb14-49a4-a60a-cd1e989b0d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-6036ad98-e93a-402c-b2cb-8f0e1de731f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.max.limit
component: hdfs:NameNode
v1: 65536
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77376317-172.17.0.19-1597101393302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-6cbfa50f-3c65-4303-b2f7-d84163e98511,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-8f494f51-85e0-44c6-87c7-dcb99d3cfd21,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-1d9237d5-1d0e-4cde-8a60-c219e8298006,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-82e3bad4-9cdf-4d99-9525-7e5e783d991d,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-9716b9aa-59ee-45ea-8fff-2060b9dbeeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-e0c89684-a7b3-404f-b6de-f22f3d462dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-b0484f62-9850-4f99-9a1c-e9e79fb9601f,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-5c264d06-09b9-47d0-a01e-efdea2fb30b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77376317-172.17.0.19-1597101393302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-6cbfa50f-3c65-4303-b2f7-d84163e98511,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-8f494f51-85e0-44c6-87c7-dcb99d3cfd21,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-1d9237d5-1d0e-4cde-8a60-c219e8298006,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-82e3bad4-9cdf-4d99-9525-7e5e783d991d,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-9716b9aa-59ee-45ea-8fff-2060b9dbeeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-e0c89684-a7b3-404f-b6de-f22f3d462dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-b0484f62-9850-4f99-9a1c-e9e79fb9601f,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-5c264d06-09b9-47d0-a01e-efdea2fb30b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5176
