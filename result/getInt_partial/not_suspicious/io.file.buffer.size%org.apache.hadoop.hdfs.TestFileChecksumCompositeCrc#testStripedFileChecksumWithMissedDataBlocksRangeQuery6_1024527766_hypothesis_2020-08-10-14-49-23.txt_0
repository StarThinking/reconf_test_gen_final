reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759040101-172.17.0.20-1597070980260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43674,DS-34b9146e-ded1-43a1-bae5-e366af687028,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-1b1328f3-48c1-4c44-bd4b-d98b73734b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-2420f316-1993-4df2-ab09-975e906d37c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-68e5f353-1d41-4d3f-a84c-9e0a77fa2cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-c99d26b2-cbec-4412-a829-709e04bbf502,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-650b4914-9b0e-46fe-82b0-9d8e41111e68,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-9591bfa3-5051-47d6-8d37-cfc6c3a1ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-bd805dc2-33a8-4992-9f07-79ca3ceb5f8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759040101-172.17.0.20-1597070980260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43674,DS-34b9146e-ded1-43a1-bae5-e366af687028,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-1b1328f3-48c1-4c44-bd4b-d98b73734b19,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-2420f316-1993-4df2-ab09-975e906d37c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-68e5f353-1d41-4d3f-a84c-9e0a77fa2cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-c99d26b2-cbec-4412-a829-709e04bbf502,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-650b4914-9b0e-46fe-82b0-9d8e41111e68,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-9591bfa3-5051-47d6-8d37-cfc6c3a1ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-bd805dc2-33a8-4992-9f07-79ca3ceb5f8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434037730-172.17.0.20-1597071362122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-7f1d991d-2093-4740-82d9-4744d26183d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-e2305b4e-2096-4069-8593-0d21bee54eef,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-8f88997c-282d-497b-a904-8af16c762cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-16f3f528-db58-4ec1-9abd-1c16f333cde7,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-7a779d46-2377-4239-8d1b-8acffcb39416,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-712203b4-9f8b-45d7-bff6-fcf89f26f7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-04ec984b-036f-4cc4-a457-2c201729b465,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-bb3f42e1-ec14-4c6d-8d91-2aea4f6079ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434037730-172.17.0.20-1597071362122:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34691,DS-7f1d991d-2093-4740-82d9-4744d26183d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-e2305b4e-2096-4069-8593-0d21bee54eef,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-8f88997c-282d-497b-a904-8af16c762cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-16f3f528-db58-4ec1-9abd-1c16f333cde7,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-7a779d46-2377-4239-8d1b-8acffcb39416,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-712203b4-9f8b-45d7-bff6-fcf89f26f7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-04ec984b-036f-4cc4-a457-2c201729b465,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-bb3f42e1-ec14-4c6d-8d91-2aea4f6079ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323457096-172.17.0.20-1597071393557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45929,DS-87c9b79e-d8ea-4b09-aa19-8cf7a487439a,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-b90f3b56-9ca8-4117-97b7-8e38ee97c931,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-59f8b37c-a01e-4f76-9c89-f8f93f6f7ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-9a78c0e9-0cd4-4b89-a51d-90a192a8a5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-63d581da-9e18-4ef7-9344-7e1244670c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-eb1be696-6f2e-4139-823d-ed33c44b1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-26c81941-e553-46cb-a88b-ee223f0c4ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-b4414aac-c3cb-409b-b8b1-e4bb51ecd746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-323457096-172.17.0.20-1597071393557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45929,DS-87c9b79e-d8ea-4b09-aa19-8cf7a487439a,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-b90f3b56-9ca8-4117-97b7-8e38ee97c931,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-59f8b37c-a01e-4f76-9c89-f8f93f6f7ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-9a78c0e9-0cd4-4b89-a51d-90a192a8a5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35532,DS-63d581da-9e18-4ef7-9344-7e1244670c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-eb1be696-6f2e-4139-823d-ed33c44b1abc,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-26c81941-e553-46cb-a88b-ee223f0c4ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-b4414aac-c3cb-409b-b8b1-e4bb51ecd746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467762519-172.17.0.20-1597071562686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35009,DS-fc84c8b5-a640-4b54-8f90-1aebdeb8b67c,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-c2020a14-a645-4be2-8ce0-b9993ade1608,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-2c91d5e3-2b8c-45d9-a1e7-35842aa5ea45,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-106218a9-7f99-4328-a8f2-6ac48586ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-3c1702c3-8e08-4d0e-bd5f-53f3e6000d45,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-53acb9d4-43dc-4b38-8b24-4da0e58014c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-fd394f5d-cce4-4397-9189-97db9594a6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-4e366b98-ea02-4ffc-ba35-2beb67b6dac2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1467762519-172.17.0.20-1597071562686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35009,DS-fc84c8b5-a640-4b54-8f90-1aebdeb8b67c,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-c2020a14-a645-4be2-8ce0-b9993ade1608,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-2c91d5e3-2b8c-45d9-a1e7-35842aa5ea45,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-106218a9-7f99-4328-a8f2-6ac48586ef65,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-3c1702c3-8e08-4d0e-bd5f-53f3e6000d45,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-53acb9d4-43dc-4b38-8b24-4da0e58014c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-fd394f5d-cce4-4397-9189-97db9594a6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-4e366b98-ea02-4ffc-ba35-2beb67b6dac2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569875197-172.17.0.20-1597071903472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33087,DS-f8947433-1e4a-44d0-826a-18b1460cd557,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-d07608ed-7fcc-4d79-a4d8-b07904d1522e,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-5d9d2967-6c9f-448b-9ad2-143acab26243,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-8a5d2faf-eb16-443c-be98-f23cc01e98d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-36eab076-e959-4f61-a6de-f974afc4d864,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-df4d387c-cb72-437d-a75f-58a494ae43eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-d4732640-f7c0-485a-8be8-24f7c463ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-7fd8cf60-ab93-4f15-a98a-870fc9b1c504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569875197-172.17.0.20-1597071903472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33087,DS-f8947433-1e4a-44d0-826a-18b1460cd557,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-d07608ed-7fcc-4d79-a4d8-b07904d1522e,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-5d9d2967-6c9f-448b-9ad2-143acab26243,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-8a5d2faf-eb16-443c-be98-f23cc01e98d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-36eab076-e959-4f61-a6de-f974afc4d864,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-df4d387c-cb72-437d-a75f-58a494ae43eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-d4732640-f7c0-485a-8be8-24f7c463ae63,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-7fd8cf60-ab93-4f15-a98a-870fc9b1c504,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054018312-172.17.0.20-1597071981868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-4a80d240-9e02-43a4-9a2b-57edbd803239,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-d268c4b6-85d9-4afe-b974-2b46013bf00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-5d893ea5-2c4a-4d32-9335-7cbcedfd384b,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-59106fdb-a2d3-47b3-97a3-b73d429af834,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-4ead0383-6e68-4540-8da6-dcddb090ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-076aa40e-13c5-4bab-8df5-225b0011ddd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-195e4360-ce39-4337-af02-eac8f4e21e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-1adb2824-aee6-4b72-a37b-bedc201a2922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054018312-172.17.0.20-1597071981868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35827,DS-4a80d240-9e02-43a4-9a2b-57edbd803239,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-d268c4b6-85d9-4afe-b974-2b46013bf00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-5d893ea5-2c4a-4d32-9335-7cbcedfd384b,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-59106fdb-a2d3-47b3-97a3-b73d429af834,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-4ead0383-6e68-4540-8da6-dcddb090ce6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-076aa40e-13c5-4bab-8df5-225b0011ddd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-195e4360-ce39-4337-af02-eac8f4e21e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-1adb2824-aee6-4b72-a37b-bedc201a2922,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954069273-172.17.0.20-1597072364216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44223,DS-34918649-7280-4c45-b222-b3efae7b7eea,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-0f2df9ad-2814-423d-99b4-1f45d0f8a3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-287dcb59-5d18-4bbc-b899-6be5d2c71721,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-4bac9445-d1cb-4f1c-ae63-ff4007c59300,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-3e9de162-d547-4ea4-8484-df0bc3318c29,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-13f89fe9-161d-4a31-a0fe-7021f987d4df,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-6ddb25e0-f3d7-4830-afc5-4a8e4dcf7851,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-b5e48063-9bc7-46cb-8d8e-c0fa083b7941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954069273-172.17.0.20-1597072364216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44223,DS-34918649-7280-4c45-b222-b3efae7b7eea,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-0f2df9ad-2814-423d-99b4-1f45d0f8a3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-287dcb59-5d18-4bbc-b899-6be5d2c71721,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-4bac9445-d1cb-4f1c-ae63-ff4007c59300,DISK], DatanodeInfoWithStorage[127.0.0.1:44442,DS-3e9de162-d547-4ea4-8484-df0bc3318c29,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-13f89fe9-161d-4a31-a0fe-7021f987d4df,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-6ddb25e0-f3d7-4830-afc5-4a8e4dcf7851,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-b5e48063-9bc7-46cb-8d8e-c0fa083b7941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671290837-172.17.0.20-1597072520334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41167,DS-6158726c-2a30-4f08-829c-1dc0ffdc04de,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-3a6eb07b-6f5d-460f-b074-84d8bcbafb51,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-57436743-092e-4b5e-9b09-ea5557c503c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-dc7b1222-f282-446d-b0b7-7dc8bce6d6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-4d10afdf-a2c1-4437-b251-f00619d52de2,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-35a061ef-e220-40b1-91cd-cefe976c1d87,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-fb6cbaa7-69a7-461a-8e3a-5e882a386246,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-89d6f340-1d81-41bb-90cc-b2356b2bcebf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671290837-172.17.0.20-1597072520334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41167,DS-6158726c-2a30-4f08-829c-1dc0ffdc04de,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-3a6eb07b-6f5d-460f-b074-84d8bcbafb51,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-57436743-092e-4b5e-9b09-ea5557c503c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-dc7b1222-f282-446d-b0b7-7dc8bce6d6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-4d10afdf-a2c1-4437-b251-f00619d52de2,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-35a061ef-e220-40b1-91cd-cefe976c1d87,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-fb6cbaa7-69a7-461a-8e3a-5e882a386246,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-89d6f340-1d81-41bb-90cc-b2356b2bcebf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697213804-172.17.0.20-1597072726502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34332,DS-7187f03d-f501-4854-8b36-1d8d86c9427d,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-04af0b6e-2dac-458b-9072-842934fd4dac,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-9b73d1d4-9546-481a-b688-c6fad174780d,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-98458e9a-2260-43cd-a38c-ec13b0a23436,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-0477f581-327a-4dd7-b144-8889df483199,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-e8280b16-4fdf-483d-8a66-f7d930537e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-3db2ce56-b346-4034-ab0a-b82e8617aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-90f5157e-b306-4430-a28f-b200a66d43d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-697213804-172.17.0.20-1597072726502:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34332,DS-7187f03d-f501-4854-8b36-1d8d86c9427d,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-04af0b6e-2dac-458b-9072-842934fd4dac,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-9b73d1d4-9546-481a-b688-c6fad174780d,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-98458e9a-2260-43cd-a38c-ec13b0a23436,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-0477f581-327a-4dd7-b144-8889df483199,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-e8280b16-4fdf-483d-8a66-f7d930537e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-3db2ce56-b346-4034-ab0a-b82e8617aa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-90f5157e-b306-4430-a28f-b200a66d43d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322455535-172.17.0.20-1597072932021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33075,DS-8b101ebc-dec3-4259-a5e0-8df40ce6f083,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-dff5ae2c-91b3-49ca-887e-0dbb9e2303da,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-eb16f6a4-f6d2-4371-8cdc-c0a891beda0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-abbdecfe-ce7f-4842-8a5b-52e5ad256b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-a4741d2f-7eac-497d-9676-583d4b10fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-2d1d7f7a-e64d-4094-9b8d-f855ef5acd70,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-745512a0-6c3a-4502-b50d-6bd293d03406,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-533657f1-dff7-4c10-ae32-fb570e6a744d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-322455535-172.17.0.20-1597072932021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33075,DS-8b101ebc-dec3-4259-a5e0-8df40ce6f083,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-dff5ae2c-91b3-49ca-887e-0dbb9e2303da,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-eb16f6a4-f6d2-4371-8cdc-c0a891beda0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-abbdecfe-ce7f-4842-8a5b-52e5ad256b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-a4741d2f-7eac-497d-9676-583d4b10fcad,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-2d1d7f7a-e64d-4094-9b8d-f855ef5acd70,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-745512a0-6c3a-4502-b50d-6bd293d03406,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-533657f1-dff7-4c10-ae32-fb570e6a744d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697555108-172.17.0.20-1597073222565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41382,DS-61bcd4dd-f776-472c-87e2-6aa3250d4385,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-12018e28-89a0-498a-8c65-7deec9dc369c,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-9b173121-5fe1-4332-8d74-c50f2b8ff12a,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-bff9e9fc-f6d8-4576-babe-875ba21f95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-a0c8628c-1858-498d-9bc8-716c7602f238,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-3c1a9859-b44c-44b3-80f0-7bd03788ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-77000978-79f4-4888-995c-54c74051e672,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-f7f40755-d0f5-45d5-b3f7-bfc7b0c31594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697555108-172.17.0.20-1597073222565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41382,DS-61bcd4dd-f776-472c-87e2-6aa3250d4385,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-12018e28-89a0-498a-8c65-7deec9dc369c,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-9b173121-5fe1-4332-8d74-c50f2b8ff12a,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-bff9e9fc-f6d8-4576-babe-875ba21f95e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-a0c8628c-1858-498d-9bc8-716c7602f238,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-3c1a9859-b44c-44b3-80f0-7bd03788ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-77000978-79f4-4888-995c-54c74051e672,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-f7f40755-d0f5-45d5-b3f7-bfc7b0c31594,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7822011-172.17.0.20-1597073643765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38962,DS-e2e07256-101c-4d0d-81d1-6ae3db96caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-9b79aba3-868c-453b-9285-0da664467255,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-225ae7dc-39ce-40f2-9287-4bcf98cf72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-12ab589a-e039-4945-a74a-8d9c85e75428,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-62627270-7777-4f5d-bc7f-5fa8c3191fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-b38a4a78-aebc-4d13-a03d-c71314aa7f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-2ef70a73-831b-4929-a549-39b066adeae6,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-3ea9681c-900e-400c-b5af-3c73e9016200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7822011-172.17.0.20-1597073643765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38962,DS-e2e07256-101c-4d0d-81d1-6ae3db96caf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-9b79aba3-868c-453b-9285-0da664467255,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-225ae7dc-39ce-40f2-9287-4bcf98cf72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-12ab589a-e039-4945-a74a-8d9c85e75428,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-62627270-7777-4f5d-bc7f-5fa8c3191fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-b38a4a78-aebc-4d13-a03d-c71314aa7f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-2ef70a73-831b-4929-a549-39b066adeae6,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-3ea9681c-900e-400c-b5af-3c73e9016200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208252606-172.17.0.20-1597073682895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42674,DS-bde5fbfb-5e8b-438d-bfb8-6d7517411f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-914aa4c6-8fab-456b-a3ec-d94a12919bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-e1a12e5a-5a09-4159-9391-34e10148b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-806724a0-ca4e-45f6-8f5b-d74a7f57004c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-07fdeb46-d368-4d49-9e9a-85b3e00a0f98,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-1cc03b50-a128-4d15-888d-820ff44ce3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-050c79d5-779f-44ce-938e-6c3477f2d62b,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-8341d75f-8843-4e11-92da-f0568aab2a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-208252606-172.17.0.20-1597073682895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42674,DS-bde5fbfb-5e8b-438d-bfb8-6d7517411f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-914aa4c6-8fab-456b-a3ec-d94a12919bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-e1a12e5a-5a09-4159-9391-34e10148b23a,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-806724a0-ca4e-45f6-8f5b-d74a7f57004c,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-07fdeb46-d368-4d49-9e9a-85b3e00a0f98,DISK], DatanodeInfoWithStorage[127.0.0.1:39294,DS-1cc03b50-a128-4d15-888d-820ff44ce3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-050c79d5-779f-44ce-938e-6c3477f2d62b,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-8341d75f-8843-4e11-92da-f0568aab2a7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931971393-172.17.0.20-1597073902610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35125,DS-50fb7f70-cb38-4add-b724-b9bb4c53aee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-19d43209-e7e9-435c-9392-da08fca3d875,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-2892e349-b384-430c-b88e-3904e1c36d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-18fe74b9-4e26-4550-90a0-f0b0d2faa037,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-f2aea4a6-3c14-41b2-9f6b-5a6e8f641b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-ac9d6681-6d67-4f32-b302-0efccce2d0df,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-b790aadc-a1ab-4e8e-8bb8-bb63b5972abc,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-1c0e8a18-7859-4454-8ed1-cb5a40508226,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1931971393-172.17.0.20-1597073902610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35125,DS-50fb7f70-cb38-4add-b724-b9bb4c53aee5,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-19d43209-e7e9-435c-9392-da08fca3d875,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-2892e349-b384-430c-b88e-3904e1c36d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-18fe74b9-4e26-4550-90a0-f0b0d2faa037,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-f2aea4a6-3c14-41b2-9f6b-5a6e8f641b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-ac9d6681-6d67-4f32-b302-0efccce2d0df,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-b790aadc-a1ab-4e8e-8bb8-bb63b5972abc,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-1c0e8a18-7859-4454-8ed1-cb5a40508226,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294870675-172.17.0.20-1597074213134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41836,DS-4960c89f-074e-4c16-9938-ec1b34b496e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-95f90a27-f4b2-4efe-9ad2-462d240a32ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-55d774ef-1974-4f12-a0c3-db458e505a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-c401d7b0-5fdc-464d-ad23-e0924be56d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-a88a37ac-9762-490d-9469-d3858322a2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-24c3466b-cfb9-41fa-8d9b-b7585180caee,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-adfb290d-733b-4c8f-8002-d9b03ab4f501,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-7360426b-79a9-432a-8c79-9f04ccb6f223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294870675-172.17.0.20-1597074213134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41836,DS-4960c89f-074e-4c16-9938-ec1b34b496e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-95f90a27-f4b2-4efe-9ad2-462d240a32ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-55d774ef-1974-4f12-a0c3-db458e505a23,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-c401d7b0-5fdc-464d-ad23-e0924be56d69,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-a88a37ac-9762-490d-9469-d3858322a2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43569,DS-24c3466b-cfb9-41fa-8d9b-b7585180caee,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-adfb290d-733b-4c8f-8002-d9b03ab4f501,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-7360426b-79a9-432a-8c79-9f04ccb6f223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776403295-172.17.0.20-1597074689448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44357,DS-93588d74-5294-4a45-afa5-011fe9f0386e,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-3897ff3f-399f-44b0-9674-157777b38de6,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-2aa8b777-1e96-45a4-a772-6a754a8920ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-d0f9d936-b952-442c-b5ce-b1339643247a,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-68c83618-edde-4bfe-9d12-429ab5e723d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-8de2234f-eb86-4559-ba1f-c3dc31b55d91,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b73c68ca-d581-4f0c-82b9-9d2222569902,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-e376dbe5-27c6-41df-826d-31cd731d85c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776403295-172.17.0.20-1597074689448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44357,DS-93588d74-5294-4a45-afa5-011fe9f0386e,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-3897ff3f-399f-44b0-9674-157777b38de6,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-2aa8b777-1e96-45a4-a772-6a754a8920ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-d0f9d936-b952-442c-b5ce-b1339643247a,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-68c83618-edde-4bfe-9d12-429ab5e723d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-8de2234f-eb86-4559-ba1f-c3dc31b55d91,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-b73c68ca-d581-4f0c-82b9-9d2222569902,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-e376dbe5-27c6-41df-826d-31cd731d85c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050505148-172.17.0.20-1597074996134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35902,DS-2b257807-8099-4aeb-b3eb-e2bf4a14a35d,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-0e1f9da7-33a8-4475-a34c-0cde38c45fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-7d0d26c8-d35f-4826-88db-3948a2e96718,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-5b917e83-6c22-4618-9082-0068d0c47fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-e349ad47-a0df-40be-94df-1c206e653988,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-79ed46c6-9615-41ae-b609-ff26134a09e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-52834f69-54ea-484f-9530-f5762897454d,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-65c60557-d06d-49b4-84e6-cc0c4373558d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050505148-172.17.0.20-1597074996134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35902,DS-2b257807-8099-4aeb-b3eb-e2bf4a14a35d,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-0e1f9da7-33a8-4475-a34c-0cde38c45fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-7d0d26c8-d35f-4826-88db-3948a2e96718,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-5b917e83-6c22-4618-9082-0068d0c47fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-e349ad47-a0df-40be-94df-1c206e653988,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-79ed46c6-9615-41ae-b609-ff26134a09e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-52834f69-54ea-484f-9530-f5762897454d,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-65c60557-d06d-49b4-84e6-cc0c4373558d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599966233-172.17.0.20-1597075087360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37327,DS-29d4691d-d294-4b0b-8bfc-273bf08f1096,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-3a6dc5f6-e33b-47f1-a6ce-4d7d111f8f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-afd7554b-4e3b-45c9-a629-d1c21ec201dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-f783d46e-49c0-459a-92d7-614ae06c7005,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-97409b3d-d911-40b7-99e7-ed680746ba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-dd78079f-06f0-4e53-80a4-987a27326fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-64df9b5c-3924-4b04-ba47-e770a55e4b92,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-b4a54e2d-76d1-4314-a0b7-ab90186ddf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599966233-172.17.0.20-1597075087360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37327,DS-29d4691d-d294-4b0b-8bfc-273bf08f1096,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-3a6dc5f6-e33b-47f1-a6ce-4d7d111f8f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-afd7554b-4e3b-45c9-a629-d1c21ec201dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-f783d46e-49c0-459a-92d7-614ae06c7005,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-97409b3d-d911-40b7-99e7-ed680746ba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38652,DS-dd78079f-06f0-4e53-80a4-987a27326fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-64df9b5c-3924-4b04-ba47-e770a55e4b92,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-b4a54e2d-76d1-4314-a0b7-ab90186ddf29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229155479-172.17.0.20-1597075134953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38380,DS-ab8bc30e-acc0-45eb-b5fe-c2fd2c19f965,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-7c53a4aa-7b7b-47c9-9a01-f525def6ad20,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-70492ee1-4fb9-4cc8-a6c4-da77c34bca21,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-862daf74-4401-4e1f-a1c2-d5a6018b315e,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-70b3eb87-576e-482c-8850-f96410fafc46,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-c4828896-249d-4662-b53f-9dbc27f8c9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-95d52970-4d7e-4e98-8015-3c9fdcc83fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-5d24c2c3-62e3-4a47-84c2-16e86f651360,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229155479-172.17.0.20-1597075134953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38380,DS-ab8bc30e-acc0-45eb-b5fe-c2fd2c19f965,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-7c53a4aa-7b7b-47c9-9a01-f525def6ad20,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-70492ee1-4fb9-4cc8-a6c4-da77c34bca21,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-862daf74-4401-4e1f-a1c2-d5a6018b315e,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-70b3eb87-576e-482c-8850-f96410fafc46,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-c4828896-249d-4662-b53f-9dbc27f8c9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-95d52970-4d7e-4e98-8015-3c9fdcc83fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-5d24c2c3-62e3-4a47-84c2-16e86f651360,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312136573-172.17.0.20-1597075289343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42925,DS-3804ed17-616b-4b34-851e-7b6b76399bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-b02790b3-b374-4702-8d4a-d9da7f22b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-a63c62a1-c3ca-4012-804b-967b889678a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-d266e72c-cead-4a9b-93ae-dbea95667fba,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-c048c398-afa0-4481-a385-feb57bff83f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-dae122b9-b761-48a3-bccf-e0b89c991c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-1e0cd5b2-b1ef-4187-a0ec-1e8730a14918,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-c15260c3-2507-4da6-bab1-906970853dbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312136573-172.17.0.20-1597075289343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42925,DS-3804ed17-616b-4b34-851e-7b6b76399bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-b02790b3-b374-4702-8d4a-d9da7f22b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-a63c62a1-c3ca-4012-804b-967b889678a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-d266e72c-cead-4a9b-93ae-dbea95667fba,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-c048c398-afa0-4481-a385-feb57bff83f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-dae122b9-b761-48a3-bccf-e0b89c991c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-1e0cd5b2-b1ef-4187-a0ec-1e8730a14918,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-c15260c3-2507-4da6-bab1-906970853dbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011480041-172.17.0.20-1597075323496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40097,DS-21dd7e28-4567-4d15-a741-3eae5fdae942,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-91291aa3-f57e-4a8f-8787-8f93193e3680,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-461535bb-4bd4-47a9-8fa6-6717a0624af8,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-fe6faabc-80e4-4cc5-a0f5-aa9f6752cb71,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-ce9bf3fc-2e1d-4e4b-b3df-e9bacf855217,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-5c416740-83a2-4399-a2e5-a27941bc76f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-bf4957ea-2216-405a-9e41-62789114f176,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-63428e19-db68-4b69-aaf6-533c07132d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011480041-172.17.0.20-1597075323496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40097,DS-21dd7e28-4567-4d15-a741-3eae5fdae942,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-91291aa3-f57e-4a8f-8787-8f93193e3680,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-461535bb-4bd4-47a9-8fa6-6717a0624af8,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-fe6faabc-80e4-4cc5-a0f5-aa9f6752cb71,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-ce9bf3fc-2e1d-4e4b-b3df-e9bacf855217,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-5c416740-83a2-4399-a2e5-a27941bc76f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-bf4957ea-2216-405a-9e41-62789114f176,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-63428e19-db68-4b69-aaf6-533c07132d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599083358-172.17.0.20-1597075420823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-c9359918-192f-40a8-914c-b174d241ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-60b4f803-9ba3-49e7-95d2-133a6edddf15,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-cad573b1-b99d-4895-bf00-b9d45de43704,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-29bd1c50-ab00-44eb-9a83-c377dbd4e335,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-2e02bc12-7e71-4bd3-8c27-fc6e32650802,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-3ed80f0f-a808-4377-8b03-2fd3395c68e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-4af98895-35de-4ff8-9f75-36b6de3fbd54,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-0f12bb09-4e66-4f3f-b282-dff34e3d3c26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599083358-172.17.0.20-1597075420823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37047,DS-c9359918-192f-40a8-914c-b174d241ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-60b4f803-9ba3-49e7-95d2-133a6edddf15,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-cad573b1-b99d-4895-bf00-b9d45de43704,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-29bd1c50-ab00-44eb-9a83-c377dbd4e335,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-2e02bc12-7e71-4bd3-8c27-fc6e32650802,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-3ed80f0f-a808-4377-8b03-2fd3395c68e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-4af98895-35de-4ff8-9f75-36b6de3fbd54,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-0f12bb09-4e66-4f3f-b282-dff34e3d3c26,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513571937-172.17.0.20-1597075590780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39892,DS-3c8bba8e-806c-4b31-aef1-dd5a07c28210,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-f4f93f74-6c75-44bc-ace4-4357fef3d481,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-98299517-8c12-4f64-b030-1069a9b0c1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-a7502386-ff81-4b64-87cd-0bb99b559c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-b31f02d8-2a72-46ae-820e-b2ce64b7e2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-e6f6a675-74be-4f2c-841c-3a0587be12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-2d9587e3-992f-4d7a-83ec-7e10b0e8ed01,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-9542e2eb-8247-4cab-a762-99abca326621,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-513571937-172.17.0.20-1597075590780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39892,DS-3c8bba8e-806c-4b31-aef1-dd5a07c28210,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-f4f93f74-6c75-44bc-ace4-4357fef3d481,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-98299517-8c12-4f64-b030-1069a9b0c1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-a7502386-ff81-4b64-87cd-0bb99b559c17,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-b31f02d8-2a72-46ae-820e-b2ce64b7e2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-e6f6a675-74be-4f2c-841c-3a0587be12ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-2d9587e3-992f-4d7a-83ec-7e10b0e8ed01,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-9542e2eb-8247-4cab-a762-99abca326621,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425684613-172.17.0.20-1597075751367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-8b92597b-71b9-48dd-9ffc-4bc12babd901,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-08872aee-efd7-475a-9dbb-b28527aea7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-2dd6f18b-737d-445a-befd-03c7044447e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-8e2cbf75-d8ee-4cb8-8320-97322a732441,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-0b84ba2e-7909-4239-a4ec-788601066000,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-a75964b3-90ec-4e8e-b9c2-dedec5253f69,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-791d92fd-061f-4a8f-8946-07063997d0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-aa66474d-8f5a-41eb-a840-9cb061823936,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425684613-172.17.0.20-1597075751367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-8b92597b-71b9-48dd-9ffc-4bc12babd901,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-08872aee-efd7-475a-9dbb-b28527aea7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-2dd6f18b-737d-445a-befd-03c7044447e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-8e2cbf75-d8ee-4cb8-8320-97322a732441,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-0b84ba2e-7909-4239-a4ec-788601066000,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-a75964b3-90ec-4e8e-b9c2-dedec5253f69,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-791d92fd-061f-4a8f-8946-07063997d0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-aa66474d-8f5a-41eb-a840-9cb061823936,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257190676-172.17.0.20-1597076005197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-d8624825-9b79-438b-aa28-2c10919c2773,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-673b08a4-a9ad-4439-a1d6-6931c1958137,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-c03d508d-8f3d-4884-823d-9d5e0f832a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-a7efd215-ab30-4a60-96a2-d9bf311d7244,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-c93222d9-a09f-4fe1-baa2-f76e4e3fcd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-65b3b7d1-2693-43c2-8022-f7d4d8589265,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-0f1dcdde-aef9-4b41-bd2f-06949225c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-189eb00c-ab48-4bd2-a4de-cc99b3ebd4b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257190676-172.17.0.20-1597076005197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33351,DS-d8624825-9b79-438b-aa28-2c10919c2773,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-673b08a4-a9ad-4439-a1d6-6931c1958137,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-c03d508d-8f3d-4884-823d-9d5e0f832a63,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-a7efd215-ab30-4a60-96a2-d9bf311d7244,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-c93222d9-a09f-4fe1-baa2-f76e4e3fcd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-65b3b7d1-2693-43c2-8022-f7d4d8589265,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-0f1dcdde-aef9-4b41-bd2f-06949225c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-189eb00c-ab48-4bd2-a4de-cc99b3ebd4b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593992314-172.17.0.20-1597076091904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-f0b58388-f45b-4d8a-a422-fd2fe4827a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-396da329-9d32-446d-9228-3a2aba1b048e,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-887075cb-ed83-46f2-92f8-bd852b7f3a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-54e66be3-327b-4989-8d75-e7a46efd8a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-a84091bd-a918-40cc-ba09-fb2939c7088f,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-63f13873-18ab-4eb2-8dcf-2cc490fd9028,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-7eebbdc3-72d7-4800-b6e4-910324a5abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-f4affbc1-1daf-4f75-b9bb-75dbd6ac5889,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593992314-172.17.0.20-1597076091904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38095,DS-f0b58388-f45b-4d8a-a422-fd2fe4827a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-396da329-9d32-446d-9228-3a2aba1b048e,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-887075cb-ed83-46f2-92f8-bd852b7f3a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-54e66be3-327b-4989-8d75-e7a46efd8a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-a84091bd-a918-40cc-ba09-fb2939c7088f,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-63f13873-18ab-4eb2-8dcf-2cc490fd9028,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-7eebbdc3-72d7-4800-b6e4-910324a5abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-f4affbc1-1daf-4f75-b9bb-75dbd6ac5889,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779665715-172.17.0.20-1597076125346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-4a695822-e54a-4bf6-bdb8-e2a6999b2588,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-727cdf12-eb46-4d57-98ee-674a9062bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-874cde9e-932f-4ecc-a28b-733a78cb9583,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-f64d1378-2111-4fe0-9d84-2a4aa060e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-bb6071c1-b508-40a1-aedd-24b75909853f,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-2e836aba-9f8c-4c09-9874-95099eeea02b,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-9b8b5da8-d4c2-4ff2-adf2-a5393e6275fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-8f19ba9c-8550-4d5b-b6e5-46408942ae45,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779665715-172.17.0.20-1597076125346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38307,DS-4a695822-e54a-4bf6-bdb8-e2a6999b2588,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-727cdf12-eb46-4d57-98ee-674a9062bb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-874cde9e-932f-4ecc-a28b-733a78cb9583,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-f64d1378-2111-4fe0-9d84-2a4aa060e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-bb6071c1-b508-40a1-aedd-24b75909853f,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-2e836aba-9f8c-4c09-9874-95099eeea02b,DISK], DatanodeInfoWithStorage[127.0.0.1:34461,DS-9b8b5da8-d4c2-4ff2-adf2-a5393e6275fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-8f19ba9c-8550-4d5b-b6e5-46408942ae45,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942908103-172.17.0.20-1597076160409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44519,DS-220a5475-b927-4167-afe7-05ad80aeac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-d19208d2-63ed-413c-ad44-06f6d371a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-bb9fd499-4aa9-43b7-a99e-c241cdec49f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-ca6e8baa-73da-4264-a55e-6a104a0b0ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-d1c3701b-d69b-411a-85e2-89843783215c,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-51b4c08c-e652-4c2e-be90-0f79a114100a,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-37592831-3bb4-42e6-a212-4cffc4b4861c,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-bcedcfab-4a6d-407d-b8bd-dc308e4c7c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942908103-172.17.0.20-1597076160409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44519,DS-220a5475-b927-4167-afe7-05ad80aeac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-d19208d2-63ed-413c-ad44-06f6d371a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-bb9fd499-4aa9-43b7-a99e-c241cdec49f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-ca6e8baa-73da-4264-a55e-6a104a0b0ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-d1c3701b-d69b-411a-85e2-89843783215c,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-51b4c08c-e652-4c2e-be90-0f79a114100a,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-37592831-3bb4-42e6-a212-4cffc4b4861c,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-bcedcfab-4a6d-407d-b8bd-dc308e4c7c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626662185-172.17.0.20-1597076368426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43634,DS-91e6c082-e26e-4601-be99-2ce5aa819a34,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-9b98d345-eb65-46f9-aa28-d618d5a7f873,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-28ed1914-6aa6-4395-862f-0b83c4581cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-c628d041-93a0-4e6b-9ef6-b7eab76e431b,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-f3a64325-77c3-4eeb-a0a3-1c0c6203fba4,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-efb58977-1698-4542-8db8-9de4a5bf996c,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-f1b867c9-a08e-4891-a563-67d6787ddff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-61a459cb-3335-4984-993e-67ef5b79b2f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626662185-172.17.0.20-1597076368426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43634,DS-91e6c082-e26e-4601-be99-2ce5aa819a34,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-9b98d345-eb65-46f9-aa28-d618d5a7f873,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-28ed1914-6aa6-4395-862f-0b83c4581cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-c628d041-93a0-4e6b-9ef6-b7eab76e431b,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-f3a64325-77c3-4eeb-a0a3-1c0c6203fba4,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-efb58977-1698-4542-8db8-9de4a5bf996c,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-f1b867c9-a08e-4891-a563-67d6787ddff0,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-61a459cb-3335-4984-993e-67ef5b79b2f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877012813-172.17.0.20-1597076648354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-c40a0e3a-d6c2-43e9-8e4e-dc9c34d17b29,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-4929fcf2-b343-43a4-8f89-cbbaf2fcb977,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-6eee179e-ea92-4455-9d10-aad1a78a6e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-bd1dfddc-51d4-49c5-9315-d50848ce0ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-22df966d-0288-4a08-b123-0c4836b79ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-8173990b-329e-4b86-a860-016ea76861c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-6d1c4d8b-686c-48c3-af96-74eb2770630b,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-a6ababfc-ccc0-428e-834a-6f19c9a36023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877012813-172.17.0.20-1597076648354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44150,DS-c40a0e3a-d6c2-43e9-8e4e-dc9c34d17b29,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-4929fcf2-b343-43a4-8f89-cbbaf2fcb977,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-6eee179e-ea92-4455-9d10-aad1a78a6e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-bd1dfddc-51d4-49c5-9315-d50848ce0ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-22df966d-0288-4a08-b123-0c4836b79ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-8173990b-329e-4b86-a860-016ea76861c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-6d1c4d8b-686c-48c3-af96-74eb2770630b,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-a6ababfc-ccc0-428e-834a-6f19c9a36023,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4194304
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805151115-172.17.0.20-1597076850079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45080,DS-63564325-e417-44fb-9ac3-259c2ff719fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-6aea8080-ab54-4980-9ff5-0d97638cca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-e68a986e-22a6-4ef8-a0a4-ad7f019f4f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-ba2ef723-2c08-492f-bfc8-5187d6bc755f,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-b1455ac4-e1db-41cd-a4de-029b37ec9db5,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-39ea2e35-c1e3-4382-b0d0-b8b0f1ffd6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-d8f8b3d0-f257-467c-9ec9-e567760a0940,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-32e06c6f-6b12-4dc5-8d68-a2948225b011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-805151115-172.17.0.20-1597076850079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45080,DS-63564325-e417-44fb-9ac3-259c2ff719fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45052,DS-6aea8080-ab54-4980-9ff5-0d97638cca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-e68a986e-22a6-4ef8-a0a4-ad7f019f4f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-ba2ef723-2c08-492f-bfc8-5187d6bc755f,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-b1455ac4-e1db-41cd-a4de-029b37ec9db5,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-39ea2e35-c1e3-4382-b0d0-b8b0f1ffd6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33856,DS-d8f8b3d0-f257-467c-9ec9-e567760a0940,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-32e06c6f-6b12-4dc5-8d68-a2948225b011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6231
