reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851670138-172.17.0.10-1597170350872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-2cc1d701-cedc-49ff-9da1-3c9f928c6e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-59a41972-9893-4978-9c42-b8aa8a6ea4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-ccdf1ff1-1f92-4a52-8547-2b4f6fca01f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-976942c1-f209-41a2-8f71-4ed1ff06eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-84d7aa2d-1440-455e-80ed-2ee4d5f529f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-95fd4aa5-58e7-446f-beca-e4740b1f563a,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-6a854dfe-d1e9-4b98-a1c7-7b1eac78399e,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-c4baa984-7d06-42d0-8c8c-47cd4764fedb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851670138-172.17.0.10-1597170350872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-2cc1d701-cedc-49ff-9da1-3c9f928c6e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-59a41972-9893-4978-9c42-b8aa8a6ea4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-ccdf1ff1-1f92-4a52-8547-2b4f6fca01f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-976942c1-f209-41a2-8f71-4ed1ff06eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-84d7aa2d-1440-455e-80ed-2ee4d5f529f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-95fd4aa5-58e7-446f-beca-e4740b1f563a,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-6a854dfe-d1e9-4b98-a1c7-7b1eac78399e,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-c4baa984-7d06-42d0-8c8c-47cd4764fedb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430756533-172.17.0.10-1597170547354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35877,DS-30040c47-d906-4005-abc2-6170ea824817,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-b462733e-eaf1-41c1-8ee9-d24b1ec58cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-e3de40a9-7f25-4437-aeb2-12c361bd3d32,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-5e5bfb94-3c1e-4dd4-af43-4955cfc65f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-11e84618-44a1-4c6f-bf6a-2316f30cdbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-7197e0b7-61e0-4207-a9d8-ac72e02498e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-6bff691a-710a-404c-9b70-8e6ceac6ccf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-a6ffd4c1-9cb9-4f4f-b9aa-2d097c3795ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430756533-172.17.0.10-1597170547354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35877,DS-30040c47-d906-4005-abc2-6170ea824817,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-b462733e-eaf1-41c1-8ee9-d24b1ec58cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-e3de40a9-7f25-4437-aeb2-12c361bd3d32,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-5e5bfb94-3c1e-4dd4-af43-4955cfc65f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-11e84618-44a1-4c6f-bf6a-2316f30cdbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-7197e0b7-61e0-4207-a9d8-ac72e02498e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-6bff691a-710a-404c-9b70-8e6ceac6ccf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-a6ffd4c1-9cb9-4f4f-b9aa-2d097c3795ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138730620-172.17.0.10-1597170964224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-544283ff-da2b-4621-b045-90f674258af6,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-938b00d6-55d0-451e-933c-5646f9167680,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-b09ef05b-09bc-4d92-90c1-db321c021162,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-b277621e-b1bf-4a24-a382-693f044c54dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-c44c198e-e94f-4f76-962d-4980c43fef08,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-907ed3f9-d055-4689-9555-fa65f15292de,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-c8e7acf8-dbff-482f-95a8-5b0d3ce598de,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-06f98d8c-450d-453d-819f-9b0557104a10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-138730620-172.17.0.10-1597170964224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36881,DS-544283ff-da2b-4621-b045-90f674258af6,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-938b00d6-55d0-451e-933c-5646f9167680,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-b09ef05b-09bc-4d92-90c1-db321c021162,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-b277621e-b1bf-4a24-a382-693f044c54dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-c44c198e-e94f-4f76-962d-4980c43fef08,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-907ed3f9-d055-4689-9555-fa65f15292de,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-c8e7acf8-dbff-482f-95a8-5b0d3ce598de,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-06f98d8c-450d-453d-819f-9b0557104a10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028610309-172.17.0.10-1597171245965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-41d628b4-5846-459f-bd76-28c7ade88765,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-1d1cb839-5577-4318-8e3d-b86bf3b04093,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-f82e3acf-3fcb-45cd-8b45-b4396455c73f,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-8a6c9807-f9a2-451f-b5b4-1edc6df0442c,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-b9c7ee46-da7a-4a82-b634-53b374115755,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-dce5b4b8-e85b-4e27-bb03-0b8491073fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-1fb440c4-5478-4bee-8389-82ecb6c86532,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-de5a1e02-d8f3-4f0f-beb4-087528c2ef8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028610309-172.17.0.10-1597171245965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-41d628b4-5846-459f-bd76-28c7ade88765,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-1d1cb839-5577-4318-8e3d-b86bf3b04093,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-f82e3acf-3fcb-45cd-8b45-b4396455c73f,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-8a6c9807-f9a2-451f-b5b4-1edc6df0442c,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-b9c7ee46-da7a-4a82-b634-53b374115755,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-dce5b4b8-e85b-4e27-bb03-0b8491073fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:37844,DS-1fb440c4-5478-4bee-8389-82ecb6c86532,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-de5a1e02-d8f3-4f0f-beb4-087528c2ef8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050552752-172.17.0.10-1597171660907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-9faf8531-fdae-4844-ade5-50ed962fb21d,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-15c4008f-2faf-4505-b425-aa1f05b9f6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-60f0164a-4207-45db-abab-c76781b6db46,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-6562a164-690e-41d6-a362-14386ac7deda,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-88198730-c0e4-492e-86b5-79b63eaf5f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-341ca796-6db9-40da-a392-a3f82a610d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-e0ca089d-5bf8-4a13-a1cf-5e26fb198aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-0e36715d-7f91-46f0-bc84-272611d455d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050552752-172.17.0.10-1597171660907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-9faf8531-fdae-4844-ade5-50ed962fb21d,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-15c4008f-2faf-4505-b425-aa1f05b9f6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-60f0164a-4207-45db-abab-c76781b6db46,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-6562a164-690e-41d6-a362-14386ac7deda,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-88198730-c0e4-492e-86b5-79b63eaf5f46,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-341ca796-6db9-40da-a392-a3f82a610d19,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-e0ca089d-5bf8-4a13-a1cf-5e26fb198aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-0e36715d-7f91-46f0-bc84-272611d455d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053205303-172.17.0.10-1597172407840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38070,DS-ddc3e504-a366-43c7-971b-60da366e2f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-8c316907-9932-42f4-b054-1479dd015b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-8d28a9f6-d343-453f-b7d9-293dfb64b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-ed96f199-c845-4684-ae6a-6ca6109405ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-fac2fed4-5f21-494f-b15c-cb4c68bc80c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-92b62fbc-7357-4702-9aa9-d88e313def5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-1966fc65-6f91-461f-9272-d2728aab98bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-d3d75af9-7912-46e7-9222-165ade088c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053205303-172.17.0.10-1597172407840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38070,DS-ddc3e504-a366-43c7-971b-60da366e2f24,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-8c316907-9932-42f4-b054-1479dd015b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-8d28a9f6-d343-453f-b7d9-293dfb64b0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-ed96f199-c845-4684-ae6a-6ca6109405ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-fac2fed4-5f21-494f-b15c-cb4c68bc80c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-92b62fbc-7357-4702-9aa9-d88e313def5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-1966fc65-6f91-461f-9272-d2728aab98bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-d3d75af9-7912-46e7-9222-165ade088c1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901315542-172.17.0.10-1597172945932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36097,DS-6dad7452-216e-4186-85fc-9cdee52b3399,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-28830af3-054e-476b-b2a2-f225acfeb711,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-18b3b50c-0c43-4475-979b-2d1fd723bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-bc4ef601-7095-4874-8573-335875c8b7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-49610395-31a0-414f-b3ab-af126157f9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-40a8cb98-1c9d-4868-ac0e-86e5da7f3e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-2695c069-597c-4ae1-aeec-dab46c5ffff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-a190c121-fb68-44b6-b14e-e43fc8556129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901315542-172.17.0.10-1597172945932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36097,DS-6dad7452-216e-4186-85fc-9cdee52b3399,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-28830af3-054e-476b-b2a2-f225acfeb711,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-18b3b50c-0c43-4475-979b-2d1fd723bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-bc4ef601-7095-4874-8573-335875c8b7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-49610395-31a0-414f-b3ab-af126157f9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-40a8cb98-1c9d-4868-ac0e-86e5da7f3e02,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-2695c069-597c-4ae1-aeec-dab46c5ffff4,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-a190c121-fb68-44b6-b14e-e43fc8556129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579684833-172.17.0.10-1597173130416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34123,DS-d43444a6-381e-47ed-bf3a-ee91298b9f72,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-12393f87-cd97-44cc-bafd-5f9ebff8ae5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-3c50ad36-6b0f-4b7b-a956-705793a68227,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-9e15e552-4b02-4e22-84e0-56ce474f6505,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-d4006cef-beb3-4aba-9b0f-af5fdd45d899,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-79000bce-7c45-4c88-902d-a15b83349849,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-7bc3da99-8933-496e-8f50-6b58bc6b1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-97e728ff-4830-4827-9740-ce407c37f348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579684833-172.17.0.10-1597173130416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34123,DS-d43444a6-381e-47ed-bf3a-ee91298b9f72,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-12393f87-cd97-44cc-bafd-5f9ebff8ae5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-3c50ad36-6b0f-4b7b-a956-705793a68227,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-9e15e552-4b02-4e22-84e0-56ce474f6505,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-d4006cef-beb3-4aba-9b0f-af5fdd45d899,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-79000bce-7c45-4c88-902d-a15b83349849,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-7bc3da99-8933-496e-8f50-6b58bc6b1e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-97e728ff-4830-4827-9740-ce407c37f348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443628346-172.17.0.10-1597173234599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35551,DS-c994da94-25b5-40c9-9c0a-53dd2a7a93bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-71288659-26ab-477e-bb1d-9e7d29749d06,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-2a74c83d-70d7-4538-8287-07b6012afc91,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-8949d421-c6b4-464b-8a36-c9fb8691a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-60694ad0-f6be-46ec-a13f-2f80a4346235,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-b0eedeb7-db98-4a43-8224-15bdf91fdd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-a9d894e2-dc70-448e-8f3a-30ab1510f301,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-2282d467-d344-4d14-ba60-5f62d3763ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443628346-172.17.0.10-1597173234599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35551,DS-c994da94-25b5-40c9-9c0a-53dd2a7a93bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-71288659-26ab-477e-bb1d-9e7d29749d06,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-2a74c83d-70d7-4538-8287-07b6012afc91,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-8949d421-c6b4-464b-8a36-c9fb8691a15d,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-60694ad0-f6be-46ec-a13f-2f80a4346235,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-b0eedeb7-db98-4a43-8224-15bdf91fdd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-a9d894e2-dc70-448e-8f3a-30ab1510f301,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-2282d467-d344-4d14-ba60-5f62d3763ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306006648-172.17.0.10-1597173687780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34170,DS-a206d2d8-7c81-4cb1-b482-91079b3f4563,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-71abdde0-2161-4356-a165-2a8fc4eeee85,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-7ebf01d4-87bf-43d6-96e7-42f6956dc035,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-49578e71-22ea-44d6-8602-7d2211e987b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-4630bf75-f30e-44cf-8174-9b665f75f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-7cd274ac-9b9f-4492-b11b-1f679bc8821d,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-cd8ab37e-ff3b-44ef-a23c-4bc8d1f699bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-3c6edadd-4154-44e8-9561-5c3b1fee9fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306006648-172.17.0.10-1597173687780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34170,DS-a206d2d8-7c81-4cb1-b482-91079b3f4563,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-71abdde0-2161-4356-a165-2a8fc4eeee85,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-7ebf01d4-87bf-43d6-96e7-42f6956dc035,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-49578e71-22ea-44d6-8602-7d2211e987b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-4630bf75-f30e-44cf-8174-9b665f75f16e,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-7cd274ac-9b9f-4492-b11b-1f679bc8821d,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-cd8ab37e-ff3b-44ef-a23c-4bc8d1f699bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34620,DS-3c6edadd-4154-44e8-9561-5c3b1fee9fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625682804-172.17.0.10-1597173864577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35358,DS-e19848ec-3c20-4bf9-97ae-c29ac3301bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-c523a555-544d-44b7-9a58-19be12af47aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-db4860f4-1a77-46d1-81ca-d57ba52f5583,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-18b1b7c1-f66c-40c3-883d-7ef72adbcee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-3ec3521d-70df-4468-9444-a368bb9a3600,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-76fe21cf-5dcf-4b71-9c67-23aec1e2dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-0cd2ca0e-6a13-4dfe-bc11-ea296b270058,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-510b18c9-0516-4f8b-9cf0-ac8a50eff529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625682804-172.17.0.10-1597173864577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35358,DS-e19848ec-3c20-4bf9-97ae-c29ac3301bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-c523a555-544d-44b7-9a58-19be12af47aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-db4860f4-1a77-46d1-81ca-d57ba52f5583,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-18b1b7c1-f66c-40c3-883d-7ef72adbcee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-3ec3521d-70df-4468-9444-a368bb9a3600,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-76fe21cf-5dcf-4b71-9c67-23aec1e2dbd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-0cd2ca0e-6a13-4dfe-bc11-ea296b270058,DISK], DatanodeInfoWithStorage[127.0.0.1:34447,DS-510b18c9-0516-4f8b-9cf0-ac8a50eff529,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031548627-172.17.0.10-1597173928387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42141,DS-ef5e7eed-ab79-43cf-b419-7def422422de,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-e0416592-cd46-4c16-a0f7-e03d95cf60bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-75b42a85-043d-4831-91a9-d852c543c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-de69d877-336c-466d-818b-3554fc04753e,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-1b7563ed-4bbd-4661-916f-2bd7b79d6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-894b218b-d430-4515-a667-0e4a1199ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-ebed9e2e-df68-4492-82c0-4dc4c8fa0fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-6607aaec-6460-4c6b-b730-2a94333bc554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031548627-172.17.0.10-1597173928387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42141,DS-ef5e7eed-ab79-43cf-b419-7def422422de,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-e0416592-cd46-4c16-a0f7-e03d95cf60bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-75b42a85-043d-4831-91a9-d852c543c70c,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-de69d877-336c-466d-818b-3554fc04753e,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-1b7563ed-4bbd-4661-916f-2bd7b79d6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-894b218b-d430-4515-a667-0e4a1199ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-ebed9e2e-df68-4492-82c0-4dc4c8fa0fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-6607aaec-6460-4c6b-b730-2a94333bc554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711825178-172.17.0.10-1597174111791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-f8541cfc-9763-4ecc-8ec3-9647c2262f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-c569bc18-dd7e-4cc2-a079-2d169f35774c,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-21ca76ba-6a8c-4a80-b009-fabb06eb2fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-1f125f82-67b1-4eff-8a1c-1f6017752b15,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-aa72a3b9-2f40-4897-89bd-53385a39b1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-f967e6ac-b10c-4043-b3ee-314b554f6ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-a64de5f5-9740-4961-bea2-66e310cffb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-3ac65f84-2c17-4f7d-a04b-a1127511fe22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-711825178-172.17.0.10-1597174111791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-f8541cfc-9763-4ecc-8ec3-9647c2262f86,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-c569bc18-dd7e-4cc2-a079-2d169f35774c,DISK], DatanodeInfoWithStorage[127.0.0.1:37680,DS-21ca76ba-6a8c-4a80-b009-fabb06eb2fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-1f125f82-67b1-4eff-8a1c-1f6017752b15,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-aa72a3b9-2f40-4897-89bd-53385a39b1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-f967e6ac-b10c-4043-b3ee-314b554f6ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-a64de5f5-9740-4961-bea2-66e310cffb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-3ac65f84-2c17-4f7d-a04b-a1127511fe22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494231109-172.17.0.10-1597174758113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42893,DS-cb49b040-d397-44c4-a2e1-9457470123c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-fbe4a1ad-ae66-4778-a891-a92749021889,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-25e6b574-680c-4ef1-9283-bb7d0e09e898,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-e1aec97a-d282-4e10-8b15-97b3a9f45236,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-fd934515-2370-412c-a41b-77bafbd5baef,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-e811cf12-4510-4886-8989-535507f751d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-f0c40b1e-ac26-4038-8c9e-9c0ead7b23e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-94bb1169-29bd-4d43-96b8-aa2d993333b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494231109-172.17.0.10-1597174758113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42893,DS-cb49b040-d397-44c4-a2e1-9457470123c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-fbe4a1ad-ae66-4778-a891-a92749021889,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-25e6b574-680c-4ef1-9283-bb7d0e09e898,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-e1aec97a-d282-4e10-8b15-97b3a9f45236,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-fd934515-2370-412c-a41b-77bafbd5baef,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-e811cf12-4510-4886-8989-535507f751d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-f0c40b1e-ac26-4038-8c9e-9c0ead7b23e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39432,DS-94bb1169-29bd-4d43-96b8-aa2d993333b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 400
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022722367-172.17.0.10-1597175301972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-bef6e1a1-4cad-4f89-84db-88615d77bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-2ef82a46-0dec-4024-80fd-76f79c58e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-7c13bb96-427a-44b2-b3b7-9b27cda41449,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-814af312-2f29-40d9-8ebc-09d4c33fc54e,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-3b501123-d4a5-4870-bc40-fce48fd88baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-afe83cdb-5fd1-4da0-bb23-2b10f980885d,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-70bc112b-f496-493b-a5c1-c494967bdefb,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-3b2cba7d-6b38-44df-911e-b7f750790543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022722367-172.17.0.10-1597175301972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-bef6e1a1-4cad-4f89-84db-88615d77bef2,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-2ef82a46-0dec-4024-80fd-76f79c58e8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41134,DS-7c13bb96-427a-44b2-b3b7-9b27cda41449,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-814af312-2f29-40d9-8ebc-09d4c33fc54e,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-3b501123-d4a5-4870-bc40-fce48fd88baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-afe83cdb-5fd1-4da0-bb23-2b10f980885d,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-70bc112b-f496-493b-a5c1-c494967bdefb,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-3b2cba7d-6b38-44df-911e-b7f750790543,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5492
