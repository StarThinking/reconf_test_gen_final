reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210735887-172.17.0.10-1597153598942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-e025726a-873c-4225-aa59-9895de8c2c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-28289570-43c4-4311-8611-7d00fe6e2288,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-53d45c0e-7371-4443-803d-3d0418904e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-8c0574ef-e97f-4f1e-a038-cda030976574,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-f66b406c-2a3c-47ce-89d4-e597bbeb06b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-6dc33a4c-9d02-495c-9b8d-8b7046aedd31,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-85319d89-5089-4290-9b9b-5eaba47dbe44,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-ee1ca9c3-0270-4184-975f-3ca442daee56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210735887-172.17.0.10-1597153598942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36582,DS-e025726a-873c-4225-aa59-9895de8c2c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-28289570-43c4-4311-8611-7d00fe6e2288,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-53d45c0e-7371-4443-803d-3d0418904e26,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-8c0574ef-e97f-4f1e-a038-cda030976574,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-f66b406c-2a3c-47ce-89d4-e597bbeb06b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-6dc33a4c-9d02-495c-9b8d-8b7046aedd31,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-85319d89-5089-4290-9b9b-5eaba47dbe44,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-ee1ca9c3-0270-4184-975f-3ca442daee56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692970812-172.17.0.10-1597153865559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46531,DS-76f8b9bb-3280-4acd-a570-ba063951d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-7452f940-1f03-4569-97a9-009c628a3270,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-dd523442-22b9-4d3d-9a65-4ce657203d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-6824ac5e-1c92-4065-8334-bc1bc85f92a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-afa2b1a1-b0e5-4e34-884f-8a72d5021a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-a2c8f223-b04d-402d-bea5-3d6c7fbb07f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-0706d98e-882f-4379-9971-3adc1c8d62dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-a40f2728-20e7-4a63-92ca-86d4e49c303c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1692970812-172.17.0.10-1597153865559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46531,DS-76f8b9bb-3280-4acd-a570-ba063951d6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-7452f940-1f03-4569-97a9-009c628a3270,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-dd523442-22b9-4d3d-9a65-4ce657203d96,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-6824ac5e-1c92-4065-8334-bc1bc85f92a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-afa2b1a1-b0e5-4e34-884f-8a72d5021a55,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-a2c8f223-b04d-402d-bea5-3d6c7fbb07f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-0706d98e-882f-4379-9971-3adc1c8d62dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-a40f2728-20e7-4a63-92ca-86d4e49c303c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736019610-172.17.0.10-1597153937935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-f02701cc-284f-4656-a556-2a48e3a7f787,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-b88e3f65-6907-4390-bf80-baa860956777,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-91b82952-7f0e-4a83-93fd-a02f6901827f,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-e28d52bb-a715-478c-bc58-660c7adc3764,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-5222b647-941e-47e8-b8db-b75d7a2a9317,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-9682a0ac-4c31-4b27-9ddc-1648762273b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-e4668989-468a-4c2b-bc25-7a6fa0364337,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-4a9adbc6-c26c-44dd-bd4c-bbd0d6231c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736019610-172.17.0.10-1597153937935:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41762,DS-f02701cc-284f-4656-a556-2a48e3a7f787,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-b88e3f65-6907-4390-bf80-baa860956777,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-91b82952-7f0e-4a83-93fd-a02f6901827f,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-e28d52bb-a715-478c-bc58-660c7adc3764,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-5222b647-941e-47e8-b8db-b75d7a2a9317,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-9682a0ac-4c31-4b27-9ddc-1648762273b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-e4668989-468a-4c2b-bc25-7a6fa0364337,DISK], DatanodeInfoWithStorage[127.0.0.1:38073,DS-4a9adbc6-c26c-44dd-bd4c-bbd0d6231c0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742230726-172.17.0.10-1597154143169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-046d8369-2207-4c2a-bef4-7d8d2f12a070,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-d550156b-0a0b-42f4-a81c-903709cf775e,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-35b79449-8dfb-45e7-8af8-992e82585bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-2d704e3f-5bdb-4de8-9b99-ae3c04a900e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-c2574cef-fad2-40e2-b5a1-846acfa8e900,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-ed3b7892-994c-4c6d-a97f-c538dda310c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-16bfbb7f-5474-4b63-908a-cfc73e455134,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-10eb8c6d-4f08-4628-a870-275a0164b1e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742230726-172.17.0.10-1597154143169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-046d8369-2207-4c2a-bef4-7d8d2f12a070,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-d550156b-0a0b-42f4-a81c-903709cf775e,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-35b79449-8dfb-45e7-8af8-992e82585bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-2d704e3f-5bdb-4de8-9b99-ae3c04a900e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-c2574cef-fad2-40e2-b5a1-846acfa8e900,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-ed3b7892-994c-4c6d-a97f-c538dda310c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-16bfbb7f-5474-4b63-908a-cfc73e455134,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-10eb8c6d-4f08-4628-a870-275a0164b1e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512385571-172.17.0.10-1597154719620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35206,DS-2c20007b-ad43-4c1b-991f-b4393005e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-34e89653-3b83-4dbb-8da3-197f1c1aa5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-8c23332d-a6f6-4dab-9295-549449358dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-259377cd-e5bf-4c97-9ac5-8bd8970e8499,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-3fd7625e-69bc-4b7f-9263-1fde05fcb447,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-20ce9ac1-58e5-4204-a019-65afc8c17496,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-6f41d380-0365-4fde-851e-834d9f1ec8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-dd1300da-3089-4795-b6ae-34dd3fe8e57d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512385571-172.17.0.10-1597154719620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35206,DS-2c20007b-ad43-4c1b-991f-b4393005e6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-34e89653-3b83-4dbb-8da3-197f1c1aa5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-8c23332d-a6f6-4dab-9295-549449358dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-259377cd-e5bf-4c97-9ac5-8bd8970e8499,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-3fd7625e-69bc-4b7f-9263-1fde05fcb447,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-20ce9ac1-58e5-4204-a019-65afc8c17496,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-6f41d380-0365-4fde-851e-834d9f1ec8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-dd1300da-3089-4795-b6ae-34dd3fe8e57d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753859415-172.17.0.10-1597155230875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-28c1d064-5b61-437f-946f-839c6b6ca169,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-6c8a3113-fd13-4d8c-a12e-ccfc6404f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-741a33ce-ebb0-41c3-b37d-0211f201aabc,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-58ac93d7-ff18-4705-b07b-3915667037f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-00d5a9cd-8674-4dc1-b6f3-63e9d8b6cc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-6c1b8557-6046-4db4-9e76-f69057f9aa28,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-fdadc2d0-7be2-4e27-9d3f-5a709fdb30a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-849b7622-b1ca-42cb-8c02-9167e515c400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753859415-172.17.0.10-1597155230875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-28c1d064-5b61-437f-946f-839c6b6ca169,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-6c8a3113-fd13-4d8c-a12e-ccfc6404f6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-741a33ce-ebb0-41c3-b37d-0211f201aabc,DISK], DatanodeInfoWithStorage[127.0.0.1:42464,DS-58ac93d7-ff18-4705-b07b-3915667037f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-00d5a9cd-8674-4dc1-b6f3-63e9d8b6cc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-6c1b8557-6046-4db4-9e76-f69057f9aa28,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-fdadc2d0-7be2-4e27-9d3f-5a709fdb30a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-849b7622-b1ca-42cb-8c02-9167e515c400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921728485-172.17.0.10-1597155458419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40801,DS-a15bc2c4-ada0-4c90-86e8-9032463bbc31,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-b0bcf7a2-14ce-45d5-ac59-71de596183b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-86a1df1d-60c5-44b1-914f-70c7f6227124,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-5d699ade-eba6-4117-9ca7-93c36ef8ed1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-190c16db-5280-4937-a457-3b1939df285d,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-dad0d09a-2fbd-43c3-9316-be127a098e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-5ab3e160-944d-4b31-84bf-17a2e571faee,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-73394d70-afa0-4d5d-9f51-c5f8a57d076a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921728485-172.17.0.10-1597155458419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40801,DS-a15bc2c4-ada0-4c90-86e8-9032463bbc31,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-b0bcf7a2-14ce-45d5-ac59-71de596183b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-86a1df1d-60c5-44b1-914f-70c7f6227124,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-5d699ade-eba6-4117-9ca7-93c36ef8ed1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-190c16db-5280-4937-a457-3b1939df285d,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-dad0d09a-2fbd-43c3-9316-be127a098e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-5ab3e160-944d-4b31-84bf-17a2e571faee,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-73394d70-afa0-4d5d-9f51-c5f8a57d076a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425305937-172.17.0.10-1597155828452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-ccc3a78b-ccc3-4b50-ad79-dfcc816def0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-3a8c9bc4-a49e-4af6-9e21-a89163fb9938,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-a215bb31-6a5d-4c47-ae3f-d2fc94f252f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-8d7a6671-42d9-4c89-aac5-ab4ac388e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-9d695baa-5e53-4d39-8c8b-08a343c639b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-f12bef13-7aad-444b-aff9-ef89aeac6145,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-b74d1c96-b5d0-4ab2-b217-1fb55955199c,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-4bf2bc3b-0324-4db1-8427-b32bc28e8b4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425305937-172.17.0.10-1597155828452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37772,DS-ccc3a78b-ccc3-4b50-ad79-dfcc816def0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-3a8c9bc4-a49e-4af6-9e21-a89163fb9938,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-a215bb31-6a5d-4c47-ae3f-d2fc94f252f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-8d7a6671-42d9-4c89-aac5-ab4ac388e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-9d695baa-5e53-4d39-8c8b-08a343c639b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-f12bef13-7aad-444b-aff9-ef89aeac6145,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-b74d1c96-b5d0-4ab2-b217-1fb55955199c,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-4bf2bc3b-0324-4db1-8427-b32bc28e8b4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597407327-172.17.0.10-1597155865073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-a2c30bc0-a430-4b30-b5f6-d6330556debe,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-b12196a5-d236-44e7-987e-b2179c45c448,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-38b5ed63-e260-4b17-b67b-4f7dc458651e,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-f4ea8db5-8d70-4ec1-aaf0-1533f789462c,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-6fa07d8e-3966-45db-9527-25263598c9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-3e51654f-a39e-43fc-b1f3-48b76b5bfe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-64c9ffa4-a5ef-4616-baea-cfde0c3a4481,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-38a65714-a8ef-4af3-a32b-9b431642ddac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597407327-172.17.0.10-1597155865073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44073,DS-a2c30bc0-a430-4b30-b5f6-d6330556debe,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-b12196a5-d236-44e7-987e-b2179c45c448,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-38b5ed63-e260-4b17-b67b-4f7dc458651e,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-f4ea8db5-8d70-4ec1-aaf0-1533f789462c,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-6fa07d8e-3966-45db-9527-25263598c9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-3e51654f-a39e-43fc-b1f3-48b76b5bfe1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-64c9ffa4-a5ef-4616-baea-cfde0c3a4481,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-38a65714-a8ef-4af3-a32b-9b431642ddac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529146698-172.17.0.10-1597156066509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35000,DS-6c6c6526-d2d0-49ac-b438-9e5a96531289,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-6295c482-444b-4ef9-b4a5-eb7b47225b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-4810910d-4c02-48b2-bc45-77dea9ed75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-1b51b38f-65e5-4631-8889-77637237f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-c62b96ef-c3bf-4699-be56-16ef5a0dfd47,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-b5f6bb2f-134a-4548-8958-297713045ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-9fa41121-3070-4597-9eb3-8d0d4a8f5bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-5a998476-8fa3-4af8-aa54-d83be0c2e172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1529146698-172.17.0.10-1597156066509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35000,DS-6c6c6526-d2d0-49ac-b438-9e5a96531289,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-6295c482-444b-4ef9-b4a5-eb7b47225b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-4810910d-4c02-48b2-bc45-77dea9ed75e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-1b51b38f-65e5-4631-8889-77637237f0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-c62b96ef-c3bf-4699-be56-16ef5a0dfd47,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-b5f6bb2f-134a-4548-8958-297713045ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-9fa41121-3070-4597-9eb3-8d0d4a8f5bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-5a998476-8fa3-4af8-aa54-d83be0c2e172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430294557-172.17.0.10-1597156094046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34939,DS-2a0dc890-4b82-489d-bcb6-f4bebeab35dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-2a1f085d-695d-404f-b555-2f157c017493,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-ac47553e-5a97-4b37-b98f-3e65339e7547,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-fdfc38bb-ff25-4060-9414-9afe1b915309,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-e69ecced-8886-494a-8d6a-43a7d1d44568,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-b8230925-b5e3-49e2-bbca-5515f92f1e71,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-792b6c6f-cb15-485d-90ff-130203e68164,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-b7b59ae2-cb28-48c1-aa7d-cd346dc1fe55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430294557-172.17.0.10-1597156094046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34939,DS-2a0dc890-4b82-489d-bcb6-f4bebeab35dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-2a1f085d-695d-404f-b555-2f157c017493,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-ac47553e-5a97-4b37-b98f-3e65339e7547,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-fdfc38bb-ff25-4060-9414-9afe1b915309,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-e69ecced-8886-494a-8d6a-43a7d1d44568,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-b8230925-b5e3-49e2-bbca-5515f92f1e71,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-792b6c6f-cb15-485d-90ff-130203e68164,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-b7b59ae2-cb28-48c1-aa7d-cd346dc1fe55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278180756-172.17.0.10-1597156153684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41825,DS-8cf07fc3-9748-44a2-9580-8c049ee74be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-d71b21ac-7532-4a19-882a-83a912896fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-b838d140-bfe7-4c87-a17a-5f3d11e909b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-a499c013-3952-4be5-b0aa-899ea9a3adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-bde3a824-6a86-4f1e-83f4-fe20e48147e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-876f6354-21ee-4442-9b54-87c4698e380b,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-248b5cc3-4ccf-424e-9765-50a31fec2152,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-bbb0ddcf-d921-48fd-acc8-c7cbb83da407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278180756-172.17.0.10-1597156153684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41825,DS-8cf07fc3-9748-44a2-9580-8c049ee74be5,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-d71b21ac-7532-4a19-882a-83a912896fce,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-b838d140-bfe7-4c87-a17a-5f3d11e909b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-a499c013-3952-4be5-b0aa-899ea9a3adc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-bde3a824-6a86-4f1e-83f4-fe20e48147e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-876f6354-21ee-4442-9b54-87c4698e380b,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-248b5cc3-4ccf-424e-9765-50a31fec2152,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-bbb0ddcf-d921-48fd-acc8-c7cbb83da407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025387097-172.17.0.10-1597156587556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-89a83d85-0ee1-4ff8-a46f-3dabf8373dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-cff66dd3-ea40-417f-8ea1-9d8a261dad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-7916ee9e-093c-4dd8-b968-20cae17bdc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-385d3503-6736-4ce9-b036-a184810ee15c,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-f4aabd59-1c1f-4441-854e-733cd55a7b58,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-b7e338fa-7f34-4d88-9c89-0cefe7299ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-be95b8ae-d45b-4ea8-955c-ba5e1c8b50dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-8b45a789-d786-45fe-ab8c-bf722d7581c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025387097-172.17.0.10-1597156587556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39418,DS-89a83d85-0ee1-4ff8-a46f-3dabf8373dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-cff66dd3-ea40-417f-8ea1-9d8a261dad2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-7916ee9e-093c-4dd8-b968-20cae17bdc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-385d3503-6736-4ce9-b036-a184810ee15c,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-f4aabd59-1c1f-4441-854e-733cd55a7b58,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-b7e338fa-7f34-4d88-9c89-0cefe7299ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-be95b8ae-d45b-4ea8-955c-ba5e1c8b50dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-8b45a789-d786-45fe-ab8c-bf722d7581c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482432363-172.17.0.10-1597157042335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41067,DS-5dbd4955-0c19-4901-9537-8b2a7b89cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-e0586d90-d639-41ab-8b0b-ba7199ff403b,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-61da320a-cde4-4e70-bf46-14f5636f8488,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-79a38503-06f8-47f8-b5b9-eceb7879d0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-77ed0f79-cef0-48a1-b8b1-97db340bee72,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-6d43d0fc-ffca-4f90-ba3c-9bd4466167d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-128a7c7d-c46c-4496-aaf1-c81450464614,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-9615bbf8-f3c5-4e38-b2aa-33bac5154c04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482432363-172.17.0.10-1597157042335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41067,DS-5dbd4955-0c19-4901-9537-8b2a7b89cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-e0586d90-d639-41ab-8b0b-ba7199ff403b,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-61da320a-cde4-4e70-bf46-14f5636f8488,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-79a38503-06f8-47f8-b5b9-eceb7879d0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-77ed0f79-cef0-48a1-b8b1-97db340bee72,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-6d43d0fc-ffca-4f90-ba3c-9bd4466167d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-128a7c7d-c46c-4496-aaf1-c81450464614,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-9615bbf8-f3c5-4e38-b2aa-33bac5154c04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647259492-172.17.0.10-1597157104191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-25c568d4-7d70-4f62-92a1-50f2edd524a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-5e6f5266-a838-4497-8d7e-082e11b471bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-e9849e57-9517-49f0-bca6-b0e505423802,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-a5457173-f503-430e-b97b-2213b2c68413,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-3bb8ea3f-1522-4413-a920-2dd843f2d008,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-a6d75bab-8903-4098-bdb1-120f089a76fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-6d120ee7-d24d-4c27-a7e0-4276d778faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-83c1e899-956a-4858-a728-c1be4d125b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647259492-172.17.0.10-1597157104191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43138,DS-25c568d4-7d70-4f62-92a1-50f2edd524a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-5e6f5266-a838-4497-8d7e-082e11b471bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-e9849e57-9517-49f0-bca6-b0e505423802,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-a5457173-f503-430e-b97b-2213b2c68413,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-3bb8ea3f-1522-4413-a920-2dd843f2d008,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-a6d75bab-8903-4098-bdb1-120f089a76fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-6d120ee7-d24d-4c27-a7e0-4276d778faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40155,DS-83c1e899-956a-4858-a728-c1be4d125b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732857956-172.17.0.10-1597157566486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46632,DS-4f93d26a-fcc8-4c0e-a883-db93c3cb1987,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-fb912d85-3e3c-45f9-8b1b-c77ef97846ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-ff645301-02d2-48cc-a6cc-8d73af422d72,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-30daaa37-3aa0-4bf5-908d-4964a2010ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-7e1229dd-2d8e-48bc-a994-fdd043986955,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-a9f882a3-7bed-4763-a0e1-c9defbb3322c,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-f67547cb-8a46-4955-9240-8dcac7a26231,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-d5797eed-1a13-4fc6-bfc7-4a0a50d3295a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732857956-172.17.0.10-1597157566486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46632,DS-4f93d26a-fcc8-4c0e-a883-db93c3cb1987,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-fb912d85-3e3c-45f9-8b1b-c77ef97846ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-ff645301-02d2-48cc-a6cc-8d73af422d72,DISK], DatanodeInfoWithStorage[127.0.0.1:35294,DS-30daaa37-3aa0-4bf5-908d-4964a2010ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-7e1229dd-2d8e-48bc-a994-fdd043986955,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-a9f882a3-7bed-4763-a0e1-c9defbb3322c,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-f67547cb-8a46-4955-9240-8dcac7a26231,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-d5797eed-1a13-4fc6-bfc7-4a0a50d3295a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500938524-172.17.0.10-1597157624415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36297,DS-fae5aff0-7c6d-4bbb-b009-68990047fe52,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-47c36a15-b994-49fe-958b-006fb3c0ef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-19fff870-cd23-4e60-baf8-fe4f468413a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-3ac09141-cd1e-4735-8d81-af9aa2e20d86,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-828377a0-52fe-4652-81d0-927fe32b7643,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-eeeda01b-424f-4113-8d7c-ba8e3fb1c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-7013d337-e7a3-472f-a5d0-211000c7b194,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-e63767fd-5654-4749-b4a5-3fafe1849cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500938524-172.17.0.10-1597157624415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36297,DS-fae5aff0-7c6d-4bbb-b009-68990047fe52,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-47c36a15-b994-49fe-958b-006fb3c0ef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-19fff870-cd23-4e60-baf8-fe4f468413a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-3ac09141-cd1e-4735-8d81-af9aa2e20d86,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-828377a0-52fe-4652-81d0-927fe32b7643,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-eeeda01b-424f-4113-8d7c-ba8e3fb1c30d,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-7013d337-e7a3-472f-a5d0-211000c7b194,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-e63767fd-5654-4749-b4a5-3fafe1849cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681967787-172.17.0.10-1597157931150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-066cd59a-d6a5-4233-b93c-ba9696eb1f76,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-3caa70a1-3d6e-457c-bfd7-673546f73929,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-f3da3e0b-7eee-4de0-850b-c90ad60370dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-3f29e0d0-7337-4245-a2df-356ca532c726,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-21b28933-58f9-419b-af22-60a0b0903479,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-470269f5-2fdf-47ff-bd20-7afba5f22070,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-8b41b1e4-522d-4b82-afb5-29a8291ebca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-690cf606-1ef0-4db5-baf4-83d8b81809d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681967787-172.17.0.10-1597157931150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36148,DS-066cd59a-d6a5-4233-b93c-ba9696eb1f76,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-3caa70a1-3d6e-457c-bfd7-673546f73929,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-f3da3e0b-7eee-4de0-850b-c90ad60370dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-3f29e0d0-7337-4245-a2df-356ca532c726,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-21b28933-58f9-419b-af22-60a0b0903479,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-470269f5-2fdf-47ff-bd20-7afba5f22070,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-8b41b1e4-522d-4b82-afb5-29a8291ebca2,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-690cf606-1ef0-4db5-baf4-83d8b81809d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968325390-172.17.0.10-1597158042116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-058c9dde-fc1b-490b-b752-555b176211b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-188aff74-7783-49a5-b658-ff29d0dfb11c,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-4e574f9d-273d-4719-9cc1-7f75dfffb851,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-5f6e8908-a91e-4c45-ad57-22655c4d20f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-407e59c0-788a-4c2c-88e5-09dae4102981,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-ac54e803-3d14-4330-b0b8-1fc6698a7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-f5899163-73ac-48cd-8c9f-66e9b92db91a,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-cea77aa1-78d5-48f1-be5f-3fee64bd5b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968325390-172.17.0.10-1597158042116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-058c9dde-fc1b-490b-b752-555b176211b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-188aff74-7783-49a5-b658-ff29d0dfb11c,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-4e574f9d-273d-4719-9cc1-7f75dfffb851,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-5f6e8908-a91e-4c45-ad57-22655c4d20f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-407e59c0-788a-4c2c-88e5-09dae4102981,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-ac54e803-3d14-4330-b0b8-1fc6698a7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-f5899163-73ac-48cd-8c9f-66e9b92db91a,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-cea77aa1-78d5-48f1-be5f-3fee64bd5b05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923957138-172.17.0.10-1597158078357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40449,DS-27e1edd5-0d6e-491b-9eab-4d6c34367019,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-ed60176b-2bfb-4729-a885-a08272e86659,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-b4359490-58e2-4e73-9dc7-265b3d9ce276,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-7ec2a86e-f559-44ef-9a98-14f775076643,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-1b495242-0add-4655-9850-f30dbe2fa16d,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-e8c4c57d-7f64-49a0-bc9d-d00566650294,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-280f629c-6e76-4eb0-9edf-e65a9d94ae01,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-6ee376ed-5813-4977-bce4-5f5f42b98670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923957138-172.17.0.10-1597158078357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40449,DS-27e1edd5-0d6e-491b-9eab-4d6c34367019,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-ed60176b-2bfb-4729-a885-a08272e86659,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-b4359490-58e2-4e73-9dc7-265b3d9ce276,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-7ec2a86e-f559-44ef-9a98-14f775076643,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-1b495242-0add-4655-9850-f30dbe2fa16d,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-e8c4c57d-7f64-49a0-bc9d-d00566650294,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-280f629c-6e76-4eb0-9edf-e65a9d94ae01,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-6ee376ed-5813-4977-bce4-5f5f42b98670,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 128
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059271935-172.17.0.10-1597158436616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40565,DS-47250a7d-681a-4566-b747-9e8a57508910,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-d82c1df5-c4d6-4da3-966d-b883f4dad383,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-61883366-2325-4b0e-973e-8dbd16eec986,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-2f5d4992-88c7-485f-9f61-de1a855d67f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-4db50a92-f5fe-46f0-8c06-5fa2496afdef,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-0ac86e85-9322-49a8-9a38-fec41474bf64,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-c4c5608a-5a62-4b82-8749-8247c9517df8,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-5addac52-3fd2-4b40-9152-8d8644e26d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059271935-172.17.0.10-1597158436616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40565,DS-47250a7d-681a-4566-b747-9e8a57508910,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-d82c1df5-c4d6-4da3-966d-b883f4dad383,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-61883366-2325-4b0e-973e-8dbd16eec986,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-2f5d4992-88c7-485f-9f61-de1a855d67f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-4db50a92-f5fe-46f0-8c06-5fa2496afdef,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-0ac86e85-9322-49a8-9a38-fec41474bf64,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-c4c5608a-5a62-4b82-8749-8247c9517df8,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-5addac52-3fd2-4b40-9152-8d8644e26d5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4944
