reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250447431-172.17.0.16-1597106159456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44135,DS-bcd0b18d-ea79-4009-a8cb-d51148d092a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-b4620399-eddb-4177-b699-35e34011cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-2967716b-4b91-48a4-9580-a280f69f6094,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-02eac8df-156e-491e-a8d6-4057f1218ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-f188ed91-9536-46e4-8b9f-fcf955e57583,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-fe0260ad-2b8e-44cd-8976-0625837b5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-3a8407fe-2ba8-41a6-b309-e45f93ef05f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-cad9bef8-428a-4598-865f-7b3b9008a653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250447431-172.17.0.16-1597106159456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44135,DS-bcd0b18d-ea79-4009-a8cb-d51148d092a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-b4620399-eddb-4177-b699-35e34011cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-2967716b-4b91-48a4-9580-a280f69f6094,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-02eac8df-156e-491e-a8d6-4057f1218ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-f188ed91-9536-46e4-8b9f-fcf955e57583,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-fe0260ad-2b8e-44cd-8976-0625837b5b75,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-3a8407fe-2ba8-41a6-b309-e45f93ef05f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-cad9bef8-428a-4598-865f-7b3b9008a653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785640002-172.17.0.16-1597106626760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35196,DS-5b73cea3-33a9-4eda-9174-4e0b49b1e249,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-c95c67c0-28bf-4c8f-8ffd-0db9ebe3ca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-113eaa15-9448-412d-a4db-1cf184cfaee2,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-0350562b-70f3-43cc-8364-7c455696d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-c7622398-e64d-4394-9985-c4aa541b6f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-019ded00-f7e0-42a8-99d0-cc6d9eaf6f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-4a820377-3911-4f64-bc4b-b22dbdb076ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-93324fad-8de4-4f0e-8d89-ef98accc5c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785640002-172.17.0.16-1597106626760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35196,DS-5b73cea3-33a9-4eda-9174-4e0b49b1e249,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-c95c67c0-28bf-4c8f-8ffd-0db9ebe3ca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-113eaa15-9448-412d-a4db-1cf184cfaee2,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-0350562b-70f3-43cc-8364-7c455696d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-c7622398-e64d-4394-9985-c4aa541b6f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-019ded00-f7e0-42a8-99d0-cc6d9eaf6f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-4a820377-3911-4f64-bc4b-b22dbdb076ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-93324fad-8de4-4f0e-8d89-ef98accc5c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856363316-172.17.0.16-1597107022417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-3f349bd4-d52b-4d80-827f-e63265810084,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-5acc9609-729e-4f40-978e-ab527f20c523,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-683a7edb-7790-4009-bdf3-c4e7e3855d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-013b2d34-2dd3-444f-afa0-5b6da9964044,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-2cda6b05-b1fc-4600-84fd-704c2304c1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-3dfcefe6-ee95-45d6-ad60-419a55d096d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-3c87ab4a-3cf1-4680-90f5-cf67f67d0ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-3e63f931-8014-44de-afbc-dcca19c9e882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856363316-172.17.0.16-1597107022417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36593,DS-3f349bd4-d52b-4d80-827f-e63265810084,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-5acc9609-729e-4f40-978e-ab527f20c523,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-683a7edb-7790-4009-bdf3-c4e7e3855d16,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-013b2d34-2dd3-444f-afa0-5b6da9964044,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-2cda6b05-b1fc-4600-84fd-704c2304c1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-3dfcefe6-ee95-45d6-ad60-419a55d096d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-3c87ab4a-3cf1-4680-90f5-cf67f67d0ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-3e63f931-8014-44de-afbc-dcca19c9e882,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483745080-172.17.0.16-1597107051334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-ea08fbdb-537e-4a42-87be-5376cccc6155,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-eb7bfad5-a43b-430c-abc7-b2fc2b6da979,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-4add4425-b83b-4a79-bf49-8efe8ed829cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-efc5dcac-4296-4b37-928a-873c91e3a204,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-224da4df-fdc2-4c01-b513-849e38c39f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-d552aed3-6c44-4cbf-8537-d36d22fd39b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-22aca925-2c84-4078-b1ea-cb871f665886,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-fd20bc68-04be-41f3-8762-5d7db8ebbad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483745080-172.17.0.16-1597107051334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40191,DS-ea08fbdb-537e-4a42-87be-5376cccc6155,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-eb7bfad5-a43b-430c-abc7-b2fc2b6da979,DISK], DatanodeInfoWithStorage[127.0.0.1:45624,DS-4add4425-b83b-4a79-bf49-8efe8ed829cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-efc5dcac-4296-4b37-928a-873c91e3a204,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-224da4df-fdc2-4c01-b513-849e38c39f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-d552aed3-6c44-4cbf-8537-d36d22fd39b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-22aca925-2c84-4078-b1ea-cb871f665886,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-fd20bc68-04be-41f3-8762-5d7db8ebbad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465887211-172.17.0.16-1597107361569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-92b170e6-6996-4cc1-b9e1-7b4caa5ad210,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-a0217ed7-d4f6-47e9-929f-e5b4cbfb99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-c3d90b34-7de4-4152-92e8-9dcdd673b57c,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-5d08b57c-83eb-40b0-bfe8-f89159296792,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-5ebcebea-6b9e-4f0b-8e6e-051cf71921d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-546c6d19-283a-4bdd-b3b8-2a4d5b53ebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-223e6b5d-0f42-439b-a8fa-a4068fbd0395,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-8e9f2960-854a-4c72-969d-1b0cc23b70ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465887211-172.17.0.16-1597107361569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-92b170e6-6996-4cc1-b9e1-7b4caa5ad210,DISK], DatanodeInfoWithStorage[127.0.0.1:46734,DS-a0217ed7-d4f6-47e9-929f-e5b4cbfb99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-c3d90b34-7de4-4152-92e8-9dcdd673b57c,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-5d08b57c-83eb-40b0-bfe8-f89159296792,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-5ebcebea-6b9e-4f0b-8e6e-051cf71921d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-546c6d19-283a-4bdd-b3b8-2a4d5b53ebd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-223e6b5d-0f42-439b-a8fa-a4068fbd0395,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-8e9f2960-854a-4c72-969d-1b0cc23b70ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553110317-172.17.0.16-1597107585674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43476,DS-f2f4d1ba-0d1e-4a1c-9516-e1f91ef0dbac,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-e4f407e7-7f67-4bc0-87d9-c9545f9ab51b,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-0e076d9d-73c9-4fbd-b0cd-05a797172812,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-5215e119-0561-4043-8e49-8df84a64b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-eb323ac5-a41f-42a3-a26e-f84a2b14c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-42936d7b-5a44-468c-a1a7-55ff55e533b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-bd9bf732-966e-4622-a4ad-58f566641246,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-29a4173d-98eb-4a6f-b7c5-704e86e0e2aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553110317-172.17.0.16-1597107585674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43476,DS-f2f4d1ba-0d1e-4a1c-9516-e1f91ef0dbac,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-e4f407e7-7f67-4bc0-87d9-c9545f9ab51b,DISK], DatanodeInfoWithStorage[127.0.0.1:41975,DS-0e076d9d-73c9-4fbd-b0cd-05a797172812,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-5215e119-0561-4043-8e49-8df84a64b18d,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-eb323ac5-a41f-42a3-a26e-f84a2b14c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-42936d7b-5a44-468c-a1a7-55ff55e533b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-bd9bf732-966e-4622-a4ad-58f566641246,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-29a4173d-98eb-4a6f-b7c5-704e86e0e2aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289258726-172.17.0.16-1597107681706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-86eb699d-baba-47a0-aa21-354181528e68,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-35c6c299-630f-4728-b533-484cf4806192,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-f7acb9ab-25ab-43f5-b23e-5d1fa17c927f,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-2fd6c035-30f6-445e-b453-af50f8eccdae,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-c60eb294-7971-45a1-a92e-9312e87a4958,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-be721183-52c3-49e8-ac72-2f43ac66635d,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-d64347da-ce32-4ded-ba1c-780da347fa37,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-72e82910-2d58-4662-a28f-f80929ef8fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289258726-172.17.0.16-1597107681706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-86eb699d-baba-47a0-aa21-354181528e68,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-35c6c299-630f-4728-b533-484cf4806192,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-f7acb9ab-25ab-43f5-b23e-5d1fa17c927f,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-2fd6c035-30f6-445e-b453-af50f8eccdae,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-c60eb294-7971-45a1-a92e-9312e87a4958,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-be721183-52c3-49e8-ac72-2f43ac66635d,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-d64347da-ce32-4ded-ba1c-780da347fa37,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-72e82910-2d58-4662-a28f-f80929ef8fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991885809-172.17.0.16-1597107706887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-03ffe1a0-d001-427a-803a-b5985dc7558a,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-65001038-70d0-4e25-89a3-da1f62352cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-0246e691-6fb4-4eb8-84c7-a28eca3948ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-5d9c1caa-423b-4e6c-b355-7062e9b6da97,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-185b4af6-3460-48c9-aa2c-34be4a97d074,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-9ae898df-6a88-461b-9a66-b8e20e76059c,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-0bde2e3e-d8d9-4dd3-ac7c-270f09ec5ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-18666c0d-885f-4de4-a503-329f40f1e77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991885809-172.17.0.16-1597107706887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-03ffe1a0-d001-427a-803a-b5985dc7558a,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-65001038-70d0-4e25-89a3-da1f62352cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-0246e691-6fb4-4eb8-84c7-a28eca3948ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-5d9c1caa-423b-4e6c-b355-7062e9b6da97,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-185b4af6-3460-48c9-aa2c-34be4a97d074,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-9ae898df-6a88-461b-9a66-b8e20e76059c,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-0bde2e3e-d8d9-4dd3-ac7c-270f09ec5ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-18666c0d-885f-4de4-a503-329f40f1e77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726785839-172.17.0.16-1597107743404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45512,DS-7a33dd2c-7248-4707-a1ad-0558a8c8f388,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-6a3a34b0-34f9-48a5-bed9-e10bd5792f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-3dbabd70-8122-4820-8bd0-f6adfc02e0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-3f4f4ca1-442b-4f5b-8f4c-12c3913009cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-873b9844-84f4-4f31-b2b8-933566bb567c,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-f7aecc30-00ac-4212-88d9-9c43f7921168,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-23edea2d-0403-43d1-92e5-04393853a3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-578b413a-a830-4f28-af61-bacb2c0d9e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726785839-172.17.0.16-1597107743404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45512,DS-7a33dd2c-7248-4707-a1ad-0558a8c8f388,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-6a3a34b0-34f9-48a5-bed9-e10bd5792f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-3dbabd70-8122-4820-8bd0-f6adfc02e0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-3f4f4ca1-442b-4f5b-8f4c-12c3913009cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-873b9844-84f4-4f31-b2b8-933566bb567c,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-f7aecc30-00ac-4212-88d9-9c43f7921168,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-23edea2d-0403-43d1-92e5-04393853a3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-578b413a-a830-4f28-af61-bacb2c0d9e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181661794-172.17.0.16-1597107771709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-3f57f845-f940-46a9-a0d2-53689b52d283,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-1f3d492f-cb37-42f7-ad50-aaea781b724f,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-d73b4223-f7dc-4517-ae26-96ac93a07c05,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-7e7d5487-d158-4cdd-805d-19b7d18b9554,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-b4a90552-07c2-4838-af96-9b8e405e282f,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-590d251d-5b2e-4d8f-a1a1-e38a5c126d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-96e18052-0303-41c4-a412-d6a47965307b,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-32957025-1214-489a-8e9c-62f13aa9bfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181661794-172.17.0.16-1597107771709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39811,DS-3f57f845-f940-46a9-a0d2-53689b52d283,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-1f3d492f-cb37-42f7-ad50-aaea781b724f,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-d73b4223-f7dc-4517-ae26-96ac93a07c05,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-7e7d5487-d158-4cdd-805d-19b7d18b9554,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-b4a90552-07c2-4838-af96-9b8e405e282f,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-590d251d-5b2e-4d8f-a1a1-e38a5c126d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-96e18052-0303-41c4-a412-d6a47965307b,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-32957025-1214-489a-8e9c-62f13aa9bfef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463727136-172.17.0.16-1597107902574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-b7a370f6-421f-4dc5-84f1-e3d3e7d044db,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-61a699b4-6097-4ea1-902c-927388ad85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-23439dfa-a855-42db-8c13-d26f17e6e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-c18bf60d-6b91-483b-a727-1c5d16040ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-9901c94e-fb29-4e16-935f-87952f9c9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-26c4ed4e-c9c5-4822-89ce-c029dca75cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-f9f7bf62-ec2b-4ef0-ad9a-a250d51c497a,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-80d60e71-f47c-4414-9ce4-2039e6cb6207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463727136-172.17.0.16-1597107902574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44702,DS-b7a370f6-421f-4dc5-84f1-e3d3e7d044db,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-61a699b4-6097-4ea1-902c-927388ad85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-23439dfa-a855-42db-8c13-d26f17e6e14e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-c18bf60d-6b91-483b-a727-1c5d16040ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-9901c94e-fb29-4e16-935f-87952f9c9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-26c4ed4e-c9c5-4822-89ce-c029dca75cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-f9f7bf62-ec2b-4ef0-ad9a-a250d51c497a,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-80d60e71-f47c-4414-9ce4-2039e6cb6207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108759787-172.17.0.16-1597107937949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-c6ba68a0-a2b7-45e2-911e-2246eac70e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-9700e239-67e5-4e6d-b4f8-99d81a243101,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-bd0cffd0-98ab-44bf-a82f-78a92d00f957,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-421e6846-64f8-4c94-9355-0b1aa7c73a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-ae1d1811-fe6c-4a8e-8933-29cb3cfa6072,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-c7749d08-53dd-4d5b-918b-0ccf318bd49f,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-90fd4668-176f-4b44-9375-cef1b9448bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-66e50d4c-94d4-491a-ba2c-bf545610e1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108759787-172.17.0.16-1597107937949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-c6ba68a0-a2b7-45e2-911e-2246eac70e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-9700e239-67e5-4e6d-b4f8-99d81a243101,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-bd0cffd0-98ab-44bf-a82f-78a92d00f957,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-421e6846-64f8-4c94-9355-0b1aa7c73a94,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-ae1d1811-fe6c-4a8e-8933-29cb3cfa6072,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-c7749d08-53dd-4d5b-918b-0ccf318bd49f,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-90fd4668-176f-4b44-9375-cef1b9448bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-66e50d4c-94d4-491a-ba2c-bf545610e1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870443230-172.17.0.16-1597108252798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-25f559b2-de5e-4207-9399-c2ecfdf24062,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-c374b0b1-0921-4701-8be9-4c5a692efa56,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-848a8d4b-8e9a-4966-83c7-f6e33aef4456,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-50d7fcde-0bf7-4c9a-ab61-93f77637f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-2ebdf3f9-0806-4efd-a6d7-eebfb6c79142,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-e3b4acb9-1b7d-493f-ad4a-17da0a1e07d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-ee7e7c55-d48b-490c-a5b4-af8eb3430eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-31939866-e51e-490e-8e47-ccb86158ac63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870443230-172.17.0.16-1597108252798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36795,DS-25f559b2-de5e-4207-9399-c2ecfdf24062,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-c374b0b1-0921-4701-8be9-4c5a692efa56,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-848a8d4b-8e9a-4966-83c7-f6e33aef4456,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-50d7fcde-0bf7-4c9a-ab61-93f77637f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-2ebdf3f9-0806-4efd-a6d7-eebfb6c79142,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-e3b4acb9-1b7d-493f-ad4a-17da0a1e07d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41162,DS-ee7e7c55-d48b-490c-a5b4-af8eb3430eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-31939866-e51e-490e-8e47-ccb86158ac63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722205304-172.17.0.16-1597108357434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36548,DS-c96ca26e-cd17-42b1-9253-54889311e70e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-93ac6b6e-8463-4fe8-abd6-049e4a0027ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-0e1d064f-1e7a-4016-8e23-81857dc60247,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-cfd3aa38-92ae-45f3-88f7-f795bcd821d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-cfe4e2ec-4cc8-4476-8e64-15b774945868,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-0641772b-3649-4585-a64a-0f917feb28e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-32090c4c-e50a-49b1-95bd-0c0f926205f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-fd829aec-c75a-4789-9990-f5570029212c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1722205304-172.17.0.16-1597108357434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36548,DS-c96ca26e-cd17-42b1-9253-54889311e70e,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-93ac6b6e-8463-4fe8-abd6-049e4a0027ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-0e1d064f-1e7a-4016-8e23-81857dc60247,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-cfd3aa38-92ae-45f3-88f7-f795bcd821d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-cfe4e2ec-4cc8-4476-8e64-15b774945868,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-0641772b-3649-4585-a64a-0f917feb28e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-32090c4c-e50a-49b1-95bd-0c0f926205f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-fd829aec-c75a-4789-9990-f5570029212c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444490284-172.17.0.16-1597108709696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-742a24e8-739d-46f2-a296-a2026ecea904,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-a9ce04e4-8566-422b-9e86-5e5312704da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-1ecfd383-982a-4eee-883a-5b300ba3b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-d8d83683-dcac-4298-99dd-ebb97f5542ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-7e92f750-9168-4298-a160-784e7871b57a,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-34826c8b-d4bb-4419-987f-f810043807fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-7b283120-8720-4f0f-96dd-4ed1ce23e00f,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-0e10c9a1-de47-4837-a2f0-838d1607425d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1444490284-172.17.0.16-1597108709696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-742a24e8-739d-46f2-a296-a2026ecea904,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-a9ce04e4-8566-422b-9e86-5e5312704da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-1ecfd383-982a-4eee-883a-5b300ba3b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-d8d83683-dcac-4298-99dd-ebb97f5542ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-7e92f750-9168-4298-a160-784e7871b57a,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-34826c8b-d4bb-4419-987f-f810043807fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-7b283120-8720-4f0f-96dd-4ed1ce23e00f,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-0e10c9a1-de47-4837-a2f0-838d1607425d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649187254-172.17.0.16-1597108955481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-bbfd0471-249b-4b54-8ff3-e713cc2ecd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-3ede1eeb-b24e-4c2f-9a7a-3a0f128fe8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-a8ef54ce-f378-4ad9-aab3-2fa42e115b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-6f921a42-e3ae-43eb-9611-3a5bcb298437,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-062283dd-55e9-4f89-8337-3cd89398766e,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-e40007b1-1570-486a-afff-58e157916631,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-812907c2-f3d1-46df-8af9-f430c224a181,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-26df8e25-41de-49eb-8c56-8f9f9762ed9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649187254-172.17.0.16-1597108955481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-bbfd0471-249b-4b54-8ff3-e713cc2ecd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-3ede1eeb-b24e-4c2f-9a7a-3a0f128fe8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-a8ef54ce-f378-4ad9-aab3-2fa42e115b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-6f921a42-e3ae-43eb-9611-3a5bcb298437,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-062283dd-55e9-4f89-8337-3cd89398766e,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-e40007b1-1570-486a-afff-58e157916631,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-812907c2-f3d1-46df-8af9-f430c224a181,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-26df8e25-41de-49eb-8c56-8f9f9762ed9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214402703-172.17.0.16-1597109103244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45548,DS-8f5d5285-307a-4aad-b461-d12951c447b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-964a834b-88d0-4ecb-9c42-0d56988533c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-e875e3a3-1324-45ba-8d52-b458531ea2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-36de7c9d-ab73-4f63-951c-45a294275289,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-53368ac0-b6ca-4333-8429-74269cbc5675,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-4f25d52c-0e49-4f84-b3a6-b04976915fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-462c6884-ef8d-4f46-a1a3-3038232f1210,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-4b70bf8c-25d5-4dce-81a8-800757429fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214402703-172.17.0.16-1597109103244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45548,DS-8f5d5285-307a-4aad-b461-d12951c447b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-964a834b-88d0-4ecb-9c42-0d56988533c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-e875e3a3-1324-45ba-8d52-b458531ea2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-36de7c9d-ab73-4f63-951c-45a294275289,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-53368ac0-b6ca-4333-8429-74269cbc5675,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-4f25d52c-0e49-4f84-b3a6-b04976915fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-462c6884-ef8d-4f46-a1a3-3038232f1210,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-4b70bf8c-25d5-4dce-81a8-800757429fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387512749-172.17.0.16-1597109590261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-548a3c60-ac1f-4d75-b6d3-448979c10190,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-f9e3dd17-4b29-4da8-a23e-24c178bde0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-085386f8-330e-4031-be3d-d3aff82cccad,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-071fee66-5292-4f92-9a48-c25f5671c59e,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-0c294846-5761-40d3-b4b4-e7d6fc4d4b01,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-8d03f764-2200-49fe-82e2-79ac138a9880,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-2b6b8308-a466-4df0-a932-926bf39ee0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-f08e295a-e083-4af0-8395-7040f028e20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387512749-172.17.0.16-1597109590261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-548a3c60-ac1f-4d75-b6d3-448979c10190,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-f9e3dd17-4b29-4da8-a23e-24c178bde0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-085386f8-330e-4031-be3d-d3aff82cccad,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-071fee66-5292-4f92-9a48-c25f5671c59e,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-0c294846-5761-40d3-b4b4-e7d6fc4d4b01,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-8d03f764-2200-49fe-82e2-79ac138a9880,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-2b6b8308-a466-4df0-a932-926bf39ee0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-f08e295a-e083-4af0-8395-7040f028e20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460233227-172.17.0.16-1597109777595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-64591597-62c9-4087-bdd7-db0c369cb7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-8c4f5ecb-73a9-4f23-939b-ddd7200810e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-b3267b30-ddff-4876-a984-b1a8256a8007,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-a4dcf1c6-7455-4c6d-a634-96383c73bbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-27302332-968f-4518-86c7-4cc884407296,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-e75e6a46-54b7-4878-b705-848e311119db,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-ef7afd00-3c3b-400e-ae25-8ba32f26993f,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-cbb20f23-d0c1-4243-96eb-0084b12f93fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460233227-172.17.0.16-1597109777595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-64591597-62c9-4087-bdd7-db0c369cb7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-8c4f5ecb-73a9-4f23-939b-ddd7200810e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-b3267b30-ddff-4876-a984-b1a8256a8007,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-a4dcf1c6-7455-4c6d-a634-96383c73bbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-27302332-968f-4518-86c7-4cc884407296,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-e75e6a46-54b7-4878-b705-848e311119db,DISK], DatanodeInfoWithStorage[127.0.0.1:40036,DS-ef7afd00-3c3b-400e-ae25-8ba32f26993f,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-cbb20f23-d0c1-4243-96eb-0084b12f93fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75925029-172.17.0.16-1597109854582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-ad555ad3-3604-4def-8793-0bb41c6d0513,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-26782e48-442c-4a28-a3eb-8015640dc8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-d50bf677-f5da-48cf-980a-4cd2052b12d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-6070c052-550b-4af0-bff8-f5c1d9ae4c28,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-fcb7a229-65e8-4872-b3aa-1c0227968797,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-0fd15013-f8c0-4f6b-97cd-5f91650a06a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-cc1ebf66-a393-41d2-b4c9-573049ed1f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-e8dc4cdf-f19c-4a7a-89bf-b3bac64c8af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75925029-172.17.0.16-1597109854582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41023,DS-ad555ad3-3604-4def-8793-0bb41c6d0513,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-26782e48-442c-4a28-a3eb-8015640dc8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-d50bf677-f5da-48cf-980a-4cd2052b12d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-6070c052-550b-4af0-bff8-f5c1d9ae4c28,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-fcb7a229-65e8-4872-b3aa-1c0227968797,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-0fd15013-f8c0-4f6b-97cd-5f91650a06a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-cc1ebf66-a393-41d2-b4c9-573049ed1f83,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-e8dc4cdf-f19c-4a7a-89bf-b3bac64c8af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924807094-172.17.0.16-1597110289691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-68f909a2-eb49-42e3-8ac2-dd30d1c0dffb,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-2e4f6477-010f-4399-8c33-979ec6512967,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-6b6277e6-cdff-41d0-bb44-ae9b17900a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-d4fa833b-790c-4f31-a76c-187fc59ffbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-6751418c-521c-4a5f-984b-301a519d9a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-1f33d806-e5c2-4585-968b-1c740bce975d,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-293d8151-9b9d-40d1-930b-c1eb23381202,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-c86210af-cfea-4a4d-b4b9-f83b77583369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924807094-172.17.0.16-1597110289691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43307,DS-68f909a2-eb49-42e3-8ac2-dd30d1c0dffb,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-2e4f6477-010f-4399-8c33-979ec6512967,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-6b6277e6-cdff-41d0-bb44-ae9b17900a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-d4fa833b-790c-4f31-a76c-187fc59ffbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-6751418c-521c-4a5f-984b-301a519d9a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-1f33d806-e5c2-4585-968b-1c740bce975d,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-293d8151-9b9d-40d1-930b-c1eb23381202,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-c86210af-cfea-4a4d-b4b9-f83b77583369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653699468-172.17.0.16-1597110389945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35312,DS-d8cf48f0-b6ff-40e0-bb61-1b3269fb792a,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-e3b2a8d1-9f37-4c61-8655-0f28da20fce0,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-86da5852-f6f8-42ec-8a6d-526eea2cb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-de4b1f6b-6cd1-4a87-87aa-3a0d5385670e,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-5fd6ae18-3232-4f7b-9c71-8ef8da9a047e,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-c38a5654-f4b5-4c97-8b9f-a476f3814017,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-942c3e71-3cc6-46f4-bd1c-d9626d303209,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-9c8939bf-97ea-4b3c-a6c8-65c0f90f92ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653699468-172.17.0.16-1597110389945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35312,DS-d8cf48f0-b6ff-40e0-bb61-1b3269fb792a,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-e3b2a8d1-9f37-4c61-8655-0f28da20fce0,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-86da5852-f6f8-42ec-8a6d-526eea2cb2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-de4b1f6b-6cd1-4a87-87aa-3a0d5385670e,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-5fd6ae18-3232-4f7b-9c71-8ef8da9a047e,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-c38a5654-f4b5-4c97-8b9f-a476f3814017,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-942c3e71-3cc6-46f4-bd1c-d9626d303209,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-9c8939bf-97ea-4b3c-a6c8-65c0f90f92ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.max.connections
component: hdfs:NameNode
v1: 0
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581776924-172.17.0.16-1597110418853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-34b69b34-993a-465d-9565-f9217d972fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-86976054-4d74-4508-a0bd-dd21d24a1640,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-35d4079e-5fbd-4ff5-b1ed-babdd00a493e,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-7b22571e-120f-4ccc-b4cb-e303c59fbd62,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-f8420b57-08ec-4ddd-8e55-9174a3c802f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-7c78037c-a99d-4e51-be41-627b1ecea1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-d943db74-2beb-4892-ad75-48366f318f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-9f379afa-6e46-4c15-93bc-0284fc67b108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581776924-172.17.0.16-1597110418853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46229,DS-34b69b34-993a-465d-9565-f9217d972fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-86976054-4d74-4508-a0bd-dd21d24a1640,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-35d4079e-5fbd-4ff5-b1ed-babdd00a493e,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-7b22571e-120f-4ccc-b4cb-e303c59fbd62,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-f8420b57-08ec-4ddd-8e55-9174a3c802f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-7c78037c-a99d-4e51-be41-627b1ecea1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-d943db74-2beb-4892-ad75-48366f318f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-9f379afa-6e46-4c15-93bc-0284fc67b108,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5232
