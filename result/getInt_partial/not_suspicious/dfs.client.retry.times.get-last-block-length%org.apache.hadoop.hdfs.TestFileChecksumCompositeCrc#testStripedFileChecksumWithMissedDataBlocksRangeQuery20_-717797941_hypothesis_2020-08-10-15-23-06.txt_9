reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1755208867-172.17.0.2-1597073200039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-5d786fad-5f4a-42e2-a461-c82dd44c70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-b885f6df-be93-4c14-a091-4cdbb014d8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-62671d49-8688-440c-aa50-5b9f4fa11424,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-f47cb193-0e93-42d5-9622-d6eb3147e782,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-8751940a-40fa-4598-896f-822f7258b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-83d9cbc3-0006-4e0f-ba86-988247e461f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-3d5ade32-7582-4504-aeae-9830da22c936,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-e84816b7-274d-4efb-adec-63a36bc15b35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1755208867-172.17.0.2-1597073200039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45750,DS-5d786fad-5f4a-42e2-a461-c82dd44c70ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-b885f6df-be93-4c14-a091-4cdbb014d8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-62671d49-8688-440c-aa50-5b9f4fa11424,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-f47cb193-0e93-42d5-9622-d6eb3147e782,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-8751940a-40fa-4598-896f-822f7258b91d,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-83d9cbc3-0006-4e0f-ba86-988247e461f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-3d5ade32-7582-4504-aeae-9830da22c936,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-e84816b7-274d-4efb-adec-63a36bc15b35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937972447-172.17.0.2-1597073395652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41740,DS-0d141c40-4d07-4dce-863f-e5a529ad206b,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-9bfcb8d5-df4e-41d5-aa3a-80fae4dd5d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-a8809016-eab0-4113-8d25-055e783d2d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-9c29577a-f99c-493e-9d6a-fddb0d7c0bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-837ae12f-f174-43a1-a640-47650bdeeb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-c59d6ebb-9cee-4f75-8e1a-b9152529cc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-e2797a5b-298e-4711-b89c-bd5a80b93a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-5601eee9-ab86-4915-ae0e-01d5cad473b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937972447-172.17.0.2-1597073395652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41740,DS-0d141c40-4d07-4dce-863f-e5a529ad206b,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-9bfcb8d5-df4e-41d5-aa3a-80fae4dd5d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-a8809016-eab0-4113-8d25-055e783d2d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-9c29577a-f99c-493e-9d6a-fddb0d7c0bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-837ae12f-f174-43a1-a640-47650bdeeb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-c59d6ebb-9cee-4f75-8e1a-b9152529cc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-e2797a5b-298e-4711-b89c-bd5a80b93a56,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-5601eee9-ab86-4915-ae0e-01d5cad473b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639151636-172.17.0.2-1597073994646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-bc9e2d9f-20fa-4076-9c1c-6d41d19b0ede,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-14e42def-d4bb-4c34-b577-4cf300731e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-efd819c8-cca4-4499-9db1-0d6dd0de94e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-9203fa38-08a2-462a-ad10-d0100e38dbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-3f5efbbb-522b-4dca-98f1-826a8e26e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-501165fb-a06e-416d-a612-12eb75f40c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-56a9bcc0-0a18-4231-920c-18357a2a80a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-4787a4e9-b941-4740-befa-c59540646b8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639151636-172.17.0.2-1597073994646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-bc9e2d9f-20fa-4076-9c1c-6d41d19b0ede,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-14e42def-d4bb-4c34-b577-4cf300731e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-efd819c8-cca4-4499-9db1-0d6dd0de94e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-9203fa38-08a2-462a-ad10-d0100e38dbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41895,DS-3f5efbbb-522b-4dca-98f1-826a8e26e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-501165fb-a06e-416d-a612-12eb75f40c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-56a9bcc0-0a18-4231-920c-18357a2a80a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-4787a4e9-b941-4740-befa-c59540646b8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735771106-172.17.0.2-1597074101211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-7ba4395b-8c60-425a-9e7d-b771b150c046,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-1a9c066e-a1ea-496e-94a2-4a074ec796cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-563d0fc6-509b-472a-99dd-4f69f5c5476a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-97e4c36f-c40e-4a1a-ae21-3f679ff6a878,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-07c34085-4034-4226-88b5-06c4cdd922d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-aca2730f-1264-4844-a6e7-7ca179e052f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-00ad44f4-13fa-4e20-afdd-8b5ae5a8e840,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-e5249aa0-c9d8-4524-9bf8-995932d3433d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735771106-172.17.0.2-1597074101211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36349,DS-7ba4395b-8c60-425a-9e7d-b771b150c046,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-1a9c066e-a1ea-496e-94a2-4a074ec796cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-563d0fc6-509b-472a-99dd-4f69f5c5476a,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-97e4c36f-c40e-4a1a-ae21-3f679ff6a878,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-07c34085-4034-4226-88b5-06c4cdd922d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-aca2730f-1264-4844-a6e7-7ca179e052f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-00ad44f4-13fa-4e20-afdd-8b5ae5a8e840,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-e5249aa0-c9d8-4524-9bf8-995932d3433d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070648515-172.17.0.2-1597074470513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-ac1e0958-ce43-40f2-a76c-f2964d15b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-96534be2-1d0a-48a5-a513-2f0c4eea8119,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-4537bb9e-5d32-4d28-bb69-63e926e79a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-cebd4022-80e2-437d-b3ec-04299b70355b,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-dcaf99e7-0812-4c36-8d9e-55d091c18dce,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-9454a636-0a12-4b79-9d2d-ebfcb36c5400,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-ffb97099-78b3-4985-870e-dd10f3b83534,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-060b98e4-52b5-4af3-8533-93d7e88b63bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070648515-172.17.0.2-1597074470513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-ac1e0958-ce43-40f2-a76c-f2964d15b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-96534be2-1d0a-48a5-a513-2f0c4eea8119,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-4537bb9e-5d32-4d28-bb69-63e926e79a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-cebd4022-80e2-437d-b3ec-04299b70355b,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-dcaf99e7-0812-4c36-8d9e-55d091c18dce,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-9454a636-0a12-4b79-9d2d-ebfcb36c5400,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-ffb97099-78b3-4985-870e-dd10f3b83534,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-060b98e4-52b5-4af3-8533-93d7e88b63bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660079687-172.17.0.2-1597074684097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-82d6190e-a4a8-4ad1-9642-26f2efdefa66,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-81c6c4ae-98b1-485f-8a71-5dd1c859c8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-2b8ac318-7d0b-48f1-baeb-1111b5559e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-c735fcdc-b68c-442d-b713-49650741d870,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-d05493e0-ba00-44c9-9bed-9db4ccac103a,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-ff307f34-a384-4729-a8a5-c97413c2717c,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-9b669ea0-1653-41f2-8b41-6eaf70f1ce70,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-8adbb74d-452f-4dd0-8d40-2451adbed77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660079687-172.17.0.2-1597074684097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39317,DS-82d6190e-a4a8-4ad1-9642-26f2efdefa66,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-81c6c4ae-98b1-485f-8a71-5dd1c859c8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-2b8ac318-7d0b-48f1-baeb-1111b5559e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-c735fcdc-b68c-442d-b713-49650741d870,DISK], DatanodeInfoWithStorage[127.0.0.1:43554,DS-d05493e0-ba00-44c9-9bed-9db4ccac103a,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-ff307f34-a384-4729-a8a5-c97413c2717c,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-9b669ea0-1653-41f2-8b41-6eaf70f1ce70,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-8adbb74d-452f-4dd0-8d40-2451adbed77b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085175748-172.17.0.2-1597075288557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36240,DS-ac0cf932-f028-4229-baf9-ed2acf20c354,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-0291a9a5-bf04-4b59-bf17-c375543cc7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-04a758d8-49de-450d-ae05-8c436dbd08a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-12eeff0e-73dc-49cc-accd-df1957b04318,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-c264e521-d269-44bb-9743-a73151de027c,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-19706fa9-66d1-4708-aaf7-cf1d4e025040,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-d9ffb23d-2b6a-4467-b080-c711f8f26a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-ecc52c99-b12c-4690-9d1a-6bf4015a8c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085175748-172.17.0.2-1597075288557:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36240,DS-ac0cf932-f028-4229-baf9-ed2acf20c354,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-0291a9a5-bf04-4b59-bf17-c375543cc7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-04a758d8-49de-450d-ae05-8c436dbd08a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-12eeff0e-73dc-49cc-accd-df1957b04318,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-c264e521-d269-44bb-9743-a73151de027c,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-19706fa9-66d1-4708-aaf7-cf1d4e025040,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-d9ffb23d-2b6a-4467-b080-c711f8f26a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-ecc52c99-b12c-4690-9d1a-6bf4015a8c89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937255577-172.17.0.2-1597076140097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-6d193d83-9f64-468e-823f-51cf3a01c57a,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-bd86b9f2-9a89-4559-a420-28e73d5411e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-4dfe63fd-24f4-4e99-94af-dc035079ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-ec04057d-ffd8-43d8-be42-a212092af62f,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-2268c252-89ef-4c0a-8668-2386fd62f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-cbc3c23f-40c3-45e2-a1ac-1d7dbbbabcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-338801aa-b8b3-4dce-9700-0f0c455f1dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-1c92f413-cb10-4f94-ad7f-715bb33c3681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937255577-172.17.0.2-1597076140097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-6d193d83-9f64-468e-823f-51cf3a01c57a,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-bd86b9f2-9a89-4559-a420-28e73d5411e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-4dfe63fd-24f4-4e99-94af-dc035079ac3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-ec04057d-ffd8-43d8-be42-a212092af62f,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-2268c252-89ef-4c0a-8668-2386fd62f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-cbc3c23f-40c3-45e2-a1ac-1d7dbbbabcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-338801aa-b8b3-4dce-9700-0f0c455f1dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-1c92f413-cb10-4f94-ad7f-715bb33c3681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290209162-172.17.0.2-1597076213046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36436,DS-bb5ddfe0-8c88-44f8-b3c2-8d5e8c08d04c,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-1a50b6da-ddda-471f-8f9e-22c979e11340,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-15b66db5-0b3e-4304-bec4-2d366c24eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-a6002052-37e9-49ea-8761-47dec38e28b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-973b1622-d00b-4bb2-b84d-b52b479ba893,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-0eeb3a62-a049-4094-9a49-dc4cec0c1f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-0b66d090-f12a-43ab-b95c-4e2baa1e2ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-b3b85180-3763-4033-9deb-27bb854027dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1290209162-172.17.0.2-1597076213046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36436,DS-bb5ddfe0-8c88-44f8-b3c2-8d5e8c08d04c,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-1a50b6da-ddda-471f-8f9e-22c979e11340,DISK], DatanodeInfoWithStorage[127.0.0.1:41606,DS-15b66db5-0b3e-4304-bec4-2d366c24eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-a6002052-37e9-49ea-8761-47dec38e28b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-973b1622-d00b-4bb2-b84d-b52b479ba893,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-0eeb3a62-a049-4094-9a49-dc4cec0c1f35,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-0b66d090-f12a-43ab-b95c-4e2baa1e2ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-b3b85180-3763-4033-9deb-27bb854027dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56735049-172.17.0.2-1597076565445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-2eeab0af-2fa3-4c1f-a9ad-d659b564dea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-0b07726b-4bae-43b7-a40e-44eedb13c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-312a1add-7b1d-4153-a0f8-2bb354e6bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-d30760a1-866b-4a8d-a86c-8ef215b66ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-4ed2b61e-7924-48ce-935d-c0cf41b84f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-28c7aeeb-b777-447d-9d56-379482d9f17c,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-b03d01d2-968f-41b5-8689-2bf5098ef4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-e6f2df50-74a2-4cc7-b94e-0e4f01684c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56735049-172.17.0.2-1597076565445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40061,DS-2eeab0af-2fa3-4c1f-a9ad-d659b564dea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-0b07726b-4bae-43b7-a40e-44eedb13c13b,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-312a1add-7b1d-4153-a0f8-2bb354e6bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-d30760a1-866b-4a8d-a86c-8ef215b66ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-4ed2b61e-7924-48ce-935d-c0cf41b84f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-28c7aeeb-b777-447d-9d56-379482d9f17c,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-b03d01d2-968f-41b5-8689-2bf5098ef4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-e6f2df50-74a2-4cc7-b94e-0e4f01684c62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252163666-172.17.0.2-1597077312317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-a3691b8a-f691-424c-9dda-3ce6816e9d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-3aa9fcdf-73ac-4df4-99b0-8ba057a9be21,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-e077c740-f625-445d-8baa-dcbfae97eb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-3d9416e4-708f-4603-8e7a-18ee1c81430d,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-2d4d558f-9854-4a58-b404-7c0dcbc11017,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-96090a15-5297-48f2-afe4-02165dea6e56,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-cf958c4f-af0d-40f3-b99f-86ffc7dd94a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-c2185851-6839-474c-a095-85b26651b393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252163666-172.17.0.2-1597077312317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44848,DS-a3691b8a-f691-424c-9dda-3ce6816e9d06,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-3aa9fcdf-73ac-4df4-99b0-8ba057a9be21,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-e077c740-f625-445d-8baa-dcbfae97eb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-3d9416e4-708f-4603-8e7a-18ee1c81430d,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-2d4d558f-9854-4a58-b404-7c0dcbc11017,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-96090a15-5297-48f2-afe4-02165dea6e56,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-cf958c4f-af0d-40f3-b99f-86ffc7dd94a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-c2185851-6839-474c-a095-85b26651b393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180231310-172.17.0.2-1597077999404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-1bb375a3-0ac4-42f5-a6c1-075cfcb1883b,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-0f27290f-f1ec-4275-8a1e-48352ceabc46,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-941a7152-6566-4bbd-90bf-d863cc79ed6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-5af47dc1-5028-44de-bdd3-dd3433d24b03,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-f6bdfe93-ebea-4492-87a1-dde3517876b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-4735d271-d0a6-42f2-bee0-54ed54129df2,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-58ddd280-978f-4426-b6dc-9fc2b7678c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-ea4ff5ba-c608-4ee2-beb4-d98504f4fbe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-180231310-172.17.0.2-1597077999404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-1bb375a3-0ac4-42f5-a6c1-075cfcb1883b,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-0f27290f-f1ec-4275-8a1e-48352ceabc46,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-941a7152-6566-4bbd-90bf-d863cc79ed6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-5af47dc1-5028-44de-bdd3-dd3433d24b03,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-f6bdfe93-ebea-4492-87a1-dde3517876b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-4735d271-d0a6-42f2-bee0-54ed54129df2,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-58ddd280-978f-4426-b6dc-9fc2b7678c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-ea4ff5ba-c608-4ee2-beb4-d98504f4fbe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505158366-172.17.0.2-1597078037292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41757,DS-d6ee0e2c-6e45-45ff-b891-b2ede0666c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-203ab454-5651-45ba-8792-011c8509cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-a92add12-b35b-4dc9-8da0-8e09d7f15ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-a630e647-00b8-4e86-b775-3eada3b3ef2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-278472ed-e11e-4771-a18e-c5cf9367eaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-9507057e-817c-47d0-a302-efa9b206dc92,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-8892b792-1403-43b6-9256-c310f2e5a590,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-00123b61-6cee-40ea-925a-5e766b64fe91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505158366-172.17.0.2-1597078037292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41757,DS-d6ee0e2c-6e45-45ff-b891-b2ede0666c80,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-203ab454-5651-45ba-8792-011c8509cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-a92add12-b35b-4dc9-8da0-8e09d7f15ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-a630e647-00b8-4e86-b775-3eada3b3ef2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-278472ed-e11e-4771-a18e-c5cf9367eaf5,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-9507057e-817c-47d0-a302-efa9b206dc92,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-8892b792-1403-43b6-9256-c310f2e5a590,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-00123b61-6cee-40ea-925a-5e766b64fe91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5327
