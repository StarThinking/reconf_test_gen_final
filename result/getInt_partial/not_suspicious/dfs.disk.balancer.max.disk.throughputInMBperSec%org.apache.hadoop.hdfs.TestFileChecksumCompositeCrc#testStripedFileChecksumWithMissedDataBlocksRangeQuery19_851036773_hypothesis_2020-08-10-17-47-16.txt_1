reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162270825-172.17.0.20-1597081990953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37216,DS-fd64b987-2f2f-4ce7-8f9c-fd7d86c58f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-04497385-2fb4-431d-a4a3-fe80069a5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-f05f3e85-1f5e-412b-894a-48490687277a,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-0711cc75-8ca1-445b-91f4-32292ed16889,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-f1891a0c-e0df-47bd-87ee-ccfc00792449,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-30d1c674-c994-4332-86d3-bc357247213d,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-246940ce-a34f-4939-9407-efd8f378a97d,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-ccc38faa-6bcf-4ed0-9a77-a9853f29ca58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162270825-172.17.0.20-1597081990953:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37216,DS-fd64b987-2f2f-4ce7-8f9c-fd7d86c58f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-04497385-2fb4-431d-a4a3-fe80069a5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-f05f3e85-1f5e-412b-894a-48490687277a,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-0711cc75-8ca1-445b-91f4-32292ed16889,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-f1891a0c-e0df-47bd-87ee-ccfc00792449,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-30d1c674-c994-4332-86d3-bc357247213d,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-246940ce-a34f-4939-9407-efd8f378a97d,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-ccc38faa-6bcf-4ed0-9a77-a9853f29ca58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099510688-172.17.0.20-1597082056292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40137,DS-47a6bc67-597b-48a8-a291-3431bb9950eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-57a89d82-68e6-4d5a-a85b-e792c607ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-fe1c6f46-4b8f-477f-9b5c-c6f8dad8c9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-5e2865d6-de4c-4aeb-8561-da3ddf4d6e91,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-5b95cf1d-77d3-45ed-ba21-a3af3bef0d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-bdf4b4ab-5ad8-442e-9259-4d7bdf28ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-f372964e-679a-41a0-bbbf-524492b50472,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-ff9f0232-6bc8-402a-8668-ffb166c2fadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2099510688-172.17.0.20-1597082056292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40137,DS-47a6bc67-597b-48a8-a291-3431bb9950eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-57a89d82-68e6-4d5a-a85b-e792c607ecb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-fe1c6f46-4b8f-477f-9b5c-c6f8dad8c9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-5e2865d6-de4c-4aeb-8561-da3ddf4d6e91,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-5b95cf1d-77d3-45ed-ba21-a3af3bef0d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-bdf4b4ab-5ad8-442e-9259-4d7bdf28ac78,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-f372964e-679a-41a0-bbbf-524492b50472,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-ff9f0232-6bc8-402a-8668-ffb166c2fadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574631461-172.17.0.20-1597082160693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-6c93f7a2-e079-4cfb-96e9-f661c25dfe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-64fac7cc-be88-4e87-886e-e47834240b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-1c787a5e-081f-43a7-ba1f-6411fb698879,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-8a1bb6ed-9045-49f0-b46f-2ab628b8330d,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-5d180335-fb2d-4dd1-a254-b8914e17b2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-ed8e5029-4410-40b9-82b7-7c9af6679992,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-2cb75191-a894-4620-a82e-f73aebcca579,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-e74f2c32-f00b-438d-9384-e2d1b07dd952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1574631461-172.17.0.20-1597082160693:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36487,DS-6c93f7a2-e079-4cfb-96e9-f661c25dfe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-64fac7cc-be88-4e87-886e-e47834240b05,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-1c787a5e-081f-43a7-ba1f-6411fb698879,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-8a1bb6ed-9045-49f0-b46f-2ab628b8330d,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-5d180335-fb2d-4dd1-a254-b8914e17b2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-ed8e5029-4410-40b9-82b7-7c9af6679992,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-2cb75191-a894-4620-a82e-f73aebcca579,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-e74f2c32-f00b-438d-9384-e2d1b07dd952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851081954-172.17.0.20-1597082380194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41396,DS-3f5e0732-d987-4ca2-8c22-084c343c4ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-f78742f2-90ad-4a11-a6c1-a5f5c2a095e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-0c15fb45-7f04-4c27-a94c-b6e910ace547,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-80d7f5a2-1929-4c71-8419-21c59acc7bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-7c3f9924-edaa-4145-aa8b-ae1208d5d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-41683301-48e1-4836-96bb-a5f4c345b9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-4c39ebf7-3f2f-4807-aa53-b0cbf202c271,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-ef078b84-5f77-41b7-8276-d349216cfc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851081954-172.17.0.20-1597082380194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41396,DS-3f5e0732-d987-4ca2-8c22-084c343c4ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-f78742f2-90ad-4a11-a6c1-a5f5c2a095e8,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-0c15fb45-7f04-4c27-a94c-b6e910ace547,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-80d7f5a2-1929-4c71-8419-21c59acc7bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-7c3f9924-edaa-4145-aa8b-ae1208d5d0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-41683301-48e1-4836-96bb-a5f4c345b9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-4c39ebf7-3f2f-4807-aa53-b0cbf202c271,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-ef078b84-5f77-41b7-8276-d349216cfc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233565612-172.17.0.20-1597082701947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39857,DS-daa9b491-66c9-4fed-9b3a-98c2d2438f28,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-f4d12bc8-ea54-48c5-b3d0-938252110775,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-4159071f-c71e-4d26-a6a2-f9571404f84f,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-015f9718-a6ee-4dd4-93ed-cfd8245c3888,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-97fb872e-9f87-4ac3-91ef-9c34983a5e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-bf9541b4-2610-4a3b-8019-439664df58bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-2c9e9a11-314d-4994-a163-5412a18b2ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-102710f8-8f33-4665-ba3e-906db9ede8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233565612-172.17.0.20-1597082701947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39857,DS-daa9b491-66c9-4fed-9b3a-98c2d2438f28,DISK], DatanodeInfoWithStorage[127.0.0.1:41382,DS-f4d12bc8-ea54-48c5-b3d0-938252110775,DISK], DatanodeInfoWithStorage[127.0.0.1:40506,DS-4159071f-c71e-4d26-a6a2-f9571404f84f,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-015f9718-a6ee-4dd4-93ed-cfd8245c3888,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-97fb872e-9f87-4ac3-91ef-9c34983a5e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-bf9541b4-2610-4a3b-8019-439664df58bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-2c9e9a11-314d-4994-a163-5412a18b2ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-102710f8-8f33-4665-ba3e-906db9ede8d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032515378-172.17.0.20-1597082776065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-4f4a42a4-51d4-445e-8a5e-74e459e9e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-bc393662-af66-42c1-9e32-b1ec6f4729a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-db43f1f2-2d31-417f-85b2-37575d0effd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-010b3b4b-a72d-4d23-b018-980af45f1d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-3bc15e06-af71-4cf6-a941-b5db0cea312f,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-595170e6-6591-428e-83e9-0bf7714f9ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-19a1e891-35f2-418a-a119-087daada7f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-b68b911d-d608-43ec-a8af-7532c5f1566d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032515378-172.17.0.20-1597082776065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34730,DS-4f4a42a4-51d4-445e-8a5e-74e459e9e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-bc393662-af66-42c1-9e32-b1ec6f4729a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-db43f1f2-2d31-417f-85b2-37575d0effd7,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-010b3b4b-a72d-4d23-b018-980af45f1d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35565,DS-3bc15e06-af71-4cf6-a941-b5db0cea312f,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-595170e6-6591-428e-83e9-0bf7714f9ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-19a1e891-35f2-418a-a119-087daada7f11,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-b68b911d-d608-43ec-a8af-7532c5f1566d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903689159-172.17.0.20-1597083476299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44628,DS-7896a5c1-7fe6-4043-a369-b94e52a5f862,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-c3809b6e-fed4-4273-ae0d-7e225c0edb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-8795b3f2-6578-4427-acca-9cdad637e496,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-0a465c6a-e851-4bc6-9918-a33c0c37cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-87c94d8a-a60d-4462-bc7d-87212efc7020,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-5d7e087d-dc77-4e86-adf5-852d7d338356,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-303e0d5a-b8d9-43a6-ab70-4d6c56e7df12,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-f9a86c52-8a0d-408e-86da-4f821740a17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903689159-172.17.0.20-1597083476299:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44628,DS-7896a5c1-7fe6-4043-a369-b94e52a5f862,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-c3809b6e-fed4-4273-ae0d-7e225c0edb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-8795b3f2-6578-4427-acca-9cdad637e496,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-0a465c6a-e851-4bc6-9918-a33c0c37cb51,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-87c94d8a-a60d-4462-bc7d-87212efc7020,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-5d7e087d-dc77-4e86-adf5-852d7d338356,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-303e0d5a-b8d9-43a6-ab70-4d6c56e7df12,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-f9a86c52-8a0d-408e-86da-4f821740a17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690608989-172.17.0.20-1597083579460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-5206adff-1016-4ebf-ab94-74887cc3fa00,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-5ba2e9cf-367b-49bf-8811-066b4272f167,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-1732ac54-5340-486f-958d-ecde099b84c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-0572edbc-eb5c-4d62-9b88-c85de9063183,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-d4670735-4e6f-4ffb-af5b-b1700591602e,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-b5a1dd3b-4641-4748-9100-164e4161362f,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-1c65b456-7fb1-437a-aeb6-7bdb247989cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-50c8dd84-45c0-4988-9b83-8925c09ff706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1690608989-172.17.0.20-1597083579460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-5206adff-1016-4ebf-ab94-74887cc3fa00,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-5ba2e9cf-367b-49bf-8811-066b4272f167,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-1732ac54-5340-486f-958d-ecde099b84c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35700,DS-0572edbc-eb5c-4d62-9b88-c85de9063183,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-d4670735-4e6f-4ffb-af5b-b1700591602e,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-b5a1dd3b-4641-4748-9100-164e4161362f,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-1c65b456-7fb1-437a-aeb6-7bdb247989cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-50c8dd84-45c0-4988-9b83-8925c09ff706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630804955-172.17.0.20-1597084388184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-85c262f5-d314-4708-bdee-7ae0ce473003,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-0956eff7-51ae-4754-9d1e-b43817cf9558,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-54bb5eb1-0ead-4696-bcc2-84be4a931e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-9681f2c8-d5ef-481a-a03c-9a32d4b82c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-e8ce027b-9b0d-403f-9368-d3b773228829,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-32bb591d-df95-454c-9109-50a37c166f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-c20ddc0b-96a6-4904-9c50-778b53439acf,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-dca66b82-881f-4a85-b307-043b2d5c6909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630804955-172.17.0.20-1597084388184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46374,DS-85c262f5-d314-4708-bdee-7ae0ce473003,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-0956eff7-51ae-4754-9d1e-b43817cf9558,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-54bb5eb1-0ead-4696-bcc2-84be4a931e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-9681f2c8-d5ef-481a-a03c-9a32d4b82c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-e8ce027b-9b0d-403f-9368-d3b773228829,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-32bb591d-df95-454c-9109-50a37c166f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-c20ddc0b-96a6-4904-9c50-778b53439acf,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-dca66b82-881f-4a85-b307-043b2d5c6909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273071283-172.17.0.20-1597084718251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-a292ae72-cdcd-4c10-b06b-eeab721b20f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-73076b31-2c47-4bca-bde0-1082bbbd1827,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-3f5a1f27-b823-4730-87cc-a55dd4112533,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-7b376e2c-03a1-4fbf-a797-b67f23f58fec,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-67a3c06c-6f0c-49ad-a50a-77fe885d92e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-015f0efe-8104-4d7d-875a-5a1176f0ad42,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-ff7caff6-dead-44b6-bc9d-9e3d208714eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-beb9b72a-4fb7-48dc-8cff-fbef27d2a025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273071283-172.17.0.20-1597084718251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-a292ae72-cdcd-4c10-b06b-eeab721b20f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-73076b31-2c47-4bca-bde0-1082bbbd1827,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-3f5a1f27-b823-4730-87cc-a55dd4112533,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-7b376e2c-03a1-4fbf-a797-b67f23f58fec,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-67a3c06c-6f0c-49ad-a50a-77fe885d92e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-015f0efe-8104-4d7d-875a-5a1176f0ad42,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-ff7caff6-dead-44b6-bc9d-9e3d208714eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-beb9b72a-4fb7-48dc-8cff-fbef27d2a025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41214548-172.17.0.20-1597085174026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43848,DS-244c6331-4e38-4b64-b042-1302b714dada,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-cf9d84f7-fba9-4cea-bda2-c69343a12291,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-b0e8af24-61ca-4283-8d7a-0ab6d5346cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-356a3984-8c45-428a-8265-a00f9d37521a,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-cbafc758-f5ac-429f-92ea-cc6b0b970b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-459bd1bc-4a4a-4ae0-9882-ca00013334e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-9f7b6edb-dfd4-4f14-a655-21148a823f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-dd9649f7-40c9-4d8c-862b-547469966654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41214548-172.17.0.20-1597085174026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43848,DS-244c6331-4e38-4b64-b042-1302b714dada,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-cf9d84f7-fba9-4cea-bda2-c69343a12291,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-b0e8af24-61ca-4283-8d7a-0ab6d5346cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-356a3984-8c45-428a-8265-a00f9d37521a,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-cbafc758-f5ac-429f-92ea-cc6b0b970b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-459bd1bc-4a4a-4ae0-9882-ca00013334e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-9f7b6edb-dfd4-4f14-a655-21148a823f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-dd9649f7-40c9-4d8c-862b-547469966654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830572231-172.17.0.20-1597085789817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39854,DS-656ff08d-48d4-4de9-89e4-1779ce2240e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-a53d5e76-a8db-4122-a29d-eddc46b1c358,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c4fbbca8-5481-4774-8256-7b7feac4f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-5dc26483-a05f-4ea4-a0e6-901a5bfd8e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-5aba6e01-ba36-4a7a-8419-666eae869435,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-e89a5114-0ba8-478e-8ae0-9710b9d828f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-cbe62181-693b-45bd-851c-c7b29928e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-38324dd4-d178-47e1-8b76-4d2858aad08a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830572231-172.17.0.20-1597085789817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39854,DS-656ff08d-48d4-4de9-89e4-1779ce2240e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-a53d5e76-a8db-4122-a29d-eddc46b1c358,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c4fbbca8-5481-4774-8256-7b7feac4f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-5dc26483-a05f-4ea4-a0e6-901a5bfd8e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-5aba6e01-ba36-4a7a-8419-666eae869435,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-e89a5114-0ba8-478e-8ae0-9710b9d828f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-cbe62181-693b-45bd-851c-c7b29928e13c,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-38324dd4-d178-47e1-8b76-4d2858aad08a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409044069-172.17.0.20-1597085824329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43442,DS-81973d08-908f-429e-9a77-68ce444e4f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-bd0b4063-f5f9-4e3d-95c5-ece5fed776a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-a122df8c-86b9-44f7-b45e-89b6f9aa776a,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-201219bf-e9ab-465f-bac0-8dfc48bf4d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-ca52eab1-a5c1-4bb5-a291-60e1a3b764c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5c44047f-70a3-4b31-9601-01bc0f47163b,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-0a2d44df-5736-44d4-a310-65471d12e384,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-bec1adbf-3c4f-4975-b401-9af1dc6b545e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1409044069-172.17.0.20-1597085824329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43442,DS-81973d08-908f-429e-9a77-68ce444e4f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-bd0b4063-f5f9-4e3d-95c5-ece5fed776a1,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-a122df8c-86b9-44f7-b45e-89b6f9aa776a,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-201219bf-e9ab-465f-bac0-8dfc48bf4d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-ca52eab1-a5c1-4bb5-a291-60e1a3b764c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5c44047f-70a3-4b31-9601-01bc0f47163b,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-0a2d44df-5736-44d4-a310-65471d12e384,DISK], DatanodeInfoWithStorage[127.0.0.1:33366,DS-bec1adbf-3c4f-4975-b401-9af1dc6b545e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593682067-172.17.0.20-1597086046786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-c00526e6-19b2-46a0-abb1-eb8c38c21d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-50e3b94d-3628-44f0-9266-14481f8076ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-0d52c971-d7af-49fd-a318-22a7e1f5a6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-56514f03-07ed-42e4-9643-ac3aa7b115c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-68cf30af-5db9-41ef-b729-73b8d23016de,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-a018b801-3db2-4c1c-9f60-ad4c2844bfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-5f6f8986-b9c1-4441-882e-dbf97b776c79,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-77d524df-f131-407c-990a-fa20d6653e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593682067-172.17.0.20-1597086046786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-c00526e6-19b2-46a0-abb1-eb8c38c21d23,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-50e3b94d-3628-44f0-9266-14481f8076ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-0d52c971-d7af-49fd-a318-22a7e1f5a6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-56514f03-07ed-42e4-9643-ac3aa7b115c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-68cf30af-5db9-41ef-b729-73b8d23016de,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-a018b801-3db2-4c1c-9f60-ad4c2844bfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-5f6f8986-b9c1-4441-882e-dbf97b776c79,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-77d524df-f131-407c-990a-fa20d6653e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051246556-172.17.0.20-1597086276517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-db122d67-19cd-454e-ab55-1b5ec8114ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-48662172-a8a5-49bc-a822-be27b5150a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-88767357-3667-46f8-97ca-2856a1976665,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-bb0bfa33-ef8b-4701-957a-6738f3d82594,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-bc2fd172-2403-422b-b742-ab7e129704a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-3d30a388-bc1b-4ec9-8a40-9602dfab34df,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-00451f72-79b1-404c-8daf-536ff5570fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-4599b36d-cb08-49cf-b5a0-5ab585c171b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1051246556-172.17.0.20-1597086276517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33285,DS-db122d67-19cd-454e-ab55-1b5ec8114ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-48662172-a8a5-49bc-a822-be27b5150a49,DISK], DatanodeInfoWithStorage[127.0.0.1:41848,DS-88767357-3667-46f8-97ca-2856a1976665,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-bb0bfa33-ef8b-4701-957a-6738f3d82594,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-bc2fd172-2403-422b-b742-ab7e129704a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-3d30a388-bc1b-4ec9-8a40-9602dfab34df,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-00451f72-79b1-404c-8daf-536ff5570fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-4599b36d-cb08-49cf-b5a0-5ab585c171b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446069430-172.17.0.20-1597086340102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36117,DS-401f68e8-fd3f-4642-b945-d2a716578f91,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-9bc6f60c-1d65-4448-a582-f29d53395e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-44b1a88f-6732-49cb-af8f-c2c584bff501,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-54d1d410-f3b1-439e-b26c-3753985ba079,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-5300fcd4-9c4c-45fe-970d-8071f0e750f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-57961f4e-66fa-4049-8135-fad596a711d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-fcf0f780-3733-4be2-9fca-9090f89b4585,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-52238573-ef4e-4bed-a794-31335b2d86ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446069430-172.17.0.20-1597086340102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36117,DS-401f68e8-fd3f-4642-b945-d2a716578f91,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-9bc6f60c-1d65-4448-a582-f29d53395e88,DISK], DatanodeInfoWithStorage[127.0.0.1:37182,DS-44b1a88f-6732-49cb-af8f-c2c584bff501,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-54d1d410-f3b1-439e-b26c-3753985ba079,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-5300fcd4-9c4c-45fe-970d-8071f0e750f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-57961f4e-66fa-4049-8135-fad596a711d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-fcf0f780-3733-4be2-9fca-9090f89b4585,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-52238573-ef4e-4bed-a794-31335b2d86ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399861620-172.17.0.20-1597086485743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-336a51f9-0d39-4b43-98aa-f671630b4400,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-c6f44bb3-1837-4633-b0bf-b638095488f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-07a30f28-b45a-4ff7-a24b-0380adf5add0,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-a124c8b6-8608-4529-b3fe-49f69a62eee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-f197ea51-f21a-4744-a750-0f094270e016,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-a137e78e-7d73-465b-a167-6c9e4445aba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-7801045e-ed04-46e5-b6a3-3629bc3e876e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-21adb139-37e4-48e4-8baa-4e2529e5757a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399861620-172.17.0.20-1597086485743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40428,DS-336a51f9-0d39-4b43-98aa-f671630b4400,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-c6f44bb3-1837-4633-b0bf-b638095488f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-07a30f28-b45a-4ff7-a24b-0380adf5add0,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-a124c8b6-8608-4529-b3fe-49f69a62eee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-f197ea51-f21a-4744-a750-0f094270e016,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-a137e78e-7d73-465b-a167-6c9e4445aba5,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-7801045e-ed04-46e5-b6a3-3629bc3e876e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-21adb139-37e4-48e4-8baa-4e2529e5757a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907822982-172.17.0.20-1597086749313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-7e8e5abd-fe45-4f42-90cf-24c6a21417cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-91cdcb6f-656e-4d43-80d7-e75b75b8c755,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-dea6d1fa-d0cc-4702-8b93-f52f758c7b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-d870e597-e487-4f14-b414-ef8a0e911328,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-b2702d29-e5d1-44a1-83c9-4a2d546bd504,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-0b7a2732-25c5-427e-a59e-209975fba200,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-65334f0a-7302-4277-9d1c-a9a473b4cd52,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-fb508498-a338-4697-a55c-13747fb95e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-907822982-172.17.0.20-1597086749313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44950,DS-7e8e5abd-fe45-4f42-90cf-24c6a21417cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-91cdcb6f-656e-4d43-80d7-e75b75b8c755,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-dea6d1fa-d0cc-4702-8b93-f52f758c7b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-d870e597-e487-4f14-b414-ef8a0e911328,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-b2702d29-e5d1-44a1-83c9-4a2d546bd504,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-0b7a2732-25c5-427e-a59e-209975fba200,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-65334f0a-7302-4277-9d1c-a9a473b4cd52,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-fb508498-a338-4697-a55c-13747fb95e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183035382-172.17.0.20-1597086824315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41145,DS-b64fc403-e9ec-4568-b8ea-4673f86c016d,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-e75fdc92-80b7-419b-adaa-9db3fd8a0280,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-0ab75826-32c2-4a5d-9922-ffdfc67ea6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-df55bfb7-2ad9-455d-b17a-fe642aef9696,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-b2b6f085-3e29-4ca1-9e86-d0b8a279acdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-ffe6b07d-79f7-45d3-be8d-57cb277bab51,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-1f4bde1b-9262-4703-8360-16fe016b171a,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-c6230a75-683c-4517-9434-f134e040b93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-183035382-172.17.0.20-1597086824315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41145,DS-b64fc403-e9ec-4568-b8ea-4673f86c016d,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-e75fdc92-80b7-419b-adaa-9db3fd8a0280,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-0ab75826-32c2-4a5d-9922-ffdfc67ea6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-df55bfb7-2ad9-455d-b17a-fe642aef9696,DISK], DatanodeInfoWithStorage[127.0.0.1:39426,DS-b2b6f085-3e29-4ca1-9e86-d0b8a279acdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-ffe6b07d-79f7-45d3-be8d-57cb277bab51,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-1f4bde1b-9262-4703-8360-16fe016b171a,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-c6230a75-683c-4517-9434-f134e040b93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680082302-172.17.0.20-1597086933391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-be7c8b29-5e51-4c32-9641-d94c30b8b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-e24a25d1-7d8d-49da-919c-e3759c3946e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-352c2b72-cf8d-4cba-a35c-473a70987918,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-ba99e917-00e3-49df-8f8a-0cc23c84d60e,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-9fb69a6d-f8f8-4d44-acc6-12cb633e01a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-85f99fa0-680c-4def-aadd-86f0b5729877,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-a6fe11da-51cb-4c4d-946b-f9df137b1ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-506890af-52ef-496f-8173-afe4a5f12668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680082302-172.17.0.20-1597086933391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41127,DS-be7c8b29-5e51-4c32-9641-d94c30b8b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-e24a25d1-7d8d-49da-919c-e3759c3946e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-352c2b72-cf8d-4cba-a35c-473a70987918,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-ba99e917-00e3-49df-8f8a-0cc23c84d60e,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-9fb69a6d-f8f8-4d44-acc6-12cb633e01a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-85f99fa0-680c-4def-aadd-86f0b5729877,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-a6fe11da-51cb-4c4d-946b-f9df137b1ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-506890af-52ef-496f-8173-afe4a5f12668,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5498
