reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393015676-172.17.0.8-1597195948640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46389,DS-6d0af405-25c1-4610-8225-53fc048932cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-ba831b2a-ebf3-4ae3-8318-9fa7b37d6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-e1accceb-97ab-4761-a133-0d2d156adc04,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-f78c0341-7784-4201-8464-7412eac7e524,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-249f4d99-c22a-441f-8f7b-fce98dd1d602,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-76dcff66-3805-4808-b1fe-26b445da3b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-1086b0a5-d341-4650-a236-549166cd3992,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-18c014c0-7312-485f-bfb7-dd53f57e0d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393015676-172.17.0.8-1597195948640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46389,DS-6d0af405-25c1-4610-8225-53fc048932cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-ba831b2a-ebf3-4ae3-8318-9fa7b37d6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-e1accceb-97ab-4761-a133-0d2d156adc04,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-f78c0341-7784-4201-8464-7412eac7e524,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-249f4d99-c22a-441f-8f7b-fce98dd1d602,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-76dcff66-3805-4808-b1fe-26b445da3b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-1086b0a5-d341-4650-a236-549166cd3992,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-18c014c0-7312-485f-bfb7-dd53f57e0d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667297890-172.17.0.8-1597196167960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43765,DS-a83cf36e-0a4d-4723-aa8f-3e17fb67c456,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-9ba4f43a-db2c-4570-baed-5d5ac09d4610,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-2baa382a-116e-4126-91e9-7a02f0432be7,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-ea95d687-c912-493a-ad39-f4bf2922391a,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-6b304a97-bd9f-491e-a09f-0d1f06680bde,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-a44bc92d-29b1-47cf-a16c-ae9a42f752bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-967f8da0-4169-4414-b270-541191fa05b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-dc7fe722-3612-4b4e-878a-b40e738a4607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667297890-172.17.0.8-1597196167960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43765,DS-a83cf36e-0a4d-4723-aa8f-3e17fb67c456,DISK], DatanodeInfoWithStorage[127.0.0.1:38941,DS-9ba4f43a-db2c-4570-baed-5d5ac09d4610,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-2baa382a-116e-4126-91e9-7a02f0432be7,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-ea95d687-c912-493a-ad39-f4bf2922391a,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-6b304a97-bd9f-491e-a09f-0d1f06680bde,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-a44bc92d-29b1-47cf-a16c-ae9a42f752bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-967f8da0-4169-4414-b270-541191fa05b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-dc7fe722-3612-4b4e-878a-b40e738a4607,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245023699-172.17.0.8-1597196342988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37079,DS-738996ee-e50e-4159-bcfe-26166734c062,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-4ec36523-535d-4ca2-9498-cbdc40eacd49,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-b23db28c-38af-46d7-bb3e-d3602bb47406,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-f536bbb3-0068-4510-b375-fecc3cf07e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-23010f52-5d91-4610-b291-77c46cfc82a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-41e255ff-3276-473e-932c-1e6e25b71496,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-90d40227-3860-4074-adc5-91e8ba554cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-ba1eb507-7786-4f9d-bde1-5effba981f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1245023699-172.17.0.8-1597196342988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37079,DS-738996ee-e50e-4159-bcfe-26166734c062,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-4ec36523-535d-4ca2-9498-cbdc40eacd49,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-b23db28c-38af-46d7-bb3e-d3602bb47406,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-f536bbb3-0068-4510-b375-fecc3cf07e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-23010f52-5d91-4610-b291-77c46cfc82a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-41e255ff-3276-473e-932c-1e6e25b71496,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-90d40227-3860-4074-adc5-91e8ba554cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-ba1eb507-7786-4f9d-bde1-5effba981f9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988818009-172.17.0.8-1597197022115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42896,DS-333d19c5-33be-4347-818e-ad08fc3f00a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-74214102-6119-4da2-8cbe-f4dc5f278a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-5a9020d2-fd81-4000-b991-43cb9fbafc94,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-efc46ab0-fc3c-4ef7-9297-f1eeb89c776b,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-55a45f92-c1e2-4863-8f73-cd12872f39fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-123b140d-604c-4d43-ad11-257261ef5ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-e0ed3fa7-ca14-449f-a8e0-ce2bd74c5831,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-e4a2ae9f-a0ad-40ed-b8f8-537e6c1246b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-988818009-172.17.0.8-1597197022115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42896,DS-333d19c5-33be-4347-818e-ad08fc3f00a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-74214102-6119-4da2-8cbe-f4dc5f278a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-5a9020d2-fd81-4000-b991-43cb9fbafc94,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-efc46ab0-fc3c-4ef7-9297-f1eeb89c776b,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-55a45f92-c1e2-4863-8f73-cd12872f39fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-123b140d-604c-4d43-ad11-257261ef5ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-e0ed3fa7-ca14-449f-a8e0-ce2bd74c5831,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-e4a2ae9f-a0ad-40ed-b8f8-537e6c1246b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393124303-172.17.0.8-1597197092428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43930,DS-35315ec4-412f-40e6-b2df-18fb1d76fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-6c3caa72-7470-498e-b4c7-739591eb1d29,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-d75ce227-d9b7-4e85-8c3a-959e81371f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-207a20b6-793f-4210-9446-69cb0207eb93,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-fbd1db01-863c-47bd-a1e1-4105675cd061,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-2b6014c7-6d1b-4092-af18-46ece4159377,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-c43b0a27-b05d-442e-9ef5-516ada15877a,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-ab1f503c-40a2-472a-9978-7c3670d95b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-393124303-172.17.0.8-1597197092428:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43930,DS-35315ec4-412f-40e6-b2df-18fb1d76fe65,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-6c3caa72-7470-498e-b4c7-739591eb1d29,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-d75ce227-d9b7-4e85-8c3a-959e81371f39,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-207a20b6-793f-4210-9446-69cb0207eb93,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-fbd1db01-863c-47bd-a1e1-4105675cd061,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-2b6014c7-6d1b-4092-af18-46ece4159377,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-c43b0a27-b05d-442e-9ef5-516ada15877a,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-ab1f503c-40a2-472a-9978-7c3670d95b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022743201-172.17.0.8-1597197340364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-1cb567a0-cb95-4918-8423-7a8e3ddc4a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-8bbd10a3-402b-48c8-b7ff-c36f665ae3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-2417b317-63ed-41e6-991e-3463ec3d69b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-18e9cc32-fe2e-4081-b496-88023356e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-eefd2668-8765-4980-b12b-86dfc6aeeab6,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-b8015d37-3a64-4220-8fbb-a9e613307211,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-dc9de3e7-8477-4a4e-80e1-94b08fda4789,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-e238bb12-0316-455d-a3b7-f88b98645b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022743201-172.17.0.8-1597197340364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-1cb567a0-cb95-4918-8423-7a8e3ddc4a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-8bbd10a3-402b-48c8-b7ff-c36f665ae3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-2417b317-63ed-41e6-991e-3463ec3d69b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36629,DS-18e9cc32-fe2e-4081-b496-88023356e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-eefd2668-8765-4980-b12b-86dfc6aeeab6,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-b8015d37-3a64-4220-8fbb-a9e613307211,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-dc9de3e7-8477-4a4e-80e1-94b08fda4789,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-e238bb12-0316-455d-a3b7-f88b98645b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217574141-172.17.0.8-1597197421964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-bff3d0f8-55f5-44cd-b6cd-833aac0968f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-0dd335b0-a0a6-40fa-afb0-54dd81816efd,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-1a5ec838-c6e9-43bb-a269-bd59d99fde55,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-5507ce5e-6bf5-4679-9095-eeb6ab31c7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-e885e473-34d9-4678-a5e0-5f4431b7f44b,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-f17fd861-5b5d-4079-865d-e2b26f8c57f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-8e308347-6038-4139-80ad-2d66ca7d2622,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-d918a181-7ba6-4110-889e-250f59cf670c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-217574141-172.17.0.8-1597197421964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-bff3d0f8-55f5-44cd-b6cd-833aac0968f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-0dd335b0-a0a6-40fa-afb0-54dd81816efd,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-1a5ec838-c6e9-43bb-a269-bd59d99fde55,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-5507ce5e-6bf5-4679-9095-eeb6ab31c7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-e885e473-34d9-4678-a5e0-5f4431b7f44b,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-f17fd861-5b5d-4079-865d-e2b26f8c57f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-8e308347-6038-4139-80ad-2d66ca7d2622,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-d918a181-7ba6-4110-889e-250f59cf670c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262772913-172.17.0.8-1597197658458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-e0cc9d4e-12bd-4d26-8354-82ea0ceb4ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-bcbf2dae-dc81-43b0-a341-4399c6ca3240,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-55042889-5bae-45c6-9990-2b1396ba3e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-3877d814-d9f9-4b08-99e9-5811fbe7840b,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-fe9fbe1d-86bb-47a1-b82d-a6b17acf3f26,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-2c6d9014-3544-453f-aba5-a03886c0b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-5d4756ea-7595-4bc8-93c3-127c14d03668,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-e8554267-a425-4cf6-b2ef-e7ae26b77d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-262772913-172.17.0.8-1597197658458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45151,DS-e0cc9d4e-12bd-4d26-8354-82ea0ceb4ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42683,DS-bcbf2dae-dc81-43b0-a341-4399c6ca3240,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-55042889-5bae-45c6-9990-2b1396ba3e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-3877d814-d9f9-4b08-99e9-5811fbe7840b,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-fe9fbe1d-86bb-47a1-b82d-a6b17acf3f26,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-2c6d9014-3544-453f-aba5-a03886c0b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-5d4756ea-7595-4bc8-93c3-127c14d03668,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-e8554267-a425-4cf6-b2ef-e7ae26b77d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383109515-172.17.0.8-1597197728810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-b7f9f1a0-1bee-4a74-b978-d4607fc0d066,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-bd6a56e2-fa9e-4237-906d-2f0d0fa249ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-cdef030f-dce6-439d-bfb5-c6f3f2b435cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-b8be119a-94a4-4984-87a6-d81f79eb7173,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-51f5c365-0189-45dc-bd66-cbe1827ec584,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-bf133fe4-b487-4b05-97ac-375be5c68d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-f150215c-5d02-49e4-833e-ae9ec3ae051f,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-e75727f0-a0a7-4b08-b550-0c4ea895e34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383109515-172.17.0.8-1597197728810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-b7f9f1a0-1bee-4a74-b978-d4607fc0d066,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-bd6a56e2-fa9e-4237-906d-2f0d0fa249ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-cdef030f-dce6-439d-bfb5-c6f3f2b435cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-b8be119a-94a4-4984-87a6-d81f79eb7173,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-51f5c365-0189-45dc-bd66-cbe1827ec584,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-bf133fe4-b487-4b05-97ac-375be5c68d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-f150215c-5d02-49e4-833e-ae9ec3ae051f,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-e75727f0-a0a7-4b08-b550-0c4ea895e34e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359759044-172.17.0.8-1597197979456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37002,DS-7ed6d440-1417-4ec1-aaf0-043f6e5b2e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-59bb2995-4387-422f-98df-f922e4ea3610,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-4bbbec99-8e79-4bf3-82fd-f21dcabb427b,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-2341c861-2ac4-4893-9027-cbfae8598f87,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-86870b8e-49a3-4f13-8e0c-a5177b25e1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-42b18951-714f-44ab-8dbb-17e698453fef,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-065088e9-e435-42b1-b64e-a1b9b6230c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-0dd9616f-8523-4853-b7f6-f07778fb9392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359759044-172.17.0.8-1597197979456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37002,DS-7ed6d440-1417-4ec1-aaf0-043f6e5b2e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-59bb2995-4387-422f-98df-f922e4ea3610,DISK], DatanodeInfoWithStorage[127.0.0.1:43805,DS-4bbbec99-8e79-4bf3-82fd-f21dcabb427b,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-2341c861-2ac4-4893-9027-cbfae8598f87,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-86870b8e-49a3-4f13-8e0c-a5177b25e1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-42b18951-714f-44ab-8dbb-17e698453fef,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-065088e9-e435-42b1-b64e-a1b9b6230c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-0dd9616f-8523-4853-b7f6-f07778fb9392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43497684-172.17.0.8-1597198307956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-2e18dd8d-7ec0-4235-b29f-45be53bfb65f,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-d4ceeba5-d94f-451b-a688-561e068d5632,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-ab3e88a7-ba96-4a18-98ef-d28062aac3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-8c7ab202-4b1e-4862-8909-7a5368367dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-71298e72-685b-44b7-800e-febb5b79f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e02180f0-ee93-4d40-9e24-c2213a1a96e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-548599c6-c657-4c20-a510-d5538ed6bf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-42e1edb5-7074-4e00-a440-19d172a14f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43497684-172.17.0.8-1597198307956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42068,DS-2e18dd8d-7ec0-4235-b29f-45be53bfb65f,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-d4ceeba5-d94f-451b-a688-561e068d5632,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-ab3e88a7-ba96-4a18-98ef-d28062aac3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-8c7ab202-4b1e-4862-8909-7a5368367dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-71298e72-685b-44b7-800e-febb5b79f08c,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e02180f0-ee93-4d40-9e24-c2213a1a96e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-548599c6-c657-4c20-a510-d5538ed6bf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-42e1edb5-7074-4e00-a440-19d172a14f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944461605-172.17.0.8-1597198453205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40722,DS-5e8b43ac-68c1-433e-ab6d-d8903530018b,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-57c1f9ea-03e5-407e-9546-6154edeb748a,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-e6bdc570-7540-4581-8f75-5873e697018f,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-20af812a-9ae6-4272-857e-3742bd3417d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-47429983-fd97-462f-91e6-971472629de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-1e877320-9c68-40ac-8ec2-fe8d2246d6df,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-57d289a3-c4cb-4720-ba29-8ed2a597f2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-2b8309a8-aba2-446b-9096-1a5ef85bde95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-944461605-172.17.0.8-1597198453205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40722,DS-5e8b43ac-68c1-433e-ab6d-d8903530018b,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-57c1f9ea-03e5-407e-9546-6154edeb748a,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-e6bdc570-7540-4581-8f75-5873e697018f,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-20af812a-9ae6-4272-857e-3742bd3417d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-47429983-fd97-462f-91e6-971472629de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-1e877320-9c68-40ac-8ec2-fe8d2246d6df,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-57d289a3-c4cb-4720-ba29-8ed2a597f2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-2b8309a8-aba2-446b-9096-1a5ef85bde95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025706767-172.17.0.8-1597198598012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-a792f28c-bcc1-4e2c-9247-45fe72375867,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-219f3cf2-0a41-4cd2-9b0b-812b864f1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-fe91d728-287a-4ee5-976c-4bf337abdac3,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-9a93b483-9685-4529-8bd9-6952ab665022,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-ee3b9c9e-1305-4183-81c9-553033558552,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-f4b41ab3-0e38-4f51-ac97-52cd605a7299,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-87bbf192-acac-42d4-a9ad-903858b386d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-6e684fb8-0361-4bd7-a1e7-2a1b26af6a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025706767-172.17.0.8-1597198598012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42922,DS-a792f28c-bcc1-4e2c-9247-45fe72375867,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-219f3cf2-0a41-4cd2-9b0b-812b864f1b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-fe91d728-287a-4ee5-976c-4bf337abdac3,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-9a93b483-9685-4529-8bd9-6952ab665022,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-ee3b9c9e-1305-4183-81c9-553033558552,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-f4b41ab3-0e38-4f51-ac97-52cd605a7299,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-87bbf192-acac-42d4-a9ad-903858b386d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-6e684fb8-0361-4bd7-a1e7-2a1b26af6a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771161899-172.17.0.8-1597198669079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38440,DS-8c55f67f-a801-422f-b33d-9f3ea39f98fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-eef17837-abcb-4f80-844e-89380b3f5e86,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-a49f6b96-06aa-4e4e-86b0-91859aae4839,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-acb05cec-c7f9-4f8f-802b-ff7812d89afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-63196363-7340-482a-8e60-92f3282cb4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-36d38df2-5e51-475b-b3be-a58dfeac17b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-3b1c2190-eafc-4696-98ae-50c1aa21c2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-ed7e16c4-e04d-4029-b6ea-89a99d0a268d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-771161899-172.17.0.8-1597198669079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38440,DS-8c55f67f-a801-422f-b33d-9f3ea39f98fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-eef17837-abcb-4f80-844e-89380b3f5e86,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-a49f6b96-06aa-4e4e-86b0-91859aae4839,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-acb05cec-c7f9-4f8f-802b-ff7812d89afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-63196363-7340-482a-8e60-92f3282cb4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-36d38df2-5e51-475b-b3be-a58dfeac17b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-3b1c2190-eafc-4696-98ae-50c1aa21c2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-ed7e16c4-e04d-4029-b6ea-89a99d0a268d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946666557-172.17.0.8-1597199610962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45274,DS-79c0a59a-f856-40cb-860f-c6a23932e3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-b18eb590-3472-4920-acb9-2f129d0fec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-d404a172-54c2-48fc-b72a-0badf2836111,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-34c7a10f-d554-48c9-8302-ce1bece08e92,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-801cfec2-0639-4fbc-a49b-76e09efd2016,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-94b974b6-fd3c-4bee-a2f5-7eb6d9109dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-85155f0a-e594-4d28-be14-23854676b7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-5c51d9f4-534c-47a4-8660-0443f37841cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-946666557-172.17.0.8-1597199610962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45274,DS-79c0a59a-f856-40cb-860f-c6a23932e3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-b18eb590-3472-4920-acb9-2f129d0fec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-d404a172-54c2-48fc-b72a-0badf2836111,DISK], DatanodeInfoWithStorage[127.0.0.1:42012,DS-34c7a10f-d554-48c9-8302-ce1bece08e92,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-801cfec2-0639-4fbc-a49b-76e09efd2016,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-94b974b6-fd3c-4bee-a2f5-7eb6d9109dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-85155f0a-e594-4d28-be14-23854676b7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-5c51d9f4-534c-47a4-8660-0443f37841cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796056584-172.17.0.8-1597199641259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42059,DS-c180fb6c-ed4f-4d12-8dcf-2de59a651af7,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-83116f64-5158-497e-943a-516a68c33d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-7da56356-8df3-494e-b7a9-3c2c0fa7911f,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-0a5647ad-4bdc-4af8-85f7-6fd25085e751,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-a864818a-1204-462d-b83d-0627d9b4e9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-e034f300-71dd-481a-80fc-a8c938a0f310,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-46c2c20c-041d-4144-8ef2-f52a66fe9196,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-af315bab-9f3c-4e15-bc63-92fde21dff11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-796056584-172.17.0.8-1597199641259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42059,DS-c180fb6c-ed4f-4d12-8dcf-2de59a651af7,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-83116f64-5158-497e-943a-516a68c33d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-7da56356-8df3-494e-b7a9-3c2c0fa7911f,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-0a5647ad-4bdc-4af8-85f7-6fd25085e751,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-a864818a-1204-462d-b83d-0627d9b4e9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-e034f300-71dd-481a-80fc-a8c938a0f310,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-46c2c20c-041d-4144-8ef2-f52a66fe9196,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-af315bab-9f3c-4e15-bc63-92fde21dff11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243325766-172.17.0.8-1597200027666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-baa73907-5bf7-4f59-8ea6-fb97c4778324,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-c3114e5a-392c-49e7-8bab-34a21986c42a,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-1708ddbb-f97d-4c74-915e-ded7c5b3b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-d1942af2-1018-4108-9d1f-f3f951cc5bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-4f2591fb-8f1b-4118-82e6-2783865fd928,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-d506ed07-b8d8-4935-8040-4d25288497a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-3419d682-2582-46ff-9636-4efa0ae06636,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-8fd17079-d5f1-424b-a1fb-d290ff09960d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243325766-172.17.0.8-1597200027666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37729,DS-baa73907-5bf7-4f59-8ea6-fb97c4778324,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-c3114e5a-392c-49e7-8bab-34a21986c42a,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-1708ddbb-f97d-4c74-915e-ded7c5b3b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-d1942af2-1018-4108-9d1f-f3f951cc5bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-4f2591fb-8f1b-4118-82e6-2783865fd928,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-d506ed07-b8d8-4935-8040-4d25288497a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-3419d682-2582-46ff-9636-4efa0ae06636,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-8fd17079-d5f1-424b-a1fb-d290ff09960d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768513137-172.17.0.8-1597200264799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39712,DS-2dde418a-c211-4060-853b-41c44e8c6347,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-9e5c4058-d70d-4b9d-a92b-0376edcc5e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-ca8d18ac-f1ca-459d-a38a-cacdfc58c1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-73b9f102-3082-4ee1-b948-c5fa26eb81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-0600e757-359a-4f5b-a5f1-3674788a7b92,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-82d968c3-6da4-4680-9bb4-b77d6308b865,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-164c2578-08ed-4468-bc24-75fe5bd8fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-8ab4f759-e845-4147-a477-5ad4300727f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768513137-172.17.0.8-1597200264799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39712,DS-2dde418a-c211-4060-853b-41c44e8c6347,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-9e5c4058-d70d-4b9d-a92b-0376edcc5e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-ca8d18ac-f1ca-459d-a38a-cacdfc58c1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-73b9f102-3082-4ee1-b948-c5fa26eb81a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-0600e757-359a-4f5b-a5f1-3674788a7b92,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-82d968c3-6da4-4680-9bb4-b77d6308b865,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-164c2578-08ed-4468-bc24-75fe5bd8fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-8ab4f759-e845-4147-a477-5ad4300727f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.decommission.max.concurrent.tracked.nodes
component: hdfs:NameNode
v1: 200
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835960440-172.17.0.8-1597200515697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42698,DS-6538a39a-615a-4d86-8f5a-b9145f766255,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-fd25e392-3f20-463c-8ec2-8a1cf25d4914,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-0e3cc995-228c-45c0-bdd6-c747409c53d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-42e20e3f-9ae7-49a1-8073-4caca66a76c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-7c464d4b-a1b8-497c-80c4-d23fe8a7661c,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-245b3812-dd70-4fc0-bdb4-c0a7a443d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-6d9b03e6-6072-458e-b429-06ccba8cea30,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-8f6d16ef-dbbf-4c50-843e-6359430c6ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835960440-172.17.0.8-1597200515697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42698,DS-6538a39a-615a-4d86-8f5a-b9145f766255,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-fd25e392-3f20-463c-8ec2-8a1cf25d4914,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-0e3cc995-228c-45c0-bdd6-c747409c53d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44838,DS-42e20e3f-9ae7-49a1-8073-4caca66a76c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-7c464d4b-a1b8-497c-80c4-d23fe8a7661c,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-245b3812-dd70-4fc0-bdb4-c0a7a443d90c,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-6d9b03e6-6072-458e-b429-06ccba8cea30,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-8f6d16ef-dbbf-4c50-843e-6359430c6ff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5326
