reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931647447-172.17.0.14-1597204891887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-2d98e91d-a90f-4ca8-b406-5f1e36ff5022,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-4fb93337-ecc4-4e8d-a9c9-132025ce71c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-f4d423a8-9147-4df1-b931-bc2242b5a2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-0a2814f7-55c2-4ee8-9a03-56801a0fbfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-2d7e821c-08a8-469e-8f71-1248abb0df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-0061b674-16e6-4ecd-8dda-d99b5f33f225,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-a68aab58-71c8-4fec-8666-4f6f533a945f,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-d499729b-2594-489f-9837-e23a74f1c8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-931647447-172.17.0.14-1597204891887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-2d98e91d-a90f-4ca8-b406-5f1e36ff5022,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-4fb93337-ecc4-4e8d-a9c9-132025ce71c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-f4d423a8-9147-4df1-b931-bc2242b5a2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-0a2814f7-55c2-4ee8-9a03-56801a0fbfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-2d7e821c-08a8-469e-8f71-1248abb0df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-0061b674-16e6-4ecd-8dda-d99b5f33f225,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-a68aab58-71c8-4fec-8666-4f6f533a945f,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-d499729b-2594-489f-9837-e23a74f1c8e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444276884-172.17.0.14-1597205272718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-6d957ee6-f501-4d3c-86a2-deec09420461,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-9a78fffa-fe18-49ad-8618-3ed7b70c2adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-ff916a2e-033a-48fd-8687-8d3c7744cc10,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-b616237e-3925-4b8a-a6dd-6fe442d3a22e,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-423a0192-a819-477f-a0f1-564c19ccd097,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-5cc48d2f-357a-419b-bc79-a4dc3b3c0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-6e0b4cd8-0e23-4003-9011-3b6eaabe5558,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-71b39caa-bc73-4694-b1d9-c74db10fc017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444276884-172.17.0.14-1597205272718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36385,DS-6d957ee6-f501-4d3c-86a2-deec09420461,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-9a78fffa-fe18-49ad-8618-3ed7b70c2adf,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-ff916a2e-033a-48fd-8687-8d3c7744cc10,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-b616237e-3925-4b8a-a6dd-6fe442d3a22e,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-423a0192-a819-477f-a0f1-564c19ccd097,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-5cc48d2f-357a-419b-bc79-a4dc3b3c0c44,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-6e0b4cd8-0e23-4003-9011-3b6eaabe5558,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-71b39caa-bc73-4694-b1d9-c74db10fc017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987797975-172.17.0.14-1597205346432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38820,DS-97151c53-a217-42b8-bb27-e2e8063cdfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-2dadcc06-3245-440b-9948-3c0625856d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-306c52b2-ac7c-41b1-9036-63f946e494b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-d9d5bb4e-64d4-4d8f-a95d-0eb407b10d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-59590d6c-d391-4ecd-b8fc-6a9fe51fe887,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-0b1c5f4b-7a89-432c-af22-5528d2b9c035,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-43bb964c-2066-46ef-9246-f6293b811dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-b3befbe4-d371-4b02-88c3-f2573b4cf0ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-987797975-172.17.0.14-1597205346432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38820,DS-97151c53-a217-42b8-bb27-e2e8063cdfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-2dadcc06-3245-440b-9948-3c0625856d36,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-306c52b2-ac7c-41b1-9036-63f946e494b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-d9d5bb4e-64d4-4d8f-a95d-0eb407b10d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-59590d6c-d391-4ecd-b8fc-6a9fe51fe887,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-0b1c5f4b-7a89-432c-af22-5528d2b9c035,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-43bb964c-2066-46ef-9246-f6293b811dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-b3befbe4-d371-4b02-88c3-f2573b4cf0ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583323875-172.17.0.14-1597205391534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40539,DS-2873cc89-d787-487f-9c16-7d3f4850b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-f66b190e-de33-4b8e-b933-9784f737cdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-293fc7ec-4e41-4515-8268-daea2e605f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-de2c6947-12ec-42e2-835e-0389045f2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-6a79ba42-8768-4195-8c12-40d8feb4291f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-0d88bf98-bb10-4b8a-a9ae-1879f15a7e23,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-63966668-758c-470c-ab3a-558201581445,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-0fa41da2-885c-4411-808d-acc85e892fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583323875-172.17.0.14-1597205391534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40539,DS-2873cc89-d787-487f-9c16-7d3f4850b62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-f66b190e-de33-4b8e-b933-9784f737cdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-293fc7ec-4e41-4515-8268-daea2e605f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-de2c6947-12ec-42e2-835e-0389045f2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-6a79ba42-8768-4195-8c12-40d8feb4291f,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-0d88bf98-bb10-4b8a-a9ae-1879f15a7e23,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-63966668-758c-470c-ab3a-558201581445,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-0fa41da2-885c-4411-808d-acc85e892fa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112577495-172.17.0.14-1597205965320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-123a0491-9c99-4cdd-b123-472d8fbf35d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-1350abaa-2cdd-4e38-83da-7567cb39a357,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-164cb982-aa31-415f-b099-0c165e68429b,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-de4f9eb5-7d61-482d-9c66-22ee880acb96,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-1c6ad7bc-32e5-4a48-a8e9-52511bf84272,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-9183c4dd-5543-4fdc-94ac-7c771b3c6f55,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-4bd1b859-e4b8-4b95-bcc1-cf240ab2c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-605ab5a9-c388-42bd-9273-ab28be494086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112577495-172.17.0.14-1597205965320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37185,DS-123a0491-9c99-4cdd-b123-472d8fbf35d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-1350abaa-2cdd-4e38-83da-7567cb39a357,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-164cb982-aa31-415f-b099-0c165e68429b,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-de4f9eb5-7d61-482d-9c66-22ee880acb96,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-1c6ad7bc-32e5-4a48-a8e9-52511bf84272,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-9183c4dd-5543-4fdc-94ac-7c771b3c6f55,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-4bd1b859-e4b8-4b95-bcc1-cf240ab2c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-605ab5a9-c388-42bd-9273-ab28be494086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245687223-172.17.0.14-1597206001400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40907,DS-2e7a80c2-8e60-4b38-a150-cf978a79bbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-cf97c359-27f2-44ab-a359-3feaa85c547f,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-ab1be245-718b-4b75-acdd-34988647d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-05996597-7319-4ce3-b841-6bbdb9a79ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-5e690960-fb7e-450a-b08f-0b6b6417a1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-304c52df-ec5b-44a8-a402-dd061d70686c,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-17f3eaa8-92bd-4359-9e6b-cd1719778cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-6ce6ab33-2971-40dd-9c29-bc7473f84a26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245687223-172.17.0.14-1597206001400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40907,DS-2e7a80c2-8e60-4b38-a150-cf978a79bbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-cf97c359-27f2-44ab-a359-3feaa85c547f,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-ab1be245-718b-4b75-acdd-34988647d7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-05996597-7319-4ce3-b841-6bbdb9a79ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-5e690960-fb7e-450a-b08f-0b6b6417a1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-304c52df-ec5b-44a8-a402-dd061d70686c,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-17f3eaa8-92bd-4359-9e6b-cd1719778cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-6ce6ab33-2971-40dd-9c29-bc7473f84a26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064144248-172.17.0.14-1597206267417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-930c429a-4c6b-499a-9b9a-ca55dde5218d,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-34014f39-a72a-4433-8e0f-dc8a805fa6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-6c5bb91b-a07f-432d-a69b-a29731b59e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-2c5a4d59-ef09-405a-a171-eb7efc31e36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-487a10d7-550a-4250-8ed4-cf86e2b4fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-e659272c-ddca-4a88-ac11-43576bf30c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-ee9671e0-d8e0-4ad8-a971-68e7628def6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-a7c2ea79-6777-4c31-ae22-46eb5998996a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064144248-172.17.0.14-1597206267417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37976,DS-930c429a-4c6b-499a-9b9a-ca55dde5218d,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-34014f39-a72a-4433-8e0f-dc8a805fa6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-6c5bb91b-a07f-432d-a69b-a29731b59e12,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-2c5a4d59-ef09-405a-a171-eb7efc31e36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37385,DS-487a10d7-550a-4250-8ed4-cf86e2b4fbec,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-e659272c-ddca-4a88-ac11-43576bf30c15,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-ee9671e0-d8e0-4ad8-a971-68e7628def6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-a7c2ea79-6777-4c31-ae22-46eb5998996a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298502805-172.17.0.14-1597206377848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37712,DS-87ea7eb6-c149-4a74-ac3c-e5f1426c8623,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-3d63df6f-2997-41c4-8735-24ac0589cddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-c04dd4e2-4a76-4052-9647-b2aa6145b068,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-477ab0e4-90df-44e9-9f54-120f0638c586,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-7c267279-3551-4df7-9d01-a46da2021ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-46f48c98-3f5b-4f3e-9893-44ab65132545,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-c1697b7e-7a8c-45c3-8e84-e0e18281a731,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-2338b586-feec-42b8-a846-93a9c0966dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1298502805-172.17.0.14-1597206377848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37712,DS-87ea7eb6-c149-4a74-ac3c-e5f1426c8623,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-3d63df6f-2997-41c4-8735-24ac0589cddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-c04dd4e2-4a76-4052-9647-b2aa6145b068,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-477ab0e4-90df-44e9-9f54-120f0638c586,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-7c267279-3551-4df7-9d01-a46da2021ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-46f48c98-3f5b-4f3e-9893-44ab65132545,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-c1697b7e-7a8c-45c3-8e84-e0e18281a731,DISK], DatanodeInfoWithStorage[127.0.0.1:37429,DS-2338b586-feec-42b8-a846-93a9c0966dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365296317-172.17.0.14-1597206560199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37029,DS-7751b9ad-c67a-4778-9d50-80103ad70a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-15442588-dbda-467e-9160-0404c03d8ede,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-fbb0d080-ca2b-4a5d-aece-9da82ca27b74,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-78892074-906e-4931-91cc-e59215cd8e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-4b162a41-1d3c-42e8-9b69-a0740b9272ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-c614847c-20b4-438f-9d75-954dfb7591d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-376dabef-5065-488f-a588-7e85f3764283,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-a5069ff1-3410-45c4-a78c-9ca4748f6538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365296317-172.17.0.14-1597206560199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37029,DS-7751b9ad-c67a-4778-9d50-80103ad70a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-15442588-dbda-467e-9160-0404c03d8ede,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-fbb0d080-ca2b-4a5d-aece-9da82ca27b74,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-78892074-906e-4931-91cc-e59215cd8e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35269,DS-4b162a41-1d3c-42e8-9b69-a0740b9272ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-c614847c-20b4-438f-9d75-954dfb7591d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-376dabef-5065-488f-a588-7e85f3764283,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-a5069ff1-3410-45c4-a78c-9ca4748f6538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116513406-172.17.0.14-1597207059027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-c5bacd7b-799b-473d-97f6-ab3f90de92fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-b07512a4-c9de-4cc1-ad60-31f6c76c8104,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-cc0db491-b4ab-4096-a74f-d4b749358d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-2a8a9183-28c9-40c7-8cb0-03503f69c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-02c0d9a6-a4af-4570-9311-711d7ffec50c,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-481a48fa-aa66-4faa-99c1-0209ada95fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-fde9b412-4c1d-4903-b2a2-068f8b07f168,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-ce8f63d8-09f7-456a-b023-09852d11c7de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116513406-172.17.0.14-1597207059027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-c5bacd7b-799b-473d-97f6-ab3f90de92fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-b07512a4-c9de-4cc1-ad60-31f6c76c8104,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-cc0db491-b4ab-4096-a74f-d4b749358d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37949,DS-2a8a9183-28c9-40c7-8cb0-03503f69c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-02c0d9a6-a4af-4570-9311-711d7ffec50c,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-481a48fa-aa66-4faa-99c1-0209ada95fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-fde9b412-4c1d-4903-b2a2-068f8b07f168,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-ce8f63d8-09f7-456a-b023-09852d11c7de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586817519-172.17.0.14-1597207406741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39709,DS-b04d47f7-6c47-4c62-af65-6ca0b02a9794,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-a8a07ee2-e377-460b-9172-0b840f367a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-047b9876-330d-4f5f-a319-b177bcf5ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-f4dbba54-dca0-4fd9-a45e-9c632725ec47,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-1056162f-bce6-47be-aab1-23542b4c4c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-02829bbc-2b72-4382-9383-8181f441fca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-d711d39c-eb74-406f-a33c-dc9614826b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-2f7e4a30-d8b5-4860-8a5f-ce4fef97afcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-586817519-172.17.0.14-1597207406741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39709,DS-b04d47f7-6c47-4c62-af65-6ca0b02a9794,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-a8a07ee2-e377-460b-9172-0b840f367a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-047b9876-330d-4f5f-a319-b177bcf5ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-f4dbba54-dca0-4fd9-a45e-9c632725ec47,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-1056162f-bce6-47be-aab1-23542b4c4c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-02829bbc-2b72-4382-9383-8181f441fca9,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-d711d39c-eb74-406f-a33c-dc9614826b14,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-2f7e4a30-d8b5-4860-8a5f-ce4fef97afcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895295030-172.17.0.14-1597208180096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-bb9effc7-1823-4948-b49e-072b0e566ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-97600f40-34d7-41d5-a1ea-b424156adc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-9122445f-b753-4af9-9335-6e139e324cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-d5e22968-b6ec-40f9-aa48-37397d38a274,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-bebac390-a47e-4261-b5d5-8ca5220763d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-5eb30bad-ea90-4c54-9676-ca3e7668eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-d1144d5d-a160-4fb7-ac39-e9bfbc06ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-370ab364-3236-42c9-a1da-641614c557f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895295030-172.17.0.14-1597208180096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45682,DS-bb9effc7-1823-4948-b49e-072b0e566ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-97600f40-34d7-41d5-a1ea-b424156adc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-9122445f-b753-4af9-9335-6e139e324cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-d5e22968-b6ec-40f9-aa48-37397d38a274,DISK], DatanodeInfoWithStorage[127.0.0.1:44965,DS-bebac390-a47e-4261-b5d5-8ca5220763d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-5eb30bad-ea90-4c54-9676-ca3e7668eaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-d1144d5d-a160-4fb7-ac39-e9bfbc06ace9,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-370ab364-3236-42c9-a1da-641614c557f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475572560-172.17.0.14-1597208504605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42494,DS-6a438654-3a70-4067-914b-1b214771af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-8ca00826-4f5d-429a-9d02-ceba1e062fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-9467ee69-709d-4ffd-8041-47e1118105f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-1a7bcc8c-78b0-43cf-aca6-ac9a0329cd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-1b80d5e7-b81d-4809-bc17-ff04890ae5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-95d8fe0e-0fa5-4194-900e-7ae9269671b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-c88e1870-3a53-4158-ae78-9aabc04836cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-3561a1dc-d2bb-4739-93ed-de2708f3f4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-475572560-172.17.0.14-1597208504605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42494,DS-6a438654-3a70-4067-914b-1b214771af9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-8ca00826-4f5d-429a-9d02-ceba1e062fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-9467ee69-709d-4ffd-8041-47e1118105f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-1a7bcc8c-78b0-43cf-aca6-ac9a0329cd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-1b80d5e7-b81d-4809-bc17-ff04890ae5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-95d8fe0e-0fa5-4194-900e-7ae9269671b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-c88e1870-3a53-4158-ae78-9aabc04836cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-3561a1dc-d2bb-4739-93ed-de2708f3f4fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862048420-172.17.0.14-1597209140584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-6070a136-c984-4b61-a255-a5d4b51c4f81,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-c4e7b68c-8d36-4f76-a9dc-8ed6a57cd9af,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-a170f5f6-1636-4390-b735-9b2f7459e8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-d74b8d61-d5f6-43fa-a61b-ba65f34c10e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-a16789fa-51ce-4e05-8b35-85933cabfae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-7c22133d-076b-4238-9bcf-c0a38c1967ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-30d8ae2b-3d9f-4771-8c17-9e0b31f7c262,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-fa6a10aa-8c40-4610-9197-f1325aadfa37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862048420-172.17.0.14-1597209140584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43718,DS-6070a136-c984-4b61-a255-a5d4b51c4f81,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-c4e7b68c-8d36-4f76-a9dc-8ed6a57cd9af,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-a170f5f6-1636-4390-b735-9b2f7459e8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-d74b8d61-d5f6-43fa-a61b-ba65f34c10e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-a16789fa-51ce-4e05-8b35-85933cabfae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-7c22133d-076b-4238-9bcf-c0a38c1967ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-30d8ae2b-3d9f-4771-8c17-9e0b31f7c262,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-fa6a10aa-8c40-4610-9197-f1325aadfa37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346327741-172.17.0.14-1597209763224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-39beb1bc-7ae3-4cf9-8761-1edcb4a8e903,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-01ec3ced-212a-4eee-a77c-f1785099740e,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-20c40692-4ecd-42a4-8ef3-ebc12cd7f685,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-06388bb0-1364-4be8-b893-cc50f1215069,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-f22b5275-9453-464b-b60e-281747fe09f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-9b46f6b9-e55b-4e96-be7a-2e5a99f0c9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-f643c350-61e2-4478-be56-a522902fef76,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-1ebe9260-aa05-49af-8530-e553348e3baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346327741-172.17.0.14-1597209763224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-39beb1bc-7ae3-4cf9-8761-1edcb4a8e903,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-01ec3ced-212a-4eee-a77c-f1785099740e,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-20c40692-4ecd-42a4-8ef3-ebc12cd7f685,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-06388bb0-1364-4be8-b893-cc50f1215069,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-f22b5275-9453-464b-b60e-281747fe09f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-9b46f6b9-e55b-4e96-be7a-2e5a99f0c9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-f643c350-61e2-4478-be56-a522902fef76,DISK], DatanodeInfoWithStorage[127.0.0.1:36923,DS-1ebe9260-aa05-49af-8530-e553348e3baf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351101844-172.17.0.14-1597209805407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46003,DS-ecf9e6dd-4d19-494b-8a8d-6845cd28ee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-18c43391-6124-4697-a41b-29926785d83e,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-dc5d1f4c-3231-46c8-92e5-a1deea5199ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-5262f4aa-85fc-4808-a738-be890a9f6306,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-aa501249-fb27-4489-af9b-89521c477276,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-886d1064-9c76-46ad-9cea-fe4c515bf2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-069a4665-0d69-465c-8798-ec460d1d394f,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-b1388926-6b65-4d29-b41e-46ae05a90dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-351101844-172.17.0.14-1597209805407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46003,DS-ecf9e6dd-4d19-494b-8a8d-6845cd28ee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-18c43391-6124-4697-a41b-29926785d83e,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-dc5d1f4c-3231-46c8-92e5-a1deea5199ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-5262f4aa-85fc-4808-a738-be890a9f6306,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-aa501249-fb27-4489-af9b-89521c477276,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-886d1064-9c76-46ad-9cea-fe4c515bf2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-069a4665-0d69-465c-8798-ec460d1d394f,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-b1388926-6b65-4d29-b41e-46ae05a90dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525437184-172.17.0.14-1597209927940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35006,DS-6ad8aa4d-692b-4217-897c-24b0a40962a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-999fadb8-f1e3-456d-9ce1-f3b750581c47,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-9987bfcd-aa5b-4964-b379-3e680da4761e,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-dd5d8900-0bd5-4c86-9d54-4237e481a173,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-27a9100b-75ac-4e5b-8d3e-fe1e309ebaba,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-523a3f8d-a789-4c36-b368-ee042723c40f,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-df142ee6-a5ea-4a4d-8c09-3f062ec3d80c,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-d87b76f7-ae19-4d13-a9ec-8d6c76a9dff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525437184-172.17.0.14-1597209927940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35006,DS-6ad8aa4d-692b-4217-897c-24b0a40962a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-999fadb8-f1e3-456d-9ce1-f3b750581c47,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-9987bfcd-aa5b-4964-b379-3e680da4761e,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-dd5d8900-0bd5-4c86-9d54-4237e481a173,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-27a9100b-75ac-4e5b-8d3e-fe1e309ebaba,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-523a3f8d-a789-4c36-b368-ee042723c40f,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-df142ee6-a5ea-4a4d-8c09-3f062ec3d80c,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-d87b76f7-ae19-4d13-a9ec-8d6c76a9dff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5945
