reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892254217-172.17.0.3-1597053837308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-1308547e-60e2-4194-85c0-c22466e735fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-c4fce367-53d5-4762-b6ae-16166c62b695,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-0b40634c-e011-46af-b4c2-998eacc18533,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-10cd246e-b7e6-40c2-9919-cb919c00265e,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-7e3d3a96-bba5-47a2-a63f-c15dd695f982,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-c23a1a1c-26d7-4990-944f-e7979d5280db,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-b18d1d5b-c086-49a1-834a-d0a791846cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-b0a03532-c91b-4223-9b63-690dbf4fc378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1892254217-172.17.0.3-1597053837308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42853,DS-1308547e-60e2-4194-85c0-c22466e735fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-c4fce367-53d5-4762-b6ae-16166c62b695,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-0b40634c-e011-46af-b4c2-998eacc18533,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-10cd246e-b7e6-40c2-9919-cb919c00265e,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-7e3d3a96-bba5-47a2-a63f-c15dd695f982,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-c23a1a1c-26d7-4990-944f-e7979d5280db,DISK], DatanodeInfoWithStorage[127.0.0.1:43037,DS-b18d1d5b-c086-49a1-834a-d0a791846cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-b0a03532-c91b-4223-9b63-690dbf4fc378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309507611-172.17.0.3-1597054581509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-b3040657-b0c3-4a39-8460-472a6ee10888,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-43bf3e26-8fa2-48e0-a026-3d6dfdc14e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-8f8bdc9b-2b41-428e-a171-a7825982c988,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-355b3724-d04e-4fae-9bfe-afc6ccfc54e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-3bf292db-e669-40f9-a4b8-c5fd05e05384,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-c766ceef-5c4e-4015-a81c-5c9f31663d65,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-8956358c-765d-49d5-a6d0-013b8194d354,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-f0c507da-94e3-4394-8aa1-8399c51bafa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309507611-172.17.0.3-1597054581509:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37757,DS-b3040657-b0c3-4a39-8460-472a6ee10888,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-43bf3e26-8fa2-48e0-a026-3d6dfdc14e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-8f8bdc9b-2b41-428e-a171-a7825982c988,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-355b3724-d04e-4fae-9bfe-afc6ccfc54e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-3bf292db-e669-40f9-a4b8-c5fd05e05384,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-c766ceef-5c4e-4015-a81c-5c9f31663d65,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-8956358c-765d-49d5-a6d0-013b8194d354,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-f0c507da-94e3-4394-8aa1-8399c51bafa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-291693101-172.17.0.3-1597054619924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38508,DS-2dc9827e-6f19-4ce7-aec5-d53c05b50b70,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-874e1f19-062e-4b8a-9b45-5ca4cdc9e258,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-d7c5e26d-1c13-4009-b044-adbdc1e0fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-d0f598bc-1261-4b52-b6af-c5e253f2e599,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-b87aa8bb-c3f4-4778-9094-d81edba20d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-0b1a7693-f680-45f0-8653-70bd8220c425,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-c477f213-4aa0-4afa-8ed6-00981b3c6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-c0f515ed-f961-4391-896a-ab82dbe7c468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-291693101-172.17.0.3-1597054619924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38508,DS-2dc9827e-6f19-4ce7-aec5-d53c05b50b70,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-874e1f19-062e-4b8a-9b45-5ca4cdc9e258,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-d7c5e26d-1c13-4009-b044-adbdc1e0fe25,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-d0f598bc-1261-4b52-b6af-c5e253f2e599,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-b87aa8bb-c3f4-4778-9094-d81edba20d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-0b1a7693-f680-45f0-8653-70bd8220c425,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-c477f213-4aa0-4afa-8ed6-00981b3c6a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-c0f515ed-f961-4391-896a-ab82dbe7c468,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048517299-172.17.0.3-1597054657961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-5314c1c4-35aa-4350-8418-1fe8ec11a55b,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-261e8172-262d-4ed8-ae55-ff4d3a36b7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-41004767-9c56-4015-a3db-7a3ddda86468,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-62a1ad34-bc6f-443c-88f9-ef399a269b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-38abd42b-16b2-4bfb-a590-b33d44f5d6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-5d97fd20-afa2-4aa0-8033-6ca651be3b20,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-86369c96-14eb-42e1-8509-dabe802591ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-cfa89743-a71e-45c7-a405-1e2fd2f9cbbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048517299-172.17.0.3-1597054657961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-5314c1c4-35aa-4350-8418-1fe8ec11a55b,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-261e8172-262d-4ed8-ae55-ff4d3a36b7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-41004767-9c56-4015-a3db-7a3ddda86468,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-62a1ad34-bc6f-443c-88f9-ef399a269b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-38abd42b-16b2-4bfb-a590-b33d44f5d6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-5d97fd20-afa2-4aa0-8033-6ca651be3b20,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-86369c96-14eb-42e1-8509-dabe802591ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-cfa89743-a71e-45c7-a405-1e2fd2f9cbbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775234620-172.17.0.3-1597054835260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-7bb6ef74-8bf2-4fa9-88a1-a5dd0af011b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-6bfa9d86-b1e5-4557-97d4-7e1e90bd5c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-964734c6-725b-4ee7-903c-5c37561dc651,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-787a302f-e71f-43bd-b91e-cdc1ed7be06f,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-5b1c24c1-d5b7-4ef8-919b-81ea2f599e23,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-b16c9cdd-1d99-45eb-865a-33ab5565b9de,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-ddf05bb5-b383-46f7-8271-92e834810fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-983d4145-2757-49c2-b5c0-ec4000c0996e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-775234620-172.17.0.3-1597054835260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-7bb6ef74-8bf2-4fa9-88a1-a5dd0af011b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-6bfa9d86-b1e5-4557-97d4-7e1e90bd5c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-964734c6-725b-4ee7-903c-5c37561dc651,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-787a302f-e71f-43bd-b91e-cdc1ed7be06f,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-5b1c24c1-d5b7-4ef8-919b-81ea2f599e23,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-b16c9cdd-1d99-45eb-865a-33ab5565b9de,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-ddf05bb5-b383-46f7-8271-92e834810fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-983d4145-2757-49c2-b5c0-ec4000c0996e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667556961-172.17.0.3-1597054967845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-17091b81-fc77-431c-978d-cb555b16a81f,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-f4246fba-ed71-465b-a1a3-fc901e0df7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-79a6fef3-ffee-42f4-a647-85555150a570,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-2f7dab71-10ba-4a68-b2f0-a845a2aa57c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-1fb2eddd-67f5-4950-8b5d-dba1248815fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-37a4ab6b-1b56-4145-8a80-0d321e2edb33,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-196837b3-e3b1-48ba-bfdd-9e2828be91c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-01032302-5380-49b3-988a-47ce9b9b1261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667556961-172.17.0.3-1597054967845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45683,DS-17091b81-fc77-431c-978d-cb555b16a81f,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-f4246fba-ed71-465b-a1a3-fc901e0df7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-79a6fef3-ffee-42f4-a647-85555150a570,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-2f7dab71-10ba-4a68-b2f0-a845a2aa57c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-1fb2eddd-67f5-4950-8b5d-dba1248815fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-37a4ab6b-1b56-4145-8a80-0d321e2edb33,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-196837b3-e3b1-48ba-bfdd-9e2828be91c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39320,DS-01032302-5380-49b3-988a-47ce9b9b1261,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496516722-172.17.0.3-1597055077447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-39f4e380-37ac-4d83-8b75-ef2212010aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-9c1f9924-3110-4641-b44e-7f8094709c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-d71f8f8d-6ec3-41bf-ae2c-4336fd791c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-60bc1faf-555e-4e18-a5f3-fd2813bae3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-ec111a00-5096-4b15-bea0-9824cbafa8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-ea334046-824d-4ffa-9298-1499a7636c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-9d131ea5-8315-47e8-a344-f8ca32c66109,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-6016464c-98b7-4660-a425-24ec90c32861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496516722-172.17.0.3-1597055077447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43531,DS-39f4e380-37ac-4d83-8b75-ef2212010aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-9c1f9924-3110-4641-b44e-7f8094709c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43054,DS-d71f8f8d-6ec3-41bf-ae2c-4336fd791c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-60bc1faf-555e-4e18-a5f3-fd2813bae3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-ec111a00-5096-4b15-bea0-9824cbafa8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-ea334046-824d-4ffa-9298-1499a7636c1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-9d131ea5-8315-47e8-a344-f8ca32c66109,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-6016464c-98b7-4660-a425-24ec90c32861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085760783-172.17.0.3-1597055857440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35137,DS-3bdc3e8c-f908-44ae-91b8-51cb2e4e5b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-beab0979-c0a4-4120-8358-ff34a9beeef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-942343f4-03ae-435e-94ff-60012c4b6d80,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-b6f2df28-3b66-4056-b787-65601b8eb7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-e137039b-e8bd-4b45-8c74-e0f4f1468e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-7795a8cd-842b-429b-8426-d369380a723b,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-a91ecd82-a1e4-4b13-9b48-929b53a95048,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-be619c06-c3ca-4841-81bd-6fb85d8a8ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1085760783-172.17.0.3-1597055857440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35137,DS-3bdc3e8c-f908-44ae-91b8-51cb2e4e5b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-beab0979-c0a4-4120-8358-ff34a9beeef8,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-942343f4-03ae-435e-94ff-60012c4b6d80,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-b6f2df28-3b66-4056-b787-65601b8eb7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-e137039b-e8bd-4b45-8c74-e0f4f1468e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-7795a8cd-842b-429b-8426-d369380a723b,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-a91ecd82-a1e4-4b13-9b48-929b53a95048,DISK], DatanodeInfoWithStorage[127.0.0.1:42935,DS-be619c06-c3ca-4841-81bd-6fb85d8a8ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523694518-172.17.0.3-1597055996984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-8a256e34-cd82-463c-b17c-cdf1707b5b04,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-0c3ec5cd-1dbf-4d90-bbdd-02f4b15c5c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-36c3f438-74b2-4958-8294-d54996f83389,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-6423aea7-51ab-489d-8677-8ceead3ef63f,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-2b40b394-0e5a-4cdf-aff9-6db5dbea0239,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-b6e4f490-dae5-42eb-9e84-8c82bf72114d,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-f65f4b39-94e0-404c-b737-1ff249a8bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-92f51443-b2b9-4e69-ad25-8b3293145eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523694518-172.17.0.3-1597055996984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35344,DS-8a256e34-cd82-463c-b17c-cdf1707b5b04,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-0c3ec5cd-1dbf-4d90-bbdd-02f4b15c5c05,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-36c3f438-74b2-4958-8294-d54996f83389,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-6423aea7-51ab-489d-8677-8ceead3ef63f,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-2b40b394-0e5a-4cdf-aff9-6db5dbea0239,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-b6e4f490-dae5-42eb-9e84-8c82bf72114d,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-f65f4b39-94e0-404c-b737-1ff249a8bcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-92f51443-b2b9-4e69-ad25-8b3293145eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26531786-172.17.0.3-1597056184565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-695511ce-516f-4c4a-8e90-c15a112cdee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-fb15fa43-40cc-43be-804a-8f50b773890c,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-587be4f6-c204-45ba-b91c-75ce88fc21ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-26d91041-d7c1-44c5-ae94-56a1b72e8500,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-6ea2eee2-5029-43ea-ab1b-a1001d137eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-ff9f3c53-ecac-4517-953e-2e352cce151d,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-ace06600-066a-43b1-a99b-6ebe3a35f9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-54d43a3e-ac3f-4d90-a3d1-5596612aa7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26531786-172.17.0.3-1597056184565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39336,DS-695511ce-516f-4c4a-8e90-c15a112cdee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-fb15fa43-40cc-43be-804a-8f50b773890c,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-587be4f6-c204-45ba-b91c-75ce88fc21ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-26d91041-d7c1-44c5-ae94-56a1b72e8500,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-6ea2eee2-5029-43ea-ab1b-a1001d137eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-ff9f3c53-ecac-4517-953e-2e352cce151d,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-ace06600-066a-43b1-a99b-6ebe3a35f9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-54d43a3e-ac3f-4d90-a3d1-5596612aa7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988004070-172.17.0.3-1597056678959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-62a1d2f2-2f1f-45eb-8b3d-8deff84c7a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-f829515a-8288-468c-af3e-a619cafd4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-1a878f24-235e-41b8-b127-09d3cb12af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-22b9535b-fb0e-4362-b4f0-269734ebce44,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-edab1b5c-3428-4908-bedc-3d53221992c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-edf3997d-3c54-4778-975b-f8ebb1f0e250,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-570bb957-7963-4589-933f-8915678cabbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-bc63ee33-3124-4fed-9d9a-cb1661835234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988004070-172.17.0.3-1597056678959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42080,DS-62a1d2f2-2f1f-45eb-8b3d-8deff84c7a16,DISK], DatanodeInfoWithStorage[127.0.0.1:42828,DS-f829515a-8288-468c-af3e-a619cafd4b71,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-1a878f24-235e-41b8-b127-09d3cb12af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-22b9535b-fb0e-4362-b4f0-269734ebce44,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-edab1b5c-3428-4908-bedc-3d53221992c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-edf3997d-3c54-4778-975b-f8ebb1f0e250,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-570bb957-7963-4589-933f-8915678cabbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-bc63ee33-3124-4fed-9d9a-cb1661835234,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704488841-172.17.0.3-1597056829108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41931,DS-e930b83a-3964-42a0-8baf-9e0a0760c975,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-fd0510f6-f9d5-4dc2-9b66-8648f2586d73,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-dfd7a358-e8b3-4950-894e-41b560a563b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-0442e1bf-f517-442d-b8ac-b3662e460524,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-1fefe3d1-254f-467a-8179-e800ce4ebba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-278bbf98-bd69-469a-b8f4-0820b364cd00,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-8ab71cc7-8678-4a87-8acf-f83bfdd1ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-a215f775-9d83-4eb9-891b-251930d2e87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704488841-172.17.0.3-1597056829108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41931,DS-e930b83a-3964-42a0-8baf-9e0a0760c975,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-fd0510f6-f9d5-4dc2-9b66-8648f2586d73,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-dfd7a358-e8b3-4950-894e-41b560a563b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-0442e1bf-f517-442d-b8ac-b3662e460524,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-1fefe3d1-254f-467a-8179-e800ce4ebba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-278bbf98-bd69-469a-b8f4-0820b364cd00,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-8ab71cc7-8678-4a87-8acf-f83bfdd1ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-a215f775-9d83-4eb9-891b-251930d2e87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14319062-172.17.0.3-1597057048368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37763,DS-78d43e42-fd93-456c-b008-c898d66bc859,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-d0748607-e5f0-40a6-a121-4dccda8e8af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-d051fd28-b012-4705-8d1e-89b41917557c,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-a983a72c-5326-4213-a4d1-74f186a12738,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-3c889003-c99a-4fb1-bd2d-802f98029352,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-a9f44c60-85d1-47da-bb66-4d80e93fd604,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-b7defb68-406d-4f56-b26e-1bdcd00e2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-00835cc0-3b66-4723-a3fc-4d5edd7d3c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14319062-172.17.0.3-1597057048368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37763,DS-78d43e42-fd93-456c-b008-c898d66bc859,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-d0748607-e5f0-40a6-a121-4dccda8e8af3,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-d051fd28-b012-4705-8d1e-89b41917557c,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-a983a72c-5326-4213-a4d1-74f186a12738,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-3c889003-c99a-4fb1-bd2d-802f98029352,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-a9f44c60-85d1-47da-bb66-4d80e93fd604,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-b7defb68-406d-4f56-b26e-1bdcd00e2b35,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-00835cc0-3b66-4723-a3fc-4d5edd7d3c44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61810296-172.17.0.3-1597057504636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-0615adb1-28e6-4859-9181-d6d936abc752,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-c2d3fb56-7a05-4986-8ddd-79139120d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-98443d36-1649-4cff-9868-829760d5b22e,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-29ae260a-2e3d-4624-bcbb-9395d3a0ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-234bb0c3-ad99-4aae-a80b-480f1db3bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-e1499719-a62e-40e1-a4d0-d3371012109a,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-eca5b0d1-4942-4f6c-adb8-12ed3a1bb49f,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-452889be-8b29-4de4-b7bc-1f26f0f650b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61810296-172.17.0.3-1597057504636:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38027,DS-0615adb1-28e6-4859-9181-d6d936abc752,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-c2d3fb56-7a05-4986-8ddd-79139120d19e,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-98443d36-1649-4cff-9868-829760d5b22e,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-29ae260a-2e3d-4624-bcbb-9395d3a0ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-234bb0c3-ad99-4aae-a80b-480f1db3bf3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-e1499719-a62e-40e1-a4d0-d3371012109a,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-eca5b0d1-4942-4f6c-adb8-12ed3a1bb49f,DISK], DatanodeInfoWithStorage[127.0.0.1:35129,DS-452889be-8b29-4de4-b7bc-1f26f0f650b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951924211-172.17.0.3-1597057626460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46171,DS-4bbb8434-5677-410b-8967-ea6916ca26e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-482a22fa-b367-4498-b759-1e83a7717238,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-921a8829-5a9e-47ca-bbd1-951a3c9e97c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-2e617f29-b30f-4efd-9e01-cd9e7b044e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-d9a21dad-9e77-4e66-9044-6f63a44c8332,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-984307a7-1905-4fc2-9a2f-431ef281cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-5059609c-1a36-4894-982d-9e2732fc953d,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-042f7055-fe3e-4afe-bdd1-1afef2a91f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951924211-172.17.0.3-1597057626460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46171,DS-4bbb8434-5677-410b-8967-ea6916ca26e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-482a22fa-b367-4498-b759-1e83a7717238,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-921a8829-5a9e-47ca-bbd1-951a3c9e97c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-2e617f29-b30f-4efd-9e01-cd9e7b044e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-d9a21dad-9e77-4e66-9044-6f63a44c8332,DISK], DatanodeInfoWithStorage[127.0.0.1:46264,DS-984307a7-1905-4fc2-9a2f-431ef281cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-5059609c-1a36-4894-982d-9e2732fc953d,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-042f7055-fe3e-4afe-bdd1-1afef2a91f95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937908340-172.17.0.3-1597057812555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34091,DS-f9bdfbc6-c0f2-41bc-b26e-cc6743dd963e,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-f833617d-cfaf-4781-8e95-a3351fc81e19,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-e6b211bd-057a-4a77-904a-04650c290837,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-5ff2aeac-eb96-4820-b828-beea5deb6b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-5ae1fe13-9793-4d99-88fc-ddc6585225fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-8cc94fd2-e012-45f5-8ebf-39d8aced6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-481cc2d9-be42-4a29-9ba0-0e4c09e6681d,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-884176e8-22e4-49a3-9d13-3af0aad9cd20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937908340-172.17.0.3-1597057812555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34091,DS-f9bdfbc6-c0f2-41bc-b26e-cc6743dd963e,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-f833617d-cfaf-4781-8e95-a3351fc81e19,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-e6b211bd-057a-4a77-904a-04650c290837,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-5ff2aeac-eb96-4820-b828-beea5deb6b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-5ae1fe13-9793-4d99-88fc-ddc6585225fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-8cc94fd2-e012-45f5-8ebf-39d8aced6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-481cc2d9-be42-4a29-9ba0-0e4c09e6681d,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-884176e8-22e4-49a3-9d13-3af0aad9cd20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1343136346-172.17.0.3-1597058044834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44163,DS-e39c27bf-87b2-4e6c-a98a-c79f4df2e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-36c9cd71-f794-4e12-b13a-6f601983ae80,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-f433aad3-38f1-42a4-aec7-ca23ba9c5dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-2f0a32cc-5be1-4469-bdd0-b213a9997a75,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-aab99f46-529c-49f6-a878-fe2e4f3dcb49,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-dfee7e7c-d842-466d-883d-c8833666ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-07d4a11c-dc3d-45b5-a11e-457e16a403e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-2f98cd15-4140-42db-ab53-b89573f34812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1343136346-172.17.0.3-1597058044834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44163,DS-e39c27bf-87b2-4e6c-a98a-c79f4df2e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-36c9cd71-f794-4e12-b13a-6f601983ae80,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-f433aad3-38f1-42a4-aec7-ca23ba9c5dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-2f0a32cc-5be1-4469-bdd0-b213a9997a75,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-aab99f46-529c-49f6-a878-fe2e4f3dcb49,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-dfee7e7c-d842-466d-883d-c8833666ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-07d4a11c-dc3d-45b5-a11e-457e16a403e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-2f98cd15-4140-42db-ab53-b89573f34812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427143264-172.17.0.3-1597058107337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-73c613d4-ac3c-48fd-9470-e1ff9d0e1511,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-2ff7be95-40ca-4935-8add-0fd538d1b9db,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-31a0a984-4df5-499f-a286-3f3b7280e865,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-ca24d90c-4f7b-4837-8d0a-6a6d3e3bd2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-049ce189-5db9-4d2c-acdb-9cc5c244fd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-09ad7208-9d26-415e-b7d2-8059472fd421,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-e11f3874-ef08-49f8-91f0-3d281126ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-679f0f7d-481c-4944-8b86-5ef5e289ce8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427143264-172.17.0.3-1597058107337:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34018,DS-73c613d4-ac3c-48fd-9470-e1ff9d0e1511,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-2ff7be95-40ca-4935-8add-0fd538d1b9db,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-31a0a984-4df5-499f-a286-3f3b7280e865,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-ca24d90c-4f7b-4837-8d0a-6a6d3e3bd2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-049ce189-5db9-4d2c-acdb-9cc5c244fd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-09ad7208-9d26-415e-b7d2-8059472fd421,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-e11f3874-ef08-49f8-91f0-3d281126ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-679f0f7d-481c-4944-8b86-5ef5e289ce8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137994226-172.17.0.3-1597058406711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-a427931e-05f6-401c-9119-4b3dfadbf9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-e7d0d479-dbcd-4333-ae7b-815ccd51f858,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-5166a7e3-5218-4468-ab2a-572e487f9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-bbf29bf1-94ec-459c-9f6b-d8a35a8b7459,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-50e0a2bd-d62b-4468-a833-52f5c94940c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-897d0f21-a66d-4499-917c-5328ffc28bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-4490c376-1cef-4376-b7a5-c3650e3d0a04,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-22e54d42-cc03-4640-a8fa-79d786bb5006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137994226-172.17.0.3-1597058406711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-a427931e-05f6-401c-9119-4b3dfadbf9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-e7d0d479-dbcd-4333-ae7b-815ccd51f858,DISK], DatanodeInfoWithStorage[127.0.0.1:42453,DS-5166a7e3-5218-4468-ab2a-572e487f9af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-bbf29bf1-94ec-459c-9f6b-d8a35a8b7459,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-50e0a2bd-d62b-4468-a833-52f5c94940c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-897d0f21-a66d-4499-917c-5328ffc28bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-4490c376-1cef-4376-b7a5-c3650e3d0a04,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-22e54d42-cc03-4640-a8fa-79d786bb5006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093837103-172.17.0.3-1597058910181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39775,DS-fe3e162f-1ab8-41b8-92bb-ee436c3f2f79,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-1eb77c17-c334-4a21-afde-b3295cd3b977,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-9843aac8-1e4a-4a97-90d8-35865ee9565a,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-8f5452b0-9f91-4fb0-bc6e-d9eca3acf9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-5b9284c1-c71d-414e-bda8-c66a2ebedaba,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-7bd2214c-0725-4968-b6b9-fe7dfb608d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-ea32fe1b-125b-47b1-bf5d-cb930a9f6a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-a2f22fd0-6083-4a70-9879-61d4d6de9703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093837103-172.17.0.3-1597058910181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39775,DS-fe3e162f-1ab8-41b8-92bb-ee436c3f2f79,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-1eb77c17-c334-4a21-afde-b3295cd3b977,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-9843aac8-1e4a-4a97-90d8-35865ee9565a,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-8f5452b0-9f91-4fb0-bc6e-d9eca3acf9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-5b9284c1-c71d-414e-bda8-c66a2ebedaba,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-7bd2214c-0725-4968-b6b9-fe7dfb608d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-ea32fe1b-125b-47b1-bf5d-cb930a9f6a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-a2f22fd0-6083-4a70-9879-61d4d6de9703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67149942-172.17.0.3-1597058948341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-30ab29f9-624d-4fd9-8d6e-0d6b22573794,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-71fb5e8d-530f-43e0-ab97-ce622116fea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-ab51fbf1-13d3-4828-a017-99e5812d023f,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-17673518-ebf1-4d75-a8dd-2b867b6f580e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-27e04d01-8f9d-4514-9e47-d1eac63c46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-452f2a1e-7a82-4519-82a8-bd7df86e6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-7e3b0574-2431-4ce4-9f18-d9b07ce3215f,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-8ca136b7-1672-4370-8f03-0690b243026e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67149942-172.17.0.3-1597058948341:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38806,DS-30ab29f9-624d-4fd9-8d6e-0d6b22573794,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-71fb5e8d-530f-43e0-ab97-ce622116fea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-ab51fbf1-13d3-4828-a017-99e5812d023f,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-17673518-ebf1-4d75-a8dd-2b867b6f580e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-27e04d01-8f9d-4514-9e47-d1eac63c46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-452f2a1e-7a82-4519-82a8-bd7df86e6a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-7e3b0574-2431-4ce4-9f18-d9b07ce3215f,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-8ca136b7-1672-4370-8f03-0690b243026e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349241896-172.17.0.3-1597058980767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34210,DS-23628dd6-5224-4e36-9dd5-a4f0a563c806,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-acd4e12e-8d25-49a0-a615-d1fdc1bfa653,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-b7d7cb4b-4035-4253-bf24-c6ebaba5465b,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-f1322da7-c614-46ef-9285-1c40ac8aad20,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-92cff7c4-102d-473a-9178-189db6052f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-679ec0b8-b1fa-4f63-9aeb-09057030fa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-9b7a7875-72a7-4331-951d-b40dc03b10a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-73928140-fb5f-4461-97de-0701cdc2ff4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349241896-172.17.0.3-1597058980767:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34210,DS-23628dd6-5224-4e36-9dd5-a4f0a563c806,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-acd4e12e-8d25-49a0-a615-d1fdc1bfa653,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-b7d7cb4b-4035-4253-bf24-c6ebaba5465b,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-f1322da7-c614-46ef-9285-1c40ac8aad20,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-92cff7c4-102d-473a-9178-189db6052f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-679ec0b8-b1fa-4f63-9aeb-09057030fa7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-9b7a7875-72a7-4331-951d-b40dc03b10a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-73928140-fb5f-4461-97de-0701cdc2ff4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.netty.low.watermark
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210122387-172.17.0.3-1597059052937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35518,DS-16dae70d-2222-4dcd-a444-48d577f59391,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-47c6d05f-7f68-456e-8370-a90501b1b777,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-e7dc863e-930c-46c3-9c7e-6f352e598b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-28f88888-b0e7-49e8-83cc-a66b993c0c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-083794eb-355d-404c-8a1c-dc04f4eb7fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-e12b7666-606b-4c11-a119-1acf54a3f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-9b12b0b5-1d8c-400f-a0af-ea0b9c066484,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-0ee99a07-e8fe-4393-8c2a-eb013c67daaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210122387-172.17.0.3-1597059052937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35518,DS-16dae70d-2222-4dcd-a444-48d577f59391,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-47c6d05f-7f68-456e-8370-a90501b1b777,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-e7dc863e-930c-46c3-9c7e-6f352e598b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-28f88888-b0e7-49e8-83cc-a66b993c0c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-083794eb-355d-404c-8a1c-dc04f4eb7fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-e12b7666-606b-4c11-a119-1acf54a3f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-9b12b0b5-1d8c-400f-a0af-ea0b9c066484,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-0ee99a07-e8fe-4393-8c2a-eb013c67daaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5491
