reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211170326-172.17.0.17-1597106222231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46448,DS-5ba0ba90-d052-409f-aa7b-14035da1258e,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-b65b8e7a-4361-42e6-af3f-21b7defe77bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-fd980fb4-5cf6-4817-890d-81a58a6f99b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a784be25-e8e6-4e3a-8680-944fb9cea874,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-1230298d-4aec-4adf-8eea-323dc37ba57f,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-4e37345e-2730-41f9-b208-eef1da5e86b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-67e4fc7c-04ee-4ed4-84d6-9c506d02214d,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-4e86f121-e5d0-4252-9aaf-4b428d5c546c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211170326-172.17.0.17-1597106222231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46448,DS-5ba0ba90-d052-409f-aa7b-14035da1258e,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-b65b8e7a-4361-42e6-af3f-21b7defe77bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-fd980fb4-5cf6-4817-890d-81a58a6f99b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a784be25-e8e6-4e3a-8680-944fb9cea874,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-1230298d-4aec-4adf-8eea-323dc37ba57f,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-4e37345e-2730-41f9-b208-eef1da5e86b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-67e4fc7c-04ee-4ed4-84d6-9c506d02214d,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-4e86f121-e5d0-4252-9aaf-4b428d5c546c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456029103-172.17.0.17-1597106716158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39769,DS-28a3ec63-8436-4637-8827-99fc7f5c1c24,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-315b7052-4181-43f9-9eed-74c7bad838de,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-62fbc4f6-f236-4c5e-94c2-19277a9f0494,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-ede26b41-c371-4335-880c-195279bd2df7,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-1e83f454-f0bc-43bf-97bf-e30505b225b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-575fcd11-7bec-4abe-8c6d-80edfc5ad395,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-0333c08d-e1a8-4b13-8a3b-994fecf9e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-4381257b-3687-4ffa-bcb8-c17709eca859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456029103-172.17.0.17-1597106716158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39769,DS-28a3ec63-8436-4637-8827-99fc7f5c1c24,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-315b7052-4181-43f9-9eed-74c7bad838de,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-62fbc4f6-f236-4c5e-94c2-19277a9f0494,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-ede26b41-c371-4335-880c-195279bd2df7,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-1e83f454-f0bc-43bf-97bf-e30505b225b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-575fcd11-7bec-4abe-8c6d-80edfc5ad395,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-0333c08d-e1a8-4b13-8a3b-994fecf9e8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-4381257b-3687-4ffa-bcb8-c17709eca859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104100879-172.17.0.17-1597107154197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33806,DS-3fa226c6-ffb3-4631-914f-17f3edec335a,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-3506810b-8a04-4880-9608-67ee6df9d76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-f51f6546-4884-4495-899c-4eaca2d4354e,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-4e3c3944-a7a5-451b-ae0a-9379064050da,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-a50f2838-eeae-4a1f-82f1-d02f87d82307,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-d89c987a-04de-43ea-83ae-fb4dea6d9e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-c0d2bd33-1529-454b-b197-dd9cd37918c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-73c36945-2419-41a2-a100-27c5e45ecf98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-104100879-172.17.0.17-1597107154197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33806,DS-3fa226c6-ffb3-4631-914f-17f3edec335a,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-3506810b-8a04-4880-9608-67ee6df9d76a,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-f51f6546-4884-4495-899c-4eaca2d4354e,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-4e3c3944-a7a5-451b-ae0a-9379064050da,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-a50f2838-eeae-4a1f-82f1-d02f87d82307,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-d89c987a-04de-43ea-83ae-fb4dea6d9e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-c0d2bd33-1529-454b-b197-dd9cd37918c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-73c36945-2419-41a2-a100-27c5e45ecf98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081552619-172.17.0.17-1597107409084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45760,DS-d95bd4e8-ff8a-4002-8d6e-772e8b7e7d35,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ffa54723-34d5-4ed0-a6a0-571580c0c11f,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-dc27626b-8685-4a69-ad45-8260a95144f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-879988f4-90e0-4ada-9f16-e9a6a9463dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-1321d4a5-e69e-43fd-9e7d-74ed32e2cf44,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-f26db670-0495-4e27-9084-deb35b379afc,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-baa74c37-4a23-4b48-889a-e2595162c927,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-4ebac320-2016-43dc-85a6-2950abc5850a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081552619-172.17.0.17-1597107409084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45760,DS-d95bd4e8-ff8a-4002-8d6e-772e8b7e7d35,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ffa54723-34d5-4ed0-a6a0-571580c0c11f,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-dc27626b-8685-4a69-ad45-8260a95144f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-879988f4-90e0-4ada-9f16-e9a6a9463dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-1321d4a5-e69e-43fd-9e7d-74ed32e2cf44,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-f26db670-0495-4e27-9084-deb35b379afc,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-baa74c37-4a23-4b48-889a-e2595162c927,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-4ebac320-2016-43dc-85a6-2950abc5850a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390555871-172.17.0.17-1597107787810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40518,DS-004e9a2c-6f69-4318-9d27-802a04cdfae3,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-82b31fee-b2d9-4f5e-87b4-9e721ed0e54f,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-81e958bb-7efe-4e3b-b93d-d68481bdee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-50930530-ff06-48e3-9ebb-e012a225c0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-4d6f0ff3-d0de-43a4-a0a6-e3eeb4d04de4,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-64c6595d-6766-4297-b2f8-8845bdd22946,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-482a0374-b9b4-4c0f-b16d-9d5c40f3cd39,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-71a69292-29cf-474d-bb3c-a50926ada553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390555871-172.17.0.17-1597107787810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40518,DS-004e9a2c-6f69-4318-9d27-802a04cdfae3,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-82b31fee-b2d9-4f5e-87b4-9e721ed0e54f,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-81e958bb-7efe-4e3b-b93d-d68481bdee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-50930530-ff06-48e3-9ebb-e012a225c0a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-4d6f0ff3-d0de-43a4-a0a6-e3eeb4d04de4,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-64c6595d-6766-4297-b2f8-8845bdd22946,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-482a0374-b9b4-4c0f-b16d-9d5c40f3cd39,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-71a69292-29cf-474d-bb3c-a50926ada553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033998770-172.17.0.17-1597107982737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40385,DS-26fd3906-b720-45e8-b21f-22cb7a853194,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-de9adef4-8f57-4cc1-995b-3ae8a0c9712a,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-6c2c63c7-04a9-4d31-ae9a-2945f5aa2742,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-ee71e123-0162-48d9-9850-fcda87f960f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-cf078d56-f0ab-48dc-ac01-ce8580b8ee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-b1f96c68-55a2-4297-bff1-4ee8f92882e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-565f684e-8fcd-4343-a4df-ccf6e8bd0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-3a2cddf3-806e-4f20-b469-31a8e89cc565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033998770-172.17.0.17-1597107982737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40385,DS-26fd3906-b720-45e8-b21f-22cb7a853194,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-de9adef4-8f57-4cc1-995b-3ae8a0c9712a,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-6c2c63c7-04a9-4d31-ae9a-2945f5aa2742,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-ee71e123-0162-48d9-9850-fcda87f960f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-cf078d56-f0ab-48dc-ac01-ce8580b8ee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-b1f96c68-55a2-4297-bff1-4ee8f92882e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-565f684e-8fcd-4343-a4df-ccf6e8bd0fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-3a2cddf3-806e-4f20-b469-31a8e89cc565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428278263-172.17.0.17-1597108263804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-c12404f3-c2e3-4156-bb24-b52c669d7856,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-f1b4cdfc-800c-4303-9229-33e699bed2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-96ae363b-d672-4362-80c0-eddee364bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-158dac81-868c-4835-a1ce-3ae47ad6ea44,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-80894fff-d3f8-4e72-bc58-b792c70b67e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-51dd4bf9-e7ed-4c92-947b-0fce5f08be0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-62206687-a89a-41c2-bfe5-af3c31d92b09,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-7a7bdac2-6f1b-4cea-b7f3-4234cf765937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1428278263-172.17.0.17-1597108263804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34804,DS-c12404f3-c2e3-4156-bb24-b52c669d7856,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-f1b4cdfc-800c-4303-9229-33e699bed2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-96ae363b-d672-4362-80c0-eddee364bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-158dac81-868c-4835-a1ce-3ae47ad6ea44,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-80894fff-d3f8-4e72-bc58-b792c70b67e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-51dd4bf9-e7ed-4c92-947b-0fce5f08be0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-62206687-a89a-41c2-bfe5-af3c31d92b09,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-7a7bdac2-6f1b-4cea-b7f3-4234cf765937,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622833130-172.17.0.17-1597108446248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-811b065c-5eaa-4a17-bbb5-73ac51576b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-5989e79e-84b3-463c-91cd-f78d3a5c6d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-4e0245a6-820e-499a-aef9-8675bd91d79c,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-fbedf3f9-e09f-4c3b-b03e-b22b9369060d,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-ccc1add6-eeed-4c45-939f-fb812b9afb78,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-47630cb7-109f-4c0e-be3e-b118a19022fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-ac6858e3-47a3-4e00-b6c5-e3e8664a02fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-a235433c-0dff-4e7c-84bf-e17d8e498beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622833130-172.17.0.17-1597108446248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-811b065c-5eaa-4a17-bbb5-73ac51576b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-5989e79e-84b3-463c-91cd-f78d3a5c6d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-4e0245a6-820e-499a-aef9-8675bd91d79c,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-fbedf3f9-e09f-4c3b-b03e-b22b9369060d,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-ccc1add6-eeed-4c45-939f-fb812b9afb78,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-47630cb7-109f-4c0e-be3e-b118a19022fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-ac6858e3-47a3-4e00-b6c5-e3e8664a02fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-a235433c-0dff-4e7c-84bf-e17d8e498beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736763799-172.17.0.17-1597108512503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37727,DS-6f1eeecd-40b8-4c0a-b5ef-90d37dd56d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-3610e29f-9c5e-4ad5-857f-0feb5099846c,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-95b438d2-49c3-4163-9e42-b8ad59613d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-002ed234-4f89-4aa3-91d1-16c75eb9463c,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-55a37740-39a0-49a7-8e50-55937ca26ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-ff7bc61e-e201-45e0-8081-120298a0bbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-cc90a20c-aa06-4991-af84-42a0c7ddadad,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-5036e87f-c14a-4df9-b0af-40ff77564592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736763799-172.17.0.17-1597108512503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37727,DS-6f1eeecd-40b8-4c0a-b5ef-90d37dd56d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-3610e29f-9c5e-4ad5-857f-0feb5099846c,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-95b438d2-49c3-4163-9e42-b8ad59613d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-002ed234-4f89-4aa3-91d1-16c75eb9463c,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-55a37740-39a0-49a7-8e50-55937ca26ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-ff7bc61e-e201-45e0-8081-120298a0bbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-cc90a20c-aa06-4991-af84-42a0c7ddadad,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-5036e87f-c14a-4df9-b0af-40ff77564592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727402791-172.17.0.17-1597108700680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43869,DS-0a555f5d-8765-4b98-9826-51bb02f16272,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-618918e8-2cc6-4dfd-b4b8-67f9fbf26ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-bd8dda59-e521-4f4e-9fb7-cb3c3e8bc490,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-8e8ba8a7-989a-41b0-a89c-844feba3a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-f514fae6-9ae7-4257-8663-eb4d52a25eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-78d02411-2b05-485c-9b5e-e3903ab56729,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-72e118b9-6108-4842-a10c-f7de550c9770,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-88f3c77d-657d-4150-bd4d-32482529d5c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727402791-172.17.0.17-1597108700680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43869,DS-0a555f5d-8765-4b98-9826-51bb02f16272,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-618918e8-2cc6-4dfd-b4b8-67f9fbf26ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-bd8dda59-e521-4f4e-9fb7-cb3c3e8bc490,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-8e8ba8a7-989a-41b0-a89c-844feba3a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-f514fae6-9ae7-4257-8663-eb4d52a25eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-78d02411-2b05-485c-9b5e-e3903ab56729,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-72e118b9-6108-4842-a10c-f7de550c9770,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-88f3c77d-657d-4150-bd4d-32482529d5c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323110885-172.17.0.17-1597108812691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-ca11c283-036a-4732-9791-aa90911bbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-998c3d53-19f4-4c14-8d9a-63645d4507d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-54e6d78f-7665-4147-a659-fa6c3651254f,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-06bf70c7-ceda-4160-893a-780f27e1eb39,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-9db40477-e1fd-4551-abfb-62b47b34da65,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-d21e911f-a8e2-4c85-99a0-7e7f2dbd9732,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-2a5895d9-c626-4bff-b64e-5f34e737f1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-9c714546-34e9-4d9a-8a98-358e53ab17b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323110885-172.17.0.17-1597108812691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40236,DS-ca11c283-036a-4732-9791-aa90911bbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-998c3d53-19f4-4c14-8d9a-63645d4507d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-54e6d78f-7665-4147-a659-fa6c3651254f,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-06bf70c7-ceda-4160-893a-780f27e1eb39,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-9db40477-e1fd-4551-abfb-62b47b34da65,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-d21e911f-a8e2-4c85-99a0-7e7f2dbd9732,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-2a5895d9-c626-4bff-b64e-5f34e737f1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-9c714546-34e9-4d9a-8a98-358e53ab17b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183463549-172.17.0.17-1597108923047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36952,DS-90a4a18e-ebf5-4622-bc2b-85345e6fdfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-7b6b1f16-05fb-4153-b767-1a9472451852,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-9adff76a-f2fc-4c23-857a-9c6a1b31527d,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-23726864-6546-480f-8803-1868e48c5825,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-e105db63-e957-4f23-afc8-7316ffc47257,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-c2965307-b8bd-4a2b-acaa-eb8f081430f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-7c9f247a-97f7-4d63-be69-1829cd2c6919,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-84233279-5494-4bdd-9c20-5ee37a23a133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183463549-172.17.0.17-1597108923047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36952,DS-90a4a18e-ebf5-4622-bc2b-85345e6fdfc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-7b6b1f16-05fb-4153-b767-1a9472451852,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-9adff76a-f2fc-4c23-857a-9c6a1b31527d,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-23726864-6546-480f-8803-1868e48c5825,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-e105db63-e957-4f23-afc8-7316ffc47257,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-c2965307-b8bd-4a2b-acaa-eb8f081430f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-7c9f247a-97f7-4d63-be69-1829cd2c6919,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-84233279-5494-4bdd-9c20-5ee37a23a133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864072605-172.17.0.17-1597108953090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34171,DS-251d90cc-facb-4eee-8725-cb8c990f5b12,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-a85644d2-f57d-4b2e-a8be-3c2f4d700295,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-21c4e134-ce32-4f1c-a7f6-c3c4d6ac212e,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-5e1c05ef-80ef-413c-972c-702a8a950b67,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-8cc3da8b-9194-4a99-98b7-f4b676f1eae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-a0c486e0-a7df-4dcd-8ed6-1be2e7f099fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-285c5814-df64-404c-8145-fc4272794c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-84163705-aafa-46e4-91c3-23c093cbf34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864072605-172.17.0.17-1597108953090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34171,DS-251d90cc-facb-4eee-8725-cb8c990f5b12,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-a85644d2-f57d-4b2e-a8be-3c2f4d700295,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-21c4e134-ce32-4f1c-a7f6-c3c4d6ac212e,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-5e1c05ef-80ef-413c-972c-702a8a950b67,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-8cc3da8b-9194-4a99-98b7-f4b676f1eae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-a0c486e0-a7df-4dcd-8ed6-1be2e7f099fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-285c5814-df64-404c-8145-fc4272794c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-84163705-aafa-46e4-91c3-23c093cbf34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524518359-172.17.0.17-1597109126731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34534,DS-2257dc37-14f7-4d2e-b304-6d77aa441ade,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-8bea3788-393d-42d9-b71c-aca13ad3e84c,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-293edabf-6037-4c38-ba34-87df0e07ca96,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-9e9d4350-c53c-4c3d-9d91-b439b0b0faca,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-e1823537-b88e-4937-b92a-0bf8f699dae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-69c2bd5a-8e2b-4cc4-9f38-112535f43da7,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-4aab4b22-b2ed-49e2-baee-8df422bb781e,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-7b3b7712-ac8f-4036-934d-ee1d4a821de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524518359-172.17.0.17-1597109126731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34534,DS-2257dc37-14f7-4d2e-b304-6d77aa441ade,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-8bea3788-393d-42d9-b71c-aca13ad3e84c,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-293edabf-6037-4c38-ba34-87df0e07ca96,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-9e9d4350-c53c-4c3d-9d91-b439b0b0faca,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-e1823537-b88e-4937-b92a-0bf8f699dae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-69c2bd5a-8e2b-4cc4-9f38-112535f43da7,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-4aab4b22-b2ed-49e2-baee-8df422bb781e,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-7b3b7712-ac8f-4036-934d-ee1d4a821de6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598514630-172.17.0.17-1597109163025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-c438771a-cf98-4dd7-a618-1946c6510bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-938f0a8f-da65-4b61-acd8-8795af6ece0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-839b0e5d-200b-436e-946a-2263eac453a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-c7059a88-2ed3-4f35-a0e5-a48fcd76df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-4d8b5516-e5a5-4455-aa30-6e896c7ffa29,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-468f2589-5be7-4ce6-a337-b14edbf3f819,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-225cb3a7-ff4e-43f8-81a8-10ace732e21c,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-86009e91-2cf7-426d-a780-3aa860b895c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598514630-172.17.0.17-1597109163025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-c438771a-cf98-4dd7-a618-1946c6510bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-938f0a8f-da65-4b61-acd8-8795af6ece0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35905,DS-839b0e5d-200b-436e-946a-2263eac453a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-c7059a88-2ed3-4f35-a0e5-a48fcd76df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-4d8b5516-e5a5-4455-aa30-6e896c7ffa29,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-468f2589-5be7-4ce6-a337-b14edbf3f819,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-225cb3a7-ff4e-43f8-81a8-10ace732e21c,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-86009e91-2cf7-426d-a780-3aa860b895c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728136795-172.17.0.17-1597109505552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44614,DS-d6916364-6630-42fe-b390-0a0cb7244c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-338f9833-9fbf-4791-b266-a5c517dc2bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-f93b1438-af3e-4f46-9780-96f4d12941df,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-d0deee65-d5c0-42c0-a165-24d0887486ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-cd0608ff-1c21-4152-9d99-b86bd88588b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-aaa693df-367c-4d81-941e-e71c5e1c4188,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-f266feb4-0ef4-4567-87d8-c77a5b9479f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-f405cb70-cd97-4a1b-8407-2e2abaa16e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1728136795-172.17.0.17-1597109505552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44614,DS-d6916364-6630-42fe-b390-0a0cb7244c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-338f9833-9fbf-4791-b266-a5c517dc2bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-f93b1438-af3e-4f46-9780-96f4d12941df,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-d0deee65-d5c0-42c0-a165-24d0887486ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-cd0608ff-1c21-4152-9d99-b86bd88588b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-aaa693df-367c-4d81-941e-e71c5e1c4188,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-f266feb4-0ef4-4567-87d8-c77a5b9479f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-f405cb70-cd97-4a1b-8407-2e2abaa16e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712183122-172.17.0.17-1597109808393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46327,DS-4fa15bdc-88dd-4f1f-8e1b-8e7e049c29e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-60603a72-d00c-4602-bac7-34da049b1fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-72764cb4-c8f2-41b7-b013-29d7d4613319,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-1de1883e-f77f-4ba7-a942-51b2be94eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-a727343d-c982-47cc-bd4e-f2565259d78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-e469ddd3-f425-484b-9134-da599ff5f72a,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-b7782881-6fb5-4565-9d4a-42ed0106c2db,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-6d113962-6ddd-4c2a-a19b-0db764831b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712183122-172.17.0.17-1597109808393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46327,DS-4fa15bdc-88dd-4f1f-8e1b-8e7e049c29e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-60603a72-d00c-4602-bac7-34da049b1fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-72764cb4-c8f2-41b7-b013-29d7d4613319,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-1de1883e-f77f-4ba7-a942-51b2be94eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-a727343d-c982-47cc-bd4e-f2565259d78b,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-e469ddd3-f425-484b-9134-da599ff5f72a,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-b7782881-6fb5-4565-9d4a-42ed0106c2db,DISK], DatanodeInfoWithStorage[127.0.0.1:46709,DS-6d113962-6ddd-4c2a-a19b-0db764831b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72100959-172.17.0.17-1597110289431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-f21b4313-5a3a-41e2-b497-5049918273a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-227bd0bf-99c5-489d-9f96-2c4bcaedc577,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-8e6fe331-9e17-4666-b73e-990d133f4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-91245491-f559-4910-8dc5-31176b145405,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-d887b136-1b0a-4bc5-8a22-4be12cbb91c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-41645257-6349-49d9-9907-b853cafcc1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-d6f93a65-add0-467e-8f62-f2125da11201,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-c643675f-3ac9-4870-b38f-5eaebe9f6110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72100959-172.17.0.17-1597110289431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46682,DS-f21b4313-5a3a-41e2-b497-5049918273a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-227bd0bf-99c5-489d-9f96-2c4bcaedc577,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-8e6fe331-9e17-4666-b73e-990d133f4a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-91245491-f559-4910-8dc5-31176b145405,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-d887b136-1b0a-4bc5-8a22-4be12cbb91c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-41645257-6349-49d9-9907-b853cafcc1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-d6f93a65-add0-467e-8f62-f2125da11201,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-c643675f-3ac9-4870-b38f-5eaebe9f6110,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703344924-172.17.0.17-1597110367268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39009,DS-9a6470a5-36d3-402f-b456-1d9de04ec6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a9c27f6e-4357-4fed-8857-af8b43298236,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-f7ac2b93-c4d1-48b7-a5f2-b3e48dec50ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-7b76981b-71f5-4803-bf8f-b0a87a01e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-fb2057d6-d6e2-4a73-8649-49bc6a85d691,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-4862a8a4-eb21-4368-9238-57e6f0466690,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-ccdba898-220a-4a03-ad76-68449dfb54c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-a015767e-1c60-4108-ac7a-f47a7e5f834b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1703344924-172.17.0.17-1597110367268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39009,DS-9a6470a5-36d3-402f-b456-1d9de04ec6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a9c27f6e-4357-4fed-8857-af8b43298236,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-f7ac2b93-c4d1-48b7-a5f2-b3e48dec50ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-7b76981b-71f5-4803-bf8f-b0a87a01e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-fb2057d6-d6e2-4a73-8649-49bc6a85d691,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-4862a8a4-eb21-4368-9238-57e6f0466690,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-ccdba898-220a-4a03-ad76-68449dfb54c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-a015767e-1c60-4108-ac7a-f47a7e5f834b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105267305-172.17.0.17-1597111016390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-bdec7461-e096-473c-9d5e-f15e12a34318,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-faf82201-1461-4abe-b541-bbd558108445,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-28117dea-ee99-4322-ad9f-897d9267e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-e218aa01-bf12-46c7-94d6-6905a559bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-4e3fc61b-9153-46d6-9e35-b36ecff34dce,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-cc862616-29ac-4280-b677-72df882cd9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-513d5bd8-a5a7-48ed-8285-1f33462a8684,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-1d2eb392-bec8-4896-8b48-205c64e3e81a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105267305-172.17.0.17-1597111016390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39452,DS-bdec7461-e096-473c-9d5e-f15e12a34318,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-faf82201-1461-4abe-b541-bbd558108445,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-28117dea-ee99-4322-ad9f-897d9267e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-e218aa01-bf12-46c7-94d6-6905a559bb9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-4e3fc61b-9153-46d6-9e35-b36ecff34dce,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-cc862616-29ac-4280-b677-72df882cd9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-513d5bd8-a5a7-48ed-8285-1f33462a8684,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-1d2eb392-bec8-4896-8b48-205c64e3e81a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 3000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458985969-172.17.0.17-1597111134403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43633,DS-f0829acb-502f-423d-a35e-c13c7a0c6696,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-fec553f1-d736-4cb4-a58b-9bbf8d493a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-456cdcbe-cac9-4302-84d4-a10ab77b1b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-b42bf2be-c86d-449d-be3e-2763b30b3c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-a56f6141-6be4-447d-be16-bab76df53280,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-cd8806dc-0eeb-48a0-af2e-a6b7a0d167f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-448ca997-b092-428a-95fa-0c2b4441f90e,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-9ef84699-ad0a-4bb0-998e-9615fe165ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458985969-172.17.0.17-1597111134403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43633,DS-f0829acb-502f-423d-a35e-c13c7a0c6696,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-fec553f1-d736-4cb4-a58b-9bbf8d493a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-456cdcbe-cac9-4302-84d4-a10ab77b1b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-b42bf2be-c86d-449d-be3e-2763b30b3c50,DISK], DatanodeInfoWithStorage[127.0.0.1:41577,DS-a56f6141-6be4-447d-be16-bab76df53280,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-cd8806dc-0eeb-48a0-af2e-a6b7a0d167f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-448ca997-b092-428a-95fa-0c2b4441f90e,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-9ef84699-ad0a-4bb0-998e-9615fe165ebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5534
