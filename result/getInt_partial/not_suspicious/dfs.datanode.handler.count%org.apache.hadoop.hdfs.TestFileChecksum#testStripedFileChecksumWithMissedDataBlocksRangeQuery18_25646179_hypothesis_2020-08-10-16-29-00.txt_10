reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136159661-172.17.0.4-1597077249409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-8c4bf3b7-fa16-4d2e-bdcd-5e44b9c0c9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-c4483a25-e9ff-4523-aef6-9b224cac70cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-a5bbfbf9-4e4c-43dc-a78a-824f955345bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-dddef5ab-342e-437b-b68d-3263db93dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-ae8e0bb7-74af-4cfa-9f46-7ea214c59308,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-fed8cce4-2e04-4a91-9f79-bccb25fdaefa,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-51e8a8ad-12e2-4924-9b04-223539771ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-ac950c73-542d-4b9e-8bbc-294d1b81abdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1136159661-172.17.0.4-1597077249409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35022,DS-8c4bf3b7-fa16-4d2e-bdcd-5e44b9c0c9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-c4483a25-e9ff-4523-aef6-9b224cac70cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-a5bbfbf9-4e4c-43dc-a78a-824f955345bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-dddef5ab-342e-437b-b68d-3263db93dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-ae8e0bb7-74af-4cfa-9f46-7ea214c59308,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-fed8cce4-2e04-4a91-9f79-bccb25fdaefa,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-51e8a8ad-12e2-4924-9b04-223539771ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-ac950c73-542d-4b9e-8bbc-294d1b81abdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118546405-172.17.0.4-1597077934058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-fa047de0-2f34-4b38-a7f6-22afc5fb59df,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-50cef23f-570f-4695-9255-dc07961247e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-8ea524dd-c54b-4ba6-8226-ef1402fe3c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-0a6a88cb-527a-466f-893e-cffa76cc1bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-0e4bbd42-ac1b-4a5e-9396-855604b3c82c,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-06832ed2-cac7-4fb3-a89a-127a7b6b4dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-dbf906ea-9cd5-4e41-a2da-93945af3fd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-a3f8a30e-f959-47bb-a172-678322537235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118546405-172.17.0.4-1597077934058:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-fa047de0-2f34-4b38-a7f6-22afc5fb59df,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-50cef23f-570f-4695-9255-dc07961247e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-8ea524dd-c54b-4ba6-8226-ef1402fe3c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-0a6a88cb-527a-466f-893e-cffa76cc1bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-0e4bbd42-ac1b-4a5e-9396-855604b3c82c,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-06832ed2-cac7-4fb3-a89a-127a7b6b4dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-dbf906ea-9cd5-4e41-a2da-93945af3fd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-a3f8a30e-f959-47bb-a172-678322537235,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505557584-172.17.0.4-1597078155357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-d6a4536a-77e2-4e76-95f5-c6ad7764ea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f67397bb-6760-4c34-b535-49a5fdd0efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-a01fa174-e8b8-45b7-bf00-d807b7f038c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-251d3c16-4576-4e34-90ea-867cf128bac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-f7b208fc-011a-47d1-90a2-89ea7cc8dac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-a12b437f-14c4-404e-ad87-af7f91956c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-c34a8f22-66aa-4213-bfa9-5c60f190b906,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-ec9f07ec-63e2-4d6f-b9c7-75805278c6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505557584-172.17.0.4-1597078155357:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36969,DS-d6a4536a-77e2-4e76-95f5-c6ad7764ea4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-f67397bb-6760-4c34-b535-49a5fdd0efeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-a01fa174-e8b8-45b7-bf00-d807b7f038c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39643,DS-251d3c16-4576-4e34-90ea-867cf128bac7,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-f7b208fc-011a-47d1-90a2-89ea7cc8dac4,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-a12b437f-14c4-404e-ad87-af7f91956c10,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-c34a8f22-66aa-4213-bfa9-5c60f190b906,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-ec9f07ec-63e2-4d6f-b9c7-75805278c6be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888680382-172.17.0.4-1597078221725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33168,DS-b0f721c0-50ad-4ec9-aba8-ae6eb0f130d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-59254e62-e925-4750-952a-fe7c48215347,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-bc7d219d-01df-4bef-bbcc-82fe2d8b8a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-6c5c1129-4672-4208-a029-12cb88c4a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-8e2bfb87-6478-454d-ac3d-4d2b5002193d,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-c6b9c4d0-ac4a-40ec-ad31-26846139db63,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-e8c77e57-4353-49be-b0f8-a0852de8d022,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-4591e2e1-f8f1-44d8-b8df-2e86f6b068ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1888680382-172.17.0.4-1597078221725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33168,DS-b0f721c0-50ad-4ec9-aba8-ae6eb0f130d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-59254e62-e925-4750-952a-fe7c48215347,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-bc7d219d-01df-4bef-bbcc-82fe2d8b8a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-6c5c1129-4672-4208-a029-12cb88c4a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-8e2bfb87-6478-454d-ac3d-4d2b5002193d,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-c6b9c4d0-ac4a-40ec-ad31-26846139db63,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-e8c77e57-4353-49be-b0f8-a0852de8d022,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-4591e2e1-f8f1-44d8-b8df-2e86f6b068ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152572773-172.17.0.4-1597078366882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41422,DS-17660b22-480b-4bab-999d-8112ed34f036,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-42054259-7bdb-4776-ae89-92f834c84f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-c1d6a54c-8d96-46f2-b224-b7d0ccd65179,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-af43cca9-7601-4971-9e8c-fa7ba1f7b984,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-9dbdbe98-b7d3-45cb-9fc7-8990c14ca04c,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-17129b07-216d-458e-a468-7f2a6c6145ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-e1f26d68-2f8b-469b-84f1-1e2f97ba52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-0a3d74aa-07e7-4687-bde4-8f3a05bbd871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152572773-172.17.0.4-1597078366882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41422,DS-17660b22-480b-4bab-999d-8112ed34f036,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-42054259-7bdb-4776-ae89-92f834c84f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-c1d6a54c-8d96-46f2-b224-b7d0ccd65179,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-af43cca9-7601-4971-9e8c-fa7ba1f7b984,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-9dbdbe98-b7d3-45cb-9fc7-8990c14ca04c,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-17129b07-216d-458e-a468-7f2a6c6145ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-e1f26d68-2f8b-469b-84f1-1e2f97ba52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-0a3d74aa-07e7-4687-bde4-8f3a05bbd871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46038366-172.17.0.4-1597078560745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38391,DS-029a2a25-4f36-47e1-9a2f-171cf30ed2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-2f93a08a-e69c-403f-bb29-95c3e21e6aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-eccf710f-67a6-4b0c-87e6-1007d2059e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-97b87bf5-362c-4854-b2f2-0248a47ea6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ae431900-9dec-49d6-9d8c-6364d7c5f4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-6001ff40-b370-4cba-bab8-d198b92ca143,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-acbf9521-a768-49cf-96e5-b49ec42fea40,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-0cfbeb87-3c5e-44e5-8b7b-89bf45ac2446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46038366-172.17.0.4-1597078560745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38391,DS-029a2a25-4f36-47e1-9a2f-171cf30ed2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-2f93a08a-e69c-403f-bb29-95c3e21e6aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-eccf710f-67a6-4b0c-87e6-1007d2059e67,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-97b87bf5-362c-4854-b2f2-0248a47ea6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-ae431900-9dec-49d6-9d8c-6364d7c5f4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-6001ff40-b370-4cba-bab8-d198b92ca143,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-acbf9521-a768-49cf-96e5-b49ec42fea40,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-0cfbeb87-3c5e-44e5-8b7b-89bf45ac2446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570633902-172.17.0.4-1597078677753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-6780c6ef-19ee-43a4-85d4-abda08829004,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-49484c24-35b6-4926-a053-91241dd813bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-bf2d1dba-8a90-4475-a3e5-a9cca1e56cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-94d3340d-3aea-4f4d-9847-28a7cd541b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-9de87558-38f6-4a14-8f39-5d9b84d179ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-de8aada7-3f21-4272-bc2c-8e0778fc63cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-a7779874-f2f9-4db0-bc4e-b9698a2d74a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-cf142be6-68b3-44d3-920a-59159d0e9f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570633902-172.17.0.4-1597078677753:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42081,DS-6780c6ef-19ee-43a4-85d4-abda08829004,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-49484c24-35b6-4926-a053-91241dd813bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-bf2d1dba-8a90-4475-a3e5-a9cca1e56cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-94d3340d-3aea-4f4d-9847-28a7cd541b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-9de87558-38f6-4a14-8f39-5d9b84d179ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-de8aada7-3f21-4272-bc2c-8e0778fc63cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-a7779874-f2f9-4db0-bc4e-b9698a2d74a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-cf142be6-68b3-44d3-920a-59159d0e9f85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925013378-172.17.0.4-1597078711998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40256,DS-ee5ce6de-585e-4e9d-bc07-8afe4870d07f,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-618a7f44-891d-4fc4-b395-ce8ed164b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-e6089af7-0e2c-4ca3-86fc-315943494c68,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-37c5f13a-f63d-4eff-a39d-ff372efc86d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-9e30d1b3-3433-4743-9ac3-cdb3df1effb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-96fe1ff6-2057-4a5c-be1e-014e337e9893,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-a65c308e-3705-4b5d-a32a-9154163172a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-20a3b47d-df24-46d3-b054-807c981065e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1925013378-172.17.0.4-1597078711998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40256,DS-ee5ce6de-585e-4e9d-bc07-8afe4870d07f,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-618a7f44-891d-4fc4-b395-ce8ed164b2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-e6089af7-0e2c-4ca3-86fc-315943494c68,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-37c5f13a-f63d-4eff-a39d-ff372efc86d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-9e30d1b3-3433-4743-9ac3-cdb3df1effb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-96fe1ff6-2057-4a5c-be1e-014e337e9893,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-a65c308e-3705-4b5d-a32a-9154163172a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-20a3b47d-df24-46d3-b054-807c981065e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731538346-172.17.0.4-1597078989664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35661,DS-ee96ad07-6009-47bd-9260-dbc4e30c4bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-796feef9-21ec-4e09-b0e7-dc89fb584852,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-12e2ea52-a389-4b03-8905-214378a5feff,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-e396ad80-fe7f-4c6e-8056-a167ddf768f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-096d6ccf-d065-4745-8b28-b965882c4476,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-d5cdae41-e914-458f-89b9-b70a570b4d27,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-a1e340a1-50a7-4996-acae-f219ce9ed90b,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-aeb9e3e4-d0fc-4275-af2b-02f7638cc624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731538346-172.17.0.4-1597078989664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35661,DS-ee96ad07-6009-47bd-9260-dbc4e30c4bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-796feef9-21ec-4e09-b0e7-dc89fb584852,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-12e2ea52-a389-4b03-8905-214378a5feff,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-e396ad80-fe7f-4c6e-8056-a167ddf768f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-096d6ccf-d065-4745-8b28-b965882c4476,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-d5cdae41-e914-458f-89b9-b70a570b4d27,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-a1e340a1-50a7-4996-acae-f219ce9ed90b,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-aeb9e3e4-d0fc-4275-af2b-02f7638cc624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650954396-172.17.0.4-1597079923908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44889,DS-fb003ad9-663a-432a-b26f-7b49359f0628,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-4fd18ead-5d90-412e-9725-2d97bc649469,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-346e3a8d-ed5b-4068-aacb-bf2ae10350db,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-c1271833-4d42-4c47-8aba-8b25b16c789f,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-67af9003-6166-47ed-bf9c-676247bbafdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-65608ee5-d855-4e00-ac38-973098b815e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-9fe89997-19a6-4b8b-b655-2acb503be47a,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-5bbc66d2-eced-4ae9-af5c-79f4959ef064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-650954396-172.17.0.4-1597079923908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44889,DS-fb003ad9-663a-432a-b26f-7b49359f0628,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-4fd18ead-5d90-412e-9725-2d97bc649469,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-346e3a8d-ed5b-4068-aacb-bf2ae10350db,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-c1271833-4d42-4c47-8aba-8b25b16c789f,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-67af9003-6166-47ed-bf9c-676247bbafdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-65608ee5-d855-4e00-ac38-973098b815e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-9fe89997-19a6-4b8b-b655-2acb503be47a,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-5bbc66d2-eced-4ae9-af5c-79f4959ef064,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699546634-172.17.0.4-1597080070975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-50c01c6f-9b00-41ec-9a53-9b801c6849a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-055dc088-1bf4-4cc1-8ef2-a1434687d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-8ed1b8ba-3668-4156-9a03-13938f37a5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-bc45098c-86b9-4ff7-b050-531291e4b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-248c05bf-8cac-4968-a3cc-3b7b91da4942,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-19d0d294-d126-48cd-b16d-49704a80a319,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-c6fd8dae-f150-4478-99ce-4114f95d224b,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-e6720e1e-bebf-4358-b708-4b7307f86a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699546634-172.17.0.4-1597080070975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44007,DS-50c01c6f-9b00-41ec-9a53-9b801c6849a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-055dc088-1bf4-4cc1-8ef2-a1434687d2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-8ed1b8ba-3668-4156-9a03-13938f37a5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-bc45098c-86b9-4ff7-b050-531291e4b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-248c05bf-8cac-4968-a3cc-3b7b91da4942,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-19d0d294-d126-48cd-b16d-49704a80a319,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-c6fd8dae-f150-4478-99ce-4114f95d224b,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-e6720e1e-bebf-4358-b708-4b7307f86a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620382214-172.17.0.4-1597080137629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-5be5c3c7-ffb6-46f3-ab7c-85c19beccb63,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-a03ae6a1-fa24-43d7-96f9-2c77645fd667,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-899d89bf-0c68-44dd-a3ca-485c7e8dab69,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-86bb021e-11dc-4a9b-8288-4f9c468e9529,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-c464297a-dcaa-41cc-9a78-35af3bc5e978,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-70a8aac3-efd8-45fe-ba72-1c0e39016606,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-b0c77b2d-343e-412e-96e6-4fd0b42ad279,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-e71e5a8d-62fe-48bc-b4f1-d475711fbaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-620382214-172.17.0.4-1597080137629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37693,DS-5be5c3c7-ffb6-46f3-ab7c-85c19beccb63,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-a03ae6a1-fa24-43d7-96f9-2c77645fd667,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-899d89bf-0c68-44dd-a3ca-485c7e8dab69,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-86bb021e-11dc-4a9b-8288-4f9c468e9529,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-c464297a-dcaa-41cc-9a78-35af3bc5e978,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-70a8aac3-efd8-45fe-ba72-1c0e39016606,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-b0c77b2d-343e-412e-96e6-4fd0b42ad279,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-e71e5a8d-62fe-48bc-b4f1-d475711fbaaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454382130-172.17.0.4-1597080657728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37199,DS-4e2ee6b4-5774-40ca-aa13-19a03b36fa43,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-e24572af-8446-4c75-b889-3e96cdebd1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-a1ed922d-92b2-4a44-b515-7b0a575a54b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-1f3fd03e-bb73-482f-9cfe-fa520113d733,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-ebb3f043-d465-4684-86ef-b7975d4744df,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-cf001ccd-ee31-46ce-b62d-d3bb00dfed38,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-deab14a0-98d7-486a-a0fd-6f4d3b36cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-1d1b3665-0432-4174-8eb6-f1713f6dc866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1454382130-172.17.0.4-1597080657728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37199,DS-4e2ee6b4-5774-40ca-aa13-19a03b36fa43,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-e24572af-8446-4c75-b889-3e96cdebd1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-a1ed922d-92b2-4a44-b515-7b0a575a54b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-1f3fd03e-bb73-482f-9cfe-fa520113d733,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-ebb3f043-d465-4684-86ef-b7975d4744df,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-cf001ccd-ee31-46ce-b62d-d3bb00dfed38,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-deab14a0-98d7-486a-a0fd-6f4d3b36cfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:38933,DS-1d1b3665-0432-4174-8eb6-f1713f6dc866,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20477016-172.17.0.4-1597080773890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35747,DS-e899886f-f351-4a48-8996-4836486819cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-48cc132e-0070-494e-842b-758dedb2b0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-f98f0a21-1cf8-4e9d-b983-896314c6dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-2981ea52-7808-46b9-bf48-810ecbc3210b,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-9749fe21-73c3-4bd6-b8b5-bda769aa4929,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-957d42dd-fa02-459b-9402-619cf578eaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-cb10603b-1368-4a4b-99e4-5516a47b6ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-f89cc22c-a256-4561-a7ce-62a0c8f99654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20477016-172.17.0.4-1597080773890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35747,DS-e899886f-f351-4a48-8996-4836486819cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-48cc132e-0070-494e-842b-758dedb2b0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-f98f0a21-1cf8-4e9d-b983-896314c6dc33,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-2981ea52-7808-46b9-bf48-810ecbc3210b,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-9749fe21-73c3-4bd6-b8b5-bda769aa4929,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-957d42dd-fa02-459b-9402-619cf578eaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-cb10603b-1368-4a4b-99e4-5516a47b6ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-f89cc22c-a256-4561-a7ce-62a0c8f99654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530127279-172.17.0.4-1597081034338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-34484088-e39a-422c-b5dc-f8a4a12ef642,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-30ec2a63-6182-4ed1-8398-f0093905cd42,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-6d0011a9-a79a-4fe0-94b7-a6a0aac67fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-b942018a-bd78-494d-83f5-a37f60bb1c68,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-17bb3c41-d3a1-40fa-ab1b-d265b3e9bf57,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-5bef98d9-f8bb-4021-bf0f-4633d39de613,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-adab28f4-6dbb-43fc-aa42-f02db3ec6668,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-aac75278-eaf0-4a98-823f-c80b8664e0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530127279-172.17.0.4-1597081034338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40658,DS-34484088-e39a-422c-b5dc-f8a4a12ef642,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-30ec2a63-6182-4ed1-8398-f0093905cd42,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-6d0011a9-a79a-4fe0-94b7-a6a0aac67fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-b942018a-bd78-494d-83f5-a37f60bb1c68,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-17bb3c41-d3a1-40fa-ab1b-d265b3e9bf57,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-5bef98d9-f8bb-4021-bf0f-4633d39de613,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-adab28f4-6dbb-43fc-aa42-f02db3ec6668,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-aac75278-eaf0-4a98-823f-c80b8664e0fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227638817-172.17.0.4-1597081340145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-18fa2e5e-efba-4b1d-956a-12ed772b9547,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-6966bd92-4c5c-4ecc-b71a-a4baa24ccbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-767a5b1e-2506-40d4-8c54-0831fd934fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-27573c8b-6190-41ed-9ce5-7b0856234217,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8db0d526-2c8b-4ef9-b35f-e69fecc83c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-33f4e7c6-fc3e-4e6e-a707-1f20b84f1b58,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-575fc815-2cd8-4a13-992f-297dd971f295,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-4531efa3-5d44-4750-8f6e-3030b921e618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227638817-172.17.0.4-1597081340145:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-18fa2e5e-efba-4b1d-956a-12ed772b9547,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-6966bd92-4c5c-4ecc-b71a-a4baa24ccbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-767a5b1e-2506-40d4-8c54-0831fd934fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-27573c8b-6190-41ed-9ce5-7b0856234217,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-8db0d526-2c8b-4ef9-b35f-e69fecc83c53,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-33f4e7c6-fc3e-4e6e-a707-1f20b84f1b58,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-575fc815-2cd8-4a13-992f-297dd971f295,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-4531efa3-5d44-4750-8f6e-3030b921e618,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245526822-172.17.0.4-1597081628669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-15240a11-98b5-4e0d-bf55-6976cd8e6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-11e6bed7-c15d-425f-874e-181580181ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-15bf0c17-248d-41d8-891f-6d12f7c06934,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-25019228-23d9-4866-9a0c-08c0a85a9db7,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-58577352-60ea-44ea-8a05-a6f685a8399c,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-ad488cff-0ddb-4ff4-878a-904d630bf3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-0ab31526-e300-4dff-967c-7e4b88a7d257,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-84f21f0e-178e-4913-a91c-e38e65206245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245526822-172.17.0.4-1597081628669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37684,DS-15240a11-98b5-4e0d-bf55-6976cd8e6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-11e6bed7-c15d-425f-874e-181580181ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-15bf0c17-248d-41d8-891f-6d12f7c06934,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-25019228-23d9-4866-9a0c-08c0a85a9db7,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-58577352-60ea-44ea-8a05-a6f685a8399c,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-ad488cff-0ddb-4ff4-878a-904d630bf3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-0ab31526-e300-4dff-967c-7e4b88a7d257,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-84f21f0e-178e-4913-a91c-e38e65206245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979726779-172.17.0.4-1597081892422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-c176787f-9d28-4785-9f60-51ad65d38641,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-4f58f9e6-018d-4f42-b4ad-b399413fb8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-59bb19e2-ee6c-4240-ba73-15992a7dece7,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-82e2fb69-6931-4056-809e-f579a2528b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-3faca75e-fe04-49f2-acac-1df710d220de,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-f8baffad-da01-4f38-b482-24b698e52634,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-28cc044b-4c73-4ea7-b006-5066a081bd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-e40dbfed-cb7f-4208-8754-3f6a67118e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979726779-172.17.0.4-1597081892422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40047,DS-c176787f-9d28-4785-9f60-51ad65d38641,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-4f58f9e6-018d-4f42-b4ad-b399413fb8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-59bb19e2-ee6c-4240-ba73-15992a7dece7,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-82e2fb69-6931-4056-809e-f579a2528b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-3faca75e-fe04-49f2-acac-1df710d220de,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-f8baffad-da01-4f38-b482-24b698e52634,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-28cc044b-4c73-4ea7-b006-5066a081bd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-e40dbfed-cb7f-4208-8754-3f6a67118e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 15
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720299177-172.17.0.4-1597082075421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-a8a771cd-de74-4557-80e2-2e32d710b54d,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-29e55dc6-96a6-4b36-b8bd-ca62fd946fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-38e391de-5efb-4a1f-954c-07190ef722e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-3b57d240-3687-404f-9181-500186b11c94,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-83710353-fe85-44d9-b5cf-03f0ba56c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-6905f82a-a8da-4582-b463-ecee421bb615,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-4c9d2118-5def-4268-862b-5aaf88897eae,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-9a9c43eb-6a33-49ef-ac3d-6774b902d393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720299177-172.17.0.4-1597082075421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-a8a771cd-de74-4557-80e2-2e32d710b54d,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-29e55dc6-96a6-4b36-b8bd-ca62fd946fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-38e391de-5efb-4a1f-954c-07190ef722e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-3b57d240-3687-404f-9181-500186b11c94,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-83710353-fe85-44d9-b5cf-03f0ba56c3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-6905f82a-a8da-4582-b463-ecee421bb615,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-4c9d2118-5def-4268-862b-5aaf88897eae,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-9a9c43eb-6a33-49ef-ac3d-6774b902d393,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5443
