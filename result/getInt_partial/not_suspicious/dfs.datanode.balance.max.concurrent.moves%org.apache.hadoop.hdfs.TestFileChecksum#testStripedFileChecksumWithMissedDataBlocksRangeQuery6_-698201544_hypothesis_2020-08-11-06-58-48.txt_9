reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559684333-172.17.0.11-1597129215915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40656,DS-0d44c764-2e49-4846-a0f4-a34e85f3022c,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-59477067-7117-44ad-9c19-f5a4e53ebeee,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-76041689-c30d-4706-8ff6-a3a9adcf56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-a77197e4-b5b3-4210-8292-4959bbd8d321,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-16bc6966-27e3-44c4-bac5-31ce4e206c27,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-8bf4e79c-20bb-4fd9-a611-d48f2054f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-e1cc9266-c2ad-41fa-afd5-9897f26a6677,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-a769be53-36b7-4e3d-9448-7643adcfde52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559684333-172.17.0.11-1597129215915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40656,DS-0d44c764-2e49-4846-a0f4-a34e85f3022c,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-59477067-7117-44ad-9c19-f5a4e53ebeee,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-76041689-c30d-4706-8ff6-a3a9adcf56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-a77197e4-b5b3-4210-8292-4959bbd8d321,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-16bc6966-27e3-44c4-bac5-31ce4e206c27,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-8bf4e79c-20bb-4fd9-a611-d48f2054f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-e1cc9266-c2ad-41fa-afd5-9897f26a6677,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-a769be53-36b7-4e3d-9448-7643adcfde52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603490928-172.17.0.11-1597129291271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-75f04dfe-a4b2-4c59-b5ef-95eb4c814db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-c82c232d-e2a6-4fef-966f-a5ea3df79b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-2c38591b-0e13-4ece-90ef-538de003b476,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-07c60fb0-bf1f-408c-8daa-4a7764b89a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-c56cddb2-64db-49c3-b1fa-14c3f74875e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-bac0ed49-be26-43b3-848d-87982331037f,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-25f19640-1438-4422-b878-76f0a3c51b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-f25fd050-942d-43de-859c-6b804c1c963f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603490928-172.17.0.11-1597129291271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-75f04dfe-a4b2-4c59-b5ef-95eb4c814db4,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-c82c232d-e2a6-4fef-966f-a5ea3df79b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-2c38591b-0e13-4ece-90ef-538de003b476,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-07c60fb0-bf1f-408c-8daa-4a7764b89a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-c56cddb2-64db-49c3-b1fa-14c3f74875e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-bac0ed49-be26-43b3-848d-87982331037f,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-25f19640-1438-4422-b878-76f0a3c51b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-f25fd050-942d-43de-859c-6b804c1c963f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963021047-172.17.0.11-1597129499578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-6ce7ad0d-4994-4bef-b051-2cc5bc306285,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-ab62b229-c8fc-40f1-9bda-a4d9c57a0e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-658610ee-3b24-47da-a6f5-7b393bda47f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-1752313a-c550-42c1-8028-ecc581989231,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-e0e7edd5-dc65-4653-b59c-c7173af53b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-a18779b5-c43b-4b58-8166-8332445c6845,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-338d7285-f87c-4c91-afe4-6887e463fd45,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-d21525ca-f13a-4f25-865e-aa84f796a3c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963021047-172.17.0.11-1597129499578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32840,DS-6ce7ad0d-4994-4bef-b051-2cc5bc306285,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-ab62b229-c8fc-40f1-9bda-a4d9c57a0e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-658610ee-3b24-47da-a6f5-7b393bda47f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-1752313a-c550-42c1-8028-ecc581989231,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-e0e7edd5-dc65-4653-b59c-c7173af53b39,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-a18779b5-c43b-4b58-8166-8332445c6845,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-338d7285-f87c-4c91-afe4-6887e463fd45,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-d21525ca-f13a-4f25-865e-aa84f796a3c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406805720-172.17.0.11-1597129533868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35346,DS-2abed2cd-f72b-41c0-b80d-461b92ba4c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-2722c4b3-e431-4af0-b7fa-f59356e01333,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-7e422c2b-43b8-43b0-8a32-bdbdbe815e98,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-a763237e-02c0-48b9-8496-2ce24cf11b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-62e69e6b-baea-4c6b-8c9e-3c3a149a5abf,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-6cf85bc5-e286-4be1-8b43-54b81b2fac78,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-e001a2c6-3924-4671-855f-fa6a6ca48d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-d06a7977-40c8-4b4c-b747-703d2a486a65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406805720-172.17.0.11-1597129533868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35346,DS-2abed2cd-f72b-41c0-b80d-461b92ba4c88,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-2722c4b3-e431-4af0-b7fa-f59356e01333,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-7e422c2b-43b8-43b0-8a32-bdbdbe815e98,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-a763237e-02c0-48b9-8496-2ce24cf11b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-62e69e6b-baea-4c6b-8c9e-3c3a149a5abf,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-6cf85bc5-e286-4be1-8b43-54b81b2fac78,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-e001a2c6-3924-4671-855f-fa6a6ca48d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-d06a7977-40c8-4b4c-b747-703d2a486a65,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105937266-172.17.0.11-1597129777582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-418506c5-fcf2-4ba5-a85e-3d98ac6b2321,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-243c448a-3ec5-456a-8b16-00f0927b0ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-a0848839-94c7-435b-a333-8b2d9978a44a,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-23328449-1146-42ef-afdc-729aa1d4e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-ee7ffc3e-8fa8-46c9-8cd7-4eb81a4ca75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-acedb3a7-6617-441e-b688-c8497cb99e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-d8e82636-d401-4c02-9042-9dda74de8e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-ca67672c-d797-4370-a676-eff92c7cda95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105937266-172.17.0.11-1597129777582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44913,DS-418506c5-fcf2-4ba5-a85e-3d98ac6b2321,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-243c448a-3ec5-456a-8b16-00f0927b0ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-a0848839-94c7-435b-a333-8b2d9978a44a,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-23328449-1146-42ef-afdc-729aa1d4e7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-ee7ffc3e-8fa8-46c9-8cd7-4eb81a4ca75e,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-acedb3a7-6617-441e-b688-c8497cb99e97,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-d8e82636-d401-4c02-9042-9dda74de8e03,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-ca67672c-d797-4370-a676-eff92c7cda95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634679871-172.17.0.11-1597130409724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42792,DS-d7606b20-51f6-48ba-bb40-3343aa5988be,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-0edc4f0d-fc00-4fa2-ab81-8733f13bbf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-40e18dfd-4ee0-4cd0-92c9-a7a918c57df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-4e13ae82-5e9e-4d69-a074-2e23afc79116,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-92b74525-8869-4c56-895d-442c0b145173,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-90e2c043-77b5-4a02-8ca4-f53802b76c22,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-de5c7b08-a6b6-4dce-bf61-70298d23c44c,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-230a3b01-bf1b-495d-9766-656619008890,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-634679871-172.17.0.11-1597130409724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42792,DS-d7606b20-51f6-48ba-bb40-3343aa5988be,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-0edc4f0d-fc00-4fa2-ab81-8733f13bbf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-40e18dfd-4ee0-4cd0-92c9-a7a918c57df5,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-4e13ae82-5e9e-4d69-a074-2e23afc79116,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-92b74525-8869-4c56-895d-442c0b145173,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-90e2c043-77b5-4a02-8ca4-f53802b76c22,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-de5c7b08-a6b6-4dce-bf61-70298d23c44c,DISK], DatanodeInfoWithStorage[127.0.0.1:44867,DS-230a3b01-bf1b-495d-9766-656619008890,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320623409-172.17.0.11-1597130446709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-bf7b090e-a12a-4e26-8506-381979afca9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-4f57ae9f-fb1d-4b38-8db8-a6ed6c3b70ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-4c0d8b07-da8e-4198-aeeb-7352b9e832c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-9be1808e-f716-455e-8957-fdcd7011d568,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-81175e00-1e15-42d5-9cb3-9cfbf5b58481,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-f176a2c7-80d2-458b-81a6-394309402bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-f948742c-2282-41b5-b9c1-d1ada460ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-82dc7410-80b2-4515-b942-0c2ec5ecc2a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320623409-172.17.0.11-1597130446709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35145,DS-bf7b090e-a12a-4e26-8506-381979afca9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-4f57ae9f-fb1d-4b38-8db8-a6ed6c3b70ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-4c0d8b07-da8e-4198-aeeb-7352b9e832c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-9be1808e-f716-455e-8957-fdcd7011d568,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-81175e00-1e15-42d5-9cb3-9cfbf5b58481,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-f176a2c7-80d2-458b-81a6-394309402bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-f948742c-2282-41b5-b9c1-d1ada460ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-82dc7410-80b2-4515-b942-0c2ec5ecc2a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579952231-172.17.0.11-1597130525367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-f4b47f1d-bfca-4450-9b48-86df9a253d56,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-ee93e877-2c52-4ab3-a23d-8386f998b276,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-d6974fc5-f210-4781-8c4f-7bda3b1ffeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-0f3b0f58-e87f-4353-9c81-425df1045f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-a5e26dd4-1588-42e9-986f-9a6ac3ed8706,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-1dece8a3-5b9c-47d1-87f6-e0b36e7a26e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-2097c36a-badb-48a5-9a3c-313d3121a1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-737f9953-d75e-46d2-bc80-9a94176c7a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-579952231-172.17.0.11-1597130525367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44072,DS-f4b47f1d-bfca-4450-9b48-86df9a253d56,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-ee93e877-2c52-4ab3-a23d-8386f998b276,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-d6974fc5-f210-4781-8c4f-7bda3b1ffeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-0f3b0f58-e87f-4353-9c81-425df1045f72,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-a5e26dd4-1588-42e9-986f-9a6ac3ed8706,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-1dece8a3-5b9c-47d1-87f6-e0b36e7a26e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-2097c36a-badb-48a5-9a3c-313d3121a1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36684,DS-737f9953-d75e-46d2-bc80-9a94176c7a45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263685596-172.17.0.11-1597130555398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-20498403-0581-4561-97d1-2f0a4d9b7df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-d0b9048f-8500-4eaa-a0fb-165fca0dacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-e5886d91-17b2-4048-b541-52380dd16c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-30f0bdd8-e248-4d6f-b553-31929e4bf865,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-0e8ba2cc-07c1-4407-9fb1-08900a823249,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-4161b718-d015-4812-9fb0-5eeae9b570d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-832f1f1d-ab92-46d2-9ab7-b7714c645879,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-c11f4184-cf35-434a-9208-5a8aa02dadff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-263685596-172.17.0.11-1597130555398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45110,DS-20498403-0581-4561-97d1-2f0a4d9b7df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-d0b9048f-8500-4eaa-a0fb-165fca0dacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-e5886d91-17b2-4048-b541-52380dd16c30,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-30f0bdd8-e248-4d6f-b553-31929e4bf865,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-0e8ba2cc-07c1-4407-9fb1-08900a823249,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-4161b718-d015-4812-9fb0-5eeae9b570d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-832f1f1d-ab92-46d2-9ab7-b7714c645879,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-c11f4184-cf35-434a-9208-5a8aa02dadff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488852406-172.17.0.11-1597130696071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34236,DS-f085593b-41cc-417b-8eeb-bd362a7d1a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-87028dff-ac44-4151-83a7-721ea25c1188,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-abfe7594-7e5f-42f9-8aeb-4e162d5543c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-549b09c3-c6d6-4b29-9180-9dbc8927801e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-b4f6d44b-04f9-4cdd-a7bf-7a7b89243fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-204497a4-7de2-43db-a043-d6d7a504b404,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-0d26ca19-5564-47b6-91ec-b9050557dc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-728c5649-4eec-4fb8-9e59-8bc96704625e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1488852406-172.17.0.11-1597130696071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34236,DS-f085593b-41cc-417b-8eeb-bd362a7d1a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-87028dff-ac44-4151-83a7-721ea25c1188,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-abfe7594-7e5f-42f9-8aeb-4e162d5543c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-549b09c3-c6d6-4b29-9180-9dbc8927801e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-b4f6d44b-04f9-4cdd-a7bf-7a7b89243fc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-204497a4-7de2-43db-a043-d6d7a504b404,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-0d26ca19-5564-47b6-91ec-b9050557dc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-728c5649-4eec-4fb8-9e59-8bc96704625e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789799242-172.17.0.11-1597130768700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-76a08d54-961a-4f0f-ba4d-2db35ac3fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-56c1ebd3-eeab-479f-a08f-7d8f14c0ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-dfc8d2fb-1807-423d-87ff-66ac24eb5ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-e4288bef-1e49-49ea-bee2-7ed5b0750471,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-832c25a6-5808-4bd9-a3b1-eb9580b35699,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-5f7bf8de-ed79-4f70-9adc-d4f78dcb5f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-7dafa5f5-828f-4d29-a65f-6ac735aeb6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-fcda9035-5447-4dcf-9b3d-52a0974fadd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789799242-172.17.0.11-1597130768700:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-76a08d54-961a-4f0f-ba4d-2db35ac3fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-56c1ebd3-eeab-479f-a08f-7d8f14c0ef80,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-dfc8d2fb-1807-423d-87ff-66ac24eb5ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-e4288bef-1e49-49ea-bee2-7ed5b0750471,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-832c25a6-5808-4bd9-a3b1-eb9580b35699,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-5f7bf8de-ed79-4f70-9adc-d4f78dcb5f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-7dafa5f5-828f-4d29-a65f-6ac735aeb6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-fcda9035-5447-4dcf-9b3d-52a0974fadd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249150019-172.17.0.11-1597130897822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-2743110f-8071-42e6-a760-b9094d877a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-dbb3daad-39f2-4e19-8d11-6ba8c62c4f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-89323177-7bec-4ec6-b23a-3478a8833a41,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-6ddfba82-dc18-4708-9020-897afa296ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-c79d849d-fe5e-4d27-8398-a9595e58602a,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-684ec8e0-fa2c-4024-9b2e-a40bd781902e,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-10e07cfc-ec58-4aa9-9610-ef43f74dc637,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-a3718658-f268-41b0-b38c-905b395e95cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249150019-172.17.0.11-1597130897822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44350,DS-2743110f-8071-42e6-a760-b9094d877a34,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-dbb3daad-39f2-4e19-8d11-6ba8c62c4f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-89323177-7bec-4ec6-b23a-3478a8833a41,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-6ddfba82-dc18-4708-9020-897afa296ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-c79d849d-fe5e-4d27-8398-a9595e58602a,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-684ec8e0-fa2c-4024-9b2e-a40bd781902e,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-10e07cfc-ec58-4aa9-9610-ef43f74dc637,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-a3718658-f268-41b0-b38c-905b395e95cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970570431-172.17.0.11-1597131009563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34990,DS-fb056d55-1a03-47fc-b219-d95a90d1a3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-f88f6d2d-da4b-46c6-b2c4-c00b8f6d4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-30ec23bc-caf1-4181-96ae-851b809d9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-9b7359e3-4e30-4146-94bc-b4b4b7c67d07,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-603ad47f-49f3-4ed1-9d0d-d49f00b0f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-820ceb0b-da5f-4c82-a97f-38a5fb11de05,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-f64d2701-ef99-4726-96cd-da7c1eda0360,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-3a786759-7e6e-437a-bc57-6a7d43f39a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970570431-172.17.0.11-1597131009563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34990,DS-fb056d55-1a03-47fc-b219-d95a90d1a3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-f88f6d2d-da4b-46c6-b2c4-c00b8f6d4f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-30ec23bc-caf1-4181-96ae-851b809d9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:42797,DS-9b7359e3-4e30-4146-94bc-b4b4b7c67d07,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-603ad47f-49f3-4ed1-9d0d-d49f00b0f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-820ceb0b-da5f-4c82-a97f-38a5fb11de05,DISK], DatanodeInfoWithStorage[127.0.0.1:38114,DS-f64d2701-ef99-4726-96cd-da7c1eda0360,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-3a786759-7e6e-437a-bc57-6a7d43f39a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433305893-172.17.0.11-1597131304620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44437,DS-c9986adb-4ea0-4887-ac14-6a2224080083,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-4e01b222-a696-4ba3-89fe-33ead5a72964,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-04237089-a7df-4535-ab74-7d6c54b159ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-be6f5120-b7e9-493d-9eb9-06c7a7f5b843,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-4c582e10-41e0-4cc4-86f5-f0e88938a2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-a2c6b51f-27f3-49a1-8703-d01c569119af,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-67aa249a-7eb3-403e-a277-5cc54c5b36a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-13bdbf45-68e8-412b-9e3e-a4c4c7fa727b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1433305893-172.17.0.11-1597131304620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44437,DS-c9986adb-4ea0-4887-ac14-6a2224080083,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-4e01b222-a696-4ba3-89fe-33ead5a72964,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-04237089-a7df-4535-ab74-7d6c54b159ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-be6f5120-b7e9-493d-9eb9-06c7a7f5b843,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-4c582e10-41e0-4cc4-86f5-f0e88938a2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-a2c6b51f-27f3-49a1-8703-d01c569119af,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-67aa249a-7eb3-403e-a277-5cc54c5b36a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-13bdbf45-68e8-412b-9e3e-a4c4c7fa727b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453409291-172.17.0.11-1597131563967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-8fce30dc-01a0-42d8-bc1c-1fbf4e7460f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-2aab6811-06d5-4ed7-99cf-72f757004cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-cc2c78d3-fa1b-4f50-aedd-b51061676cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-d55b63ee-8a2f-4ecb-ac2f-f69bbf140559,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-cee3c0d8-e48a-4187-90af-12aab99443c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-02765c05-9cb3-450f-86f0-c926af33eb22,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-14722c11-986e-4271-a9ef-eae0799d269e,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-664d8375-f601-4c5e-8f54-7ae8d77532ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453409291-172.17.0.11-1597131563967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40092,DS-8fce30dc-01a0-42d8-bc1c-1fbf4e7460f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-2aab6811-06d5-4ed7-99cf-72f757004cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-cc2c78d3-fa1b-4f50-aedd-b51061676cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-d55b63ee-8a2f-4ecb-ac2f-f69bbf140559,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-cee3c0d8-e48a-4187-90af-12aab99443c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-02765c05-9cb3-450f-86f0-c926af33eb22,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-14722c11-986e-4271-a9ef-eae0799d269e,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-664d8375-f601-4c5e-8f54-7ae8d77532ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109145185-172.17.0.11-1597132071615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-9d6e9cab-7721-455a-8417-43d0c5f21f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-33415fb1-2313-4dd5-98e2-1c4a435738b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-0ad29183-b62b-42f4-a8b1-c5e41aa980c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-fde4118d-db1c-4dfd-a6ad-9d6288957f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-5a6b7031-cd9f-4797-9e29-9b600ebe4342,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-50a08c67-9069-4626-a180-79d5c920cc16,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-a22b6c85-3bbe-49a1-b19f-140de6b1a428,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-88510628-444a-4866-8ce2-318d17bbce88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109145185-172.17.0.11-1597132071615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41099,DS-9d6e9cab-7721-455a-8417-43d0c5f21f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46277,DS-33415fb1-2313-4dd5-98e2-1c4a435738b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-0ad29183-b62b-42f4-a8b1-c5e41aa980c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-fde4118d-db1c-4dfd-a6ad-9d6288957f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-5a6b7031-cd9f-4797-9e29-9b600ebe4342,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-50a08c67-9069-4626-a180-79d5c920cc16,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-a22b6c85-3bbe-49a1-b19f-140de6b1a428,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-88510628-444a-4866-8ce2-318d17bbce88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425393473-172.17.0.11-1597132216065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-4ea3d1a1-043b-4d6e-92ce-465fa1e79702,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-66ce36e4-6195-4103-bdc7-2f0d10d4fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-790019bf-3e31-4038-b4da-8f2875038976,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-e0ddfa9d-fb72-4dc1-8284-dd9003b8d697,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-a989dcea-6deb-4add-a739-c194bc9c47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-2861231b-8637-41a8-af3d-6d3f601714ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-89622c27-737a-4c7d-abb5-12ca4bdbd1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-43145f96-a94a-4098-88d6-634c1abd3143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425393473-172.17.0.11-1597132216065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39978,DS-4ea3d1a1-043b-4d6e-92ce-465fa1e79702,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-66ce36e4-6195-4103-bdc7-2f0d10d4fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-790019bf-3e31-4038-b4da-8f2875038976,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-e0ddfa9d-fb72-4dc1-8284-dd9003b8d697,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-a989dcea-6deb-4add-a739-c194bc9c47f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-2861231b-8637-41a8-af3d-6d3f601714ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46554,DS-89622c27-737a-4c7d-abb5-12ca4bdbd1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-43145f96-a94a-4098-88d6-634c1abd3143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848534411-172.17.0.11-1597132678931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39084,DS-6ef25ddb-e642-4174-8073-c0122fb22324,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-4e875196-1294-4b3d-a086-e27a96b41e32,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-efbf73d8-d2e3-4c5c-aef7-36bd63241df4,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-daa43cb3-1d03-4a01-9074-5e4ae4dd0364,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-da9472c5-5fa4-47b3-b01d-a325643f1697,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-99262f9e-bc2b-4e37-9410-ea257f325545,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-28a8b0b6-0db8-4afb-8eb8-fa3960627e31,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-c9200cbe-5ed1-4fe3-85a4-2674684b5734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848534411-172.17.0.11-1597132678931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39084,DS-6ef25ddb-e642-4174-8073-c0122fb22324,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-4e875196-1294-4b3d-a086-e27a96b41e32,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-efbf73d8-d2e3-4c5c-aef7-36bd63241df4,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-daa43cb3-1d03-4a01-9074-5e4ae4dd0364,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-da9472c5-5fa4-47b3-b01d-a325643f1697,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-99262f9e-bc2b-4e37-9410-ea257f325545,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-28a8b0b6-0db8-4afb-8eb8-fa3960627e31,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-c9200cbe-5ed1-4fe3-85a4-2674684b5734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139527721-172.17.0.11-1597132861049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-fda46a40-e581-414b-b642-458b91e7f458,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-62178860-6f27-4eea-8a77-68b1ef59236c,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-5615d861-7082-4eb1-9d1b-27107096275a,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-ea03d647-a640-48ab-9d70-05b5cfb02bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-13ed03ed-80d7-40ad-a18d-88d8ed93ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-5f740621-bf0e-4552-99be-265d281e2fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-7c09f215-abdf-4b73-a052-dcc677e9f03e,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-5af93f29-0cf3-4862-8867-af5bcbb1d17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139527721-172.17.0.11-1597132861049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-fda46a40-e581-414b-b642-458b91e7f458,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-62178860-6f27-4eea-8a77-68b1ef59236c,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-5615d861-7082-4eb1-9d1b-27107096275a,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-ea03d647-a640-48ab-9d70-05b5cfb02bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-13ed03ed-80d7-40ad-a18d-88d8ed93ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-5f740621-bf0e-4552-99be-265d281e2fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-7c09f215-abdf-4b73-a052-dcc677e9f03e,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-5af93f29-0cf3-4862-8867-af5bcbb1d17a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854130140-172.17.0.11-1597133091815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44560,DS-c2e8fd9e-0c4e-4510-9e93-9bde4da07b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-72fbdd2d-e641-432a-8961-f9631a3efa54,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-5bc4888f-a75a-4b19-a760-c4b830b6901a,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-26a7a750-cb61-4d98-a00f-14379f1dec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-248cc40f-da1e-4654-831b-971be86d1051,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-3fe9cd2f-179a-4db6-a3b8-35265be5802f,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-f9637ad6-faf1-46f5-b172-eeb2a6098f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-fed8ab35-bbd4-40a1-a014-3194edf3b601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854130140-172.17.0.11-1597133091815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44560,DS-c2e8fd9e-0c4e-4510-9e93-9bde4da07b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-72fbdd2d-e641-432a-8961-f9631a3efa54,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-5bc4888f-a75a-4b19-a760-c4b830b6901a,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-26a7a750-cb61-4d98-a00f-14379f1dec3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-248cc40f-da1e-4654-831b-971be86d1051,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-3fe9cd2f-179a-4db6-a3b8-35265be5802f,DISK], DatanodeInfoWithStorage[127.0.0.1:39952,DS-f9637ad6-faf1-46f5-b172-eeb2a6098f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-fed8ab35-bbd4-40a1-a014-3194edf3b601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129434415-172.17.0.11-1597133321161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42450,DS-ecf764dd-8387-4420-95cb-f81b6b1a89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-07f2b08c-ff04-453b-9963-be8fed6e8d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-be67c24a-5d21-43c6-afc1-525402dce9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-72f821f4-89f6-470c-95a1-0a0f263ea2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-cf024faa-b00e-43f5-a5e7-8874083f6ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-bb454ba5-ab4a-470f-97cd-2a4b7834f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-d35cb058-9853-46d1-954d-c352f1a14e28,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-1ad8a72d-b382-4520-8ffe-4ca994af15aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129434415-172.17.0.11-1597133321161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42450,DS-ecf764dd-8387-4420-95cb-f81b6b1a89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-07f2b08c-ff04-453b-9963-be8fed6e8d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-be67c24a-5d21-43c6-afc1-525402dce9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-72f821f4-89f6-470c-95a1-0a0f263ea2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-cf024faa-b00e-43f5-a5e7-8874083f6ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-bb454ba5-ab4a-470f-97cd-2a4b7834f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-d35cb058-9853-46d1-954d-c352f1a14e28,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-1ad8a72d-b382-4520-8ffe-4ca994af15aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482167036-172.17.0.11-1597133358519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33047,DS-95bb0a84-76fd-40d2-9b30-fbb12dadb72e,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-149cb744-25e7-41ea-8cb0-5545ad7bb708,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-ac753d3c-d98a-4d6b-a49a-d999ed7f10ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-d65ca4ea-04ca-4356-ae78-bcba8e62011a,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-fc77e5ea-0e7e-42dc-84fc-a7c52c7a7a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-3039b0d8-bc4f-4ee2-b256-cf95fa21b909,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-a5ef488d-1e6a-48fa-ab44-a50dc749789c,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-9d972c7a-791f-4ee0-8139-f1113e17ff19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482167036-172.17.0.11-1597133358519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33047,DS-95bb0a84-76fd-40d2-9b30-fbb12dadb72e,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-149cb744-25e7-41ea-8cb0-5545ad7bb708,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-ac753d3c-d98a-4d6b-a49a-d999ed7f10ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-d65ca4ea-04ca-4356-ae78-bcba8e62011a,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-fc77e5ea-0e7e-42dc-84fc-a7c52c7a7a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-3039b0d8-bc4f-4ee2-b256-cf95fa21b909,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-a5ef488d-1e6a-48fa-ab44-a50dc749789c,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-9d972c7a-791f-4ee0-8139-f1113e17ff19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458453637-172.17.0.11-1597133732860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-5f8abd0b-b332-4a9f-9573-a67668b8127f,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-2be7da07-568e-4069-bcb6-7bc618a37c00,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-db6fa7d7-02c3-43a6-bf86-d72ff54012b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-8e062785-1874-4014-a3b8-aa848ed30ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-ada81e2d-a46a-4374-bfd9-fd3cc03819ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-e35ce172-b00f-4d57-819a-dd7651082ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-210539d6-5dda-4ff2-9bf7-49fd0f3a2c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-4ebd3367-642c-40e1-b4f1-505750320f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458453637-172.17.0.11-1597133732860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-5f8abd0b-b332-4a9f-9573-a67668b8127f,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-2be7da07-568e-4069-bcb6-7bc618a37c00,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-db6fa7d7-02c3-43a6-bf86-d72ff54012b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-8e062785-1874-4014-a3b8-aa848ed30ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-ada81e2d-a46a-4374-bfd9-fd3cc03819ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-e35ce172-b00f-4d57-819a-dd7651082ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-210539d6-5dda-4ff2-9bf7-49fd0f3a2c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-4ebd3367-642c-40e1-b4f1-505750320f88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902661010-172.17.0.11-1597133882753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-83db5d5a-5938-483d-93db-0a75f4b13d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-19b2d575-56fd-4d3b-8822-fc8f5eda1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-5349fcda-10b3-499b-bbc3-eb19ed0584df,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-889c784a-3d83-40f7-954a-d72c838dbe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-eee6a80c-c4e6-4420-826c-0bc4b6f5cd54,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-33a0b4cb-4429-4653-bd01-496716c27efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-7f2dcaa2-e58d-40d9-a92b-83edac7aaab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-ddba33cb-9337-441c-b4ba-d8bfe9791f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902661010-172.17.0.11-1597133882753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-83db5d5a-5938-483d-93db-0a75f4b13d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-19b2d575-56fd-4d3b-8822-fc8f5eda1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-5349fcda-10b3-499b-bbc3-eb19ed0584df,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-889c784a-3d83-40f7-954a-d72c838dbe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-eee6a80c-c4e6-4420-826c-0bc4b6f5cd54,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-33a0b4cb-4429-4653-bd01-496716c27efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-7f2dcaa2-e58d-40d9-a92b-83edac7aaab9,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-ddba33cb-9337-441c-b4ba-d8bfe9791f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068256354-172.17.0.11-1597134001547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-7cc35efe-402a-497a-93d8-ac0701090aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-55531ebf-2fa6-4dac-827a-737d16d38f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-0ec82d47-e66a-46ec-a507-2bc0a1af3582,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-c90961fa-fa8f-4dec-bf4d-3da85d7eabc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-24d16255-e0d6-49a2-957a-5a2a362763fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-73b4f123-94eb-4e79-9414-7362d7bd6601,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-3b3c4578-0dd6-4fa9-b3ba-41b9c15b9cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-c4dea533-1fa7-46f5-8b94-327d39d20b56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2068256354-172.17.0.11-1597134001547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-7cc35efe-402a-497a-93d8-ac0701090aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-55531ebf-2fa6-4dac-827a-737d16d38f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-0ec82d47-e66a-46ec-a507-2bc0a1af3582,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-c90961fa-fa8f-4dec-bf4d-3da85d7eabc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-24d16255-e0d6-49a2-957a-5a2a362763fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-73b4f123-94eb-4e79-9414-7362d7bd6601,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-3b3c4578-0dd6-4fa9-b3ba-41b9c15b9cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-c4dea533-1fa7-46f5-8b94-327d39d20b56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786977580-172.17.0.11-1597134068458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42333,DS-cd3fb4b3-2525-45db-aa25-59de6caeb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-c4dedbed-783f-4729-8aa2-a868f0457858,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-96d23d86-ff3f-4adb-a664-e985c9c60893,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-aa2c8bcc-3577-4817-be7a-d3f6344027ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-494f62b6-4572-4aa6-ab42-01f55aa0c035,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-be905297-e04e-451b-ad60-0471e816cc75,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-ec1e6454-4a37-4ada-8981-b160e8b68641,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-2964ae2e-9524-4e9d-855e-49e7dc4d7cc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786977580-172.17.0.11-1597134068458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42333,DS-cd3fb4b3-2525-45db-aa25-59de6caeb5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-c4dedbed-783f-4729-8aa2-a868f0457858,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-96d23d86-ff3f-4adb-a664-e985c9c60893,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-aa2c8bcc-3577-4817-be7a-d3f6344027ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-494f62b6-4572-4aa6-ab42-01f55aa0c035,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-be905297-e04e-451b-ad60-0471e816cc75,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-ec1e6454-4a37-4ada-8981-b160e8b68641,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-2964ae2e-9524-4e9d-855e-49e7dc4d7cc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752104522-172.17.0.11-1597134174607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39554,DS-f02d099d-5a61-450c-9675-34eceaadee13,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-04632a69-c7b5-412d-ba96-57e578cf394b,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-7c6c2890-ffb7-463d-ac08-605ea6bb6b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-4d5b3ecc-b70c-4138-89cc-d09eca01416a,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-54c5f57a-b16b-43eb-9ac1-fbd17f960bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-2988af2e-18d9-4b8f-bd40-5423a1102f66,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-a570ccfe-02e6-4616-b0d9-5231b524893c,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-fd2fb6b9-0fb2-412f-91d9-b8b843fceefa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1752104522-172.17.0.11-1597134174607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39554,DS-f02d099d-5a61-450c-9675-34eceaadee13,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-04632a69-c7b5-412d-ba96-57e578cf394b,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-7c6c2890-ffb7-463d-ac08-605ea6bb6b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-4d5b3ecc-b70c-4138-89cc-d09eca01416a,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-54c5f57a-b16b-43eb-9ac1-fbd17f960bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-2988af2e-18d9-4b8f-bd40-5423a1102f66,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-a570ccfe-02e6-4616-b0d9-5231b524893c,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-fd2fb6b9-0fb2-412f-91d9-b8b843fceefa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559694378-172.17.0.11-1597134319774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-ed976e36-74dc-4891-84fe-650d5964e2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-f0df0912-7cac-42a2-9722-9005b09202c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-81340f1f-dbe7-4b11-b20b-40fc5a0e88b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-05c15f5a-e5e1-45ac-bffb-b8628d3265b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-64e6436c-893e-467e-8b02-eef3c0d8453f,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-6318719d-68b9-4ac3-8db9-5c22af3c4e30,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-11a07ab2-4108-44ad-9127-80420d93d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-c5080821-dfd4-461e-a4f4-579288135513,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559694378-172.17.0.11-1597134319774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35187,DS-ed976e36-74dc-4891-84fe-650d5964e2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-f0df0912-7cac-42a2-9722-9005b09202c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-81340f1f-dbe7-4b11-b20b-40fc5a0e88b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-05c15f5a-e5e1-45ac-bffb-b8628d3265b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34622,DS-64e6436c-893e-467e-8b02-eef3c0d8453f,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-6318719d-68b9-4ac3-8db9-5c22af3c4e30,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-11a07ab2-4108-44ad-9127-80420d93d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-c5080821-dfd4-461e-a4f4-579288135513,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370228741-172.17.0.11-1597134392750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36715,DS-e282b3d2-44ad-44bc-ba5b-bd61a71a272c,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-93aca41d-7264-4ae7-ac9e-373fac4d4ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-712c7610-6db6-4cd3-9fab-26201736ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-289a6105-a948-48e1-bfff-1b7f9a3c211f,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-a212cfe2-a380-4424-b2ec-8abeee6855e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-71a65c0f-ac41-4571-89cf-2ca30765b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-8abe8143-29a3-4413-9c1b-e848f6708d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-f2112ae8-5cf9-47a2-8acf-f38d514e03b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-370228741-172.17.0.11-1597134392750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36715,DS-e282b3d2-44ad-44bc-ba5b-bd61a71a272c,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-93aca41d-7264-4ae7-ac9e-373fac4d4ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-712c7610-6db6-4cd3-9fab-26201736ddbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-289a6105-a948-48e1-bfff-1b7f9a3c211f,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-a212cfe2-a380-4424-b2ec-8abeee6855e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-71a65c0f-ac41-4571-89cf-2ca30765b41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-8abe8143-29a3-4413-9c1b-e848f6708d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-f2112ae8-5cf9-47a2-8acf-f38d514e03b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127584532-172.17.0.11-1597134456569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-f423901d-72ee-4a4c-ba0d-ab1f1025bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-d61e160c-1b32-4a2f-a5bb-f65ee82c9038,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-f8eca7fe-b5ae-486d-af64-ffc8c8032919,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-dfd52081-14a8-419f-8053-b0ce91dc0bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-6e5f3352-b142-4c65-aeb6-5dce6e4c1b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-fe386aa5-7f9b-4100-8816-97d498d561bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-3b15f7ba-5e14-434e-870d-49b52118ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-00fa337c-f64b-40a1-aefc-d7630597277d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-127584532-172.17.0.11-1597134456569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46132,DS-f423901d-72ee-4a4c-ba0d-ab1f1025bf54,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-d61e160c-1b32-4a2f-a5bb-f65ee82c9038,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-f8eca7fe-b5ae-486d-af64-ffc8c8032919,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-dfd52081-14a8-419f-8053-b0ce91dc0bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-6e5f3352-b142-4c65-aeb6-5dce6e4c1b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-fe386aa5-7f9b-4100-8816-97d498d561bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-3b15f7ba-5e14-434e-870d-49b52118ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-00fa337c-f64b-40a1-aefc-d7630597277d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5382
