reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870859718-172.17.0.20-1597197674301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36346,DS-beb0b4b5-adb5-45a0-98f6-267d75989843,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-bde09076-1e67-4872-80d2-daff202715c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-22905250-9b6d-4fe0-98bc-23a4967ba2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-fb1f44cb-f665-4b64-8c7b-ee815ddbf078,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-4cb94311-57c7-4499-a2dd-a5b967a6ebad,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-652bb356-cd30-4edb-a8aa-92fc01807fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-cc7bdb91-9e32-4db1-9d42-8086b333e16e,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-5a077089-6574-4639-a890-2c94578fa38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870859718-172.17.0.20-1597197674301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36346,DS-beb0b4b5-adb5-45a0-98f6-267d75989843,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-bde09076-1e67-4872-80d2-daff202715c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-22905250-9b6d-4fe0-98bc-23a4967ba2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-fb1f44cb-f665-4b64-8c7b-ee815ddbf078,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-4cb94311-57c7-4499-a2dd-a5b967a6ebad,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-652bb356-cd30-4edb-a8aa-92fc01807fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-cc7bdb91-9e32-4db1-9d42-8086b333e16e,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-5a077089-6574-4639-a890-2c94578fa38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290178739-172.17.0.20-1597197874649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-632d8d12-c989-4767-970b-7752f50638f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-c083d5cd-2941-46d1-b448-301d1d1ca52c,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-f8d9eace-5c27-4cc6-a356-53647577b062,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-10a02ba3-6a11-4c88-aa9e-38dc07dac595,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-2983e565-6588-401c-82bd-3023237edd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-d39a318a-4b65-40ac-8f48-ff1f7673da0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-90eeee49-c0e4-4f98-878a-ca5d1dcbedb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-148ca216-e39a-4a19-a211-929bc4228968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290178739-172.17.0.20-1597197874649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-632d8d12-c989-4767-970b-7752f50638f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-c083d5cd-2941-46d1-b448-301d1d1ca52c,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-f8d9eace-5c27-4cc6-a356-53647577b062,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-10a02ba3-6a11-4c88-aa9e-38dc07dac595,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-2983e565-6588-401c-82bd-3023237edd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-d39a318a-4b65-40ac-8f48-ff1f7673da0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-90eeee49-c0e4-4f98-878a-ca5d1dcbedb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-148ca216-e39a-4a19-a211-929bc4228968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562779377-172.17.0.20-1597197944486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36449,DS-f3cddbff-ffcf-4209-9588-977fca33caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-daf70f4a-d357-4eac-a736-f10dedc1c576,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-a2c51f70-0c95-4589-92b9-f27c2e6c986a,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-bd420874-f4c3-4804-b8da-d9fa0e13bbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-89a6f1aa-193f-455c-88df-cd934a2d4a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-11279e20-eb8a-41ea-8555-096332a11b69,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-0efcaf74-043f-41bd-a37a-bdb2645c14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-5593202c-f194-4143-8de5-c69100412f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562779377-172.17.0.20-1597197944486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36449,DS-f3cddbff-ffcf-4209-9588-977fca33caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-daf70f4a-d357-4eac-a736-f10dedc1c576,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-a2c51f70-0c95-4589-92b9-f27c2e6c986a,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-bd420874-f4c3-4804-b8da-d9fa0e13bbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-89a6f1aa-193f-455c-88df-cd934a2d4a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-11279e20-eb8a-41ea-8555-096332a11b69,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-0efcaf74-043f-41bd-a37a-bdb2645c14d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-5593202c-f194-4143-8de5-c69100412f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440442446-172.17.0.20-1597198036838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-654cc0ec-1765-4428-9533-99dc374b769d,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-3c05f8ad-e345-4483-8206-ccea0aef26c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-8fad6282-51f9-46c5-8ccd-f433f84faa54,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-d7742d23-91f6-4614-adfd-6615ed0def5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-fec7f87d-bd42-47ec-a12f-46383fc37c13,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-5ee39bad-3fd5-4ca1-abc0-810a896e2fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-e6db891c-9ac8-420a-b8e9-dbdbdc072e75,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-24fc81e0-0964-440e-9b00-6ac8a9514aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440442446-172.17.0.20-1597198036838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32881,DS-654cc0ec-1765-4428-9533-99dc374b769d,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-3c05f8ad-e345-4483-8206-ccea0aef26c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-8fad6282-51f9-46c5-8ccd-f433f84faa54,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-d7742d23-91f6-4614-adfd-6615ed0def5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-fec7f87d-bd42-47ec-a12f-46383fc37c13,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-5ee39bad-3fd5-4ca1-abc0-810a896e2fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-e6db891c-9ac8-420a-b8e9-dbdbdc072e75,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-24fc81e0-0964-440e-9b00-6ac8a9514aad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716440915-172.17.0.20-1597198639759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36936,DS-85edb2e2-5076-49aa-b49d-627a7c65027c,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-b15f21a4-5c88-4432-a8cb-4adc51eff4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-cf0b213c-9362-4102-8519-3ebed1b4a365,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-2458fbe6-6928-4e79-8a62-27efbe2e5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-1d9f126d-e880-40a4-9bcc-a5ee0e6a5603,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-932639c6-ae3d-468c-813d-4adb06419f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-e7061db3-44c3-4983-8ac6-57fd30e43f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-9bc8d58a-a256-45d6-97c0-91e148b1f0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716440915-172.17.0.20-1597198639759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36936,DS-85edb2e2-5076-49aa-b49d-627a7c65027c,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-b15f21a4-5c88-4432-a8cb-4adc51eff4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-cf0b213c-9362-4102-8519-3ebed1b4a365,DISK], DatanodeInfoWithStorage[127.0.0.1:40854,DS-2458fbe6-6928-4e79-8a62-27efbe2e5fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-1d9f126d-e880-40a4-9bcc-a5ee0e6a5603,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-932639c6-ae3d-468c-813d-4adb06419f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-e7061db3-44c3-4983-8ac6-57fd30e43f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-9bc8d58a-a256-45d6-97c0-91e148b1f0ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455087695-172.17.0.20-1597198954712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36276,DS-53176f70-6242-481f-9cd2-2c175f63a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-cce96bc6-c884-4a4b-87cc-aa345b163c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-5cc8a5a6-4ad6-4ac2-aedc-93aa877e72aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-7f527b06-a346-40e2-aa70-ed7cdab77082,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-a65fe015-b4fa-4229-b70d-a370a1731cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-7ea125fe-56d1-4187-b723-629e49e49f98,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-186a4731-2601-46c4-ba70-321228959d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-2335dce4-2aa9-4979-b5a8-ce6e35f5f4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455087695-172.17.0.20-1597198954712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36276,DS-53176f70-6242-481f-9cd2-2c175f63a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-cce96bc6-c884-4a4b-87cc-aa345b163c98,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-5cc8a5a6-4ad6-4ac2-aedc-93aa877e72aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-7f527b06-a346-40e2-aa70-ed7cdab77082,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-a65fe015-b4fa-4229-b70d-a370a1731cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-7ea125fe-56d1-4187-b723-629e49e49f98,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-186a4731-2601-46c4-ba70-321228959d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-2335dce4-2aa9-4979-b5a8-ce6e35f5f4c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972110857-172.17.0.20-1597199422830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37015,DS-8e06a2af-394c-4b7e-9cec-07f0c738fbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-1401d90c-5cda-4771-a877-3dfa6f446e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-c46fbaff-e171-4a22-9931-3429a4047e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-70f987cc-68c9-4daf-800c-bcb4fd8204f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-9550232d-133a-42f1-bcdb-310ba1038dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-b02eb392-99ef-49b2-94c9-240e30886792,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-dcaeec34-1866-4e75-8482-091775f64f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-eb510b45-11e5-41e4-8c95-9607ddd9a1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-972110857-172.17.0.20-1597199422830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37015,DS-8e06a2af-394c-4b7e-9cec-07f0c738fbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40241,DS-1401d90c-5cda-4771-a877-3dfa6f446e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-c46fbaff-e171-4a22-9931-3429a4047e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-70f987cc-68c9-4daf-800c-bcb4fd8204f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-9550232d-133a-42f1-bcdb-310ba1038dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-b02eb392-99ef-49b2-94c9-240e30886792,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-dcaeec34-1866-4e75-8482-091775f64f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-eb510b45-11e5-41e4-8c95-9607ddd9a1ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508862720-172.17.0.20-1597199742180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40501,DS-f0e29e2d-a6fe-463c-8611-5992f0c97066,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-b2769d18-3640-4166-b1e2-ee0ebbba6655,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-92447049-d68f-443a-b6b9-8cdce4b2af98,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-9063b1ba-acf4-41c5-8f7d-b07662d1d14b,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-8f7dbc51-4ff4-4451-b188-831e8701910a,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-9060b85b-ba99-46ae-bdd3-8800d336e137,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-9df18285-fc77-4aad-b283-1c2344deacf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-3d09900f-3f21-4b38-9e2b-7c35836a4825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508862720-172.17.0.20-1597199742180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40501,DS-f0e29e2d-a6fe-463c-8611-5992f0c97066,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-b2769d18-3640-4166-b1e2-ee0ebbba6655,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-92447049-d68f-443a-b6b9-8cdce4b2af98,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-9063b1ba-acf4-41c5-8f7d-b07662d1d14b,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-8f7dbc51-4ff4-4451-b188-831e8701910a,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-9060b85b-ba99-46ae-bdd3-8800d336e137,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-9df18285-fc77-4aad-b283-1c2344deacf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-3d09900f-3f21-4b38-9e2b-7c35836a4825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350382378-172.17.0.20-1597200015974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42112,DS-57834319-cf9c-41c9-bc52-c9b6cb4a3cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-6cbc6381-9b73-41b3-af64-c4ae096573d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-f1837f18-99e8-47f1-a3f9-fc3f08229547,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-56e90107-9b1f-47ed-9d39-fa1b912adf32,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-8fb9d7ef-5993-4344-ac86-0242d261a5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-e27eaba9-37e1-4ac6-90ed-a2c4cf7525b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-52627630-0df7-4cc4-b662-1629562f24ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-7a5893e4-dc82-419b-9ce6-368ed2a6909f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350382378-172.17.0.20-1597200015974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42112,DS-57834319-cf9c-41c9-bc52-c9b6cb4a3cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-6cbc6381-9b73-41b3-af64-c4ae096573d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-f1837f18-99e8-47f1-a3f9-fc3f08229547,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-56e90107-9b1f-47ed-9d39-fa1b912adf32,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-8fb9d7ef-5993-4344-ac86-0242d261a5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-e27eaba9-37e1-4ac6-90ed-a2c4cf7525b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-52627630-0df7-4cc4-b662-1629562f24ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37076,DS-7a5893e4-dc82-419b-9ce6-368ed2a6909f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744709767-172.17.0.20-1597200929823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-736879d3-eeb8-42d0-b756-5b94ba9a10ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-ff1917c6-aa7b-4f29-aa4f-8ddf2e6b70dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-4de7556a-c338-403e-8a65-2129b1ec996c,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-acd6f808-8f96-4d97-9ca3-d0e869a1106c,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-10a69dcb-2273-4b12-9893-6e6876b808ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-08332eb3-ff4a-4e58-8798-cc956ad8f2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-b7f598ef-d561-463f-9d35-1489a4421121,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-d2c65e39-2717-45ab-8908-de4ea950d12a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744709767-172.17.0.20-1597200929823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-736879d3-eeb8-42d0-b756-5b94ba9a10ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-ff1917c6-aa7b-4f29-aa4f-8ddf2e6b70dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-4de7556a-c338-403e-8a65-2129b1ec996c,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-acd6f808-8f96-4d97-9ca3-d0e869a1106c,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-10a69dcb-2273-4b12-9893-6e6876b808ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-08332eb3-ff4a-4e58-8798-cc956ad8f2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-b7f598ef-d561-463f-9d35-1489a4421121,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-d2c65e39-2717-45ab-8908-de4ea950d12a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172918502-172.17.0.20-1597201097115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-c08af0f5-79d3-4098-8664-1a0c660127bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-b7d1c0f2-767f-46a8-9059-4dac9a7dba79,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-ff21f5cd-f671-47e5-a780-d9b204eb44e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-5e54ed49-66dc-4127-8b05-7d70ee44a173,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-c0ee41b9-b955-46af-921f-64e5a24d1ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-d649de2a-7672-4514-ada3-87c9e7567f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-26d65a5f-64bc-4739-96eb-62802ed161bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-b39ba538-4d66-4ece-9c9b-bb357dac629a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172918502-172.17.0.20-1597201097115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39081,DS-c08af0f5-79d3-4098-8664-1a0c660127bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-b7d1c0f2-767f-46a8-9059-4dac9a7dba79,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-ff21f5cd-f671-47e5-a780-d9b204eb44e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-5e54ed49-66dc-4127-8b05-7d70ee44a173,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-c0ee41b9-b955-46af-921f-64e5a24d1ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-d649de2a-7672-4514-ada3-87c9e7567f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38828,DS-26d65a5f-64bc-4739-96eb-62802ed161bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-b39ba538-4d66-4ece-9c9b-bb357dac629a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926972527-172.17.0.20-1597201398338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-dda823c1-31d2-4850-a845-1d01ef54dacc,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-a01efca2-27a9-4990-a8dd-ec7090d06464,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-31ff5ed8-85d2-4e54-838b-85cc5537ed41,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-8e0c2cc1-a43c-4afb-b3fc-0b2b56caf0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-421e91a7-c75b-43f2-9bc7-a52cca3ff9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-83262767-7f26-41df-af92-85c122959841,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-d41cdbcf-578b-4e8f-a601-22a983d1e561,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-cd82ab9e-ddf6-4e6c-a671-28ed5e600d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926972527-172.17.0.20-1597201398338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33263,DS-dda823c1-31d2-4850-a845-1d01ef54dacc,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-a01efca2-27a9-4990-a8dd-ec7090d06464,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-31ff5ed8-85d2-4e54-838b-85cc5537ed41,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-8e0c2cc1-a43c-4afb-b3fc-0b2b56caf0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-421e91a7-c75b-43f2-9bc7-a52cca3ff9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-83262767-7f26-41df-af92-85c122959841,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-d41cdbcf-578b-4e8f-a601-22a983d1e561,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-cd82ab9e-ddf6-4e6c-a671-28ed5e600d3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403729959-172.17.0.20-1597201498847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-13352e58-c2a3-4e0c-b5e8-e894dd8474b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-d1e098a0-b093-49e8-a401-9a07d836ec47,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-03ffe762-13ed-4ebe-9f31-a580dfe0677b,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-d0bff42a-92c4-4eb5-aea9-0143424a765b,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-fcf932c5-6990-4cda-87c5-11edb69ba56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-c37fd881-145e-4f71-9acc-d58e6faf3f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-4dff8642-8675-4272-a932-88a3c3f90140,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-237fa0e5-3656-430a-a61e-fb644f7d9944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403729959-172.17.0.20-1597201498847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-13352e58-c2a3-4e0c-b5e8-e894dd8474b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-d1e098a0-b093-49e8-a401-9a07d836ec47,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-03ffe762-13ed-4ebe-9f31-a580dfe0677b,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-d0bff42a-92c4-4eb5-aea9-0143424a765b,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-fcf932c5-6990-4cda-87c5-11edb69ba56f,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-c37fd881-145e-4f71-9acc-d58e6faf3f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-4dff8642-8675-4272-a932-88a3c3f90140,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-237fa0e5-3656-430a-a61e-fb644f7d9944,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504487767-172.17.0.20-1597201633000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45652,DS-5c0f06df-5ca5-49e2-8172-7951f019fa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-9bc08604-0499-4aa1-b965-10c7ccf5af82,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-88b2444b-2d39-4561-a1fe-0ae981340d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-becd76a0-796e-4e6b-84af-24fa274df4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-0f63f5f2-a809-476d-a78f-9cf2b43909d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-26803831-2d22-4513-a127-4f63d3872802,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-65807eb3-e57a-41b5-a3c7-8c53a33f353e,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-f632c52f-e3fa-4976-8787-a134348ce49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504487767-172.17.0.20-1597201633000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45652,DS-5c0f06df-5ca5-49e2-8172-7951f019fa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-9bc08604-0499-4aa1-b965-10c7ccf5af82,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-88b2444b-2d39-4561-a1fe-0ae981340d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-becd76a0-796e-4e6b-84af-24fa274df4da,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-0f63f5f2-a809-476d-a78f-9cf2b43909d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-26803831-2d22-4513-a127-4f63d3872802,DISK], DatanodeInfoWithStorage[127.0.0.1:39655,DS-65807eb3-e57a-41b5-a3c7-8c53a33f353e,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-f632c52f-e3fa-4976-8787-a134348ce49b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.transfer.threads
component: hdfs:DataNode
v1: 8192
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124261639-172.17.0.20-1597202225432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-d2910b30-4a1e-409c-881f-97dcdde06114,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-b73dece8-6a07-4f97-b7c9-a4ee039592e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-6f50a2e6-3771-4975-b9aa-d333918f6629,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-96febe17-2f65-4f3a-8456-8310b3214f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-211d489d-5e5f-4732-be0a-3c226be921c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-0daa43b7-5e73-4c74-a048-aa4d8b37bbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-3701b2f1-dac7-43c1-9ca2-adce6bbe8877,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-a81fdffc-361e-4e81-9af0-97374e3ecd61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124261639-172.17.0.20-1597202225432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34386,DS-d2910b30-4a1e-409c-881f-97dcdde06114,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-b73dece8-6a07-4f97-b7c9-a4ee039592e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-6f50a2e6-3771-4975-b9aa-d333918f6629,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-96febe17-2f65-4f3a-8456-8310b3214f59,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-211d489d-5e5f-4732-be0a-3c226be921c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-0daa43b7-5e73-4c74-a048-aa4d8b37bbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-3701b2f1-dac7-43c1-9ca2-adce6bbe8877,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-a81fdffc-361e-4e81-9af0-97374e3ecd61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5088
