reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288050479-172.17.0.8-1597138906319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33272,DS-39079d6a-cea2-4463-899d-7680a9a16227,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-c689af2e-1fd5-4399-9d11-f5c069d3221f,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-4cacb0b5-e4ca-4214-86e3-cc140d457bed,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-2e6dee4d-db64-4f51-b095-342cee2227a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-b92f3e60-697a-4474-80ee-9f29b01fc7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-792e5259-7a2a-45aa-bd76-f7a4f4607f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-8032aa61-2916-4184-b48f-620a33d3697d,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-10335015-1519-452d-ab31-d0997d2e9446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288050479-172.17.0.8-1597138906319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33272,DS-39079d6a-cea2-4463-899d-7680a9a16227,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-c689af2e-1fd5-4399-9d11-f5c069d3221f,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-4cacb0b5-e4ca-4214-86e3-cc140d457bed,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-2e6dee4d-db64-4f51-b095-342cee2227a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-b92f3e60-697a-4474-80ee-9f29b01fc7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-792e5259-7a2a-45aa-bd76-f7a4f4607f60,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-8032aa61-2916-4184-b48f-620a33d3697d,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-10335015-1519-452d-ab31-d0997d2e9446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215369309-172.17.0.8-1597139069911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-727abf71-5233-4510-9752-b08a6db8fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-a4718325-6d34-47ab-a0b3-8dde85f09422,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-05ece714-7a57-4752-8c11-25e74c10ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-6f4e9083-34d6-4776-a3d8-6f287e86f196,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-2b2be58b-d573-417c-9d0a-983e092c9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-0b9a57d1-8746-4424-94f6-817c42ace046,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-4821c516-70f3-439b-a959-0df79093c018,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-acd7f160-8d13-4c7c-8147-9c0cfd87ca49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215369309-172.17.0.8-1597139069911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-727abf71-5233-4510-9752-b08a6db8fc16,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-a4718325-6d34-47ab-a0b3-8dde85f09422,DISK], DatanodeInfoWithStorage[127.0.0.1:37711,DS-05ece714-7a57-4752-8c11-25e74c10ea23,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-6f4e9083-34d6-4776-a3d8-6f287e86f196,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-2b2be58b-d573-417c-9d0a-983e092c9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39567,DS-0b9a57d1-8746-4424-94f6-817c42ace046,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-4821c516-70f3-439b-a959-0df79093c018,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-acd7f160-8d13-4c7c-8147-9c0cfd87ca49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081312205-172.17.0.8-1597139376037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37752,DS-0e7835c7-3f1e-4133-93f9-8ef7876b09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-f2eebe0b-cd96-46a5-8066-0a4bfd475718,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-a7b8577b-b71c-4cc0-90c5-862549e4858a,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-09d70c74-2c9e-4ab1-a409-c7b208f53792,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-328bfe64-4d7c-45ed-9cce-d5dca5802852,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-52950f29-0d7e-414f-906b-c24809cf64df,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-41ef9b79-ce7a-4c18-9af0-0165ba5ebb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-bc65b31b-5a12-456f-95eb-a12d1623284f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081312205-172.17.0.8-1597139376037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37752,DS-0e7835c7-3f1e-4133-93f9-8ef7876b09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-f2eebe0b-cd96-46a5-8066-0a4bfd475718,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-a7b8577b-b71c-4cc0-90c5-862549e4858a,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-09d70c74-2c9e-4ab1-a409-c7b208f53792,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-328bfe64-4d7c-45ed-9cce-d5dca5802852,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-52950f29-0d7e-414f-906b-c24809cf64df,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-41ef9b79-ce7a-4c18-9af0-0165ba5ebb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-bc65b31b-5a12-456f-95eb-a12d1623284f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513597509-172.17.0.8-1597139531828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33260,DS-efbbb175-40e4-417e-9a0e-95b007cf57e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-2411debc-438f-45e5-9cec-23deb29655b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-5a9fbfc1-e2a6-4ed0-b558-3860a43f90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-258cce1e-4227-4523-86b9-b8c311ad4c60,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-605ff3df-fbdf-4029-b1aa-2fbfa669d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-9fc8224c-a999-462f-9625-5d6b5eb96f61,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-24d9b1f7-c465-49b6-bd26-ed42037f5f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-b952cc73-3947-42bb-b2a0-1a47d81160ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513597509-172.17.0.8-1597139531828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33260,DS-efbbb175-40e4-417e-9a0e-95b007cf57e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-2411debc-438f-45e5-9cec-23deb29655b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-5a9fbfc1-e2a6-4ed0-b558-3860a43f90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-258cce1e-4227-4523-86b9-b8c311ad4c60,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-605ff3df-fbdf-4029-b1aa-2fbfa669d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-9fc8224c-a999-462f-9625-5d6b5eb96f61,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-24d9b1f7-c465-49b6-bd26-ed42037f5f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-b952cc73-3947-42bb-b2a0-1a47d81160ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396703684-172.17.0.8-1597139924376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36145,DS-0ffb996f-69a8-46f1-b946-74b000831a67,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-bc258c12-fd3d-4405-a2a5-aa2600b3c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-5e8ad5c7-65c5-4a96-8d19-3e44b6d08db0,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-d0c8561b-7bea-448b-93a8-d3406cf207e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-cbe6b1a0-86d7-4ee1-b793-31d5faf3a234,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-31b38bcd-54d5-4f2c-a459-11b4820945bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-4010f8d5-8c20-4d66-8c06-fd4fd654536d,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-f5fd315f-096d-4c03-830f-09c57a369699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1396703684-172.17.0.8-1597139924376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36145,DS-0ffb996f-69a8-46f1-b946-74b000831a67,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-bc258c12-fd3d-4405-a2a5-aa2600b3c12b,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-5e8ad5c7-65c5-4a96-8d19-3e44b6d08db0,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-d0c8561b-7bea-448b-93a8-d3406cf207e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-cbe6b1a0-86d7-4ee1-b793-31d5faf3a234,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-31b38bcd-54d5-4f2c-a459-11b4820945bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-4010f8d5-8c20-4d66-8c06-fd4fd654536d,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-f5fd315f-096d-4c03-830f-09c57a369699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116963127-172.17.0.8-1597139989570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-eaaf0a66-73e6-44a4-aea2-db111f5d829a,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e8a6ec29-2cce-4f13-b7bf-f439b52ee200,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-632ffe28-8d3a-4e9b-9999-308aebb274ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-003eb8d1-a77a-4aec-b550-86ed1b424396,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-650feec7-4e23-4877-a68e-cf62d426b6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-fa200fcc-1e6f-4c25-9b6a-203ea5de96ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-b515a564-f150-421a-96b9-4072de87e54f,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-48e9ea40-393d-4161-9b3a-d1a1b5ce935e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116963127-172.17.0.8-1597139989570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38349,DS-eaaf0a66-73e6-44a4-aea2-db111f5d829a,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e8a6ec29-2cce-4f13-b7bf-f439b52ee200,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-632ffe28-8d3a-4e9b-9999-308aebb274ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-003eb8d1-a77a-4aec-b550-86ed1b424396,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-650feec7-4e23-4877-a68e-cf62d426b6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-fa200fcc-1e6f-4c25-9b6a-203ea5de96ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-b515a564-f150-421a-96b9-4072de87e54f,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-48e9ea40-393d-4161-9b3a-d1a1b5ce935e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385323254-172.17.0.8-1597140048681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44398,DS-e2150734-f9d9-4d31-a16c-d22b5282e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-7f9d48a3-2e74-4252-9aaf-77d124cb489e,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-8e5e12b5-83cd-494f-b135-5b520ad21a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-1ae96886-50f9-42e1-85aa-dddf492cce62,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-83b31153-3c2d-4121-8a48-8b2061fa9aab,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-19e7b774-c751-4fbf-8943-469831c1275d,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-b6cf1464-ed50-4f68-bc64-e59d213f6a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-345ad83f-49ef-43b8-a3dd-29324e64d0ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385323254-172.17.0.8-1597140048681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44398,DS-e2150734-f9d9-4d31-a16c-d22b5282e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34875,DS-7f9d48a3-2e74-4252-9aaf-77d124cb489e,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-8e5e12b5-83cd-494f-b135-5b520ad21a26,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-1ae96886-50f9-42e1-85aa-dddf492cce62,DISK], DatanodeInfoWithStorage[127.0.0.1:39038,DS-83b31153-3c2d-4121-8a48-8b2061fa9aab,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-19e7b774-c751-4fbf-8943-469831c1275d,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-b6cf1464-ed50-4f68-bc64-e59d213f6a52,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-345ad83f-49ef-43b8-a3dd-29324e64d0ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632449327-172.17.0.8-1597140454647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-b5b76736-78d5-4d56-a143-ecfa93e1efcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-d87ff0bc-cf0f-4489-9c91-e01c6c21383d,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-295d6bd8-bbe0-4d07-8fa5-417f5b8ea703,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-ca78b395-c0cd-4178-9758-8e7f55325245,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-f359289b-c109-43d6-99f3-cd40c09c56ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-b92d3cee-6b6d-4c6c-b42e-d728a6939d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-90060442-e536-438c-8a79-ab5c20d706b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-131f826e-0938-491c-96fa-22f7bb738bf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-632449327-172.17.0.8-1597140454647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-b5b76736-78d5-4d56-a143-ecfa93e1efcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-d87ff0bc-cf0f-4489-9c91-e01c6c21383d,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-295d6bd8-bbe0-4d07-8fa5-417f5b8ea703,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-ca78b395-c0cd-4178-9758-8e7f55325245,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-f359289b-c109-43d6-99f3-cd40c09c56ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-b92d3cee-6b6d-4c6c-b42e-d728a6939d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-90060442-e536-438c-8a79-ab5c20d706b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-131f826e-0938-491c-96fa-22f7bb738bf0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158812961-172.17.0.8-1597140514633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-8c973e2f-f050-4985-a6d9-1c0595256c02,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-fff6f7e1-2cf9-4c94-b74c-599fa9fd145c,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-86ff12d0-5d17-4517-9796-2824655b8475,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-497afa66-581a-4931-beb9-9c11502ba520,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-11929913-4a66-4632-b361-039c0529f154,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-c3a3b261-d166-4864-b0cc-ffac1208cbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-c52ae709-de74-4c9e-a608-63761875eb62,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-f8696ef4-5e38-41d7-82ed-4eb2da281638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158812961-172.17.0.8-1597140514633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37979,DS-8c973e2f-f050-4985-a6d9-1c0595256c02,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-fff6f7e1-2cf9-4c94-b74c-599fa9fd145c,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-86ff12d0-5d17-4517-9796-2824655b8475,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-497afa66-581a-4931-beb9-9c11502ba520,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-11929913-4a66-4632-b361-039c0529f154,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-c3a3b261-d166-4864-b0cc-ffac1208cbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-c52ae709-de74-4c9e-a608-63761875eb62,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-f8696ef4-5e38-41d7-82ed-4eb2da281638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570927087-172.17.0.8-1597140714522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36561,DS-fb55d791-0e59-48ba-aa75-e9a4033d9124,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-a2a27a48-d06b-42fb-9065-3ef50dd8c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-efaac2b5-addb-4411-a17f-69aad0ba6763,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-389b8a91-f20a-4c4d-903d-af8101c66159,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-81263542-5915-4f44-a341-407d66a2631d,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-426fe945-8da6-4bf0-9981-fc86ac56a39d,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-409b10cf-c0c6-4646-be25-bb7bef37f285,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-932c0cec-4546-44b3-9a3e-53ccbd51033d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-570927087-172.17.0.8-1597140714522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36561,DS-fb55d791-0e59-48ba-aa75-e9a4033d9124,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-a2a27a48-d06b-42fb-9065-3ef50dd8c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-efaac2b5-addb-4411-a17f-69aad0ba6763,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-389b8a91-f20a-4c4d-903d-af8101c66159,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-81263542-5915-4f44-a341-407d66a2631d,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-426fe945-8da6-4bf0-9981-fc86ac56a39d,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-409b10cf-c0c6-4646-be25-bb7bef37f285,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-932c0cec-4546-44b3-9a3e-53ccbd51033d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948364382-172.17.0.8-1597140814624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36603,DS-b7e82406-4723-42fb-b012-b0435e286a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-61dacd20-0103-4466-ae37-b03dd11e5515,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-2919e9cd-1bb2-4b71-ac36-8e7c0d0a4345,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-4940b2de-01f0-4158-aca8-91df980a4b92,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-fc970c70-987e-4f60-b8c9-e8df6605e62a,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-af36f1c3-aaa0-4afc-9f03-d4867a5d3553,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-d5dd1f86-d412-4700-87fe-bf1f824558c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-b7708159-b70c-4d85-a1fe-783369edf379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948364382-172.17.0.8-1597140814624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36603,DS-b7e82406-4723-42fb-b012-b0435e286a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-61dacd20-0103-4466-ae37-b03dd11e5515,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-2919e9cd-1bb2-4b71-ac36-8e7c0d0a4345,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-4940b2de-01f0-4158-aca8-91df980a4b92,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-fc970c70-987e-4f60-b8c9-e8df6605e62a,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-af36f1c3-aaa0-4afc-9f03-d4867a5d3553,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-d5dd1f86-d412-4700-87fe-bf1f824558c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-b7708159-b70c-4d85-a1fe-783369edf379,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115496882-172.17.0.8-1597141260437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45679,DS-5ee5827d-be15-4c49-8d75-932a651fdf39,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-fb18841d-363c-46da-a44b-4b90f1c8a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-c0212480-dc14-480c-ba80-c567e9fb85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-60a39054-6cc3-4514-a8e7-266f413062e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-df270bbd-3334-4de8-a584-f337b7d179df,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-b1c009d7-2cbb-490e-8e71-72afe441dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-36388b7f-2efd-4b30-8ea6-6d59cb96c3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-83e9d7e5-0a35-485d-839a-3b5628f07b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2115496882-172.17.0.8-1597141260437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45679,DS-5ee5827d-be15-4c49-8d75-932a651fdf39,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-fb18841d-363c-46da-a44b-4b90f1c8a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-c0212480-dc14-480c-ba80-c567e9fb85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-60a39054-6cc3-4514-a8e7-266f413062e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-df270bbd-3334-4de8-a584-f337b7d179df,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-b1c009d7-2cbb-490e-8e71-72afe441dad5,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-36388b7f-2efd-4b30-8ea6-6d59cb96c3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46815,DS-83e9d7e5-0a35-485d-839a-3b5628f07b9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760975728-172.17.0.8-1597141315908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45534,DS-b939c808-a37e-4b51-ab99-21244044e689,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-0443a2aa-a6b8-4580-ab5b-d0c476cf252b,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-9835962b-ac22-4b05-9e28-b21f9c4b7d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-ccaa1486-43d4-416c-8128-d0a024808c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-0ce29f03-82e6-4ced-b4a7-3b14399e1206,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-65263b71-2e84-42de-ac98-ec0df3aa5648,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-22a345c9-cab8-4000-97d4-cff5c73091d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-5433e682-ca4e-46ec-97a3-aed9bd5f53bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1760975728-172.17.0.8-1597141315908:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45534,DS-b939c808-a37e-4b51-ab99-21244044e689,DISK], DatanodeInfoWithStorage[127.0.0.1:34562,DS-0443a2aa-a6b8-4580-ab5b-d0c476cf252b,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-9835962b-ac22-4b05-9e28-b21f9c4b7d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-ccaa1486-43d4-416c-8128-d0a024808c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45417,DS-0ce29f03-82e6-4ced-b4a7-3b14399e1206,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-65263b71-2e84-42de-ac98-ec0df3aa5648,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-22a345c9-cab8-4000-97d4-cff5c73091d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-5433e682-ca4e-46ec-97a3-aed9bd5f53bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104433510-172.17.0.8-1597141554737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-81d19353-a498-408f-ab0f-221d72dd259c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-5585ff58-c0d7-4418-ba97-e81e7d23d369,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-c5548de3-d752-41ba-9467-1d7229b2ef75,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-5c228cee-4086-4962-a9ed-d46c4713a0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-bad2c972-8ee7-4d9b-98bb-fe0e579fae99,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-0b92ce4a-7728-4a63-ba32-262e3153349f,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-89c7a594-13f0-40a6-ab02-3fd9a13561bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-85396861-c631-4dea-ac57-d5920d307433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104433510-172.17.0.8-1597141554737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46490,DS-81d19353-a498-408f-ab0f-221d72dd259c,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-5585ff58-c0d7-4418-ba97-e81e7d23d369,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-c5548de3-d752-41ba-9467-1d7229b2ef75,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-5c228cee-4086-4962-a9ed-d46c4713a0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-bad2c972-8ee7-4d9b-98bb-fe0e579fae99,DISK], DatanodeInfoWithStorage[127.0.0.1:38785,DS-0b92ce4a-7728-4a63-ba32-262e3153349f,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-89c7a594-13f0-40a6-ab02-3fd9a13561bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34416,DS-85396861-c631-4dea-ac57-d5920d307433,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953394727-172.17.0.8-1597141617921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36350,DS-9084c3d6-5477-44d1-b881-14ec5524eb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-73de841a-0d9d-41ac-80b7-69aea546f505,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-21f19b92-9414-474a-a613-e26ec9f69bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-7231ad6a-5ecf-4934-9834-bc501b32c68b,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-a0c11e8d-24fd-4989-8a8d-c838d7854db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-ea7c837d-74fc-42be-936d-fafcca1b1e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-6073620f-2d1c-4b31-84f6-7c5f47337809,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-9bfb5b45-452a-455c-ad3e-94227e010554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953394727-172.17.0.8-1597141617921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36350,DS-9084c3d6-5477-44d1-b881-14ec5524eb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-73de841a-0d9d-41ac-80b7-69aea546f505,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-21f19b92-9414-474a-a613-e26ec9f69bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-7231ad6a-5ecf-4934-9834-bc501b32c68b,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-a0c11e8d-24fd-4989-8a8d-c838d7854db7,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-ea7c837d-74fc-42be-936d-fafcca1b1e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-6073620f-2d1c-4b31-84f6-7c5f47337809,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-9bfb5b45-452a-455c-ad3e-94227e010554,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536282254-172.17.0.8-1597141903567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36902,DS-e892adf2-9bed-4ef0-b51f-4035943ab98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-d2e81e22-d83f-4384-ab2d-53fb93fdd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-8a1c23fa-1c03-404f-b33b-942650cfa5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-d3083bb0-cd02-4218-9df0-94cf0ac0072a,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-cbca5b8e-a77c-48ff-9e4f-0c5a08b624cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-bbcded3a-fb2c-4c3d-9c47-943911e7572a,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-88106d37-d5aa-419b-8956-d685cb728990,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-33915223-8c71-4f91-9097-cd2f9513876f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536282254-172.17.0.8-1597141903567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36902,DS-e892adf2-9bed-4ef0-b51f-4035943ab98a,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-d2e81e22-d83f-4384-ab2d-53fb93fdd64c,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-8a1c23fa-1c03-404f-b33b-942650cfa5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-d3083bb0-cd02-4218-9df0-94cf0ac0072a,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-cbca5b8e-a77c-48ff-9e4f-0c5a08b624cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-bbcded3a-fb2c-4c3d-9c47-943911e7572a,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-88106d37-d5aa-419b-8956-d685cb728990,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-33915223-8c71-4f91-9097-cd2f9513876f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575699979-172.17.0.8-1597141938129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-c378de6d-6b4f-49d0-a342-6167afe02487,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-a89f8eb8-a568-47b4-9c1e-928fe56bae99,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-8849f469-87a9-457d-85f2-14ee6b594818,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-c9302019-0df2-42e3-89c9-115941f64862,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-da04f5cf-1b76-4bdd-8164-836f5b05e909,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-f1ef01c2-5f71-4485-ab33-978abfc2a64b,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-4b1f3d92-64ce-4c9a-b155-82c41a371ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-838b215d-6441-42eb-8773-91e47c33bd60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575699979-172.17.0.8-1597141938129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45580,DS-c378de6d-6b4f-49d0-a342-6167afe02487,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-a89f8eb8-a568-47b4-9c1e-928fe56bae99,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-8849f469-87a9-457d-85f2-14ee6b594818,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-c9302019-0df2-42e3-89c9-115941f64862,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-da04f5cf-1b76-4bdd-8164-836f5b05e909,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-f1ef01c2-5f71-4485-ab33-978abfc2a64b,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-4b1f3d92-64ce-4c9a-b155-82c41a371ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-838b215d-6441-42eb-8773-91e47c33bd60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651084431-172.17.0.8-1597142036507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-0cfc5cd0-de98-4fc0-a31c-55ed882186f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-2aa18f7f-dd60-4fac-9955-b7d4d1dc313d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-01942604-7db4-46ee-b6a7-d1c62bbb0608,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-c225a6d9-99a7-4208-bcc8-1c0f13a964dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-a1083132-0804-4f7b-855c-e3c1ba360664,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-717141de-6806-4b35-a542-113aa90ac275,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-445325e6-4efc-4526-9e64-48b902401772,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-87be8613-49bd-4cba-9ca4-5de1a8a9bf13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-651084431-172.17.0.8-1597142036507:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37275,DS-0cfc5cd0-de98-4fc0-a31c-55ed882186f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-2aa18f7f-dd60-4fac-9955-b7d4d1dc313d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-01942604-7db4-46ee-b6a7-d1c62bbb0608,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-c225a6d9-99a7-4208-bcc8-1c0f13a964dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-a1083132-0804-4f7b-855c-e3c1ba360664,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-717141de-6806-4b35-a542-113aa90ac275,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-445325e6-4efc-4526-9e64-48b902401772,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-87be8613-49bd-4cba-9ca4-5de1a8a9bf13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747853270-172.17.0.8-1597142161861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35647,DS-071e3c1b-630f-4c18-858d-539753ff59b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-b47a4d3e-2b77-478f-bdd2-b1e897b21e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-4c4bb730-b7ef-49d0-a08f-b037e9f4e7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-7ea9bd02-f41b-443c-bb7b-952ec255d715,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-2342ec55-d92c-43cb-864e-5404749a2955,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-290b8f5d-0f23-42e8-b05d-c9ea10f9c68f,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-a4ae601e-6d44-4ecb-b768-4b1595b4243b,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-365c17cb-c2db-4fd7-9576-0d7b661ddfbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747853270-172.17.0.8-1597142161861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35647,DS-071e3c1b-630f-4c18-858d-539753ff59b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-b47a4d3e-2b77-478f-bdd2-b1e897b21e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-4c4bb730-b7ef-49d0-a08f-b037e9f4e7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-7ea9bd02-f41b-443c-bb7b-952ec255d715,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-2342ec55-d92c-43cb-864e-5404749a2955,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-290b8f5d-0f23-42e8-b05d-c9ea10f9c68f,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-a4ae601e-6d44-4ecb-b768-4b1595b4243b,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-365c17cb-c2db-4fd7-9576-0d7b661ddfbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896905238-172.17.0.8-1597142469302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-b41851e9-b3f7-4239-8222-951abaf507aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-d1fef7cb-d7c0-48ed-98b5-1b01a00c7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-deaed055-32f8-4255-abde-d5308ab559d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-a078566b-7127-440d-848c-4adf20260c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-0df9455c-101d-499b-a4f4-30fb9c3dba58,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-dff5a9da-df3b-468f-b067-40d8633b7628,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-c69307f1-224b-4bbf-9558-b70268bfe84d,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-fd29d4b3-999e-4f2e-876c-d5ed7614d04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896905238-172.17.0.8-1597142469302:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38238,DS-b41851e9-b3f7-4239-8222-951abaf507aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-d1fef7cb-d7c0-48ed-98b5-1b01a00c7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-deaed055-32f8-4255-abde-d5308ab559d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-a078566b-7127-440d-848c-4adf20260c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-0df9455c-101d-499b-a4f4-30fb9c3dba58,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-dff5a9da-df3b-468f-b067-40d8633b7628,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-c69307f1-224b-4bbf-9558-b70268bfe84d,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-fd29d4b3-999e-4f2e-876c-d5ed7614d04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461055960-172.17.0.8-1597142953420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-ecd32eb3-bf5c-427e-84b2-badd362293db,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-6fb2d93c-461d-457a-8245-251f818c16ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-4b53e403-aee7-4893-8b61-8265b8ff19f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-cf48ec77-a196-42c2-9363-2a9fdf10f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-26c5ae84-d0ec-424a-9bf0-57b2cb1d479c,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-475a9927-234f-4b23-8f55-5649e3be8c60,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-7d15a9ec-9f02-462c-af02-2bb2eec52dad,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-8bd4c4e0-c35a-41e0-879e-4e0b8cdbf268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-461055960-172.17.0.8-1597142953420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38036,DS-ecd32eb3-bf5c-427e-84b2-badd362293db,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-6fb2d93c-461d-457a-8245-251f818c16ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-4b53e403-aee7-4893-8b61-8265b8ff19f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-cf48ec77-a196-42c2-9363-2a9fdf10f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-26c5ae84-d0ec-424a-9bf0-57b2cb1d479c,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-475a9927-234f-4b23-8f55-5649e3be8c60,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-7d15a9ec-9f02-462c-af02-2bb2eec52dad,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-8bd4c4e0-c35a-41e0-879e-4e0b8cdbf268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.pools.num.responses
component: hdfs:NameNode
v1: 100
v2: 200
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306600447-172.17.0.8-1597143023406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43868,DS-a26b1dcf-5cfb-48a4-84bf-a474115d22fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-4806c46d-02ca-4c6b-8491-e2f2ceb55566,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-842e2dd5-8697-49f1-9da0-5cb32d4ce4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-da21ab75-1447-46ce-9811-257409028249,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-16a8ee31-31a2-4a60-b262-1ca337fe40fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-18ff4646-5caf-46d9-94cc-5e4583798afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-f8f2fdaf-911e-4eed-9e58-739f51143a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-5ed20af0-51c9-4630-8e2a-4299d0fb0435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306600447-172.17.0.8-1597143023406:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43868,DS-a26b1dcf-5cfb-48a4-84bf-a474115d22fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-4806c46d-02ca-4c6b-8491-e2f2ceb55566,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-842e2dd5-8697-49f1-9da0-5cb32d4ce4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-da21ab75-1447-46ce-9811-257409028249,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-16a8ee31-31a2-4a60-b262-1ca337fe40fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-18ff4646-5caf-46d9-94cc-5e4583798afc,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-f8f2fdaf-911e-4eed-9e58-739f51143a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-5ed20af0-51c9-4630-8e2a-4299d0fb0435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 4791
