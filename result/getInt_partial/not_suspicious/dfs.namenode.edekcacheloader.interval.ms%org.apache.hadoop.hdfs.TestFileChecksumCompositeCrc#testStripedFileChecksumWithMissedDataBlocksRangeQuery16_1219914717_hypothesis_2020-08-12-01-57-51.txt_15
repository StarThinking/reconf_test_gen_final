reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219772824-172.17.0.7-1597197631518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-d9c071cb-6a71-4757-bf8d-ea3d54af4119,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-005c7053-fb1f-495f-8e63-75cfcba8ef21,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-c84f3636-300a-4fc6-b194-c935a13cde84,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-728a0923-e31e-44e2-89c3-10401e87cb15,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8d14984b-b43e-4dbf-8aeb-5679cdde1dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-5e05fcdd-0660-4b6f-8732-401b295581fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-6db7d6f8-7a1f-45d7-bd75-3168b4757ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-31d8d427-0f24-4846-9ece-8f6eb05515bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-219772824-172.17.0.7-1597197631518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-d9c071cb-6a71-4757-bf8d-ea3d54af4119,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-005c7053-fb1f-495f-8e63-75cfcba8ef21,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-c84f3636-300a-4fc6-b194-c935a13cde84,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-728a0923-e31e-44e2-89c3-10401e87cb15,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-8d14984b-b43e-4dbf-8aeb-5679cdde1dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-5e05fcdd-0660-4b6f-8732-401b295581fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-6db7d6f8-7a1f-45d7-bd75-3168b4757ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-31d8d427-0f24-4846-9ece-8f6eb05515bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154987034-172.17.0.7-1597198499074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-458fe43e-d3b4-4697-9fbb-72053267dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-6e1d54c3-c670-4505-8617-79928e75be2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-c288e77b-16f3-40d7-962f-4962c7cedd78,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-7ad0e75d-197b-461e-a414-8e243b918681,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-40f19634-aa24-4391-b635-f74776497c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-7cc2f292-fa5e-4643-94c1-2984361ddf50,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-07a981c2-0ab4-491b-9b3c-6d334f9c3b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-e4e4cb63-43ed-4c17-b011-815ea0e455bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154987034-172.17.0.7-1597198499074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-458fe43e-d3b4-4697-9fbb-72053267dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-6e1d54c3-c670-4505-8617-79928e75be2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-c288e77b-16f3-40d7-962f-4962c7cedd78,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-7ad0e75d-197b-461e-a414-8e243b918681,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-40f19634-aa24-4391-b635-f74776497c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-7cc2f292-fa5e-4643-94c1-2984361ddf50,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-07a981c2-0ab4-491b-9b3c-6d334f9c3b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-e4e4cb63-43ed-4c17-b011-815ea0e455bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794382544-172.17.0.7-1597199140001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-1c818d75-01dc-497f-add8-ecca5ba8c88f,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-c9d4071c-6e57-4fe8-bfcc-4842c1b220e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-4527e31b-3035-4d76-9f5c-652cc9be75b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-e3405936-8b9b-4edf-8887-ccb6e95f2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-cefdfb10-8bcf-4bab-932f-2dbcad5fd731,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-b39b5c24-7bd6-4551-9380-83a397a534bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1f5d305c-1e2c-48b7-9cc8-c90d24587aae,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-b9de0585-cce7-4f5a-bb26-4f699c145939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794382544-172.17.0.7-1597199140001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-1c818d75-01dc-497f-add8-ecca5ba8c88f,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-c9d4071c-6e57-4fe8-bfcc-4842c1b220e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-4527e31b-3035-4d76-9f5c-652cc9be75b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-e3405936-8b9b-4edf-8887-ccb6e95f2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-cefdfb10-8bcf-4bab-932f-2dbcad5fd731,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-b39b5c24-7bd6-4551-9380-83a397a534bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-1f5d305c-1e2c-48b7-9cc8-c90d24587aae,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-b9de0585-cce7-4f5a-bb26-4f699c145939,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927616319-172.17.0.7-1597199559268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-97e77e48-9521-4758-b602-ea70de98ee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-3252776a-3ad0-47d8-9105-ebf8a20fc930,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-d198f8d3-2b63-4874-af43-38fee37fb12b,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-dc913d70-5b25-4c6f-aab2-00c8172305b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-001108cc-d642-4300-9b02-a0c9412ce64b,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-8fed4634-27a8-4ce6-a252-18cef3654a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-b7b4feb0-32f1-4a5a-8441-853b8fa454cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-a4f7bd1b-190c-4ac7-ae99-58f90a833cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-927616319-172.17.0.7-1597199559268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-97e77e48-9521-4758-b602-ea70de98ee6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-3252776a-3ad0-47d8-9105-ebf8a20fc930,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-d198f8d3-2b63-4874-af43-38fee37fb12b,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-dc913d70-5b25-4c6f-aab2-00c8172305b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-001108cc-d642-4300-9b02-a0c9412ce64b,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-8fed4634-27a8-4ce6-a252-18cef3654a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-b7b4feb0-32f1-4a5a-8441-853b8fa454cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-a4f7bd1b-190c-4ac7-ae99-58f90a833cdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742957414-172.17.0.7-1597199628578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-ad9d0b54-ad6d-489d-8749-9722ad011b05,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-5d71f2d8-9dc5-439b-873e-f193c780286a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-0c263ed1-6caa-418f-ad19-e8ae23b9ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-70d79752-4b28-40d5-8322-05db0b835891,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-bb73fc81-ff86-4c4d-b628-5deb1ef04f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-e7c46d5f-d752-465b-8434-6959b31d34ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-861f90ca-24c0-41a7-9725-ec7527e32679,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-a7d2689c-7036-4992-b44c-7a28ac918722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-742957414-172.17.0.7-1597199628578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-ad9d0b54-ad6d-489d-8749-9722ad011b05,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-5d71f2d8-9dc5-439b-873e-f193c780286a,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-0c263ed1-6caa-418f-ad19-e8ae23b9ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-70d79752-4b28-40d5-8322-05db0b835891,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-bb73fc81-ff86-4c4d-b628-5deb1ef04f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-e7c46d5f-d752-465b-8434-6959b31d34ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-861f90ca-24c0-41a7-9725-ec7527e32679,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-a7d2689c-7036-4992-b44c-7a28ac918722,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674976507-172.17.0.7-1597200154463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-604870aa-3147-48eb-809f-90877bcad24d,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-6a3f1bb4-f5cb-430b-995d-f4a475732401,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-684025dc-ca13-446f-8349-9112d00014de,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-d7612ffa-a4e3-4fac-885d-c220db97724f,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-7ec17acb-c85b-419f-bdd2-a19392210caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-ccf38248-24c1-4171-80d1-397159fc22d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-2b71af45-ba4b-4d30-9c35-7d0aad21022b,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-a4b80379-cd97-410e-a077-59e194b54113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1674976507-172.17.0.7-1597200154463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-604870aa-3147-48eb-809f-90877bcad24d,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-6a3f1bb4-f5cb-430b-995d-f4a475732401,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-684025dc-ca13-446f-8349-9112d00014de,DISK], DatanodeInfoWithStorage[127.0.0.1:39194,DS-d7612ffa-a4e3-4fac-885d-c220db97724f,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-7ec17acb-c85b-419f-bdd2-a19392210caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-ccf38248-24c1-4171-80d1-397159fc22d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-2b71af45-ba4b-4d30-9c35-7d0aad21022b,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-a4b80379-cd97-410e-a077-59e194b54113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817116021-172.17.0.7-1597200591724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-7bc651ac-9b24-4398-9b0d-2c13674c94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-a248ea3e-4ef4-4e66-abcc-03eb4548a388,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-4be9c6de-d236-496e-ba7c-6a5a4c4b4bae,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-bc87c664-69b1-47fa-9feb-95c30aed1a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-8b97ceb0-b6e2-42b1-a6a2-3efbdaf3a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-0bdf1d9c-e1a8-43e6-87e5-917d826aa5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-8ad0ca11-069d-4c57-8999-1649776c2f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-e1569113-7c1d-41fe-84c0-f224145d7e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1817116021-172.17.0.7-1597200591724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37407,DS-7bc651ac-9b24-4398-9b0d-2c13674c94c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-a248ea3e-4ef4-4e66-abcc-03eb4548a388,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-4be9c6de-d236-496e-ba7c-6a5a4c4b4bae,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-bc87c664-69b1-47fa-9feb-95c30aed1a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-8b97ceb0-b6e2-42b1-a6a2-3efbdaf3a6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-0bdf1d9c-e1a8-43e6-87e5-917d826aa5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-8ad0ca11-069d-4c57-8999-1649776c2f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-e1569113-7c1d-41fe-84c0-f224145d7e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757843683-172.17.0.7-1597200707398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-74d30fdb-e19d-4fff-a7ff-84f8cf6a9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-945b4a21-e660-4f11-b2f3-faf7ba730d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-9c89d695-c543-48f5-934f-7f1189f8b757,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-bff67a7d-7772-4d4e-8a56-97ab4caf1e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-eff1a5cc-9189-4927-a07d-af5c480efa47,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-a31405e4-2107-448d-bfb1-19bec08c808e,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-870c3f94-5f36-48af-b171-2546d0791bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-1a4e88e4-c04e-4f6f-ad5d-5a27e068002d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757843683-172.17.0.7-1597200707398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43303,DS-74d30fdb-e19d-4fff-a7ff-84f8cf6a9bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44220,DS-945b4a21-e660-4f11-b2f3-faf7ba730d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-9c89d695-c543-48f5-934f-7f1189f8b757,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-bff67a7d-7772-4d4e-8a56-97ab4caf1e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-eff1a5cc-9189-4927-a07d-af5c480efa47,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-a31405e4-2107-448d-bfb1-19bec08c808e,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-870c3f94-5f36-48af-b171-2546d0791bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-1a4e88e4-c04e-4f6f-ad5d-5a27e068002d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59167243-172.17.0.7-1597201101944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42805,DS-c23c27c5-0f2d-4573-a6bc-498914319970,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-e1678922-b6ab-4ca9-af82-52bb6b3809fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-8a079dce-dcf0-4903-ad1c-c64b78d13199,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-2e654bef-139a-41de-8cee-a2c1547cdc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-26f808ea-0a93-4bfc-8afe-53fd6154a058,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-4f1053b8-3318-4807-9079-609034667e35,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-c12f187e-9942-46d9-965b-a11c940cafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-b699f90a-b22c-49f2-babf-8d8a0d2276ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-59167243-172.17.0.7-1597201101944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42805,DS-c23c27c5-0f2d-4573-a6bc-498914319970,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-e1678922-b6ab-4ca9-af82-52bb6b3809fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41066,DS-8a079dce-dcf0-4903-ad1c-c64b78d13199,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-2e654bef-139a-41de-8cee-a2c1547cdc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39428,DS-26f808ea-0a93-4bfc-8afe-53fd6154a058,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-4f1053b8-3318-4807-9079-609034667e35,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-c12f187e-9942-46d9-965b-a11c940cafb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-b699f90a-b22c-49f2-babf-8d8a0d2276ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816181747-172.17.0.7-1597201135998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-e1a6f754-7061-4c6d-8a0d-af661f116fae,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-acd609a2-1d96-4e67-b108-6b6957b3638f,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-bd1501dc-50d6-4808-b587-33e1e7c3b032,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-6114242a-5399-4a79-8539-f1b9b212794b,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-74171260-70a9-4958-82f0-8c6877c9e003,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-91445d16-e84d-4b0f-826b-654d4fab665c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-422cf8fd-65b5-4a53-8027-78ea73e02fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-a8582958-fbe2-439e-93c2-f18a95fbd96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816181747-172.17.0.7-1597201135998:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35113,DS-e1a6f754-7061-4c6d-8a0d-af661f116fae,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-acd609a2-1d96-4e67-b108-6b6957b3638f,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-bd1501dc-50d6-4808-b587-33e1e7c3b032,DISK], DatanodeInfoWithStorage[127.0.0.1:40074,DS-6114242a-5399-4a79-8539-f1b9b212794b,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-74171260-70a9-4958-82f0-8c6877c9e003,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-91445d16-e84d-4b0f-826b-654d4fab665c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-422cf8fd-65b5-4a53-8027-78ea73e02fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-a8582958-fbe2-439e-93c2-f18a95fbd96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742002178-172.17.0.7-1597201368960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40327,DS-832ebcb1-945b-404b-9ca8-90405f3ea838,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-e6a91d61-1b9c-4ce1-a64e-eee874df5501,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-8ad65d4a-bb43-4593-9c7a-3cd8b02b0aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-aa7f7b8f-5e9f-4c69-86cb-aa0e9227b817,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-08bd75fa-1abc-42b6-9e22-14a21e9ded9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-95434193-1c01-41c0-a511-348dfd9d687e,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-22269134-af27-4ead-8baa-8539cf08d3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-1f6232f7-cb11-4416-8206-3e92c3191d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742002178-172.17.0.7-1597201368960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40327,DS-832ebcb1-945b-404b-9ca8-90405f3ea838,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-e6a91d61-1b9c-4ce1-a64e-eee874df5501,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-8ad65d4a-bb43-4593-9c7a-3cd8b02b0aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-aa7f7b8f-5e9f-4c69-86cb-aa0e9227b817,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-08bd75fa-1abc-42b6-9e22-14a21e9ded9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-95434193-1c01-41c0-a511-348dfd9d687e,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-22269134-af27-4ead-8baa-8539cf08d3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-1f6232f7-cb11-4416-8206-3e92c3191d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763022825-172.17.0.7-1597201403752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41687,DS-e347f956-3a20-4d83-986d-88526b61176b,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-80591d77-5f53-4145-83e2-465aa6d2d0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-598cc9ca-6a68-40d4-a202-c82af9ed40bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a21d7823-2978-4490-891a-8c5bd8ff080e,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-13c5f389-578b-466a-b3f7-22e58d729453,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-2b91021a-e316-4e17-904d-d71df3c96829,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-cd51197b-37a9-43ec-8738-24a1da1a89eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-49a05bce-a31d-4bb7-9b11-2b93366d8661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1763022825-172.17.0.7-1597201403752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41687,DS-e347f956-3a20-4d83-986d-88526b61176b,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-80591d77-5f53-4145-83e2-465aa6d2d0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-598cc9ca-6a68-40d4-a202-c82af9ed40bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-a21d7823-2978-4490-891a-8c5bd8ff080e,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-13c5f389-578b-466a-b3f7-22e58d729453,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-2b91021a-e316-4e17-904d-d71df3c96829,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-cd51197b-37a9-43ec-8738-24a1da1a89eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-49a05bce-a31d-4bb7-9b11-2b93366d8661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818758710-172.17.0.7-1597202097559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-65ee8088-a103-4b6c-a3fa-fa0387ea6f97,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-c38baffc-206a-4ecf-8a58-90cbddd38fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-f50d3ce3-ef94-4c6f-9c73-ca28eeb3a3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-00bbf920-5997-4c34-82ac-4965e7cc73a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-99eca695-d34a-4799-b687-f075ce08ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-30c619f1-3479-4ba4-90ab-e6a38457466c,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-dd1347b7-ae9b-4913-a976-fd4b8741870b,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-d409cdbc-c20b-4c40-b7a5-8c289d7bb860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-818758710-172.17.0.7-1597202097559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-65ee8088-a103-4b6c-a3fa-fa0387ea6f97,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-c38baffc-206a-4ecf-8a58-90cbddd38fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-f50d3ce3-ef94-4c6f-9c73-ca28eeb3a3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-00bbf920-5997-4c34-82ac-4965e7cc73a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36663,DS-99eca695-d34a-4799-b687-f075ce08ffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-30c619f1-3479-4ba4-90ab-e6a38457466c,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-dd1347b7-ae9b-4913-a976-fd4b8741870b,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-d409cdbc-c20b-4c40-b7a5-8c289d7bb860,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859576425-172.17.0.7-1597202458141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-feefb7de-7fe6-4e9a-9c18-b0ef9912a375,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-b48f22c1-a236-4c07-92cb-0b3cd745a11f,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-1c1d912a-dba9-4e5a-959b-139b61f4cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-447764b2-8b92-472b-ac5d-864bf2c9e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-211d2516-fc65-46dd-aa84-962f342e84ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-faac01df-3374-4ba8-b5ef-6396dd79b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-2ff991ca-9a82-46d4-a4d9-d683456e179b,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-f017d87a-6aa9-4a63-b83f-4ead7c37ca87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1859576425-172.17.0.7-1597202458141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38193,DS-feefb7de-7fe6-4e9a-9c18-b0ef9912a375,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-b48f22c1-a236-4c07-92cb-0b3cd745a11f,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-1c1d912a-dba9-4e5a-959b-139b61f4cde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-447764b2-8b92-472b-ac5d-864bf2c9e35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-211d2516-fc65-46dd-aa84-962f342e84ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42039,DS-faac01df-3374-4ba8-b5ef-6396dd79b6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-2ff991ca-9a82-46d4-a4d9-d683456e179b,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-f017d87a-6aa9-4a63-b83f-4ead7c37ca87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.interval.ms
component: hdfs:NameNode
v1: 1000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660695105-172.17.0.7-1597202664612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-7fa7fa0c-9784-4589-9db4-3b15b785273b,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-463e5abe-ba3f-42c5-82c1-93f45767a197,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-c85c53b2-1a4c-4238-8b2f-4c62c0478cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-188a63dc-5b7b-406b-8c4e-574a90fa5141,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-2ee7d1d4-80ad-4c62-afd0-69490f6c7ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-83fa327d-b91b-468b-b327-5a2a9837790b,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-dd8966fa-3a2b-4eee-b0fd-beac64363c88,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-7fe734bf-9105-4cea-909b-8381205eb6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660695105-172.17.0.7-1597202664612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34265,DS-7fa7fa0c-9784-4589-9db4-3b15b785273b,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-463e5abe-ba3f-42c5-82c1-93f45767a197,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-c85c53b2-1a4c-4238-8b2f-4c62c0478cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-188a63dc-5b7b-406b-8c4e-574a90fa5141,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-2ee7d1d4-80ad-4c62-afd0-69490f6c7ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-83fa327d-b91b-468b-b327-5a2a9837790b,DISK], DatanodeInfoWithStorage[127.0.0.1:42559,DS-dd8966fa-3a2b-4eee-b0fd-beac64363c88,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-7fe734bf-9105-4cea-909b-8381205eb6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5286
