reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723524254-172.17.0.6-1597044679134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35255,DS-d590a091-8c60-4716-8d98-9ef46da011e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-19fa70aa-7b6a-4024-8eae-cbc1e55acb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-c1707b94-81cf-4608-9678-bbee3774140e,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-9a043f4e-bae0-466c-8b5f-99cec633d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-bda545e4-726a-457c-8800-da2d25619c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-b2b29b7c-11cf-4392-81d3-137f21a6447e,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-187c8fe2-0f20-43b4-a633-9befb0a95204,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-fc156408-ea4b-4780-912a-4b404872fdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723524254-172.17.0.6-1597044679134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35255,DS-d590a091-8c60-4716-8d98-9ef46da011e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-19fa70aa-7b6a-4024-8eae-cbc1e55acb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-c1707b94-81cf-4608-9678-bbee3774140e,DISK], DatanodeInfoWithStorage[127.0.0.1:33095,DS-9a043f4e-bae0-466c-8b5f-99cec633d40b,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-bda545e4-726a-457c-8800-da2d25619c30,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-b2b29b7c-11cf-4392-81d3-137f21a6447e,DISK], DatanodeInfoWithStorage[127.0.0.1:45561,DS-187c8fe2-0f20-43b4-a633-9befb0a95204,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-fc156408-ea4b-4780-912a-4b404872fdbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350836406-172.17.0.6-1597045145829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45419,DS-615c8e32-06eb-4fe0-b07a-2595d546315f,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-e339d729-b379-4a62-a33f-1a9d8df5bca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-3d1bb2cd-6139-4a9a-b057-5081479c43bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-b1182dec-22ac-4c34-9a0f-9680128f1bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-dead4791-9d14-4a05-aa09-d2a96415717c,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-a8703081-0132-45bd-8535-d5ff6bb3a461,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-a3f79f84-ebfa-4c3c-8a00-4aa03e038b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-7cc8fa0d-f68d-4e20-8363-e4254700f16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1350836406-172.17.0.6-1597045145829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45419,DS-615c8e32-06eb-4fe0-b07a-2595d546315f,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-e339d729-b379-4a62-a33f-1a9d8df5bca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-3d1bb2cd-6139-4a9a-b057-5081479c43bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33756,DS-b1182dec-22ac-4c34-9a0f-9680128f1bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-dead4791-9d14-4a05-aa09-d2a96415717c,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-a8703081-0132-45bd-8535-d5ff6bb3a461,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-a3f79f84-ebfa-4c3c-8a00-4aa03e038b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-7cc8fa0d-f68d-4e20-8363-e4254700f16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001623290-172.17.0.6-1597045565076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-8cc6de50-f1a2-48b4-9452-3db41b6ea744,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-2a29950b-97fb-48cc-9530-8df07da0f91c,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-dece8954-cec8-4e50-90a6-08dc833054c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-fe2ee15f-8bfa-4a08-a14f-7973dbdab24d,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-47647415-da67-4226-b843-97e57635dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-a0e28d61-c5e5-465d-876f-4f6853df34f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-2c4cdc84-4ce8-44ef-be25-05688498bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-91d54a0c-d970-465c-b4c9-427f3277b9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001623290-172.17.0.6-1597045565076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39070,DS-8cc6de50-f1a2-48b4-9452-3db41b6ea744,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-2a29950b-97fb-48cc-9530-8df07da0f91c,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-dece8954-cec8-4e50-90a6-08dc833054c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-fe2ee15f-8bfa-4a08-a14f-7973dbdab24d,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-47647415-da67-4226-b843-97e57635dc97,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-a0e28d61-c5e5-465d-876f-4f6853df34f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-2c4cdc84-4ce8-44ef-be25-05688498bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-91d54a0c-d970-465c-b4c9-427f3277b9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065431679-172.17.0.6-1597046008535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43781,DS-effeb943-a8ba-4ff4-88bb-3169aa3c5592,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-4d7a3b88-d631-476f-9f19-b5ac1c3a02ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-6cd9448a-5ff8-4401-b08c-5f98c27ab20f,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-cbb6a141-9d06-4be6-ba9f-2a811a01dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-2ca4a541-fb05-4a18-8912-f6732dc6ede6,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-363a5de4-0aa2-4d92-92c9-bdd32761c2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-211c3aff-184f-4a3c-91d7-e4ec6fd3c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-c0880b33-d9f8-4662-a59d-75a32dad26fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065431679-172.17.0.6-1597046008535:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43781,DS-effeb943-a8ba-4ff4-88bb-3169aa3c5592,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-4d7a3b88-d631-476f-9f19-b5ac1c3a02ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-6cd9448a-5ff8-4401-b08c-5f98c27ab20f,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-cbb6a141-9d06-4be6-ba9f-2a811a01dbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-2ca4a541-fb05-4a18-8912-f6732dc6ede6,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-363a5de4-0aa2-4d92-92c9-bdd32761c2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-211c3aff-184f-4a3c-91d7-e4ec6fd3c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-c0880b33-d9f8-4662-a59d-75a32dad26fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547855535-172.17.0.6-1597046543424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44861,DS-907b5649-5587-486d-87e6-af0dc6eee8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-dbd3da1b-dd38-4ca7-b267-dbe20e12141e,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-026d1bda-7e43-4806-93a1-f4fc4c8dd6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-280d7e50-6259-4c43-bb16-7ec2ced8ca30,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-bea7159d-f641-458c-b844-4f9384322c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-5b9eb014-f1ab-4773-bc8b-697aea5a576d,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-4529efeb-cebc-49ca-ab02-78cd02b59714,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-bb9752bb-11d0-4b72-ac04-c86fa8453ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-547855535-172.17.0.6-1597046543424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44861,DS-907b5649-5587-486d-87e6-af0dc6eee8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-dbd3da1b-dd38-4ca7-b267-dbe20e12141e,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-026d1bda-7e43-4806-93a1-f4fc4c8dd6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-280d7e50-6259-4c43-bb16-7ec2ced8ca30,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-bea7159d-f641-458c-b844-4f9384322c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-5b9eb014-f1ab-4773-bc8b-697aea5a576d,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-4529efeb-cebc-49ca-ab02-78cd02b59714,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-bb9752bb-11d0-4b72-ac04-c86fa8453ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268493681-172.17.0.6-1597046677285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43289,DS-3b675a11-80c7-45b2-a0cc-fdbd2f3439ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-6bb884cd-ddca-469c-94f5-b963af051994,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-8a0a7cf1-2b19-4eb5-8bf6-787101071ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-1434005b-17b7-4e5f-95c3-e1710b07b7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-d51cdd8f-d3f9-4f72-8061-1fe4239fdb48,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-08a45661-9b38-4774-a1ba-136ea3ad119e,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-3ce7e753-8c8b-436a-8d60-dabc5a730be6,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-9ee652c1-2396-4e84-934d-d5adb24df001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1268493681-172.17.0.6-1597046677285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43289,DS-3b675a11-80c7-45b2-a0cc-fdbd2f3439ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-6bb884cd-ddca-469c-94f5-b963af051994,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-8a0a7cf1-2b19-4eb5-8bf6-787101071ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-1434005b-17b7-4e5f-95c3-e1710b07b7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-d51cdd8f-d3f9-4f72-8061-1fe4239fdb48,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-08a45661-9b38-4774-a1ba-136ea3ad119e,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-3ce7e753-8c8b-436a-8d60-dabc5a730be6,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-9ee652c1-2396-4e84-934d-d5adb24df001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923639957-172.17.0.6-1597047006969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-514e69bd-2c8b-4c07-84e4-ad3b3ce09f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-2b584101-4732-4679-910d-c8ba9f6a2aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-f3d3442b-a086-446d-87c9-73b06dff698d,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-55be3c34-4f72-43d6-9fe8-1c4bbb697c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-e02141f6-9f2f-4985-9221-5689e9963d48,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-99065c7a-7917-4770-8c0e-76329ecf2461,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-1714862b-935d-4cc2-bf73-b212856a25ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-c4b414bb-6b26-40f0-b086-4c46625cccab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923639957-172.17.0.6-1597047006969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-514e69bd-2c8b-4c07-84e4-ad3b3ce09f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-2b584101-4732-4679-910d-c8ba9f6a2aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-f3d3442b-a086-446d-87c9-73b06dff698d,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-55be3c34-4f72-43d6-9fe8-1c4bbb697c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45297,DS-e02141f6-9f2f-4985-9221-5689e9963d48,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-99065c7a-7917-4770-8c0e-76329ecf2461,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-1714862b-935d-4cc2-bf73-b212856a25ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-c4b414bb-6b26-40f0-b086-4c46625cccab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216213377-172.17.0.6-1597048308073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36771,DS-fba2e6cd-9404-4929-91db-d046715e5b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-bf72c255-f83b-40e3-8e30-02ba69922f66,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-f76d8e2d-c5af-47da-81d2-cab0a0c0ee46,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-18b217d7-8535-490e-ba0d-34fd66089935,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-d8ddc0e6-8778-4679-b7f4-4140b308d458,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-a018b30f-9491-4ad2-9550-72723cefd2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-0b0d19cf-a5f8-431b-b03d-2ffd460c59c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-c7c913f4-9a09-4236-bdf9-30b797f9b902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216213377-172.17.0.6-1597048308073:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36771,DS-fba2e6cd-9404-4929-91db-d046715e5b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-bf72c255-f83b-40e3-8e30-02ba69922f66,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-f76d8e2d-c5af-47da-81d2-cab0a0c0ee46,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-18b217d7-8535-490e-ba0d-34fd66089935,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-d8ddc0e6-8778-4679-b7f4-4140b308d458,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-a018b30f-9491-4ad2-9550-72723cefd2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-0b0d19cf-a5f8-431b-b03d-2ffd460c59c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-c7c913f4-9a09-4236-bdf9-30b797f9b902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314704555-172.17.0.6-1597048398170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39053,DS-1b1f437e-e26b-4bd9-ac00-8b7f4a4a0fad,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-fcbdf721-c158-4641-80d2-93a17110c419,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-f1ce9ec4-5ad7-4ae5-8ea4-464ffa37cd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-43a4960a-68ec-46c2-800b-ccd62a3a80c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-855201cf-20d1-4484-a1f8-f94a7c93a970,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-b695d2d3-df96-4111-8bc8-1edcc0e544ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-22c78f39-8056-4d9a-bfe4-febd770fa151,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-b774c9b0-68ac-46b5-9ec8-4a75b0f85ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314704555-172.17.0.6-1597048398170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39053,DS-1b1f437e-e26b-4bd9-ac00-8b7f4a4a0fad,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-fcbdf721-c158-4641-80d2-93a17110c419,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-f1ce9ec4-5ad7-4ae5-8ea4-464ffa37cd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-43a4960a-68ec-46c2-800b-ccd62a3a80c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-855201cf-20d1-4484-a1f8-f94a7c93a970,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-b695d2d3-df96-4111-8bc8-1edcc0e544ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-22c78f39-8056-4d9a-bfe4-febd770fa151,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-b774c9b0-68ac-46b5-9ec8-4a75b0f85ec1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971205641-172.17.0.6-1597048489427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-ccfb39bd-6057-484a-b178-888be0bd8ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-4f4ded67-bd92-49e9-97e3-4efd8fd9730c,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-e0f82474-8fb6-4846-8aa2-803863eca198,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-0133a767-f923-4c8f-91ae-346ba676fd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-7dc79044-7ea9-4aab-8216-9d07ca7f9e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-b3f5519b-5727-4bd8-9a65-53506de3369f,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-248ae38e-b555-48c1-8632-9fe396f338e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-850b8efb-6b3e-4adc-85fe-42f2cf092e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1971205641-172.17.0.6-1597048489427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-ccfb39bd-6057-484a-b178-888be0bd8ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-4f4ded67-bd92-49e9-97e3-4efd8fd9730c,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-e0f82474-8fb6-4846-8aa2-803863eca198,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-0133a767-f923-4c8f-91ae-346ba676fd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-7dc79044-7ea9-4aab-8216-9d07ca7f9e74,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-b3f5519b-5727-4bd8-9a65-53506de3369f,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-248ae38e-b555-48c1-8632-9fe396f338e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-850b8efb-6b3e-4adc-85fe-42f2cf092e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036333353-172.17.0.6-1597049153150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42880,DS-ea374348-8967-457f-91c5-8a7c76612e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-9159cc1c-b749-40f1-b5ba-bd2bee34fbad,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-ac414514-e6b2-4746-837a-773ad3023f62,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-0ed8ebeb-22b4-4b31-b034-09674aa4a1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-21b7ad70-be46-49af-95b8-526a527ea8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-99d65338-3332-454b-9df0-b43da1204e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-b4d54ea7-773d-49eb-bdf8-db383f284b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-c2c8d040-f771-4dbd-a7c4-3e215142cedd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2036333353-172.17.0.6-1597049153150:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42880,DS-ea374348-8967-457f-91c5-8a7c76612e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-9159cc1c-b749-40f1-b5ba-bd2bee34fbad,DISK], DatanodeInfoWithStorage[127.0.0.1:38263,DS-ac414514-e6b2-4746-837a-773ad3023f62,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-0ed8ebeb-22b4-4b31-b034-09674aa4a1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-21b7ad70-be46-49af-95b8-526a527ea8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-99d65338-3332-454b-9df0-b43da1204e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-b4d54ea7-773d-49eb-bdf8-db383f284b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-c2c8d040-f771-4dbd-a7c4-3e215142cedd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527913531-172.17.0.6-1597049334223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-3bec4c5f-8898-40ad-b90b-37995ea06061,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-f663297f-5bde-4a57-bef0-0a33f0a0fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-35191d1a-af88-4973-8726-3367327298d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-b93ab688-4492-496f-b006-ce83b04f4362,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-079809c4-c116-4d13-8f3e-bc8c62ee654a,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-87f6feb5-9fee-441f-9c38-51030a6166ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-b408eccf-b3fc-4b23-8942-c12a3adbb00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-c4010f6f-2790-471a-b030-40f91445517c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-527913531-172.17.0.6-1597049334223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-3bec4c5f-8898-40ad-b90b-37995ea06061,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-f663297f-5bde-4a57-bef0-0a33f0a0fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-35191d1a-af88-4973-8726-3367327298d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-b93ab688-4492-496f-b006-ce83b04f4362,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-079809c4-c116-4d13-8f3e-bc8c62ee654a,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-87f6feb5-9fee-441f-9c38-51030a6166ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-b408eccf-b3fc-4b23-8942-c12a3adbb00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-c4010f6f-2790-471a-b030-40f91445517c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924897418-172.17.0.6-1597049587390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45378,DS-dc282b2a-445c-4a40-99fa-a94fba2b200b,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-4af9469a-1e01-4178-9d85-aa600e6b7ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-2f9c2870-200b-48e3-87d6-732e8d0d046d,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-976e71d4-c795-48c0-9a50-530338fec295,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-2a80f353-e0ad-44fe-b07a-df5a7aed9cea,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ff474540-bff0-41d5-9ed7-4feb549df883,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-e304dce8-09b0-4a3a-a9b3-b73dbdfdd7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-1d938d1d-dfbf-46c7-a146-df638e20c339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1924897418-172.17.0.6-1597049587390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45378,DS-dc282b2a-445c-4a40-99fa-a94fba2b200b,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-4af9469a-1e01-4178-9d85-aa600e6b7ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-2f9c2870-200b-48e3-87d6-732e8d0d046d,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-976e71d4-c795-48c0-9a50-530338fec295,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-2a80f353-e0ad-44fe-b07a-df5a7aed9cea,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ff474540-bff0-41d5-9ed7-4feb549df883,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-e304dce8-09b0-4a3a-a9b3-b73dbdfdd7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-1d938d1d-dfbf-46c7-a146-df638e20c339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-902756530-172.17.0.6-1597049723386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-8364cf02-6a62-4bb2-ba7b-c054892b1a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-868256c1-d737-48d9-b044-5d54ea5c3100,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-9ea824f6-84f2-42e3-8bcc-362769ce1cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-fb6999a8-3cb1-488c-855d-e70af4dd4b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-4f7631d7-ba5d-4237-844d-a59502acec66,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-f5ad6c71-6c40-4ebb-94db-6a16a9796e14,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-667585a4-e3ce-4456-ab36-643a350a8513,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-f01219c8-fa22-4554-952d-920f7d630d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-902756530-172.17.0.6-1597049723386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36039,DS-8364cf02-6a62-4bb2-ba7b-c054892b1a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-868256c1-d737-48d9-b044-5d54ea5c3100,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-9ea824f6-84f2-42e3-8bcc-362769ce1cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-fb6999a8-3cb1-488c-855d-e70af4dd4b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-4f7631d7-ba5d-4237-844d-a59502acec66,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-f5ad6c71-6c40-4ebb-94db-6a16a9796e14,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-667585a4-e3ce-4456-ab36-643a350a8513,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-f01219c8-fa22-4554-952d-920f7d630d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171146352-172.17.0.6-1597050050016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33420,DS-f6d560b1-1cb5-4dd1-8dbd-609b6b0886fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-05107948-9e36-4471-aabf-0a267966043c,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-011a1514-90e5-4152-bab3-e31deed669af,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-096c6a0b-1bfe-4086-bdbb-984312e8d277,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-72ff6240-458f-4688-8236-4c37aa087a45,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-05077d1e-eca0-4802-b535-af6215c77cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-69475c39-e3cf-4514-8f22-ce24240edab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-77a0897d-c63c-4c18-8e56-f73bd676f6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-171146352-172.17.0.6-1597050050016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33420,DS-f6d560b1-1cb5-4dd1-8dbd-609b6b0886fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-05107948-9e36-4471-aabf-0a267966043c,DISK], DatanodeInfoWithStorage[127.0.0.1:42168,DS-011a1514-90e5-4152-bab3-e31deed669af,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-096c6a0b-1bfe-4086-bdbb-984312e8d277,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-72ff6240-458f-4688-8236-4c37aa087a45,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-05077d1e-eca0-4802-b535-af6215c77cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-69475c39-e3cf-4514-8f22-ce24240edab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-77a0897d-c63c-4c18-8e56-f73bd676f6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6664
