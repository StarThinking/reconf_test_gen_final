reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945981083-172.17.0.9-1597061930326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-d9e3081f-5186-4b24-b4db-dc8cd2b30ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-b787e71e-b1a9-4a86-9bd8-26055c60e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-3cb3c043-c3d6-4a56-8b8d-3e993780e800,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-c6274bb5-7e56-45fe-901f-719789b3f0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-e30a41d5-fd50-4559-bace-a5b5fb6e272b,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-a503015b-f827-4b88-b861-bd346a8a5ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-d793be92-9291-4717-a231-6d2e584ae27e,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-f6d81a61-70ce-459d-91e3-425620a3d5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945981083-172.17.0.9-1597061930326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-d9e3081f-5186-4b24-b4db-dc8cd2b30ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-b787e71e-b1a9-4a86-9bd8-26055c60e86e,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-3cb3c043-c3d6-4a56-8b8d-3e993780e800,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-c6274bb5-7e56-45fe-901f-719789b3f0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-e30a41d5-fd50-4559-bace-a5b5fb6e272b,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-a503015b-f827-4b88-b861-bd346a8a5ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-d793be92-9291-4717-a231-6d2e584ae27e,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-f6d81a61-70ce-459d-91e3-425620a3d5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387769266-172.17.0.9-1597062282776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44792,DS-95cd9ecb-833b-49a2-95a9-f4635180b034,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-5cb2a1b7-2b3a-40ea-84b3-1dfddb94b899,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-e4835ca2-a562-4eed-9893-676f237715fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-65e06b82-43a9-4c2b-9616-049cca556f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-2e3f6847-252e-4536-af13-9f90ebadc682,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-c674bbcc-850b-48dd-85d0-14df7980c4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-8e9d4644-de93-46d6-ae65-be9d4331d722,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-4b6adb22-d817-4aaf-b223-3c958ee755f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-387769266-172.17.0.9-1597062282776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44792,DS-95cd9ecb-833b-49a2-95a9-f4635180b034,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-5cb2a1b7-2b3a-40ea-84b3-1dfddb94b899,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-e4835ca2-a562-4eed-9893-676f237715fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-65e06b82-43a9-4c2b-9616-049cca556f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-2e3f6847-252e-4536-af13-9f90ebadc682,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-c674bbcc-850b-48dd-85d0-14df7980c4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-8e9d4644-de93-46d6-ae65-be9d4331d722,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-4b6adb22-d817-4aaf-b223-3c958ee755f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204657544-172.17.0.9-1597062377136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43137,DS-17d1a06e-b506-4845-b8cf-24b1a81e0bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-e72e8dbe-94fb-43cb-a964-18ec20e9c817,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-de3a3661-ea33-4289-802e-72b6deee3e70,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-44c7306f-a60b-42bc-92a7-8636d2847412,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-9ad12313-2727-44e1-ac8e-4f9ac62dfa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-f2c2ec3f-3dfe-455a-867e-b3d9ed28c730,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-b9f83e2e-6e79-4a54-b047-1d6e3f3e75bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-79ad6811-a657-4ea5-9890-564aea16dd24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204657544-172.17.0.9-1597062377136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43137,DS-17d1a06e-b506-4845-b8cf-24b1a81e0bef,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-e72e8dbe-94fb-43cb-a964-18ec20e9c817,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-de3a3661-ea33-4289-802e-72b6deee3e70,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-44c7306f-a60b-42bc-92a7-8636d2847412,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-9ad12313-2727-44e1-ac8e-4f9ac62dfa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-f2c2ec3f-3dfe-455a-867e-b3d9ed28c730,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-b9f83e2e-6e79-4a54-b047-1d6e3f3e75bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-79ad6811-a657-4ea5-9890-564aea16dd24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699919147-172.17.0.9-1597063208890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-97805807-2e25-41f1-865e-c18ecdb2ce0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-2de76069-67db-491d-aa00-b186f5baee54,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-228aa9a2-94e0-421d-8c6a-65d1c333651e,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-bf7dcd8c-c304-4091-ac2c-9ab2642746fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-a75ddccb-3668-4dc0-ba82-2ad9cde0c0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-ccdaf14c-83d3-4d1c-8f8d-72ce190dfce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-62c1a823-87c2-4e32-a781-b704100f193d,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-60663271-202a-47a9-8f95-9e149371db02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-699919147-172.17.0.9-1597063208890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36048,DS-97805807-2e25-41f1-865e-c18ecdb2ce0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-2de76069-67db-491d-aa00-b186f5baee54,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-228aa9a2-94e0-421d-8c6a-65d1c333651e,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-bf7dcd8c-c304-4091-ac2c-9ab2642746fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-a75ddccb-3668-4dc0-ba82-2ad9cde0c0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-ccdaf14c-83d3-4d1c-8f8d-72ce190dfce1,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-62c1a823-87c2-4e32-a781-b704100f193d,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-60663271-202a-47a9-8f95-9e149371db02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716518148-172.17.0.9-1597063305881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-9ea03bd3-689e-4840-9a90-37d11555d09d,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-dda053dc-7fa7-4404-908c-d7a609804ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-89d13a68-b5e9-423a-a8d3-3eaac4e9e2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-e931c6ae-6d94-4a55-9298-6f235e0e7c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-1d9ec2fd-2202-4084-b682-41f4a8f45b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-045d23b5-62f2-49f0-aef0-3cf6a194bca4,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-b5e86dca-d969-4f53-8549-153b7dfb90d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-cce17c63-c27b-4bea-b770-bdd8bf6f0d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716518148-172.17.0.9-1597063305881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45673,DS-9ea03bd3-689e-4840-9a90-37d11555d09d,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-dda053dc-7fa7-4404-908c-d7a609804ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-89d13a68-b5e9-423a-a8d3-3eaac4e9e2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-e931c6ae-6d94-4a55-9298-6f235e0e7c28,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-1d9ec2fd-2202-4084-b682-41f4a8f45b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-045d23b5-62f2-49f0-aef0-3cf6a194bca4,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-b5e86dca-d969-4f53-8549-153b7dfb90d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-cce17c63-c27b-4bea-b770-bdd8bf6f0d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398337408-172.17.0.9-1597063347411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-cff07670-3b89-487d-946a-4c19b7743c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-9a1ce377-1b7d-4f39-bd4a-ecb2ff2a130a,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-e02fdf1b-a09e-4574-917a-b6b6c326da4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-bad26060-91bd-4e26-af28-8ba573784d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-2772d962-17d4-44d8-aad9-d2045e5b9b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-ff47d9c0-253e-4fa2-bbcb-94dffad3fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-c4ce5ab7-5e82-4402-b6b1-676a2a3dcd59,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-4bfd8c39-3948-415b-a64b-70f9a4a9656f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398337408-172.17.0.9-1597063347411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-cff07670-3b89-487d-946a-4c19b7743c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-9a1ce377-1b7d-4f39-bd4a-ecb2ff2a130a,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-e02fdf1b-a09e-4574-917a-b6b6c326da4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-bad26060-91bd-4e26-af28-8ba573784d85,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-2772d962-17d4-44d8-aad9-d2045e5b9b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-ff47d9c0-253e-4fa2-bbcb-94dffad3fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-c4ce5ab7-5e82-4402-b6b1-676a2a3dcd59,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-4bfd8c39-3948-415b-a64b-70f9a4a9656f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716324814-172.17.0.9-1597063677146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36782,DS-21aa84bd-9931-4927-9fae-132cf6565fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-f47da189-8b72-409b-a024-1d22260c7c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-b96b1f4c-784b-4a32-8fb2-5661c94ca232,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-372648b2-0105-4669-a20e-9973f5c9e542,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-2da6b3f0-4737-49b9-95eb-a84135279124,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-dc65bc31-f746-41fc-9dc3-db456a42eadd,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-73c298fe-7460-40e0-b840-47d3eec648be,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-1474aed4-e9ad-4fa9-a560-a43b47aabdeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716324814-172.17.0.9-1597063677146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36782,DS-21aa84bd-9931-4927-9fae-132cf6565fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-f47da189-8b72-409b-a024-1d22260c7c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-b96b1f4c-784b-4a32-8fb2-5661c94ca232,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-372648b2-0105-4669-a20e-9973f5c9e542,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-2da6b3f0-4737-49b9-95eb-a84135279124,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-dc65bc31-f746-41fc-9dc3-db456a42eadd,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-73c298fe-7460-40e0-b840-47d3eec648be,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-1474aed4-e9ad-4fa9-a560-a43b47aabdeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368555678-172.17.0.9-1597063914350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45434,DS-691cfe6c-ea07-4182-8520-badff2aba14c,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-021c60fb-d938-4124-80cc-d8726140753e,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-fae20da2-3b9f-435a-bc02-38c654a58655,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-344a437f-906f-47a2-8524-835ac90eebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-870f48bb-e3b5-4246-8184-7effcf8ec556,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-5196bdb2-0e8c-4e44-9218-70f0a8d2b439,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-fc4d8e8d-f790-4a15-83d4-d6efe00e60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-a7008f97-6ba0-45eb-985c-582a75dd8b6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-368555678-172.17.0.9-1597063914350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45434,DS-691cfe6c-ea07-4182-8520-badff2aba14c,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-021c60fb-d938-4124-80cc-d8726140753e,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-fae20da2-3b9f-435a-bc02-38c654a58655,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-344a437f-906f-47a2-8524-835ac90eebbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46346,DS-870f48bb-e3b5-4246-8184-7effcf8ec556,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-5196bdb2-0e8c-4e44-9218-70f0a8d2b439,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-fc4d8e8d-f790-4a15-83d4-d6efe00e60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-a7008f97-6ba0-45eb-985c-582a75dd8b6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874606654-172.17.0.9-1597064497281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-7c8bae56-6573-475b-ac27-d0a6bbb246a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-b965d1ef-9471-41ab-956c-692f15199750,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-ca64d3c5-c6b1-4243-9291-8c7015bebaac,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-e01f468a-e7df-4a35-8156-8da492f19cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-cbd339a5-23d5-42f3-9c9a-7d8c0daa7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-3bcac81b-4b8f-4b26-a520-25912f7b6f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-787098d2-c478-4307-b6b9-2e46d4623b96,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-2018c5db-9f8b-4d22-b5fd-1da60ead348b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874606654-172.17.0.9-1597064497281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38559,DS-7c8bae56-6573-475b-ac27-d0a6bbb246a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-b965d1ef-9471-41ab-956c-692f15199750,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-ca64d3c5-c6b1-4243-9291-8c7015bebaac,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-e01f468a-e7df-4a35-8156-8da492f19cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-cbd339a5-23d5-42f3-9c9a-7d8c0daa7b90,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-3bcac81b-4b8f-4b26-a520-25912f7b6f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-787098d2-c478-4307-b6b9-2e46d4623b96,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-2018c5db-9f8b-4d22-b5fd-1da60ead348b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296241615-172.17.0.9-1597064543540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37975,DS-e0655a80-8d84-401f-ad94-cb754c751a29,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-c2517964-9342-428e-9075-7db4325bbf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-c86787a9-8996-4afc-af76-189476aa97c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-735f9204-85d8-4758-a2f7-99beaa83fa90,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-bd815d69-c865-4a2e-948f-9acfb8d3f636,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-5dd51699-4f8e-4643-9055-971fcf5edcce,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-e97644e2-9214-4024-8f75-47526d429501,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-7e4b1b7b-2820-4580-a9cf-f831c5a5e366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-296241615-172.17.0.9-1597064543540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37975,DS-e0655a80-8d84-401f-ad94-cb754c751a29,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-c2517964-9342-428e-9075-7db4325bbf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-c86787a9-8996-4afc-af76-189476aa97c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-735f9204-85d8-4758-a2f7-99beaa83fa90,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-bd815d69-c865-4a2e-948f-9acfb8d3f636,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-5dd51699-4f8e-4643-9055-971fcf5edcce,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-e97644e2-9214-4024-8f75-47526d429501,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-7e4b1b7b-2820-4580-a9cf-f831c5a5e366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328907949-172.17.0.9-1597064775726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36806,DS-84afd0f7-9dc5-43ea-83d0-02380c4749c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-71fe9de0-fbfd-4f93-b049-a12310889174,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-d88da6bc-86ac-4e2b-b333-a8afef65f067,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-c421461e-96c1-470d-a087-a6d37c6fa403,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-b3e12d37-dab7-48e5-a92a-6a4a90b51179,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1c14fcd0-4eee-4e85-9b86-e152d2bcba35,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-2b6256d7-f6e9-4bee-bde9-afcba2a97667,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-45f4990d-49ba-4227-bf99-fc16e0743ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328907949-172.17.0.9-1597064775726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36806,DS-84afd0f7-9dc5-43ea-83d0-02380c4749c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-71fe9de0-fbfd-4f93-b049-a12310889174,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-d88da6bc-86ac-4e2b-b333-a8afef65f067,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-c421461e-96c1-470d-a087-a6d37c6fa403,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-b3e12d37-dab7-48e5-a92a-6a4a90b51179,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1c14fcd0-4eee-4e85-9b86-e152d2bcba35,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-2b6256d7-f6e9-4bee-bde9-afcba2a97667,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-45f4990d-49ba-4227-bf99-fc16e0743ad7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573768829-172.17.0.9-1597065764858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42363,DS-0284842e-b8d3-417e-ad9c-5d74a50bad78,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-50bd8c48-8315-4dd8-b43c-1640a7e7845d,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-3d4a9b4a-2bbb-4ea6-a85d-1f1f79da3a11,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-1450d4ac-478c-4dbd-a1ac-4c05feb80777,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-885299ce-5053-407a-8565-852f5fdf3282,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-e68c516d-4c75-46e2-b0d6-386ec6847d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-61b1a5d0-dd70-4558-bc08-65144bd164d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-d11e6eb5-affb-4877-9246-49aae1a0716c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573768829-172.17.0.9-1597065764858:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42363,DS-0284842e-b8d3-417e-ad9c-5d74a50bad78,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-50bd8c48-8315-4dd8-b43c-1640a7e7845d,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-3d4a9b4a-2bbb-4ea6-a85d-1f1f79da3a11,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-1450d4ac-478c-4dbd-a1ac-4c05feb80777,DISK], DatanodeInfoWithStorage[127.0.0.1:43745,DS-885299ce-5053-407a-8565-852f5fdf3282,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-e68c516d-4c75-46e2-b0d6-386ec6847d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-61b1a5d0-dd70-4558-bc08-65144bd164d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-d11e6eb5-affb-4877-9246-49aae1a0716c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893581326-172.17.0.9-1597065841734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-33883335-bf8a-4928-80e8-b9513d0eed03,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-c3ee6abc-f17b-4939-a515-b6f607226f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-6094e8b6-32de-43a7-a72b-b1f94a6f4c32,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-73fc4c28-c387-4381-80fd-61fc654c498c,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-5a34c3c3-20f0-4af5-b75a-125f9be2a437,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-56897d6e-ab33-4431-8c40-2914acfeb8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-3c7f5031-64f9-4a90-80eb-14173f536f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-cd27b416-28e6-4ede-a8e0-28f983d77c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1893581326-172.17.0.9-1597065841734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-33883335-bf8a-4928-80e8-b9513d0eed03,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-c3ee6abc-f17b-4939-a515-b6f607226f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-6094e8b6-32de-43a7-a72b-b1f94a6f4c32,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-73fc4c28-c387-4381-80fd-61fc654c498c,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-5a34c3c3-20f0-4af5-b75a-125f9be2a437,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-56897d6e-ab33-4431-8c40-2914acfeb8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-3c7f5031-64f9-4a90-80eb-14173f536f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-cd27b416-28e6-4ede-a8e0-28f983d77c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edekcacheloader.initial.delay.ms
component: hdfs:NameNode
v1: 300
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299586320-172.17.0.9-1597066245891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45631,DS-c13aec7a-d3f7-41a8-86a0-5dcdc94ff239,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-bc2a23b3-e1cc-4768-b0fb-4a71b8ef5a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-139f8227-9b86-46be-9cac-0c83122256a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-6b73a3e0-15af-455f-87ff-09a1979334c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-02b06a58-743b-4fbb-8bd2-3911ac43b6be,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-e1428080-96b9-4086-a0a6-309a6652051a,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-c97ad751-6d6f-4541-bad3-acdd14a95324,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-6b224c9f-62c6-42ca-9eda-90a2eb359264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299586320-172.17.0.9-1597066245891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45631,DS-c13aec7a-d3f7-41a8-86a0-5dcdc94ff239,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-bc2a23b3-e1cc-4768-b0fb-4a71b8ef5a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-139f8227-9b86-46be-9cac-0c83122256a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-6b73a3e0-15af-455f-87ff-09a1979334c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-02b06a58-743b-4fbb-8bd2-3911ac43b6be,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-e1428080-96b9-4086-a0a6-309a6652051a,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-c97ad751-6d6f-4541-bad3-acdd14a95324,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-6b224c9f-62c6-42ca-9eda-90a2eb359264,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6775
