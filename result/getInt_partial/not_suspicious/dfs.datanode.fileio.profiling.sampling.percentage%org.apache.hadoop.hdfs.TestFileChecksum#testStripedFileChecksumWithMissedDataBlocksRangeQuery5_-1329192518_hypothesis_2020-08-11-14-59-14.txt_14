reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078822707-172.17.0.15-1597158038997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-e1a044e2-bc16-4d1b-9a7c-ca5593e87845,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-2bd3f3a8-5daa-4b5d-b510-4aa7e6af9b02,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-7f5b804c-011a-4e6f-bd34-1157d2128059,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-a7cfbe47-025f-47fb-917c-a5d5a68dd72b,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-629a9785-9fac-4697-b108-fbc0c9765eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-a2d333ac-017f-4d38-8c03-410d3c7b030a,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-050e5ea9-062b-490f-812a-f1868d0ddb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-9b6b1198-af0f-445e-8faa-f9e8c3fbb29c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078822707-172.17.0.15-1597158038997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37179,DS-e1a044e2-bc16-4d1b-9a7c-ca5593e87845,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-2bd3f3a8-5daa-4b5d-b510-4aa7e6af9b02,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-7f5b804c-011a-4e6f-bd34-1157d2128059,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-a7cfbe47-025f-47fb-917c-a5d5a68dd72b,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-629a9785-9fac-4697-b108-fbc0c9765eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-a2d333ac-017f-4d38-8c03-410d3c7b030a,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-050e5ea9-062b-490f-812a-f1868d0ddb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-9b6b1198-af0f-445e-8faa-f9e8c3fbb29c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298648396-172.17.0.15-1597158073532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42169,DS-7f3bd08c-3014-4e2e-b824-89f87d04c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-c4d0470e-cb70-44c8-984b-34aded8a7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-f93be24a-46b1-4b68-b1db-1344425851c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-a0d29f92-6cc9-40da-a7b6-15a6db99e35b,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-95e24496-481e-4a49-b804-c396ff6dc34b,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-fe9f22ff-a523-4898-b769-a458fbb7934b,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-a399e059-af98-4542-8868-36d146b0f564,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-c228b6d1-fd4a-46fd-b47b-0fc7a86c59d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298648396-172.17.0.15-1597158073532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42169,DS-7f3bd08c-3014-4e2e-b824-89f87d04c40e,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-c4d0470e-cb70-44c8-984b-34aded8a7d83,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-f93be24a-46b1-4b68-b1db-1344425851c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-a0d29f92-6cc9-40da-a7b6-15a6db99e35b,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-95e24496-481e-4a49-b804-c396ff6dc34b,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-fe9f22ff-a523-4898-b769-a458fbb7934b,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-a399e059-af98-4542-8868-36d146b0f564,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-c228b6d1-fd4a-46fd-b47b-0fc7a86c59d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464563073-172.17.0.15-1597158175960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33287,DS-031bf892-544e-477a-a2fb-4cc349ba85e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-5372475a-52d4-4be9-a822-7201f5c59430,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-a757fbd7-95ce-4039-84fd-ae817e8f27f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-32344207-ac7d-4e3a-af48-6069952d7949,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-466db44f-feaf-4341-a036-bc61877d4d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-ead91854-083d-450d-866f-23722f76f943,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-2d068763-6035-45cf-ae39-c095d00bc1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-547271a1-dd43-4625-a96f-9a215b12e4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464563073-172.17.0.15-1597158175960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33287,DS-031bf892-544e-477a-a2fb-4cc349ba85e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-5372475a-52d4-4be9-a822-7201f5c59430,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-a757fbd7-95ce-4039-84fd-ae817e8f27f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-32344207-ac7d-4e3a-af48-6069952d7949,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-466db44f-feaf-4341-a036-bc61877d4d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-ead91854-083d-450d-866f-23722f76f943,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-2d068763-6035-45cf-ae39-c095d00bc1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-547271a1-dd43-4625-a96f-9a215b12e4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525936834-172.17.0.15-1597158398882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-7e39212e-5e82-4d3a-9163-ae0b28d6e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-9636ccbc-5f21-43fb-958c-de1aeb54a35f,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-5f3ca292-5a40-4ebb-a30b-3f37dff6a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-d539f925-7d5c-4114-85db-6e6afa2d6721,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-ec055ba9-ed1c-47bf-bac9-bcb5a12206b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-aad69c4e-ae44-4493-af65-ca43cea1f64e,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-d70551d7-0a30-4671-975a-dc10f0b52935,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-ea1025d7-f1f5-4862-8952-9fd09d5b47ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525936834-172.17.0.15-1597158398882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-7e39212e-5e82-4d3a-9163-ae0b28d6e5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-9636ccbc-5f21-43fb-958c-de1aeb54a35f,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-5f3ca292-5a40-4ebb-a30b-3f37dff6a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-d539f925-7d5c-4114-85db-6e6afa2d6721,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-ec055ba9-ed1c-47bf-bac9-bcb5a12206b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-aad69c4e-ae44-4493-af65-ca43cea1f64e,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-d70551d7-0a30-4671-975a-dc10f0b52935,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-ea1025d7-f1f5-4862-8952-9fd09d5b47ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786912948-172.17.0.15-1597159382239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46360,DS-8b77b5b5-315a-4bc1-bcf2-8a2eb48a8d00,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-da94cc15-1069-4ec1-b8c1-8e395e85ebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-47df4378-a539-465b-831e-a7b90af7a4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-e2b184e8-1973-4439-9fb2-72c6ba6c9823,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-7cd81fd7-4ba2-470a-9964-c078b09eaba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-b710b77e-99ad-418c-9628-401b070beafa,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-d3a09710-78f5-4039-9d91-49a387edda53,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-4862684f-557e-4b1f-afa6-abb22c1d94c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786912948-172.17.0.15-1597159382239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46360,DS-8b77b5b5-315a-4bc1-bcf2-8a2eb48a8d00,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-da94cc15-1069-4ec1-b8c1-8e395e85ebbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-47df4378-a539-465b-831e-a7b90af7a4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-e2b184e8-1973-4439-9fb2-72c6ba6c9823,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-7cd81fd7-4ba2-470a-9964-c078b09eaba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-b710b77e-99ad-418c-9628-401b070beafa,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-d3a09710-78f5-4039-9d91-49a387edda53,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-4862684f-557e-4b1f-afa6-abb22c1d94c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106072211-172.17.0.15-1597159531571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41136,DS-e228f554-a4ed-4189-9a96-ff874b520ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-6aad1f9e-2d12-4a2b-9f81-4b6afa66de7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-05692dee-9f79-42c4-a0d2-6a3c1341c1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-0150a739-aa5b-4047-a9a8-b63ac5d0ab88,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-cc980695-d7ed-444f-8beb-c8c273b9c6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-31305ae9-010a-4322-9185-eed61473fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-f6b00412-c134-4d67-8997-2e064c054990,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-d829cf7e-3925-457a-994b-2533304b61a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106072211-172.17.0.15-1597159531571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41136,DS-e228f554-a4ed-4189-9a96-ff874b520ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-6aad1f9e-2d12-4a2b-9f81-4b6afa66de7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-05692dee-9f79-42c4-a0d2-6a3c1341c1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-0150a739-aa5b-4047-a9a8-b63ac5d0ab88,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-cc980695-d7ed-444f-8beb-c8c273b9c6f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-31305ae9-010a-4322-9185-eed61473fa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-f6b00412-c134-4d67-8997-2e064c054990,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-d829cf7e-3925-457a-994b-2533304b61a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567676160-172.17.0.15-1597159635224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38110,DS-137bfde9-d657-42cc-abba-ede57be2828c,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-5fd92e8e-b54a-4457-9650-4ca6e76e06d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-b5dc1e90-3007-4e3d-8e25-aa4ab0d542f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-39fb19e5-814b-45f2-a804-0448ac73f529,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-e1678f57-bb33-429b-b410-542e9509b161,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-42a0dd15-c532-43c1-a853-57f19d3b29e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-d847971a-4423-413b-9442-cc68ddd5367a,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-9afd5247-ea10-4071-99fe-75a00a093356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567676160-172.17.0.15-1597159635224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38110,DS-137bfde9-d657-42cc-abba-ede57be2828c,DISK], DatanodeInfoWithStorage[127.0.0.1:46100,DS-5fd92e8e-b54a-4457-9650-4ca6e76e06d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-b5dc1e90-3007-4e3d-8e25-aa4ab0d542f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-39fb19e5-814b-45f2-a804-0448ac73f529,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-e1678f57-bb33-429b-b410-542e9509b161,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-42a0dd15-c532-43c1-a853-57f19d3b29e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-d847971a-4423-413b-9442-cc68ddd5367a,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-9afd5247-ea10-4071-99fe-75a00a093356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104861943-172.17.0.15-1597159892354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34213,DS-99e6a249-b01e-4a19-9c5e-d74f4e2faacc,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-391fe366-046d-4c63-91f4-97ecbb8bc710,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-43c45cc1-a174-4e79-8737-22d0045e4c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-9c65eac7-53cb-4f7d-b52c-61cf2b7273ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-d456b319-216c-4bd7-91a2-38453bf16cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-08c5d61f-e67b-4a33-812a-59a76c575c59,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-df727d36-1282-49bf-976d-6c6563a83062,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-4f6abd9f-6921-430d-8255-06acb90a255a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104861943-172.17.0.15-1597159892354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34213,DS-99e6a249-b01e-4a19-9c5e-d74f4e2faacc,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-391fe366-046d-4c63-91f4-97ecbb8bc710,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-43c45cc1-a174-4e79-8737-22d0045e4c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-9c65eac7-53cb-4f7d-b52c-61cf2b7273ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-d456b319-216c-4bd7-91a2-38453bf16cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-08c5d61f-e67b-4a33-812a-59a76c575c59,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-df727d36-1282-49bf-976d-6c6563a83062,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-4f6abd9f-6921-430d-8255-06acb90a255a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132853414-172.17.0.15-1597160102955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33836,DS-b15bb25a-a23f-4a05-8c46-5931ba9d57c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-b3a0fa44-e298-4e5a-b2da-f46952a38f37,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-6515efc6-e118-444d-925d-35ec5e7e9464,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-d5043be5-fc70-4de2-b786-7a3a8b42ed42,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-f70bf39e-f845-413f-a589-3ee82606a648,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-5d954cde-509b-48da-bdf1-61a02c9cbad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-c717cbe6-d868-4ab0-9d9e-1117527d9eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-237d32a9-fcb5-4eed-bfec-adf17f0cfebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132853414-172.17.0.15-1597160102955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33836,DS-b15bb25a-a23f-4a05-8c46-5931ba9d57c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-b3a0fa44-e298-4e5a-b2da-f46952a38f37,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-6515efc6-e118-444d-925d-35ec5e7e9464,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-d5043be5-fc70-4de2-b786-7a3a8b42ed42,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-f70bf39e-f845-413f-a589-3ee82606a648,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-5d954cde-509b-48da-bdf1-61a02c9cbad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-c717cbe6-d868-4ab0-9d9e-1117527d9eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-237d32a9-fcb5-4eed-bfec-adf17f0cfebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970922619-172.17.0.15-1597160167748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-ed0b3de7-20fa-4b07-adfd-1355f15b573e,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-f4daefcb-44d2-40da-9491-c9dce40f3c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-82386ae5-5803-421f-ad33-9a92146a1124,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-0d724ede-76ab-44eb-b61f-fd455f20dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-032c3445-6f12-419a-8788-5a81c1d7a4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-1acb804e-3540-40be-908d-edaab0627ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-12590a26-4e1d-45b7-b4ff-cd5d4d495fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-9c6202e6-773c-46e5-9133-258999238b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970922619-172.17.0.15-1597160167748:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-ed0b3de7-20fa-4b07-adfd-1355f15b573e,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-f4daefcb-44d2-40da-9491-c9dce40f3c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-82386ae5-5803-421f-ad33-9a92146a1124,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-0d724ede-76ab-44eb-b61f-fd455f20dbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-032c3445-6f12-419a-8788-5a81c1d7a4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-1acb804e-3540-40be-908d-edaab0627ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-12590a26-4e1d-45b7-b4ff-cd5d4d495fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-9c6202e6-773c-46e5-9133-258999238b28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907351418-172.17.0.15-1597160204402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43119,DS-8790a882-f914-458a-869a-a0a7524684f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-0af80005-ed5a-482b-bef7-a9cb294c91f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-e245df56-788e-412d-a5eb-5a0f62c1d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-5c9d6f81-8897-4d42-a2b4-abf32c801faa,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-f889c1b5-0c00-4e9b-bb14-89dfbb0ac9db,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-d70b4053-f11f-466c-94fd-7bf3142de87e,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-a8ad4c23-7d92-491a-9321-dcf3f118134a,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-e9be41bc-7a83-40b1-b4fb-8f8b328dacfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-907351418-172.17.0.15-1597160204402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43119,DS-8790a882-f914-458a-869a-a0a7524684f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-0af80005-ed5a-482b-bef7-a9cb294c91f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-e245df56-788e-412d-a5eb-5a0f62c1d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-5c9d6f81-8897-4d42-a2b4-abf32c801faa,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-f889c1b5-0c00-4e9b-bb14-89dfbb0ac9db,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-d70b4053-f11f-466c-94fd-7bf3142de87e,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-a8ad4c23-7d92-491a-9321-dcf3f118134a,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-e9be41bc-7a83-40b1-b4fb-8f8b328dacfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364769366-172.17.0.15-1597160341397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34236,DS-09234cad-9f79-4169-ac79-729fff341b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-dfdf0618-15b2-4768-bf3a-0998c7cf1c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-0bfff118-5a3c-4223-a15d-cb59b1d1ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-dfd23a60-289f-4d4e-af8f-7225fad12b51,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-43f75630-ef8d-4c2c-850d-83e78ee443a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-fdcf5ffd-343d-4949-ba73-7e4aab536fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-5d1712aa-4685-43c7-b46b-b3412a7714b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-39a2a246-ba81-45e2-97f6-c0df3662230f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364769366-172.17.0.15-1597160341397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34236,DS-09234cad-9f79-4169-ac79-729fff341b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-dfdf0618-15b2-4768-bf3a-0998c7cf1c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-0bfff118-5a3c-4223-a15d-cb59b1d1ea0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-dfd23a60-289f-4d4e-af8f-7225fad12b51,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-43f75630-ef8d-4c2c-850d-83e78ee443a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-fdcf5ffd-343d-4949-ba73-7e4aab536fce,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-5d1712aa-4685-43c7-b46b-b3412a7714b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33228,DS-39a2a246-ba81-45e2-97f6-c0df3662230f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497976232-172.17.0.15-1597161286075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35506,DS-ebef208d-571b-4818-a2d7-5112e426789b,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-7fc64caf-d61c-43d1-a6ac-cd14d0ce7528,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-7c7f1ca5-c93b-4913-80f4-e5cbdb546aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4d77b3ae-acb1-4395-abf0-923055de1562,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-38ba45b3-5a81-4771-80cf-0392ca4038d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-fc29c0ad-ab8b-4d64-b7dc-4149ddf612b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-2acee0fa-cef5-42d0-9855-80b125b068b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-3b4cdf1a-90ea-4398-a596-99ad2892340c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1497976232-172.17.0.15-1597161286075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35506,DS-ebef208d-571b-4818-a2d7-5112e426789b,DISK], DatanodeInfoWithStorage[127.0.0.1:36183,DS-7fc64caf-d61c-43d1-a6ac-cd14d0ce7528,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-7c7f1ca5-c93b-4913-80f4-e5cbdb546aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-4d77b3ae-acb1-4395-abf0-923055de1562,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-38ba45b3-5a81-4771-80cf-0392ca4038d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-fc29c0ad-ab8b-4d64-b7dc-4149ddf612b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-2acee0fa-cef5-42d0-9855-80b125b068b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-3b4cdf1a-90ea-4398-a596-99ad2892340c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501225673-172.17.0.15-1597161502326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38928,DS-d4f0a620-c298-4fb7-bd6e-6e6a38a8cfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-34ccf566-70b6-45f5-b6b7-d4af2b64a783,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-689d5cd3-2931-43c7-8ade-66f322faaf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-bc7d6bea-e3dd-4271-8339-1afd089030d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-4c974382-8efc-4b51-9d28-b1cafd1d67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-16054557-dfa7-497a-a5d6-865370d16a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-073adb46-a635-4761-bae4-e82c70a4e053,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-17481477-3950-4d47-be92-094d81afa258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501225673-172.17.0.15-1597161502326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38928,DS-d4f0a620-c298-4fb7-bd6e-6e6a38a8cfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-34ccf566-70b6-45f5-b6b7-d4af2b64a783,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-689d5cd3-2931-43c7-8ade-66f322faaf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-bc7d6bea-e3dd-4271-8339-1afd089030d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-4c974382-8efc-4b51-9d28-b1cafd1d67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-16054557-dfa7-497a-a5d6-865370d16a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-073adb46-a635-4761-bae4-e82c70a4e053,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-17481477-3950-4d47-be92-094d81afa258,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047631776-172.17.0.15-1597161796916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-ba283aba-2c37-47e4-b903-adec3421563e,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-d80f04b9-b431-421d-82cc-be020c1e133c,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-89dace58-fe92-4b60-b2cc-e28347265a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-f2817418-67d8-417d-b08c-842a0b4abfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-1ac8b8ce-1ccb-45e5-9132-dff444ab91fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-e2c17b7a-a1c8-4ea0-a141-727dc6bf20db,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-353249b7-e2fd-41c4-ae8d-69fa747713d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-95a30f3d-bab4-45ae-ba49-b7dca1539d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047631776-172.17.0.15-1597161796916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-ba283aba-2c37-47e4-b903-adec3421563e,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-d80f04b9-b431-421d-82cc-be020c1e133c,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-89dace58-fe92-4b60-b2cc-e28347265a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-f2817418-67d8-417d-b08c-842a0b4abfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-1ac8b8ce-1ccb-45e5-9132-dff444ab91fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-e2c17b7a-a1c8-4ea0-a141-727dc6bf20db,DISK], DatanodeInfoWithStorage[127.0.0.1:40902,DS-353249b7-e2fd-41c4-ae8d-69fa747713d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-95a30f3d-bab4-45ae-ba49-b7dca1539d09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:NameNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953352553-172.17.0.15-1597162234239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40942,DS-d0c33b64-76dd-4df0-998b-55a13478a4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-be805370-920e-4866-9d49-02a111ba8152,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-70850249-d2ff-4479-9497-d045ceab6f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-e93fcd36-0ccd-4e36-bc51-e117e8bcb188,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-8a3895d2-ce29-4524-bbd0-63b76e02547a,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-35bdc275-106a-4039-98c0-ff307bcdc701,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-55199eec-a8c1-4aab-a818-7ad07afb9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-9cd460a0-47cf-4f20-ac6a-f5105f688ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953352553-172.17.0.15-1597162234239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40942,DS-d0c33b64-76dd-4df0-998b-55a13478a4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-be805370-920e-4866-9d49-02a111ba8152,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-70850249-d2ff-4479-9497-d045ceab6f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-e93fcd36-0ccd-4e36-bc51-e117e8bcb188,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-8a3895d2-ce29-4524-bbd0-63b76e02547a,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-35bdc275-106a-4039-98c0-ff307bcdc701,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-55199eec-a8c1-4aab-a818-7ad07afb9eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-9cd460a0-47cf-4f20-ac6a-f5105f688ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5503
