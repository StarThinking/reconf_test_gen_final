reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507785585-172.17.0.21-1597180564546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-05e8488d-bb7e-46c3-9a22-bc8d55ac197d,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-c6231d04-cd42-493c-9a61-b6d153c902b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-f9013701-3161-4de3-8828-e98af9fab68c,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-b288dada-ea7d-4568-97f3-c1ac87ba1283,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-e56a6f08-04ec-45f9-ae9b-c8947273eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-0edfd689-a4a6-4afb-ba5a-b502990caa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-d33be3b5-79c2-4216-a543-4648d47ff2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-51ce6c91-b312-4add-84d4-5cbe7b602d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507785585-172.17.0.21-1597180564546:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45320,DS-05e8488d-bb7e-46c3-9a22-bc8d55ac197d,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-c6231d04-cd42-493c-9a61-b6d153c902b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-f9013701-3161-4de3-8828-e98af9fab68c,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-b288dada-ea7d-4568-97f3-c1ac87ba1283,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-e56a6f08-04ec-45f9-ae9b-c8947273eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-0edfd689-a4a6-4afb-ba5a-b502990caa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-d33be3b5-79c2-4216-a543-4648d47ff2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-51ce6c91-b312-4add-84d4-5cbe7b602d87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703432390-172.17.0.21-1597180775539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-1a933f0f-5417-4ea6-8a17-a1fa36b3b0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-1541d27a-cedf-4867-be31-d2490853b7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-efcd5001-de13-4471-9ac0-1ea33e9fb007,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-be32739d-7d30-40ad-a049-fa2a209dfa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-08ead5ca-a743-41c7-b783-c2b2707c66ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-19e79ad6-1da8-4b95-930b-eacbf8034e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-beff67f8-48fa-4335-b995-c11024363f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-aa0a2148-d374-4511-b394-b8edea68c765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703432390-172.17.0.21-1597180775539:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-1a933f0f-5417-4ea6-8a17-a1fa36b3b0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-1541d27a-cedf-4867-be31-d2490853b7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-efcd5001-de13-4471-9ac0-1ea33e9fb007,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-be32739d-7d30-40ad-a049-fa2a209dfa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-08ead5ca-a743-41c7-b783-c2b2707c66ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-19e79ad6-1da8-4b95-930b-eacbf8034e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-beff67f8-48fa-4335-b995-c11024363f74,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-aa0a2148-d374-4511-b394-b8edea68c765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172324516-172.17.0.21-1597181051271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-70826586-fc79-4c98-a567-ac23d36054e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-0c60615d-080f-4e37-b815-c180f13f55b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-c919f60a-07d4-4f94-9ffd-6a6fa26aa50d,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-84f947d1-95de-4043-b541-0894c2b0a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-86f4b5f8-0197-442d-abe9-81b3d023df12,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-dd5039fc-5791-4c4c-a190-6deefb2696d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-41ce6d14-8882-4b94-a75f-b26155ce0726,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-0b693724-f612-4c4b-8115-baad4b73f8dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172324516-172.17.0.21-1597181051271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38231,DS-70826586-fc79-4c98-a567-ac23d36054e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-0c60615d-080f-4e37-b815-c180f13f55b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-c919f60a-07d4-4f94-9ffd-6a6fa26aa50d,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-84f947d1-95de-4043-b541-0894c2b0a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-86f4b5f8-0197-442d-abe9-81b3d023df12,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-dd5039fc-5791-4c4c-a190-6deefb2696d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-41ce6d14-8882-4b94-a75f-b26155ce0726,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-0b693724-f612-4c4b-8115-baad4b73f8dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295843407-172.17.0.21-1597181406679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-fc301f48-38e3-45a7-8d89-bc34be566782,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-7258a839-d0f4-4c6b-861e-c962fce08848,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-3ce85466-700a-46cb-bce6-4a9ed8fea7de,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-22fd2db0-4d34-4f89-a899-6f88c7f4bca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-928f41df-f696-4276-9677-f107485fe653,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e47c54bb-3850-445e-a077-0dd46961be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-31f5ccee-b00b-48cf-9027-3ed9086d7754,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-633c2eb0-a55f-4e29-9b17-ae28631eaf19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295843407-172.17.0.21-1597181406679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-fc301f48-38e3-45a7-8d89-bc34be566782,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-7258a839-d0f4-4c6b-861e-c962fce08848,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-3ce85466-700a-46cb-bce6-4a9ed8fea7de,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-22fd2db0-4d34-4f89-a899-6f88c7f4bca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34688,DS-928f41df-f696-4276-9677-f107485fe653,DISK], DatanodeInfoWithStorage[127.0.0.1:42210,DS-e47c54bb-3850-445e-a077-0dd46961be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-31f5ccee-b00b-48cf-9027-3ed9086d7754,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-633c2eb0-a55f-4e29-9b17-ae28631eaf19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318734636-172.17.0.21-1597181985503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-a491ebd4-eb11-43c9-99a0-873ed82e8141,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-c23d0937-c7ba-4445-86b9-96f646804b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-c77d81c6-4587-414c-b28c-02554abd4fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-4c6ccf11-74e6-4852-87b2-be904f66ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-a2ded4a2-d986-4816-856e-6d7f389ee6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-a689a053-6b14-4571-955e-71987ad5d6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-347c8f07-e719-4c8c-a39e-63a267f5b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-8e68e4b5-f3b2-4030-a1d8-6922596ad6e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318734636-172.17.0.21-1597181985503:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-a491ebd4-eb11-43c9-99a0-873ed82e8141,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-c23d0937-c7ba-4445-86b9-96f646804b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-c77d81c6-4587-414c-b28c-02554abd4fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-4c6ccf11-74e6-4852-87b2-be904f66ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-a2ded4a2-d986-4816-856e-6d7f389ee6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-a689a053-6b14-4571-955e-71987ad5d6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-347c8f07-e719-4c8c-a39e-63a267f5b5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-8e68e4b5-f3b2-4030-a1d8-6922596ad6e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886693443-172.17.0.21-1597182127161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-6e70842d-391d-467a-b66f-e4cf65d873b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-9811f8f9-74bc-40b6-a438-83ceb4280069,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-6749db12-6b16-4b71-b81a-51f8b2e7012a,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-35647e83-1845-4907-8a44-bb922682e983,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-058ee8d3-8ce9-4ad5-a262-5033881e3058,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-8a2857d2-a8de-4eba-a14c-9eb6f5314a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-42ef8727-a0d8-4786-8fbc-1d227355d828,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-76bd774c-1ed7-4971-a224-90afc1f96479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886693443-172.17.0.21-1597182127161:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-6e70842d-391d-467a-b66f-e4cf65d873b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-9811f8f9-74bc-40b6-a438-83ceb4280069,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-6749db12-6b16-4b71-b81a-51f8b2e7012a,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-35647e83-1845-4907-8a44-bb922682e983,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-058ee8d3-8ce9-4ad5-a262-5033881e3058,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-8a2857d2-a8de-4eba-a14c-9eb6f5314a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-42ef8727-a0d8-4786-8fbc-1d227355d828,DISK], DatanodeInfoWithStorage[127.0.0.1:37744,DS-76bd774c-1ed7-4971-a224-90afc1f96479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194740103-172.17.0.21-1597182330439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39826,DS-635bbee6-5b88-457e-a98d-b702647da37d,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-f74a06ad-4f32-4108-afc6-41d469c8d7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-a56b4657-70b5-461a-9afa-90684017f315,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-cf9c423a-b4a4-4792-9e0c-f3d42c8b50e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-f4ab6340-6946-445c-a907-04bfde1b542f,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-b8c21798-459d-4472-9f05-33c2fd820506,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-88d63d2e-1268-44a2-ae2c-d93a166508e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-b1d321fa-cd7c-4c22-8f22-c37e69e04a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-194740103-172.17.0.21-1597182330439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39826,DS-635bbee6-5b88-457e-a98d-b702647da37d,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-f74a06ad-4f32-4108-afc6-41d469c8d7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-a56b4657-70b5-461a-9afa-90684017f315,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-cf9c423a-b4a4-4792-9e0c-f3d42c8b50e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-f4ab6340-6946-445c-a907-04bfde1b542f,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-b8c21798-459d-4472-9f05-33c2fd820506,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-88d63d2e-1268-44a2-ae2c-d93a166508e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-b1d321fa-cd7c-4c22-8f22-c37e69e04a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717610009-172.17.0.21-1597182363830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38176,DS-0ecf830c-1e1e-42c7-b8ad-4fc5140dcd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-5c848dc9-7701-4a86-9d5a-845e308bb8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-e43e2517-3414-47e5-b125-d6c33c72a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-0fce75bc-4734-4279-ab62-6e6e026231c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-b3b7e414-a830-4a8d-87f7-0ff43be95cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-69273a6c-6296-4f15-b311-b91a94a7c776,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-b4940cd3-44be-44c3-8bfe-ab27c9b076f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-05a51f7e-d248-4379-a028-52e6c2141597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1717610009-172.17.0.21-1597182363830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38176,DS-0ecf830c-1e1e-42c7-b8ad-4fc5140dcd82,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-5c848dc9-7701-4a86-9d5a-845e308bb8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-e43e2517-3414-47e5-b125-d6c33c72a9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-0fce75bc-4734-4279-ab62-6e6e026231c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-b3b7e414-a830-4a8d-87f7-0ff43be95cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-69273a6c-6296-4f15-b311-b91a94a7c776,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-b4940cd3-44be-44c3-8bfe-ab27c9b076f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-05a51f7e-d248-4379-a028-52e6c2141597,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117737659-172.17.0.21-1597182465451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-a525f004-9d7c-4ec8-9253-be3342a4f98b,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-055b4220-e26d-4b38-becb-0c98e795312d,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-43df4705-107f-49f8-9ec7-d52485ac3ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-6b2cc353-c645-4888-b1d6-d81bbd502c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-a85f93e9-618b-4e2f-aab6-9ed27ea30f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-77e2aa91-1aa1-4ab5-88bf-9b160617c472,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-5fca9255-ed43-4777-80e3-0f15f31df481,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-6dfaf70d-3653-45f7-8599-81561ef71810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117737659-172.17.0.21-1597182465451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33215,DS-a525f004-9d7c-4ec8-9253-be3342a4f98b,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-055b4220-e26d-4b38-becb-0c98e795312d,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-43df4705-107f-49f8-9ec7-d52485ac3ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-6b2cc353-c645-4888-b1d6-d81bbd502c53,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-a85f93e9-618b-4e2f-aab6-9ed27ea30f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-77e2aa91-1aa1-4ab5-88bf-9b160617c472,DISK], DatanodeInfoWithStorage[127.0.0.1:45096,DS-5fca9255-ed43-4777-80e3-0f15f31df481,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-6dfaf70d-3653-45f7-8599-81561ef71810,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908905463-172.17.0.21-1597182991775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37659,DS-0c92c5fd-f4bb-4359-862b-b148885d3130,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-cf39e5cb-8488-4ec1-825c-aa0d8ec19b95,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-6d57cc0f-069c-4cb4-be34-c9d7d1b477ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-78362320-de7e-426b-8449-9258d972d09f,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-535ff9e5-9332-4783-9011-6e4057afaf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-b510d0aa-2fab-4a69-9ab0-687f39f751c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-19e245b5-b7d9-495c-9c8f-008f9748b037,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-2642c7db-2551-4713-9209-eb64fc2eaf02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908905463-172.17.0.21-1597182991775:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37659,DS-0c92c5fd-f4bb-4359-862b-b148885d3130,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-cf39e5cb-8488-4ec1-825c-aa0d8ec19b95,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-6d57cc0f-069c-4cb4-be34-c9d7d1b477ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34060,DS-78362320-de7e-426b-8449-9258d972d09f,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-535ff9e5-9332-4783-9011-6e4057afaf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-b510d0aa-2fab-4a69-9ab0-687f39f751c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-19e245b5-b7d9-495c-9c8f-008f9748b037,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-2642c7db-2551-4713-9209-eb64fc2eaf02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490053761-172.17.0.21-1597183021872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34223,DS-693e6c47-a0ed-4431-9454-ad5e919746a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-1c0ec4de-f120-4a51-8bf5-5418b3ef13bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-929f4372-e0e6-44ea-9b93-072669d855ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-683ed76a-82a9-4888-8491-9efc3a207653,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-03c7e224-fab9-4216-9564-bcbeb0df9aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-3d330069-1852-4c2b-a8e3-cc60b6f869c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-24c07202-3835-4343-976c-07aec3ff8c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-ff3c0d3e-fb65-4449-927d-3b55c2d2b7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490053761-172.17.0.21-1597183021872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34223,DS-693e6c47-a0ed-4431-9454-ad5e919746a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-1c0ec4de-f120-4a51-8bf5-5418b3ef13bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35004,DS-929f4372-e0e6-44ea-9b93-072669d855ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-683ed76a-82a9-4888-8491-9efc3a207653,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-03c7e224-fab9-4216-9564-bcbeb0df9aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-3d330069-1852-4c2b-a8e3-cc60b6f869c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-24c07202-3835-4343-976c-07aec3ff8c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-ff3c0d3e-fb65-4449-927d-3b55c2d2b7b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352335710-172.17.0.21-1597183279469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-b9064c3a-5e06-4010-afaa-90bcbb7277a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-083ef6eb-9f06-4b7e-b878-b95811869c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-335a589f-c953-4759-bd33-28d8473ee5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-cabcb2bd-f204-46d3-a3b1-de224763da46,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-a3b2749a-07d8-4fd7-93ea-219daf0b9833,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-a6540851-79af-4678-88de-ca94e98d800a,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-2c3a1c79-d222-4925-bf31-a93dca17982b,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-d1fd947b-b7f3-4a5f-9e6a-bf1096b149f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352335710-172.17.0.21-1597183279469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46267,DS-b9064c3a-5e06-4010-afaa-90bcbb7277a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-083ef6eb-9f06-4b7e-b878-b95811869c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-335a589f-c953-4759-bd33-28d8473ee5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-cabcb2bd-f204-46d3-a3b1-de224763da46,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-a3b2749a-07d8-4fd7-93ea-219daf0b9833,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-a6540851-79af-4678-88de-ca94e98d800a,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-2c3a1c79-d222-4925-bf31-a93dca17982b,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-d1fd947b-b7f3-4a5f-9e6a-bf1096b149f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593924345-172.17.0.21-1597183487372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-640b1eeb-9c4b-4d94-ad9c-82b6048c45c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-62a577ee-f04f-4b86-9876-2a79cfb92637,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-382fefd2-4154-4ac5-b5d5-98ede801ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-a8b8fc41-5dfb-4759-868a-f9a2d6786f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-93462236-5177-4f10-a208-b666a155202a,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-9af13b0b-4266-4237-ba03-751d1314b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-b682b761-ea71-4fb9-a04c-82554cd30e88,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-0ad1b24f-0d34-4dcd-8510-15c5a0731a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593924345-172.17.0.21-1597183487372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34318,DS-640b1eeb-9c4b-4d94-ad9c-82b6048c45c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-62a577ee-f04f-4b86-9876-2a79cfb92637,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-382fefd2-4154-4ac5-b5d5-98ede801ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-a8b8fc41-5dfb-4759-868a-f9a2d6786f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37354,DS-93462236-5177-4f10-a208-b666a155202a,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-9af13b0b-4266-4237-ba03-751d1314b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-b682b761-ea71-4fb9-a04c-82554cd30e88,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-0ad1b24f-0d34-4dcd-8510-15c5a0731a6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580109867-172.17.0.21-1597183769207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-21735671-44fb-4831-a737-8919bd9b1f61,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-12c42387-d855-4ca3-a8dd-a35b19cf3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-106214bd-e719-463d-be50-3ae7903f2062,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-3c384092-b131-44a4-b02b-00350010cfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-dd4888fa-f8ea-4a4d-9c8f-7c6dc4a86ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-f36be428-afe3-4132-8776-8697a531ef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-19cf7dd1-7a72-4eca-b6f6-246de47b3140,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-78752b11-e68c-4e64-a2b3-0704c5db24f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580109867-172.17.0.21-1597183769207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-21735671-44fb-4831-a737-8919bd9b1f61,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-12c42387-d855-4ca3-a8dd-a35b19cf3e26,DISK], DatanodeInfoWithStorage[127.0.0.1:36196,DS-106214bd-e719-463d-be50-3ae7903f2062,DISK], DatanodeInfoWithStorage[127.0.0.1:33533,DS-3c384092-b131-44a4-b02b-00350010cfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-dd4888fa-f8ea-4a4d-9c8f-7c6dc4a86ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-f36be428-afe3-4132-8776-8697a531ef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-19cf7dd1-7a72-4eca-b6f6-246de47b3140,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-78752b11-e68c-4e64-a2b3-0704c5db24f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086125025-172.17.0.21-1597183805123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42941,DS-5902ed5f-7c15-4b6f-a97c-c09f8752f63a,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-ed571df1-fd03-47e4-85a8-dc589b44d83d,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-08043a84-3992-427e-9a16-7a577065ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-2f85ce56-dc88-479a-a7a9-46d862a6325a,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-0521d934-f87c-41d1-9a8f-12325a5c1bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-e4cfd89d-92d9-4b58-a2d8-f0e990bb5de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-8aefc18a-dc71-42be-8d22-fdefd0c62fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-02d851b5-1682-49f6-b6bd-33f59906d79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086125025-172.17.0.21-1597183805123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42941,DS-5902ed5f-7c15-4b6f-a97c-c09f8752f63a,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-ed571df1-fd03-47e4-85a8-dc589b44d83d,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-08043a84-3992-427e-9a16-7a577065ed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-2f85ce56-dc88-479a-a7a9-46d862a6325a,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-0521d934-f87c-41d1-9a8f-12325a5c1bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-e4cfd89d-92d9-4b58-a2d8-f0e990bb5de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-8aefc18a-dc71-42be-8d22-fdefd0c62fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-02d851b5-1682-49f6-b6bd-33f59906d79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-691016978-172.17.0.21-1597183946226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41945,DS-d220c971-b426-46ff-9252-3856adeeee80,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-d54d35d6-37fa-4494-b2e4-a9707eb4fe60,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-a4404fa3-a92a-41a4-8698-e1bb851d288b,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-859818b6-f4a5-483d-aaa8-c4822b27c809,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-c88e03b0-5936-4611-af54-60de79baaae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-9a207720-f370-4758-a1ab-0c2d353ffd85,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-32f72f90-a529-4e03-8dca-b699a23a7252,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-b021f7d1-d583-43d3-b928-5e99f4b8dcd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-691016978-172.17.0.21-1597183946226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41945,DS-d220c971-b426-46ff-9252-3856adeeee80,DISK], DatanodeInfoWithStorage[127.0.0.1:40922,DS-d54d35d6-37fa-4494-b2e4-a9707eb4fe60,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-a4404fa3-a92a-41a4-8698-e1bb851d288b,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-859818b6-f4a5-483d-aaa8-c4822b27c809,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-c88e03b0-5936-4611-af54-60de79baaae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-9a207720-f370-4758-a1ab-0c2d353ffd85,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-32f72f90-a529-4e03-8dca-b699a23a7252,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-b021f7d1-d583-43d3-b928-5e99f4b8dcd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870720557-172.17.0.21-1597183979198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-5355d097-f966-4069-94ac-9ca89d2fb3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-e3d04e0f-8538-4449-849e-08ae205679ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-aa1d71f1-920d-4064-ae3d-1053ad1392ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-d188c4ab-d08b-4f4c-b852-9970bfe0b50b,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-4faedfdb-285c-4640-8738-450a745625e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-f51aca58-d852-41b6-a23c-6a87cd2473e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-b9ef637b-6fd5-459b-9418-a99d10222a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-d44cbffc-c1be-4368-a2c8-dd37fdaa504d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870720557-172.17.0.21-1597183979198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-5355d097-f966-4069-94ac-9ca89d2fb3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-e3d04e0f-8538-4449-849e-08ae205679ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-aa1d71f1-920d-4064-ae3d-1053ad1392ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-d188c4ab-d08b-4f4c-b852-9970bfe0b50b,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-4faedfdb-285c-4640-8738-450a745625e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-f51aca58-d852-41b6-a23c-6a87cd2473e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-b9ef637b-6fd5-459b-9418-a99d10222a32,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-d44cbffc-c1be-4368-a2c8-dd37fdaa504d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580214202-172.17.0.21-1597184056016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-536754ed-71df-4fee-b0f9-65ef26104f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-8c6256fd-4dff-419f-bf0a-6458529c35f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-9e3af93c-a765-4596-930e-2da298194eea,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-32a88d9c-c2ec-4c14-8521-6cd5763b644a,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-8643347b-85c4-46a5-8516-9843fa2f66b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-1173b4ba-b941-45b3-a3e7-2ab060ee6399,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-f30becb7-a60d-4f3f-9137-0c76069b908a,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-5952c84d-7f8d-4666-bad1-87099cae48d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580214202-172.17.0.21-1597184056016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42972,DS-536754ed-71df-4fee-b0f9-65ef26104f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-8c6256fd-4dff-419f-bf0a-6458529c35f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-9e3af93c-a765-4596-930e-2da298194eea,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-32a88d9c-c2ec-4c14-8521-6cd5763b644a,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-8643347b-85c4-46a5-8516-9843fa2f66b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-1173b4ba-b941-45b3-a3e7-2ab060ee6399,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-f30becb7-a60d-4f3f-9137-0c76069b908a,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-5952c84d-7f8d-4666-bad1-87099cae48d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385811481-172.17.0.21-1597184132427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36436,DS-42b21827-7523-4637-8fd4-e7429c13b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-d65126ff-8da1-4fe2-9e50-4b95d5732271,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-9fa9dfd7-80ca-4ae2-a114-732c43031256,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-aa034897-f4f3-4ac7-9320-284906366ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-1c9bf4cf-3a8a-44a7-a1c7-c9881ee10a38,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-066a35dd-5442-4f0c-885d-e78fa6c6b471,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-b302e9ef-2492-478f-8894-1a4bf3c0b560,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-95b1c73a-795e-4b17-b7f5-7a10819dc27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385811481-172.17.0.21-1597184132427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36436,DS-42b21827-7523-4637-8fd4-e7429c13b6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-d65126ff-8da1-4fe2-9e50-4b95d5732271,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-9fa9dfd7-80ca-4ae2-a114-732c43031256,DISK], DatanodeInfoWithStorage[127.0.0.1:35386,DS-aa034897-f4f3-4ac7-9320-284906366ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-1c9bf4cf-3a8a-44a7-a1c7-c9881ee10a38,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-066a35dd-5442-4f0c-885d-e78fa6c6b471,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-b302e9ef-2492-478f-8894-1a4bf3c0b560,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-95b1c73a-795e-4b17-b7f5-7a10819dc27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835009919-172.17.0.21-1597184346664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-9020aebd-9792-4914-9223-66a02324ae92,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-5b22d69d-04e4-42a3-9236-5218fdaff88a,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-100bdb6d-f736-4c76-8cfe-e1af86d7b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-97137f10-0a80-4571-ac2a-9711049cfa60,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-44762c11-db1d-40d6-86ef-c6d7792528e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-567e99d1-1051-4359-b212-ca235a516247,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-ade9751f-bf0f-4566-bb7a-03c1b083c2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-ae9fb5c8-2a18-4756-ab0f-e7dfacf3e83e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835009919-172.17.0.21-1597184346664:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34611,DS-9020aebd-9792-4914-9223-66a02324ae92,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-5b22d69d-04e4-42a3-9236-5218fdaff88a,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-100bdb6d-f736-4c76-8cfe-e1af86d7b9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-97137f10-0a80-4571-ac2a-9711049cfa60,DISK], DatanodeInfoWithStorage[127.0.0.1:37114,DS-44762c11-db1d-40d6-86ef-c6d7792528e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-567e99d1-1051-4359-b212-ca235a516247,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-ade9751f-bf0f-4566-bb7a-03c1b083c2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-ae9fb5c8-2a18-4756-ab0f-e7dfacf3e83e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969615819-172.17.0.21-1597184484584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-8f2f88ca-b71b-4a8c-9031-7fb1be61544e,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-e8ecc492-ddc2-45c7-97f7-3e9341446945,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-2f0e03ba-fd56-46da-a89c-6a313efe13e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-057d3a14-b7f0-4abf-af77-739686ac09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-9426c83d-9037-4400-a565-4addd32ce66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-08255756-94fd-483b-8e99-6a7682a97aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-bbdf3614-1a18-4581-91ef-d409dc526846,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-ec8fb252-4d71-4ff2-96fa-7dcaa95cbaeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969615819-172.17.0.21-1597184484584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35479,DS-8f2f88ca-b71b-4a8c-9031-7fb1be61544e,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-e8ecc492-ddc2-45c7-97f7-3e9341446945,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-2f0e03ba-fd56-46da-a89c-6a313efe13e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-057d3a14-b7f0-4abf-af77-739686ac09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-9426c83d-9037-4400-a565-4addd32ce66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-08255756-94fd-483b-8e99-6a7682a97aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-bbdf3614-1a18-4581-91ef-d409dc526846,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-ec8fb252-4d71-4ff2-96fa-7dcaa95cbaeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813076731-172.17.0.21-1597184811883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-3e02105b-6b0f-475a-bd63-6d65883923d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-c0452338-8ee2-4985-ad26-7055f474a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-79045515-a679-4231-8911-4dca444a82b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-b8a0a726-52ef-436d-ac89-c141cd089660,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-21baff77-eaf8-4322-bd0a-af4060383300,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-8bb1aa2f-5295-4be2-8c8c-e9da6f87ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-2515c28d-05ed-4f96-83f0-bec5e59d14d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-85515e2d-bf9a-451a-a18b-2851b99cdf94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813076731-172.17.0.21-1597184811883:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44912,DS-3e02105b-6b0f-475a-bd63-6d65883923d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-c0452338-8ee2-4985-ad26-7055f474a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-79045515-a679-4231-8911-4dca444a82b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-b8a0a726-52ef-436d-ac89-c141cd089660,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-21baff77-eaf8-4322-bd0a-af4060383300,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-8bb1aa2f-5295-4be2-8c8c-e9da6f87ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-2515c28d-05ed-4f96-83f0-bec5e59d14d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-85515e2d-bf9a-451a-a18b-2851b99cdf94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673181248-172.17.0.21-1597184873862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-34665a79-4742-482a-a240-3e99b898e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-1540fe39-749d-4389-a20d-a082618ae313,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-1ba706a1-eef0-4ee1-994b-20c64ae25d70,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-f4cd48b7-004c-42cc-a833-c9a89b97bd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-c4a6d6cd-1b81-407d-aa91-7afa431d8563,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-46f3a749-00ea-417a-903d-6604980326c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ff456d85-68e5-47ab-a106-c7dffe4a97af,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-c6291262-8a04-4787-a4f9-d954d7d4411f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673181248-172.17.0.21-1597184873862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37554,DS-34665a79-4742-482a-a240-3e99b898e6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-1540fe39-749d-4389-a20d-a082618ae313,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-1ba706a1-eef0-4ee1-994b-20c64ae25d70,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-f4cd48b7-004c-42cc-a833-c9a89b97bd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-c4a6d6cd-1b81-407d-aa91-7afa431d8563,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-46f3a749-00ea-417a-903d-6604980326c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-ff456d85-68e5-47ab-a106-c7dffe4a97af,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-c6291262-8a04-4787-a4f9-d954d7d4411f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735264889-172.17.0.21-1597184968185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-7f92792e-6895-4bed-8ac5-d34bc554a260,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-36ca6936-b408-49f3-887e-aad135e38d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-735fad8c-f6f4-4fe1-81aa-644aac74aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-6dff495d-3f98-489b-a212-7842fafaaa60,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-77770c2d-37c5-4b3f-8542-c3bd2bf8f8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-b86cc14b-4ee3-4d0c-9d80-0104349a9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-09d57f96-ac10-4990-b7f3-8995870b160a,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-0afa79a8-7cf1-47ab-be44-7f6f1c48f6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735264889-172.17.0.21-1597184968185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-7f92792e-6895-4bed-8ac5-d34bc554a260,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-36ca6936-b408-49f3-887e-aad135e38d64,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-735fad8c-f6f4-4fe1-81aa-644aac74aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-6dff495d-3f98-489b-a212-7842fafaaa60,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-77770c2d-37c5-4b3f-8542-c3bd2bf8f8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36877,DS-b86cc14b-4ee3-4d0c-9d80-0104349a9f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-09d57f96-ac10-4990-b7f3-8995870b160a,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-0afa79a8-7cf1-47ab-be44-7f6f1c48f6dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999089300-172.17.0.21-1597185069043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-d5399f4c-2e97-4fc1-9b51-869678074f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-c72584fb-af87-4a1a-9452-188761fcbe15,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-be3a2e8f-0763-4a79-bcd7-9b2cef14febc,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-df944612-b131-4038-9141-3cbaedc87326,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-472a30d5-7f01-43b3-9406-fef146af0e87,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-20e28a94-6473-46a4-b397-eaa59d5e8b75,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-846ac298-3ba4-494f-bca0-d840df0f7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-fe4568b8-a0a8-40c0-82ba-006b160620e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999089300-172.17.0.21-1597185069043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-d5399f4c-2e97-4fc1-9b51-869678074f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-c72584fb-af87-4a1a-9452-188761fcbe15,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-be3a2e8f-0763-4a79-bcd7-9b2cef14febc,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-df944612-b131-4038-9141-3cbaedc87326,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-472a30d5-7f01-43b3-9406-fef146af0e87,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-20e28a94-6473-46a4-b397-eaa59d5e8b75,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-846ac298-3ba4-494f-bca0-d840df0f7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-fe4568b8-a0a8-40c0-82ba-006b160620e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.maximum.response.length
component: hdfs:DataNode
v1: 134217728
v2: 16777216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125075510-172.17.0.21-1597185271868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-350dd1cd-4396-4616-a8a5-6e9b7dba82ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-014e1d78-13b7-4bf9-8168-29d044278e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-8f14053d-8705-4ea6-adae-49878b563c20,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-4ee9d358-fb08-4d24-87ba-2f8bcf3fd87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-6076deb6-85be-490a-993e-39b1b1b143c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-1e85f792-7b30-4276-ab0c-c3b8fb776f53,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-bfe1a2b9-a81a-4596-adc0-bbc7379e8bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-374068fe-74a0-400b-a013-b17d8449ed1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2125075510-172.17.0.21-1597185271868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-350dd1cd-4396-4616-a8a5-6e9b7dba82ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-014e1d78-13b7-4bf9-8168-29d044278e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-8f14053d-8705-4ea6-adae-49878b563c20,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-4ee9d358-fb08-4d24-87ba-2f8bcf3fd87b,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-6076deb6-85be-490a-993e-39b1b1b143c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-1e85f792-7b30-4276-ab0c-c3b8fb776f53,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-bfe1a2b9-a81a-4596-adc0-bbc7379e8bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-374068fe-74a0-400b-a013-b17d8449ed1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5226
