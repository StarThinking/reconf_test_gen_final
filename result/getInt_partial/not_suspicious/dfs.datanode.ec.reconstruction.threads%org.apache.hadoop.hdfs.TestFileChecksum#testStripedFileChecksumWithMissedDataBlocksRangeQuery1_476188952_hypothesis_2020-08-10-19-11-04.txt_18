reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243182487-172.17.0.12-1597087149135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34513,DS-250c9253-8fcb-4f2d-8dd1-467d215ae01e,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-0b99f0cb-f0e1-43f8-bf09-f1d38bce7124,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-54b7c4f4-ad3e-47e1-a016-6c83e13fbedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-d0de8e1b-f1f2-4bf5-bba7-15e9e26be45f,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-f6651b40-f8a5-4949-ba7c-6bfd15fca669,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-16f40e20-4d21-43c0-88b4-676c9736a18e,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-578bde5a-26e1-4122-a586-0759c99ea93b,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-d73fe7f8-39cd-437a-8913-fc79142d0387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-243182487-172.17.0.12-1597087149135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34513,DS-250c9253-8fcb-4f2d-8dd1-467d215ae01e,DISK], DatanodeInfoWithStorage[127.0.0.1:38461,DS-0b99f0cb-f0e1-43f8-bf09-f1d38bce7124,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-54b7c4f4-ad3e-47e1-a016-6c83e13fbedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-d0de8e1b-f1f2-4bf5-bba7-15e9e26be45f,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-f6651b40-f8a5-4949-ba7c-6bfd15fca669,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-16f40e20-4d21-43c0-88b4-676c9736a18e,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-578bde5a-26e1-4122-a586-0759c99ea93b,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-d73fe7f8-39cd-437a-8913-fc79142d0387,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827639661-172.17.0.12-1597087232362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-9dd4355c-be2d-45bc-b470-62bb0c33be1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-04a80b7e-7fc5-4195-a013-493bbac1cdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-50c6e8ca-b8f9-46af-8a34-b4c8d858ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-28b910ff-f4b7-487c-bcac-56ffa11b1554,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-2de9b2f8-8ee0-4681-9421-f6950c308fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-65398af9-d53e-4cee-994a-3f41ff30cc72,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-5bbc8df4-7ae1-4d08-a900-fdce6b5d2c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-d958b0d3-9eab-483f-9a82-c48afeaeba75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827639661-172.17.0.12-1597087232362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46097,DS-9dd4355c-be2d-45bc-b470-62bb0c33be1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42116,DS-04a80b7e-7fc5-4195-a013-493bbac1cdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-50c6e8ca-b8f9-46af-8a34-b4c8d858ae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-28b910ff-f4b7-487c-bcac-56ffa11b1554,DISK], DatanodeInfoWithStorage[127.0.0.1:36591,DS-2de9b2f8-8ee0-4681-9421-f6950c308fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-65398af9-d53e-4cee-994a-3f41ff30cc72,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-5bbc8df4-7ae1-4d08-a900-fdce6b5d2c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-d958b0d3-9eab-483f-9a82-c48afeaeba75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668460389-172.17.0.12-1597087314093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-e6627840-7dd0-4668-bf54-63bf18c65522,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-fcb7d3bd-1d46-422e-a877-3e8ac7e51dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-813afa6f-2673-49e5-840a-23aad982e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-108acace-3741-4c17-b22f-fbe62159a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-dadf277c-5728-4657-9636-03f83c699d25,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-42a47bd8-af0c-4b2c-9888-52c121fdd6af,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-fd9e228d-4c2e-472a-9387-399731177992,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-c93bc0d2-a104-4bd7-8299-48ebe67da27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668460389-172.17.0.12-1597087314093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33378,DS-e6627840-7dd0-4668-bf54-63bf18c65522,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-fcb7d3bd-1d46-422e-a877-3e8ac7e51dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-813afa6f-2673-49e5-840a-23aad982e92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-108acace-3741-4c17-b22f-fbe62159a40f,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-dadf277c-5728-4657-9636-03f83c699d25,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-42a47bd8-af0c-4b2c-9888-52c121fdd6af,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-fd9e228d-4c2e-472a-9387-399731177992,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-c93bc0d2-a104-4bd7-8299-48ebe67da27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055277514-172.17.0.12-1597087860740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-b9ad1d8d-a971-4aa9-bfe9-42aac3916820,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-77b5a920-8086-4625-8a91-9bdfeabde8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a773e8f4-d8a9-4652-8a1d-ddb6a5017471,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-da052934-426f-4709-aa13-c41dda5a6dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-2745a8e2-539b-4d56-b646-7d716c9d25e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-1b767ef8-850b-4330-92dc-990bb0c77a16,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-24d6b5c0-3afb-419d-9e74-2629822bc32e,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-4eb133f8-47d2-4e22-8fa7-a60e78818344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055277514-172.17.0.12-1597087860740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44438,DS-b9ad1d8d-a971-4aa9-bfe9-42aac3916820,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-77b5a920-8086-4625-8a91-9bdfeabde8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a773e8f4-d8a9-4652-8a1d-ddb6a5017471,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-da052934-426f-4709-aa13-c41dda5a6dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-2745a8e2-539b-4d56-b646-7d716c9d25e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43137,DS-1b767ef8-850b-4330-92dc-990bb0c77a16,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-24d6b5c0-3afb-419d-9e74-2629822bc32e,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-4eb133f8-47d2-4e22-8fa7-a60e78818344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178109574-172.17.0.12-1597087901161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46650,DS-033422c5-767b-42e5-b861-58b74039b702,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-7f2c68c0-8606-418c-9209-b17b77d04ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-2e8287a1-d9e7-4481-9043-69baae105de0,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-990c03e2-d54d-4fcf-bb70-caca5769c22a,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-0c0cc11e-22db-43b1-b70b-69cb3b59d457,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-3ea33204-f5c4-46ff-b70a-2a76c989c816,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-9e22190a-da70-4c47-b2e8-e3246877ab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-35519e83-5606-4069-aa20-48bed4280291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178109574-172.17.0.12-1597087901161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46650,DS-033422c5-767b-42e5-b861-58b74039b702,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-7f2c68c0-8606-418c-9209-b17b77d04ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-2e8287a1-d9e7-4481-9043-69baae105de0,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-990c03e2-d54d-4fcf-bb70-caca5769c22a,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-0c0cc11e-22db-43b1-b70b-69cb3b59d457,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-3ea33204-f5c4-46ff-b70a-2a76c989c816,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-9e22190a-da70-4c47-b2e8-e3246877ab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-35519e83-5606-4069-aa20-48bed4280291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869148581-172.17.0.12-1597088707739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-0fae6e9d-7466-4c4b-962b-262359620457,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-d1acc95d-c34d-4ba9-a627-a088db36fa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-8c19bb77-dda8-4459-8238-3e5d9d819212,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-043e1051-dd2d-4858-a9d6-899f324797c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-c373f63b-adee-4981-9218-767323ba3f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-cb5807b3-0cc6-41d7-93e2-2b775f73f559,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-bd0616fd-a5fb-4d87-a90d-2652749d0db0,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-a9581659-d80c-486e-8737-a64598d5c4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869148581-172.17.0.12-1597088707739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42236,DS-0fae6e9d-7466-4c4b-962b-262359620457,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-d1acc95d-c34d-4ba9-a627-a088db36fa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-8c19bb77-dda8-4459-8238-3e5d9d819212,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-043e1051-dd2d-4858-a9d6-899f324797c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-c373f63b-adee-4981-9218-767323ba3f70,DISK], DatanodeInfoWithStorage[127.0.0.1:42739,DS-cb5807b3-0cc6-41d7-93e2-2b775f73f559,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-bd0616fd-a5fb-4d87-a90d-2652749d0db0,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-a9581659-d80c-486e-8737-a64598d5c4d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550892854-172.17.0.12-1597089331007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43813,DS-68cd5d52-67bb-44ad-9dc0-daea174e6feb,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-ae217523-5bbf-4bc7-8040-aa61558e96e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-ae8e8e96-bd07-46d5-8090-7f0076a28034,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-2eae70ce-fbbe-48e4-ad84-ef1be9d49ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-9856d96b-afa0-4981-a02c-2860558c2b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-3c86c347-4694-4523-a1b9-8f820503a752,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-3a4277eb-17bb-448a-a46d-4a24b557e680,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-2ecd0e5c-3a15-4dd3-8865-5bce281d560b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1550892854-172.17.0.12-1597089331007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43813,DS-68cd5d52-67bb-44ad-9dc0-daea174e6feb,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-ae217523-5bbf-4bc7-8040-aa61558e96e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-ae8e8e96-bd07-46d5-8090-7f0076a28034,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-2eae70ce-fbbe-48e4-ad84-ef1be9d49ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-9856d96b-afa0-4981-a02c-2860558c2b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-3c86c347-4694-4523-a1b9-8f820503a752,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-3a4277eb-17bb-448a-a46d-4a24b557e680,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-2ecd0e5c-3a15-4dd3-8865-5bce281d560b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780217718-172.17.0.12-1597089512077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-10ba46d7-5e21-450a-8bff-3f4eebe2c283,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-bb6df9b6-36d0-4922-8050-53dc7758d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-658a7921-d6fe-4586-af30-23d7cc5a2e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-31729a63-8406-4c3f-8906-e2413ff9df33,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-617b1820-c26b-48c6-abd7-bc96b49d7848,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-943b2bc3-6971-4e95-a0cf-b8f80148c1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-4b732d5c-a693-4a54-ac34-e5b7f75ac3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-523f7595-bca0-4932-a576-fd6490ee0285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780217718-172.17.0.12-1597089512077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40139,DS-10ba46d7-5e21-450a-8bff-3f4eebe2c283,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-bb6df9b6-36d0-4922-8050-53dc7758d6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-658a7921-d6fe-4586-af30-23d7cc5a2e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-31729a63-8406-4c3f-8906-e2413ff9df33,DISK], DatanodeInfoWithStorage[127.0.0.1:40664,DS-617b1820-c26b-48c6-abd7-bc96b49d7848,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-943b2bc3-6971-4e95-a0cf-b8f80148c1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-4b732d5c-a693-4a54-ac34-e5b7f75ac3b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-523f7595-bca0-4932-a576-fd6490ee0285,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681332523-172.17.0.12-1597089733594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42658,DS-e7ca5c12-13db-4eea-b185-009b66277525,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c9eb4693-7e27-47cb-ac11-7eb52ee8c4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-4d12c139-c671-40c9-b4d5-f40146d97ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-3eca5ff0-0b96-4f95-9a38-794452daabf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-deb346e4-3170-47ac-bc27-65528071bbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-a6895c53-1254-4a0f-911d-08363f6903f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-ae88b35a-f661-4db5-8ba0-538188e9dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-6d9b6a66-665d-43e7-a509-84c1f9e36a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681332523-172.17.0.12-1597089733594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42658,DS-e7ca5c12-13db-4eea-b185-009b66277525,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c9eb4693-7e27-47cb-ac11-7eb52ee8c4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-4d12c139-c671-40c9-b4d5-f40146d97ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-3eca5ff0-0b96-4f95-9a38-794452daabf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-deb346e4-3170-47ac-bc27-65528071bbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-a6895c53-1254-4a0f-911d-08363f6903f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-ae88b35a-f661-4db5-8ba0-538188e9dc22,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-6d9b6a66-665d-43e7-a509-84c1f9e36a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985325086-172.17.0.12-1597091020548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-17518652-2f38-48f1-9c68-4cf494945f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-e32146a1-e39f-4191-8146-d57e0af55935,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-9172be65-7a1d-40c9-87d4-e20f3d66f0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-28219bf2-0fef-4460-92aa-f17611bd2b60,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-dce217b8-2e53-40f1-a962-b1fef6480d36,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-bf628673-02ba-4888-a4b6-224bb79a18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-dd173197-4556-47b9-b875-73688f0a8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-b281c378-7235-439a-9ca7-d3470dfc49d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1985325086-172.17.0.12-1597091020548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-17518652-2f38-48f1-9c68-4cf494945f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-e32146a1-e39f-4191-8146-d57e0af55935,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-9172be65-7a1d-40c9-87d4-e20f3d66f0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-28219bf2-0fef-4460-92aa-f17611bd2b60,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-dce217b8-2e53-40f1-a962-b1fef6480d36,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-bf628673-02ba-4888-a4b6-224bb79a18cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-dd173197-4556-47b9-b875-73688f0a8de5,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-b281c378-7235-439a-9ca7-d3470dfc49d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283881786-172.17.0.12-1597091105830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-23488419-7be2-4d79-92ee-01f3f9489acd,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-9e016ada-02f1-4784-867e-a024479a6d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-3d0302cb-1bcf-4f90-aa10-601ffd0e2049,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-25b52252-c81c-421e-b815-77efab51018d,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-5bcaa7ae-82f5-43ef-bfb6-001591ab7f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-0c5fa15b-dae1-41d3-8686-d4872e6adb46,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-5b8bf6bc-bb37-4b27-91f5-a1e85093dbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-f753cba1-1e73-4cae-abf4-85f60129ac80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283881786-172.17.0.12-1597091105830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-23488419-7be2-4d79-92ee-01f3f9489acd,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-9e016ada-02f1-4784-867e-a024479a6d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-3d0302cb-1bcf-4f90-aa10-601ffd0e2049,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-25b52252-c81c-421e-b815-77efab51018d,DISK], DatanodeInfoWithStorage[127.0.0.1:41144,DS-5bcaa7ae-82f5-43ef-bfb6-001591ab7f43,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-0c5fa15b-dae1-41d3-8686-d4872e6adb46,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-5b8bf6bc-bb37-4b27-91f5-a1e85093dbf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-f753cba1-1e73-4cae-abf4-85f60129ac80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410426638-172.17.0.12-1597091156712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37891,DS-1c1eb791-7f6a-438e-8d6f-b14df2aa5377,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-dec713ae-d227-4cfb-8d3b-00754c82480d,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-6c421911-905b-420b-a485-0fa22dd947ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-af4a4648-5d9a-4752-a974-bda84b27b2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-cdb061ca-25cd-4ff5-b884-83db124f022b,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-0b62a99d-551b-4a5f-b522-d1697dd23b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-669f1ec8-c9c3-4b02-a0eb-de8dbcead669,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-c9699974-d295-4c31-8fb4-a9a8613a52bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410426638-172.17.0.12-1597091156712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37891,DS-1c1eb791-7f6a-438e-8d6f-b14df2aa5377,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-dec713ae-d227-4cfb-8d3b-00754c82480d,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-6c421911-905b-420b-a485-0fa22dd947ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-af4a4648-5d9a-4752-a974-bda84b27b2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-cdb061ca-25cd-4ff5-b884-83db124f022b,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-0b62a99d-551b-4a5f-b522-d1697dd23b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-669f1ec8-c9c3-4b02-a0eb-de8dbcead669,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-c9699974-d295-4c31-8fb4-a9a8613a52bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843832862-172.17.0.12-1597091433421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39456,DS-418fcdfb-e5b1-43b7-8815-3ec4a9c060b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-9a4fbe71-727e-4097-b96c-0aeec2fbad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-cf686698-e6b4-4bf3-bc53-1a090f6835dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-c6ec9ca1-bb55-491b-ad28-5fa20be10300,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-3e4a2cb3-532d-4e77-afe0-cfa488bc2ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-9163a449-439f-4c30-af51-a62543e6422e,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-fe97cc68-bb5d-4c45-a9d8-16a76f0d074c,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-50670d6c-37cb-41f3-bfe2-e78cae651ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-843832862-172.17.0.12-1597091433421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39456,DS-418fcdfb-e5b1-43b7-8815-3ec4a9c060b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-9a4fbe71-727e-4097-b96c-0aeec2fbad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-cf686698-e6b4-4bf3-bc53-1a090f6835dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-c6ec9ca1-bb55-491b-ad28-5fa20be10300,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-3e4a2cb3-532d-4e77-afe0-cfa488bc2ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:39098,DS-9163a449-439f-4c30-af51-a62543e6422e,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-fe97cc68-bb5d-4c45-a9d8-16a76f0d074c,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-50670d6c-37cb-41f3-bfe2-e78cae651ba8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88700598-172.17.0.12-1597091777779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-31e95564-9278-48d2-ae44-97967ac8222e,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-b3b6def1-29ea-498e-9e42-7dda53039303,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-6ad9beca-50b6-4cbe-90b7-52b2640f78d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-93ce760a-0816-4635-8771-4b36fb698960,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-ea6f105a-4dca-4e7e-a5ca-b5fd418fe808,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-4a109377-f1b1-41cf-add5-9bda440f5191,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-4c845544-5689-459a-88e7-f88edf212582,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-b7d9630a-8746-4599-a9ef-d5b9e84ee6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88700598-172.17.0.12-1597091777779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38289,DS-31e95564-9278-48d2-ae44-97967ac8222e,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-b3b6def1-29ea-498e-9e42-7dda53039303,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-6ad9beca-50b6-4cbe-90b7-52b2640f78d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-93ce760a-0816-4635-8771-4b36fb698960,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-ea6f105a-4dca-4e7e-a5ca-b5fd418fe808,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-4a109377-f1b1-41cf-add5-9bda440f5191,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-4c845544-5689-459a-88e7-f88edf212582,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-b7d9630a-8746-4599-a9ef-d5b9e84ee6d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111411493-172.17.0.12-1597091863733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36285,DS-0e9dddc6-93e1-4839-bc07-0c33acca61c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-3e138260-2d4a-416f-bbde-c3c795d6bbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-4b649f98-8a96-43a5-aed7-356197a6a8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-997070fb-c5ff-4ae9-97a8-71cefca28833,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-0aaf1581-117d-46a2-8793-e135d831155d,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-63d86b16-393c-4ed1-a1f7-0af40c19b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-c755cbc9-0ab8-4327-a8aa-33f48811676e,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-27074f3d-51ca-475a-a5e6-51034f56b65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1111411493-172.17.0.12-1597091863733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36285,DS-0e9dddc6-93e1-4839-bc07-0c33acca61c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-3e138260-2d4a-416f-bbde-c3c795d6bbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-4b649f98-8a96-43a5-aed7-356197a6a8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-997070fb-c5ff-4ae9-97a8-71cefca28833,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-0aaf1581-117d-46a2-8793-e135d831155d,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-63d86b16-393c-4ed1-a1f7-0af40c19b8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43867,DS-c755cbc9-0ab8-4327-a8aa-33f48811676e,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-27074f3d-51ca-475a-a5e6-51034f56b65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359001830-172.17.0.12-1597092233533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46305,DS-c168d6b0-8f30-4321-99e3-bd7a2b88817c,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-6b54c45a-2f02-477b-bde6-33553043e945,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-872fc94f-2d0d-4c85-9c53-d8e094912ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-fe0bca3f-b89e-4e9c-8a61-205afa9de602,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-3e9f684b-57ee-4041-bc67-d5ed2d105180,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-907f12ef-c24e-41d5-94f8-03e5cb7189d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-47764810-97d7-47d5-b9d8-c08db9de1dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-ddbe55c6-3a31-4fb2-acda-df62cf9069f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1359001830-172.17.0.12-1597092233533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46305,DS-c168d6b0-8f30-4321-99e3-bd7a2b88817c,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-6b54c45a-2f02-477b-bde6-33553043e945,DISK], DatanodeInfoWithStorage[127.0.0.1:35965,DS-872fc94f-2d0d-4c85-9c53-d8e094912ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-fe0bca3f-b89e-4e9c-8a61-205afa9de602,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-3e9f684b-57ee-4041-bc67-d5ed2d105180,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-907f12ef-c24e-41d5-94f8-03e5cb7189d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-47764810-97d7-47d5-b9d8-c08db9de1dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-ddbe55c6-3a31-4fb2-acda-df62cf9069f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793553564-172.17.0.12-1597092502196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40199,DS-1e687d5e-cef0-4033-b137-8915a9f9afee,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-2bf53957-d747-4842-9c7c-642752549f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-02a816f9-e9b4-4001-b634-9ce8ba24aa36,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-726fd2c9-73ee-4e0f-b495-eaa87e13b786,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-5522fe96-54fc-4a28-8b4d-a9e814044dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-c211dba4-ea9f-4f27-91b6-d519152b7a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-5946d5cd-7386-4aa4-9c0c-0f54f3b64f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-0bd33d97-6553-4693-ae8a-7ea0059e50e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793553564-172.17.0.12-1597092502196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40199,DS-1e687d5e-cef0-4033-b137-8915a9f9afee,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-2bf53957-d747-4842-9c7c-642752549f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-02a816f9-e9b4-4001-b634-9ce8ba24aa36,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-726fd2c9-73ee-4e0f-b495-eaa87e13b786,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-5522fe96-54fc-4a28-8b4d-a9e814044dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-c211dba4-ea9f-4f27-91b6-d519152b7a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-5946d5cd-7386-4aa4-9c0c-0f54f3b64f19,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-0bd33d97-6553-4693-ae8a-7ea0059e50e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750387006-172.17.0.12-1597092722710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34283,DS-bb020321-d5a5-453e-ab99-f5f1295dc33c,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-1b90d037-13f9-4f74-90ce-62ad130c74b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-348ef5ab-b919-47ab-81a5-9b22ee938948,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-c8f66af5-14e7-46bd-8a99-0bd3ac249874,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-6ce7de5e-98e5-4f89-bf62-878b59e03274,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-0ed38997-784d-4ec2-b2f9-568fdb12d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-239583ee-c6d2-4d70-a79f-a1a019b4f888,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-fa247141-7ca6-4828-8e9f-cc7af3f94721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750387006-172.17.0.12-1597092722710:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34283,DS-bb020321-d5a5-453e-ab99-f5f1295dc33c,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-1b90d037-13f9-4f74-90ce-62ad130c74b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-348ef5ab-b919-47ab-81a5-9b22ee938948,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-c8f66af5-14e7-46bd-8a99-0bd3ac249874,DISK], DatanodeInfoWithStorage[127.0.0.1:38578,DS-6ce7de5e-98e5-4f89-bf62-878b59e03274,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-0ed38997-784d-4ec2-b2f9-568fdb12d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-239583ee-c6d2-4d70-a79f-a1a019b4f888,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-fa247141-7ca6-4828-8e9f-cc7af3f94721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255809592-172.17.0.12-1597092904653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36455,DS-c97a38a3-e41a-4052-9825-f155b15baaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-d49bce4f-ea51-4b10-94c6-47ce041e2e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-68ac6f6b-a1e8-46ae-afe5-7a970ec0a3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-af6ad029-0ddb-4198-8317-967607bb0a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-5cd32712-4a45-4963-ad9e-5fcf4c172b19,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-db3b83f5-10c7-4516-acba-13d98503d753,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-679f1a5e-4993-4016-a9e6-1cd100dfb8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-f20ad3cb-00d3-4b66-a1fd-bebfff73926d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255809592-172.17.0.12-1597092904653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36455,DS-c97a38a3-e41a-4052-9825-f155b15baaa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-d49bce4f-ea51-4b10-94c6-47ce041e2e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-68ac6f6b-a1e8-46ae-afe5-7a970ec0a3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-af6ad029-0ddb-4198-8317-967607bb0a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-5cd32712-4a45-4963-ad9e-5fcf4c172b19,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-db3b83f5-10c7-4516-acba-13d98503d753,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-679f1a5e-4993-4016-a9e6-1cd100dfb8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-f20ad3cb-00d3-4b66-a1fd-bebfff73926d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 10
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891352120-172.17.0.12-1597093367473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36256,DS-fee73403-0f52-4a89-9d58-03b10ee8b4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-a594037b-4611-42de-96e9-58be932aeb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-fe3898b2-aae0-4afa-943c-d03d58536ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-76931af5-ac93-45f7-87bf-953163c0a735,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-f1bc91c0-e409-4e87-ac36-647a3d39fb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8f16ec76-05cf-4a1e-b9ff-8fff6d00bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-99563fb4-8fc7-4616-8434-49c83427b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-a0dc94cb-73a5-4d07-bd8e-122cfb085e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891352120-172.17.0.12-1597093367473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36256,DS-fee73403-0f52-4a89-9d58-03b10ee8b4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-a594037b-4611-42de-96e9-58be932aeb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-fe3898b2-aae0-4afa-943c-d03d58536ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-76931af5-ac93-45f7-87bf-953163c0a735,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-f1bc91c0-e409-4e87-ac36-647a3d39fb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8f16ec76-05cf-4a1e-b9ff-8fff6d00bc73,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-99563fb4-8fc7-4616-8434-49c83427b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-a0dc94cb-73a5-4d07-bd8e-122cfb085e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6728
