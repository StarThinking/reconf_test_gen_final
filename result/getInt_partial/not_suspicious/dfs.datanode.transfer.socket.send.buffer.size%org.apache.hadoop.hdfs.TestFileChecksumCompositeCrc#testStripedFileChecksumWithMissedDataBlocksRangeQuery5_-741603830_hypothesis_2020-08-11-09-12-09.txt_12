reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002499255-172.17.0.21-1597137311628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34166,DS-4e89c954-7373-4bf0-ab60-7c90025d375c,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-44a165ab-d347-4d93-a35d-974a5d8941fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-f8c5d48a-8342-4f9f-8a31-d29b44848f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-2af170d3-d573-4a6d-b7bb-b3b4ad3ec449,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-9c647481-8bc6-4310-857b-4db01beb9d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-8e8b268a-df27-4660-b261-74922374c97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-3230d90c-9993-43fb-beef-f1c98424ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-b5a3e2eb-18c2-4b7d-8497-cde3c205bf9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002499255-172.17.0.21-1597137311628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34166,DS-4e89c954-7373-4bf0-ab60-7c90025d375c,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-44a165ab-d347-4d93-a35d-974a5d8941fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34491,DS-f8c5d48a-8342-4f9f-8a31-d29b44848f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-2af170d3-d573-4a6d-b7bb-b3b4ad3ec449,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-9c647481-8bc6-4310-857b-4db01beb9d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-8e8b268a-df27-4660-b261-74922374c97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-3230d90c-9993-43fb-beef-f1c98424ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-b5a3e2eb-18c2-4b7d-8497-cde3c205bf9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20107154-172.17.0.21-1597137380192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-f98ec468-d928-4fb6-be78-7b38d545712a,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-8c1ba478-e26a-47df-b37d-32c6647606a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-3517c835-117f-4ff4-9253-e0febea47fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-0a5423dc-99fb-4f88-8e3e-71ea747183d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-a46c5f6f-81c9-432d-9e13-1d63df24517f,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-3519f9b1-b5be-46ac-8c8c-7c999738e86b,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-e03689de-3d07-41b3-af74-96b66e1ab4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-10ebedfe-6f04-4c62-a791-e0fd4bbc1ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20107154-172.17.0.21-1597137380192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-f98ec468-d928-4fb6-be78-7b38d545712a,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-8c1ba478-e26a-47df-b37d-32c6647606a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-3517c835-117f-4ff4-9253-e0febea47fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-0a5423dc-99fb-4f88-8e3e-71ea747183d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-a46c5f6f-81c9-432d-9e13-1d63df24517f,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-3519f9b1-b5be-46ac-8c8c-7c999738e86b,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-e03689de-3d07-41b3-af74-96b66e1ab4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-10ebedfe-6f04-4c62-a791-e0fd4bbc1ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616877902-172.17.0.21-1597137839786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-d1cce2d1-3194-47f5-b4a6-2dd7c662b272,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-88825f94-3727-4c49-b500-9387d170a81e,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-c33bb6e2-2908-46b7-ac9e-8a4d891c769c,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-ab2d1cac-eb2e-4e5c-bbf8-c9c0a0c77279,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-e66a21fd-8480-46e9-bc55-7610af729b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-8288238c-b7f8-4e02-a66c-47069f3c6dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-33c9543d-9e22-4ddc-af09-5c9e0e18bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-45a863d9-50cf-4c73-a017-cae78e479120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-616877902-172.17.0.21-1597137839786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33117,DS-d1cce2d1-3194-47f5-b4a6-2dd7c662b272,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-88825f94-3727-4c49-b500-9387d170a81e,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-c33bb6e2-2908-46b7-ac9e-8a4d891c769c,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-ab2d1cac-eb2e-4e5c-bbf8-c9c0a0c77279,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-e66a21fd-8480-46e9-bc55-7610af729b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-8288238c-b7f8-4e02-a66c-47069f3c6dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-33c9543d-9e22-4ddc-af09-5c9e0e18bc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-45a863d9-50cf-4c73-a017-cae78e479120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982218826-172.17.0.21-1597139593846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-30ccc7f4-e842-46e1-b106-f7891ad94478,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-261c3958-d9b1-4016-95aa-d7f330321ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-c31b02d3-967b-453e-88c4-008be9568b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-b6377e78-7e05-47c8-b9d5-5e9bbd8fc662,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-1c20093f-229b-4da3-891a-2affab323e25,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-60746e16-ff2e-4c0f-8846-0cae42c43348,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-4fa3e7fd-f497-440d-95c8-90bed24e42d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-c0801dde-a652-48e0-9991-c18b26e6e589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982218826-172.17.0.21-1597139593846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45129,DS-30ccc7f4-e842-46e1-b106-f7891ad94478,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-261c3958-d9b1-4016-95aa-d7f330321ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-c31b02d3-967b-453e-88c4-008be9568b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-b6377e78-7e05-47c8-b9d5-5e9bbd8fc662,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-1c20093f-229b-4da3-891a-2affab323e25,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-60746e16-ff2e-4c0f-8846-0cae42c43348,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-4fa3e7fd-f497-440d-95c8-90bed24e42d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-c0801dde-a652-48e0-9991-c18b26e6e589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731574149-172.17.0.21-1597139889842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-e40b2d4a-14ac-453b-8e8d-1795bc616ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-5f93269b-786b-44ff-b176-c2be069d751d,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-cbe82fad-7681-47a2-92bd-4d07a6181ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-f358c31b-2565-457f-9604-88faf2fd8f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-8096cdeb-6215-4e53-abda-661eb66ed9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-5e670014-4cee-4720-9d29-4e711122a6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-770a05a6-6b10-4531-84b3-037104f806fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-d3bca7d0-6a8d-43d8-83e5-f9e7f5d1613d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731574149-172.17.0.21-1597139889842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-e40b2d4a-14ac-453b-8e8d-1795bc616ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-5f93269b-786b-44ff-b176-c2be069d751d,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-cbe82fad-7681-47a2-92bd-4d07a6181ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-f358c31b-2565-457f-9604-88faf2fd8f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-8096cdeb-6215-4e53-abda-661eb66ed9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-5e670014-4cee-4720-9d29-4e711122a6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33913,DS-770a05a6-6b10-4531-84b3-037104f806fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-d3bca7d0-6a8d-43d8-83e5-f9e7f5d1613d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886009611-172.17.0.21-1597139966920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-0d24d8ee-3bfc-443e-96c0-d830ae09bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-89126e72-117f-4965-9aa5-2900fc31e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-e5310e0b-2f33-4b10-9359-a729add3b598,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-5196d79b-5c78-4925-908d-4663bc51d180,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-4458b2b8-b566-4965-a841-eb5add379ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-a2b57a15-19e6-4cef-8b12-51910cfe7999,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-f8226d64-dc5f-47a2-a1a4-e6f632a31d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-19318de4-6e8c-4067-9102-fb96accc499e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886009611-172.17.0.21-1597139966920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43911,DS-0d24d8ee-3bfc-443e-96c0-d830ae09bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-89126e72-117f-4965-9aa5-2900fc31e4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-e5310e0b-2f33-4b10-9359-a729add3b598,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-5196d79b-5c78-4925-908d-4663bc51d180,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-4458b2b8-b566-4965-a841-eb5add379ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-a2b57a15-19e6-4cef-8b12-51910cfe7999,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-f8226d64-dc5f-47a2-a1a4-e6f632a31d51,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-19318de4-6e8c-4067-9102-fb96accc499e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258386549-172.17.0.21-1597140416189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41603,DS-2cf77e43-5734-4fb3-a675-74997c33e8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-b0c2dfc5-c284-46c6-938e-bcec2eb77a44,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-36736f84-0058-4c3f-947f-062f31d3c9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-27200f07-a072-4dda-b73a-8fbc16dff4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-5ae37e26-09a1-4fb2-8166-0925d3a9912a,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-6eda64e5-0797-4428-af42-a00d8882a288,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-a0579864-c9d1-4d86-a24e-b5ea35f4a302,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-dacc626f-bfed-481e-8239-f8f09580cfb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258386549-172.17.0.21-1597140416189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41603,DS-2cf77e43-5734-4fb3-a675-74997c33e8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-b0c2dfc5-c284-46c6-938e-bcec2eb77a44,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-36736f84-0058-4c3f-947f-062f31d3c9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36491,DS-27200f07-a072-4dda-b73a-8fbc16dff4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35301,DS-5ae37e26-09a1-4fb2-8166-0925d3a9912a,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-6eda64e5-0797-4428-af42-a00d8882a288,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-a0579864-c9d1-4d86-a24e-b5ea35f4a302,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-dacc626f-bfed-481e-8239-f8f09580cfb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476463719-172.17.0.21-1597141009741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42900,DS-4db7eb09-591b-4ab9-aa96-4464a1225a66,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-05b0c736-c559-4a45-8380-010e6041259d,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-77a36dec-2954-4f16-91b6-73afc3cbcfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-36601aa9-f5c2-4cf9-beb1-8a33a423780d,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-abe26d79-d4ee-49c8-bc44-1f6e38c397ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-f72e3c2d-7140-4d38-9094-0dac87255014,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-1a12b863-aa15-40f4-ac4c-e3095ce22653,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-f647eeba-7d23-46a7-b1ee-0758f9833f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476463719-172.17.0.21-1597141009741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42900,DS-4db7eb09-591b-4ab9-aa96-4464a1225a66,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-05b0c736-c559-4a45-8380-010e6041259d,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-77a36dec-2954-4f16-91b6-73afc3cbcfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-36601aa9-f5c2-4cf9-beb1-8a33a423780d,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-abe26d79-d4ee-49c8-bc44-1f6e38c397ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-f72e3c2d-7140-4d38-9094-0dac87255014,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-1a12b863-aa15-40f4-ac4c-e3095ce22653,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-f647eeba-7d23-46a7-b1ee-0758f9833f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437823466-172.17.0.21-1597141082506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-25d78a62-83ac-4fab-8870-709cfb929e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-b8f42840-bab6-4828-8bed-ad37a96048b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-4f60128f-3417-4d21-a6bc-c35a44f65c91,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-7069cb50-da7d-4391-aa67-dced1ea98c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-787d007a-4684-4dc4-9486-11eccca9b7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-b7c41413-da72-4ac7-a3e3-80368f07bb51,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-d8be0fc1-d6a9-434b-b175-932294ef8518,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-59c85845-13da-4ef2-b2a4-b0ae74f36563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437823466-172.17.0.21-1597141082506:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43922,DS-25d78a62-83ac-4fab-8870-709cfb929e13,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-b8f42840-bab6-4828-8bed-ad37a96048b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-4f60128f-3417-4d21-a6bc-c35a44f65c91,DISK], DatanodeInfoWithStorage[127.0.0.1:38147,DS-7069cb50-da7d-4391-aa67-dced1ea98c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-787d007a-4684-4dc4-9486-11eccca9b7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-b7c41413-da72-4ac7-a3e3-80368f07bb51,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-d8be0fc1-d6a9-434b-b175-932294ef8518,DISK], DatanodeInfoWithStorage[127.0.0.1:46069,DS-59c85845-13da-4ef2-b2a4-b0ae74f36563,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861619622-172.17.0.21-1597141221068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-a31b75a1-503a-41ba-b045-1c2700f1e15f,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-618fd0a4-8bef-4cfe-8be9-89a83e8aff51,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-f4ead9b4-f72a-447e-91a5-7c7d7b8698f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-f583dd3e-437d-492d-8599-37365f378096,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-7f58ff48-0364-482e-9cf0-10b1c7e89964,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-00760f6c-6907-4a51-bade-4bd18221e1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-7b447d4e-330b-440e-80cf-d5254b260af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-510ab9fb-6e5d-48ec-8e7f-f9dfb1060770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861619622-172.17.0.21-1597141221068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-a31b75a1-503a-41ba-b045-1c2700f1e15f,DISK], DatanodeInfoWithStorage[127.0.0.1:46292,DS-618fd0a4-8bef-4cfe-8be9-89a83e8aff51,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-f4ead9b4-f72a-447e-91a5-7c7d7b8698f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-f583dd3e-437d-492d-8599-37365f378096,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-7f58ff48-0364-482e-9cf0-10b1c7e89964,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-00760f6c-6907-4a51-bade-4bd18221e1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-7b447d4e-330b-440e-80cf-d5254b260af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-510ab9fb-6e5d-48ec-8e7f-f9dfb1060770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546226689-172.17.0.21-1597141396768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-975c2972-087e-47da-bd40-cbc3ac0ef9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-446ff04b-6aed-4219-9faf-df5d0ab5f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-7ae0681d-c57e-45b4-a7f2-519af1ca7f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-5f086537-bdde-4f3b-8446-ba5cb80ee5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-46ded720-b492-425d-9b0b-cc00f5ca7fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-4a7f0307-ab06-42cc-a341-694443159f60,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-0735fdea-61e8-4272-a662-ece93b042f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-493877ac-33d5-4508-b890-2c8deeff79d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546226689-172.17.0.21-1597141396768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-975c2972-087e-47da-bd40-cbc3ac0ef9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-446ff04b-6aed-4219-9faf-df5d0ab5f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-7ae0681d-c57e-45b4-a7f2-519af1ca7f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-5f086537-bdde-4f3b-8446-ba5cb80ee5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34554,DS-46ded720-b492-425d-9b0b-cc00f5ca7fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-4a7f0307-ab06-42cc-a341-694443159f60,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-0735fdea-61e8-4272-a662-ece93b042f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-493877ac-33d5-4508-b890-2c8deeff79d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86771726-172.17.0.21-1597141606807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36702,DS-8fa2cebd-cd38-4cd5-85b7-45081237b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-cfa29089-c738-460c-b2f1-6099ccf27fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-ae00bf94-e087-4c04-bb1a-72c55005cecb,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-1e2ecc24-9bf1-4f41-ba9b-c51de5cbaf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-870107ca-8542-4496-a80d-9cacfda114da,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-a90c8af5-0c8c-47ab-bb6f-352534c8c180,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-0b3dd591-45b3-4f19-b9d2-023e4d4001af,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-8ffcde2c-e3ff-4a3a-93f1-bb9f8c944c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86771726-172.17.0.21-1597141606807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36702,DS-8fa2cebd-cd38-4cd5-85b7-45081237b04e,DISK], DatanodeInfoWithStorage[127.0.0.1:33475,DS-cfa29089-c738-460c-b2f1-6099ccf27fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-ae00bf94-e087-4c04-bb1a-72c55005cecb,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-1e2ecc24-9bf1-4f41-ba9b-c51de5cbaf6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-870107ca-8542-4496-a80d-9cacfda114da,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-a90c8af5-0c8c-47ab-bb6f-352534c8c180,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-0b3dd591-45b3-4f19-b9d2-023e4d4001af,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-8ffcde2c-e3ff-4a3a-93f1-bb9f8c944c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957338914-172.17.0.21-1597141981682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35002,DS-89432a5b-6c48-4d39-976d-554a96c3f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-a6fa3f71-de98-4d0e-842e-7ca4a94be4de,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-68eabe4f-47f7-45de-8dd8-c3642bad7120,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-e4c62ee8-d767-44ac-bd9d-eafbb9584bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-d7fdf489-eb4e-47a7-9c17-9f9ec75b3d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-c299ebe3-a47c-4814-abb9-130f2258e723,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-5b1010e2-fd9a-4f91-a252-4204dbc38d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-fc94dd7b-6fc3-46a0-a079-963e88de70e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957338914-172.17.0.21-1597141981682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35002,DS-89432a5b-6c48-4d39-976d-554a96c3f4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-a6fa3f71-de98-4d0e-842e-7ca4a94be4de,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-68eabe4f-47f7-45de-8dd8-c3642bad7120,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-e4c62ee8-d767-44ac-bd9d-eafbb9584bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-d7fdf489-eb4e-47a7-9c17-9f9ec75b3d23,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-c299ebe3-a47c-4814-abb9-130f2258e723,DISK], DatanodeInfoWithStorage[127.0.0.1:32960,DS-5b1010e2-fd9a-4f91-a252-4204dbc38d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-fc94dd7b-6fc3-46a0-a079-963e88de70e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 8
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740648490-172.17.0.21-1597142452297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-f4d07562-555a-4cd7-81f3-fbc5463815dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-c78aa36d-db19-4b1e-9655-5a106f607551,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-87bce740-6651-414b-8de7-146116284120,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-16ffe3ef-f48e-4267-9693-afc76cfc1184,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-d910c48c-8cb6-4a29-ae82-5d0bc720dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-b5869166-b2c1-4bbe-8082-afb38b6a88a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-f7c97dc5-e51d-4814-a6f5-48f9cc61afc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-346e3e60-034a-48b1-a0fc-dc74ad691d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740648490-172.17.0.21-1597142452297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-f4d07562-555a-4cd7-81f3-fbc5463815dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-c78aa36d-db19-4b1e-9655-5a106f607551,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-87bce740-6651-414b-8de7-146116284120,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-16ffe3ef-f48e-4267-9693-afc76cfc1184,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-d910c48c-8cb6-4a29-ae82-5d0bc720dcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-b5869166-b2c1-4bbe-8082-afb38b6a88a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-f7c97dc5-e51d-4814-a6f5-48f9cc61afc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-346e3e60-034a-48b1-a0fc-dc74ad691d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5342
