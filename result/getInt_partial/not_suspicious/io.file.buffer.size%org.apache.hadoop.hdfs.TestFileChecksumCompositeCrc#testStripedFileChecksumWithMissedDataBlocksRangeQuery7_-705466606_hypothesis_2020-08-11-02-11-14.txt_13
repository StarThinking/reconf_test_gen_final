reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227898410-172.17.0.12-1597112088772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-7d2a58c1-eb5d-4957-9c27-ba88a97cec64,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-0fa00ee0-51e6-4a4a-9fd6-327db18a4591,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-b362a1fc-cfcd-4b3f-ab90-b3870731d042,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-b79ee443-f54f-4fc4-aad1-7dd507006cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-076f9ce8-e658-447d-8a02-345572d6d995,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-4bca4530-cd34-4934-a21f-cd19af6ca4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-96cc485d-cc08-49eb-aea2-6a53c7311620,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-2a02a73c-531c-4711-9323-3bd9c6891151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-227898410-172.17.0.12-1597112088772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38492,DS-7d2a58c1-eb5d-4957-9c27-ba88a97cec64,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-0fa00ee0-51e6-4a4a-9fd6-327db18a4591,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-b362a1fc-cfcd-4b3f-ab90-b3870731d042,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-b79ee443-f54f-4fc4-aad1-7dd507006cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-076f9ce8-e658-447d-8a02-345572d6d995,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-4bca4530-cd34-4934-a21f-cd19af6ca4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-96cc485d-cc08-49eb-aea2-6a53c7311620,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-2a02a73c-531c-4711-9323-3bd9c6891151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967742307-172.17.0.12-1597112328783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-836a097c-7b04-4199-b51d-3bd0f4f1efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-5c7983fd-b2ab-48e1-a726-77c0fe753d81,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-038df8a0-4f38-4474-bb71-887843443d03,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-e23b53b5-df1c-454b-b91f-4cac0e524821,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-c8d090e2-43a2-4d4a-a148-4c465d0d23f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-43390e6e-b70d-479d-af4e-eab4d214791b,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-5614fad0-f72f-42f3-8dcc-487ca3041177,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-60ef34cf-18f8-472f-a23b-742918d36c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967742307-172.17.0.12-1597112328783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-836a097c-7b04-4199-b51d-3bd0f4f1efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-5c7983fd-b2ab-48e1-a726-77c0fe753d81,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-038df8a0-4f38-4474-bb71-887843443d03,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-e23b53b5-df1c-454b-b91f-4cac0e524821,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-c8d090e2-43a2-4d4a-a148-4c465d0d23f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-43390e6e-b70d-479d-af4e-eab4d214791b,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-5614fad0-f72f-42f3-8dcc-487ca3041177,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-60ef34cf-18f8-472f-a23b-742918d36c3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352939633-172.17.0.12-1597112545934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42452,DS-8fdbca66-2e99-42e3-868f-0158d5b51c00,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-a276584b-f6a6-43d2-9c18-357decbd74de,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-c555e1da-fe6b-41ec-add7-c8f8df173130,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-5ee0c29f-e96b-4988-b62e-273f6f84adb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-84a4b8b6-bbb5-44dc-8335-d16d328ff6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-ce3b085d-24ca-4f49-b98d-a5dad84a0257,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-1bbd7862-f9cf-4660-9fda-89a93aa7c82e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-c8c2a79d-9b50-46c6-9f05-b396e6ed944f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352939633-172.17.0.12-1597112545934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42452,DS-8fdbca66-2e99-42e3-868f-0158d5b51c00,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-a276584b-f6a6-43d2-9c18-357decbd74de,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-c555e1da-fe6b-41ec-add7-c8f8df173130,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-5ee0c29f-e96b-4988-b62e-273f6f84adb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-84a4b8b6-bbb5-44dc-8335-d16d328ff6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-ce3b085d-24ca-4f49-b98d-a5dad84a0257,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-1bbd7862-f9cf-4660-9fda-89a93aa7c82e,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-c8c2a79d-9b50-46c6-9f05-b396e6ed944f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281715851-172.17.0.12-1597112949918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34939,DS-0b3f043a-0409-42d2-8cad-1e48334aad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-feebdd7f-1bc2-4e64-a5c6-11c8202db5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-3ae08078-80af-4fa8-b420-c7c65787e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-76bbca64-e8d3-4a79-99f8-8bc4c3e4f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-285f24d1-629d-49cd-aea7-541a9c1c4b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-edfdf88d-97db-4c31-882f-b510e3e0bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-e7cb1bb8-b383-4439-8c34-e2fdafd5acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-a0e27720-5c48-4e64-b0ba-4a1f30d5560d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1281715851-172.17.0.12-1597112949918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34939,DS-0b3f043a-0409-42d2-8cad-1e48334aad0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-feebdd7f-1bc2-4e64-a5c6-11c8202db5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-3ae08078-80af-4fa8-b420-c7c65787e5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-76bbca64-e8d3-4a79-99f8-8bc4c3e4f22c,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-285f24d1-629d-49cd-aea7-541a9c1c4b54,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-edfdf88d-97db-4c31-882f-b510e3e0bac8,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-e7cb1bb8-b383-4439-8c34-e2fdafd5acb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-a0e27720-5c48-4e64-b0ba-4a1f30d5560d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70321709-172.17.0.12-1597113146160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41660,DS-f8977801-4403-4811-b692-a45187b448bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-bbcfe2a8-7a3f-42e2-8091-48ff43c65977,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-27275b5b-025e-48ad-b824-31949f9b7ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-33b5691a-731e-45a6-ae8f-8fedc6c25793,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-75e880d8-4f43-49be-a7ca-586f458d8b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-5fd90b71-dcc0-48b6-a6d2-62ca15f79dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-6d4d6c20-affd-4096-b165-0882e06900c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-7fb6f700-5f0c-4aa3-bb32-f8be6847c513,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70321709-172.17.0.12-1597113146160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41660,DS-f8977801-4403-4811-b692-a45187b448bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-bbcfe2a8-7a3f-42e2-8091-48ff43c65977,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-27275b5b-025e-48ad-b824-31949f9b7ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-33b5691a-731e-45a6-ae8f-8fedc6c25793,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-75e880d8-4f43-49be-a7ca-586f458d8b39,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-5fd90b71-dcc0-48b6-a6d2-62ca15f79dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-6d4d6c20-affd-4096-b165-0882e06900c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-7fb6f700-5f0c-4aa3-bb32-f8be6847c513,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544583611-172.17.0.12-1597113454642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38535,DS-4ac5e0f6-a0c9-4362-b5d5-0852440fdab7,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-8ab1acf3-31d1-4905-baa3-a55a3a70ff45,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-8fc0aba9-7839-4d38-807e-370fcb892faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-7009de5e-d975-4835-ac98-cb629773e958,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-100391d9-49b2-4322-84de-3ddafd77431a,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-151f593b-727c-468a-a9e2-aa167f965938,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-725a28fa-ad96-42d7-9fcd-fc4b37d71976,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-be171134-585a-4718-a4df-ea7297a49654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-544583611-172.17.0.12-1597113454642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38535,DS-4ac5e0f6-a0c9-4362-b5d5-0852440fdab7,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-8ab1acf3-31d1-4905-baa3-a55a3a70ff45,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-8fc0aba9-7839-4d38-807e-370fcb892faf,DISK], DatanodeInfoWithStorage[127.0.0.1:33171,DS-7009de5e-d975-4835-ac98-cb629773e958,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-100391d9-49b2-4322-84de-3ddafd77431a,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-151f593b-727c-468a-a9e2-aa167f965938,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-725a28fa-ad96-42d7-9fcd-fc4b37d71976,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-be171134-585a-4718-a4df-ea7297a49654,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245159157-172.17.0.12-1597113593707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40388,DS-83045342-3219-4db3-a63f-c04c4cc42ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-fed2b963-cb20-4824-b562-b29779ce71d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-6e3d2898-ebed-4bf2-aeaf-bbc678bd5249,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-3200817c-c33d-4a67-b9ab-cfe9acda3d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-4598532c-9d2e-4570-8333-166682046552,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-c0d7e527-4379-4ec7-a7cf-75645f553f93,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-585e2c75-5a5c-4806-b659-1fb7b482d147,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-40163a8a-7a70-4469-ab5c-ea12bfcbc7d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-245159157-172.17.0.12-1597113593707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40388,DS-83045342-3219-4db3-a63f-c04c4cc42ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-fed2b963-cb20-4824-b562-b29779ce71d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-6e3d2898-ebed-4bf2-aeaf-bbc678bd5249,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-3200817c-c33d-4a67-b9ab-cfe9acda3d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-4598532c-9d2e-4570-8333-166682046552,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-c0d7e527-4379-4ec7-a7cf-75645f553f93,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-585e2c75-5a5c-4806-b659-1fb7b482d147,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-40163a8a-7a70-4469-ab5c-ea12bfcbc7d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346521576-172.17.0.12-1597114004147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43221,DS-5c2972f9-2d58-482b-98ad-5e0653109716,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-6e39e7f6-311c-48d8-861f-e1b7c57206bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-3e7f9d6d-50ca-4d17-b88b-feff409db972,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-e5238f99-78a1-4583-a335-120c08c80fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-0925ae25-59bd-40c3-90e4-c4fa00eccc75,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-da8e3203-d8f3-4695-b82d-c96078829482,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-b090bd50-4b71-4284-927f-6a010634d73f,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-a2ffdddb-9cd8-4564-8133-05d284ad0129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346521576-172.17.0.12-1597114004147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43221,DS-5c2972f9-2d58-482b-98ad-5e0653109716,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-6e39e7f6-311c-48d8-861f-e1b7c57206bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-3e7f9d6d-50ca-4d17-b88b-feff409db972,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-e5238f99-78a1-4583-a335-120c08c80fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-0925ae25-59bd-40c3-90e4-c4fa00eccc75,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-da8e3203-d8f3-4695-b82d-c96078829482,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-b090bd50-4b71-4284-927f-6a010634d73f,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-a2ffdddb-9cd8-4564-8133-05d284ad0129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598995063-172.17.0.12-1597114122681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-61f2360c-9c8e-4b5c-8616-67debe5cce22,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-ce9bddb8-37ac-46d5-aa7c-718113501f32,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-df6ab402-e52b-498c-b392-868b89e67d29,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-0749f580-cc44-4c94-97fb-aca60ad6af43,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-5a4bb980-69cb-4674-83a0-e8f6ec62966d,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-1da65822-d3c1-45b1-a969-c32531bfd533,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-4a95f7e8-ee32-4dec-8e1f-128cd2a555ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-906bcc0a-d767-43c7-9fe0-4029ffdfa029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598995063-172.17.0.12-1597114122681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-61f2360c-9c8e-4b5c-8616-67debe5cce22,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-ce9bddb8-37ac-46d5-aa7c-718113501f32,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-df6ab402-e52b-498c-b392-868b89e67d29,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-0749f580-cc44-4c94-97fb-aca60ad6af43,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-5a4bb980-69cb-4674-83a0-e8f6ec62966d,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-1da65822-d3c1-45b1-a969-c32531bfd533,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-4a95f7e8-ee32-4dec-8e1f-128cd2a555ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-906bcc0a-d767-43c7-9fe0-4029ffdfa029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290272654-172.17.0.12-1597114275930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-315f64d3-6f72-495b-ba80-2019fc98d3da,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-257f756f-6e06-4c01-99ba-5a669553df0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-8a1c59c5-b24a-42ff-8bcc-6ecb87774b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-380eda0e-8429-475a-84da-88d933f5661e,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-29e6a9b0-e31b-4e3b-ae3a-b4fbad46a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-bbb02386-4f79-4806-9d88-7b09c127b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-ecd8c430-67c5-4d5c-82e7-9602cd55f203,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-1ab9a509-d377-45d1-b72f-b33439bf1147,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290272654-172.17.0.12-1597114275930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-315f64d3-6f72-495b-ba80-2019fc98d3da,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-257f756f-6e06-4c01-99ba-5a669553df0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-8a1c59c5-b24a-42ff-8bcc-6ecb87774b41,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-380eda0e-8429-475a-84da-88d933f5661e,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-29e6a9b0-e31b-4e3b-ae3a-b4fbad46a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-bbb02386-4f79-4806-9d88-7b09c127b3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-ecd8c430-67c5-4d5c-82e7-9602cd55f203,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-1ab9a509-d377-45d1-b72f-b33439bf1147,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908682319-172.17.0.12-1597114408752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-88fc8ffb-edaa-4399-9a40-8b70a1c0d88a,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-6c8678bd-ed9d-4ef9-b1b8-a63fd4f6cdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-833c4581-3995-4578-a3e5-9bc68e828531,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-33e970a1-6af6-4f18-8984-bcf0e73e50b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-5d910a15-cfa2-4f55-b39f-dd9739b35ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-fec7910d-169a-4921-864e-15bb8173ddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-940fcb71-1fb4-4e81-ac54-83138821c03e,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-4fcdce2c-7ca6-4e96-b79b-bf3319250a52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908682319-172.17.0.12-1597114408752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-88fc8ffb-edaa-4399-9a40-8b70a1c0d88a,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-6c8678bd-ed9d-4ef9-b1b8-a63fd4f6cdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-833c4581-3995-4578-a3e5-9bc68e828531,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-33e970a1-6af6-4f18-8984-bcf0e73e50b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-5d910a15-cfa2-4f55-b39f-dd9739b35ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-fec7910d-169a-4921-864e-15bb8173ddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-940fcb71-1fb4-4e81-ac54-83138821c03e,DISK], DatanodeInfoWithStorage[127.0.0.1:40735,DS-4fcdce2c-7ca6-4e96-b79b-bf3319250a52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484451949-172.17.0.12-1597114701240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45415,DS-fb9040e3-c3d3-4e8a-adfd-6c239d56a7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-972d6e9a-76cf-4cb9-8b82-8107cc58478d,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-e657d685-3955-4231-8327-7ddc22b26b14,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-b4c3d761-ed68-4d72-96e3-c895b3218d91,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-ce148d50-0c49-4b73-abc6-be1e130e24ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-e07583af-69d1-4f8d-a770-6c49d6d1523a,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-93ae4650-464b-4aa4-9cbb-ce62e861f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-6ad0b4f6-6e15-44ae-a781-246ad4517649,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484451949-172.17.0.12-1597114701240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45415,DS-fb9040e3-c3d3-4e8a-adfd-6c239d56a7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-972d6e9a-76cf-4cb9-8b82-8107cc58478d,DISK], DatanodeInfoWithStorage[127.0.0.1:35920,DS-e657d685-3955-4231-8327-7ddc22b26b14,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-b4c3d761-ed68-4d72-96e3-c895b3218d91,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-ce148d50-0c49-4b73-abc6-be1e130e24ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-e07583af-69d1-4f8d-a770-6c49d6d1523a,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-93ae4650-464b-4aa4-9cbb-ce62e861f4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-6ad0b4f6-6e15-44ae-a781-246ad4517649,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474574921-172.17.0.12-1597114735404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-4861e60a-718a-418d-8e0a-cb882f97c466,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-80635792-6d2c-4bc5-a77c-cd4759fa555d,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-16619085-a8d4-4cec-aa67-4bc4be376b37,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-b1f0e3ea-43f0-4f16-8e94-437b332ff1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-269a1857-8b35-4226-b109-a05031487eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-5414041f-7a8f-4add-aafa-f788d08d8f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-1b41fb73-469b-4ddb-b26c-2ec5401af41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-53d61086-a84c-4e07-8a53-1832bf36b096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474574921-172.17.0.12-1597114735404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-4861e60a-718a-418d-8e0a-cb882f97c466,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-80635792-6d2c-4bc5-a77c-cd4759fa555d,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-16619085-a8d4-4cec-aa67-4bc4be376b37,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-b1f0e3ea-43f0-4f16-8e94-437b332ff1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-269a1857-8b35-4226-b109-a05031487eff,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-5414041f-7a8f-4add-aafa-f788d08d8f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-1b41fb73-469b-4ddb-b26c-2ec5401af41e,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-53d61086-a84c-4e07-8a53-1832bf36b096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045745314-172.17.0.12-1597114771849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43393,DS-2b57c426-23af-469b-b99f-2a976bf8388b,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-b1205b48-adcb-4591-a7f5-18b00734f2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-7408e214-bb80-4d4d-be09-fa3adebc3683,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-e49b16ea-9f9e-4f24-849d-6857070b0aca,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-47e7cebe-cfaf-46cd-aec6-afc1ae9af83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-6c45a071-a2c8-4e20-9c25-7b4ee36d16b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-6c99ae48-5d9b-437d-8ca6-b46bea15909d,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-1bd98269-11e7-4a08-9cd9-1dd24a83a62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045745314-172.17.0.12-1597114771849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43393,DS-2b57c426-23af-469b-b99f-2a976bf8388b,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-b1205b48-adcb-4591-a7f5-18b00734f2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-7408e214-bb80-4d4d-be09-fa3adebc3683,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-e49b16ea-9f9e-4f24-849d-6857070b0aca,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-47e7cebe-cfaf-46cd-aec6-afc1ae9af83c,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-6c45a071-a2c8-4e20-9c25-7b4ee36d16b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-6c99ae48-5d9b-437d-8ca6-b46bea15909d,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-1bd98269-11e7-4a08-9cd9-1dd24a83a62f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889127496-172.17.0.12-1597114841899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33737,DS-4329ba39-15af-41ef-ac78-cb1d68e2225f,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-f385b5b5-7081-49b8-bced-58da2e7220c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-239358d2-49c2-41f6-b592-db3de0abee68,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-591d50cf-a160-4250-ba6d-45724563f156,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-55a04637-7c66-4fd0-8bbb-b66151ecc3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-ecb94fd1-186c-40b8-99d7-bd7c8edab866,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-6bc4f7b6-a579-4f51-8349-e1a4d7ad08ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-34e00638-bdb8-4bdc-aeb5-8ed18ea4e806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889127496-172.17.0.12-1597114841899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33737,DS-4329ba39-15af-41ef-ac78-cb1d68e2225f,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-f385b5b5-7081-49b8-bced-58da2e7220c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-239358d2-49c2-41f6-b592-db3de0abee68,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-591d50cf-a160-4250-ba6d-45724563f156,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-55a04637-7c66-4fd0-8bbb-b66151ecc3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-ecb94fd1-186c-40b8-99d7-bd7c8edab866,DISK], DatanodeInfoWithStorage[127.0.0.1:37646,DS-6bc4f7b6-a579-4f51-8349-e1a4d7ad08ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-34e00638-bdb8-4bdc-aeb5-8ed18ea4e806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384671064-172.17.0.12-1597115006877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40832,DS-035e6a8a-a418-4bf3-8559-1fc180b03da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-5dc1c113-3dc7-4516-8eac-982294e8ceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-31a1eb6e-860b-4ead-8b17-30a29c5214c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-ed4c88b9-c4bc-4324-9609-8737479aa9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-ff4c12af-d41b-4371-a258-3697def15bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-ec4b16a5-07b5-44b5-ab24-aa69e2fbb734,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-1b322546-22a1-4166-910d-3ce2939ecb12,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-feba814c-6158-424b-a39b-88c245ec44c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384671064-172.17.0.12-1597115006877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40832,DS-035e6a8a-a418-4bf3-8559-1fc180b03da3,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-5dc1c113-3dc7-4516-8eac-982294e8ceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-31a1eb6e-860b-4ead-8b17-30a29c5214c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-ed4c88b9-c4bc-4324-9609-8737479aa9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-ff4c12af-d41b-4371-a258-3697def15bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-ec4b16a5-07b5-44b5-ab24-aa69e2fbb734,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-1b322546-22a1-4166-910d-3ce2939ecb12,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-feba814c-6158-424b-a39b-88c245ec44c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670486960-172.17.0.12-1597115537405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38849,DS-06a379da-088f-44b3-b166-5219d2cc3499,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-640ad7cf-c823-4ec2-ab12-995cf4db201e,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-f47df5c1-74e9-4963-b3ab-e69848044512,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-bace2b27-b079-45cb-b630-41342fa4ff75,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-759a90ca-d4fc-4c58-b8c5-3f4c774444b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-ff7cb09a-d89e-48a9-8330-4351b2ddce16,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-f2e5ace9-79cb-40c3-a951-a16aee331e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-a794e5b7-9d9f-47e6-993b-4894dbd4b56f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670486960-172.17.0.12-1597115537405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38849,DS-06a379da-088f-44b3-b166-5219d2cc3499,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-640ad7cf-c823-4ec2-ab12-995cf4db201e,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-f47df5c1-74e9-4963-b3ab-e69848044512,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-bace2b27-b079-45cb-b630-41342fa4ff75,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-759a90ca-d4fc-4c58-b8c5-3f4c774444b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-ff7cb09a-d89e-48a9-8330-4351b2ddce16,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-f2e5ace9-79cb-40c3-a951-a16aee331e28,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-a794e5b7-9d9f-47e6-993b-4894dbd4b56f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461707900-172.17.0.12-1597115625250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42858,DS-41ba3313-785e-469f-8d0c-5462b2a94a01,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-617b8b8b-70c2-46a6-bb95-468252ddc9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-b93414a1-1940-4d4c-81da-b7daca9681b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-4b81eddc-f894-44e1-9237-05d1cd43c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-e2280b26-6951-46e1-9a92-f22af0a289c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-d138e42b-5dc0-4b6b-8825-5a3668cf7ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-11c0b54d-214f-499f-b05b-e5da6926b3be,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-0c70c211-4b9c-4b7a-b4a3-90a98360c00a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461707900-172.17.0.12-1597115625250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42858,DS-41ba3313-785e-469f-8d0c-5462b2a94a01,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-617b8b8b-70c2-46a6-bb95-468252ddc9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-b93414a1-1940-4d4c-81da-b7daca9681b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-4b81eddc-f894-44e1-9237-05d1cd43c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-e2280b26-6951-46e1-9a92-f22af0a289c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-d138e42b-5dc0-4b6b-8825-5a3668cf7ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-11c0b54d-214f-499f-b05b-e5da6926b3be,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-0c70c211-4b9c-4b7a-b4a3-90a98360c00a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106254034-172.17.0.12-1597115787129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-0ca50694-5112-4e24-b162-00a05bab1612,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-d87fc9d5-3d13-45fb-bcb4-7eb1bb96240a,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-4868dbad-4859-477a-b8db-8e8b065b28a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-fba3c561-c1cc-448e-b55f-5de134c46dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-0d12ef1d-1ab2-49f9-a682-1bb2634ca8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-ab3da7bf-1574-4a9e-b73d-30afe9c0f474,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-5356f14a-86d1-4784-8f99-e195ea13267b,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-0909c03e-4535-4feb-9b20-beee510fab84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106254034-172.17.0.12-1597115787129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-0ca50694-5112-4e24-b162-00a05bab1612,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-d87fc9d5-3d13-45fb-bcb4-7eb1bb96240a,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-4868dbad-4859-477a-b8db-8e8b065b28a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-fba3c561-c1cc-448e-b55f-5de134c46dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-0d12ef1d-1ab2-49f9-a682-1bb2634ca8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-ab3da7bf-1574-4a9e-b73d-30afe9c0f474,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-5356f14a-86d1-4784-8f99-e195ea13267b,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-0909c03e-4535-4feb-9b20-beee510fab84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57903438-172.17.0.12-1597115863398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37318,DS-a920ad92-b430-4025-9ed6-2d343528f996,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-c9396dbf-bca8-49b1-b249-61ee2f13801e,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-b4bbcc11-a2e1-4772-8c07-a0e2f07bf393,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-70812e68-4742-4e92-aad4-41cb644410fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-857d5ca8-266e-46d3-bbbc-fe81259187c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-470bf1c4-9744-4b83-a7bc-ffabbbbd9a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-3c47010b-9f12-4f1e-b4b5-a0ebceb25dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-bb2cc6be-085b-43a7-a821-8cd65e25198b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57903438-172.17.0.12-1597115863398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37318,DS-a920ad92-b430-4025-9ed6-2d343528f996,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-c9396dbf-bca8-49b1-b249-61ee2f13801e,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-b4bbcc11-a2e1-4772-8c07-a0e2f07bf393,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-70812e68-4742-4e92-aad4-41cb644410fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-857d5ca8-266e-46d3-bbbc-fe81259187c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-470bf1c4-9744-4b83-a7bc-ffabbbbd9a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-3c47010b-9f12-4f1e-b4b5-a0ebceb25dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-bb2cc6be-085b-43a7-a821-8cd65e25198b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030802653-172.17.0.12-1597115902318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-cd098f02-4e5f-423b-8e0c-3fb063a7edb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-73b7da4e-6407-46ac-84c2-534df8977808,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-785cfe3d-049f-4651-829a-625fe3231cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-3605b049-d56a-4b66-9227-a2bd91fecbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-d5c45b79-5ba9-47a9-a349-6ca9c07ab9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-d3ad2561-b3f3-4293-b55d-fb43c68a2b46,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-8a0fe4b6-1760-4ded-a07b-7784e1265ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-8e276b5c-7692-4f01-9eb8-4f3bbdeb2e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030802653-172.17.0.12-1597115902318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-cd098f02-4e5f-423b-8e0c-3fb063a7edb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-73b7da4e-6407-46ac-84c2-534df8977808,DISK], DatanodeInfoWithStorage[127.0.0.1:41478,DS-785cfe3d-049f-4651-829a-625fe3231cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-3605b049-d56a-4b66-9227-a2bd91fecbda,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-d5c45b79-5ba9-47a9-a349-6ca9c07ab9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-d3ad2561-b3f3-4293-b55d-fb43c68a2b46,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-8a0fe4b6-1760-4ded-a07b-7784e1265ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-8e276b5c-7692-4f01-9eb8-4f3bbdeb2e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774477932-172.17.0.12-1597115971328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44140,DS-66eb348b-52ba-421e-950c-ab542261f570,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-41d2f08d-c774-4486-a6a5-00c226fa09eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-772be94e-81ef-421d-bc4c-b38c6bb73f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f6db5aa1-4e5c-40fc-a657-cd4747309581,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-aa6d1fa8-aa7d-4cf1-8b97-2f109c30f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-c10f4518-a424-4bfa-b39b-cfa8903cfdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-e054a450-9353-4480-8fa1-1ef531422c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-73b267e9-cd04-4507-8975-1c067e843e7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774477932-172.17.0.12-1597115971328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44140,DS-66eb348b-52ba-421e-950c-ab542261f570,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-41d2f08d-c774-4486-a6a5-00c226fa09eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-772be94e-81ef-421d-bc4c-b38c6bb73f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f6db5aa1-4e5c-40fc-a657-cd4747309581,DISK], DatanodeInfoWithStorage[127.0.0.1:44528,DS-aa6d1fa8-aa7d-4cf1-8b97-2f109c30f1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-c10f4518-a424-4bfa-b39b-cfa8903cfdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-e054a450-9353-4480-8fa1-1ef531422c62,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-73b267e9-cd04-4507-8975-1c067e843e7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618936198-172.17.0.12-1597116260411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33591,DS-40911c7c-0cea-4009-99ca-1a4037ea98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-fca18cfc-b2dd-4bd3-a619-ca5c8322a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-c3751416-4675-4ca3-bbfd-2af6f063e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-840386ea-9bbe-4815-8f15-0368cce4b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-28e3107d-461e-4fcd-a5a6-520c4e07a35a,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-cc3a232b-2cb3-4476-8061-69ac726f09d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-0238a8b2-3c2f-4007-a431-8fc31f6164c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-6f7f0e1c-e5ed-4d27-ae99-1669a5df1fed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618936198-172.17.0.12-1597116260411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33591,DS-40911c7c-0cea-4009-99ca-1a4037ea98ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-fca18cfc-b2dd-4bd3-a619-ca5c8322a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43071,DS-c3751416-4675-4ca3-bbfd-2af6f063e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-840386ea-9bbe-4815-8f15-0368cce4b9af,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-28e3107d-461e-4fcd-a5a6-520c4e07a35a,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-cc3a232b-2cb3-4476-8061-69ac726f09d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-0238a8b2-3c2f-4007-a431-8fc31f6164c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-6f7f0e1c-e5ed-4d27-ae99-1669a5df1fed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345908801-172.17.0.12-1597116357826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-beb869a3-4ddf-4ce6-b84e-b95b723172d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-f968029a-4789-4cd4-85ba-d315a4365f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-66650273-2e11-42df-a5ea-fb5f267ccea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-7c074938-1775-4f81-a526-4daf719ebb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-54dbc57b-ef21-4881-9d56-663237ca4127,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-663c5eee-e0d0-49ef-8d1f-5b525c05f586,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-073df46e-b6d0-4fc4-8cfb-b9f79e3f0d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-cbf38138-c8fe-4fd4-9934-d4393701f8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345908801-172.17.0.12-1597116357826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43808,DS-beb869a3-4ddf-4ce6-b84e-b95b723172d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-f968029a-4789-4cd4-85ba-d315a4365f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-66650273-2e11-42df-a5ea-fb5f267ccea6,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-7c074938-1775-4f81-a526-4daf719ebb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-54dbc57b-ef21-4881-9d56-663237ca4127,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-663c5eee-e0d0-49ef-8d1f-5b525c05f586,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-073df46e-b6d0-4fc4-8cfb-b9f79e3f0d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-cbf38138-c8fe-4fd4-9934-d4393701f8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748198816-172.17.0.12-1597116527266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36171,DS-8902bae8-7bd2-435e-8fee-6fadf914be77,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-db2f4aff-2359-4b38-93d6-ac825e05137f,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-3694b578-524d-4ffe-9496-46bc88fab094,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-b32cebde-8b5b-4433-933e-755477434461,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-d2f99b31-2a99-48b4-a857-1ce0bbaf3e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-5b611819-1424-40cd-a9f8-1a0dd0b4d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-b52f813b-adfd-410d-9eee-90206fc73fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-78447b56-2cff-4e53-9506-d54f75e26d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748198816-172.17.0.12-1597116527266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36171,DS-8902bae8-7bd2-435e-8fee-6fadf914be77,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-db2f4aff-2359-4b38-93d6-ac825e05137f,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-3694b578-524d-4ffe-9496-46bc88fab094,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-b32cebde-8b5b-4433-933e-755477434461,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-d2f99b31-2a99-48b4-a857-1ce0bbaf3e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-5b611819-1424-40cd-a9f8-1a0dd0b4d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-b52f813b-adfd-410d-9eee-90206fc73fec,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-78447b56-2cff-4e53-9506-d54f75e26d8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693374849-172.17.0.12-1597116667011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41136,DS-fab7da2d-31f8-423c-8e8a-234342610be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-e3169f8f-e5b6-4216-8f53-9eef1121a1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-0a5c0ec1-b8f2-40ac-a3ab-2b936d9089a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-01dab7a6-810d-4f72-b84f-8a0e432487d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-8dd0fd7e-c9f0-4a2d-85ae-058090e49651,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-a13a01c7-ab9b-4fa1-8870-e714f9a8b7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-ec23d94d-deae-4df1-a6d5-b7cc0c6aa2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-f40100d4-7b90-4262-a8b6-d47c252781a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693374849-172.17.0.12-1597116667011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41136,DS-fab7da2d-31f8-423c-8e8a-234342610be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-e3169f8f-e5b6-4216-8f53-9eef1121a1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-0a5c0ec1-b8f2-40ac-a3ab-2b936d9089a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-01dab7a6-810d-4f72-b84f-8a0e432487d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-8dd0fd7e-c9f0-4a2d-85ae-058090e49651,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-a13a01c7-ab9b-4fa1-8870-e714f9a8b7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-ec23d94d-deae-4df1-a6d5-b7cc0c6aa2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-f40100d4-7b90-4262-a8b6-d47c252781a3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202052523-172.17.0.12-1597116765035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-af136f49-c6f2-48ff-9498-78091aae4903,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-93cba86a-38f3-4d71-a244-d2a7c99670fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-6a3e7ad4-442e-49ca-ab54-820084ce1839,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-8b1b8ca8-032d-4c9f-9827-67f405058b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-a9b7802f-76ee-4223-bc0a-8a484d107d38,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-89029a38-a165-40cc-a7cb-f0ea42e7a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-94b503fc-7163-4262-9685-1ecb853cbddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-c4bb30c7-e456-4987-ab15-5c74bc96eb34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202052523-172.17.0.12-1597116765035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45105,DS-af136f49-c6f2-48ff-9498-78091aae4903,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-93cba86a-38f3-4d71-a244-d2a7c99670fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-6a3e7ad4-442e-49ca-ab54-820084ce1839,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-8b1b8ca8-032d-4c9f-9827-67f405058b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-a9b7802f-76ee-4223-bc0a-8a484d107d38,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-89029a38-a165-40cc-a7cb-f0ea42e7a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-94b503fc-7163-4262-9685-1ecb853cbddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-c4bb30c7-e456-4987-ab15-5c74bc96eb34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513542692-172.17.0.12-1597116800679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-956b0719-0357-4109-9c37-c8e27bdd9217,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-cd1bc905-4740-42b9-8a13-a1eb229a7c29,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-37730564-02bb-480d-86a9-030c6cba1b04,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-5e8792ff-bc2f-489a-9b1c-42304e8713a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-c4f7ad96-beef-4b1a-874c-23837cec6705,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-ab0b2035-48fd-421b-8075-bbcf95d34ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-3b3cb4a6-6312-4d3c-a9c9-4d56878fe5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-92241128-41ea-4df6-9967-c5f6d11a87d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1513542692-172.17.0.12-1597116800679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-956b0719-0357-4109-9c37-c8e27bdd9217,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-cd1bc905-4740-42b9-8a13-a1eb229a7c29,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-37730564-02bb-480d-86a9-030c6cba1b04,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-5e8792ff-bc2f-489a-9b1c-42304e8713a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-c4f7ad96-beef-4b1a-874c-23837cec6705,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-ab0b2035-48fd-421b-8075-bbcf95d34ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-3b3cb4a6-6312-4d3c-a9c9-4d56878fe5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-92241128-41ea-4df6-9967-c5f6d11a87d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086640965-172.17.0.12-1597117028292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35304,DS-eaae1ebd-f76c-46eb-8140-2184bb1cd755,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-85f18c80-ea7d-42fd-9177-7675fd02d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-c8bb3aa5-a109-4305-8946-72866b0fcc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-9705c162-9daf-48d9-9e58-cd2ee8ab5d23,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-601b2f30-349b-4e6a-b90a-c64b24b1050b,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-075d5972-b683-4b1d-85b4-20715d97b1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-e4d97522-6fac-4e0f-8b09-b67e8b8c4a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-380d40d6-da4b-4d0d-97cc-37221bd591f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2086640965-172.17.0.12-1597117028292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35304,DS-eaae1ebd-f76c-46eb-8140-2184bb1cd755,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-85f18c80-ea7d-42fd-9177-7675fd02d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-c8bb3aa5-a109-4305-8946-72866b0fcc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-9705c162-9daf-48d9-9e58-cd2ee8ab5d23,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-601b2f30-349b-4e6a-b90a-c64b24b1050b,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-075d5972-b683-4b1d-85b4-20715d97b1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-e4d97522-6fac-4e0f-8b09-b67e8b8c4a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-380d40d6-da4b-4d0d-97cc-37221bd591f4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770086435-172.17.0.12-1597117099561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-08e0cab1-698d-479a-9c47-b27aa22698f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-b807a188-753f-4ab4-b79f-69a7cebc1760,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-69f553cb-3688-43be-a733-1c6781d25e17,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-838aa287-03e4-4ef8-a8a6-95e37f8229d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-c39193fa-14be-4e3e-8bd4-4a874d9b433c,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-128ec244-9cde-4b73-a0c9-b81607cd24be,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-df1a2764-bea0-443e-9353-9708800ea694,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-1b0279b3-e66c-4b62-873f-055eb9d56b1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770086435-172.17.0.12-1597117099561:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33333,DS-08e0cab1-698d-479a-9c47-b27aa22698f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35167,DS-b807a188-753f-4ab4-b79f-69a7cebc1760,DISK], DatanodeInfoWithStorage[127.0.0.1:42363,DS-69f553cb-3688-43be-a733-1c6781d25e17,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-838aa287-03e4-4ef8-a8a6-95e37f8229d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-c39193fa-14be-4e3e-8bd4-4a874d9b433c,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-128ec244-9cde-4b73-a0c9-b81607cd24be,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-df1a2764-bea0-443e-9353-9708800ea694,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-1b0279b3-e66c-4b62-873f-055eb9d56b1c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 64
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036913165-172.17.0.12-1597117237751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42037,DS-b66f8933-fde2-4172-ba6e-d1f432b9936f,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-5ca1e32a-1a1b-4457-957d-e59199bd0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-dd501f8e-d454-4960-8dc3-3bf15d723d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-2b268730-6a29-4331-87cf-272aab2650d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-fe083df3-beea-4cf8-b524-ef2fdac6971b,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-40d5cd80-816b-4c50-87a2-8c486d3df8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-4ae4cac4-87cf-4aec-a405-0306680ed21d,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-05586509-02bc-4166-aaf7-8bc5f49b1acf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036913165-172.17.0.12-1597117237751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42037,DS-b66f8933-fde2-4172-ba6e-d1f432b9936f,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-5ca1e32a-1a1b-4457-957d-e59199bd0fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-dd501f8e-d454-4960-8dc3-3bf15d723d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-2b268730-6a29-4331-87cf-272aab2650d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-fe083df3-beea-4cf8-b524-ef2fdac6971b,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-40d5cd80-816b-4c50-87a2-8c486d3df8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-4ae4cac4-87cf-4aec-a405-0306680ed21d,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-05586509-02bc-4166-aaf7-8bc5f49b1acf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5384
