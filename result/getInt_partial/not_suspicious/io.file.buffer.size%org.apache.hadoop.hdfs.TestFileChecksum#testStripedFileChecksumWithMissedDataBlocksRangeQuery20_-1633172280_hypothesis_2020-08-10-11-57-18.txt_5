reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410488107-172.17.0.10-1597061282829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41446,DS-bf84f78c-f9af-4259-9304-015da8adbf41,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-a5cc4237-b450-4337-a872-8f9cd7967ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-13b6a120-788d-4977-8ae4-9cdde7fd97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-fec798a9-61de-4b97-83e0-ca347a1db9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-f2f58c43-7e31-4f1d-8043-7d1ee3e43595,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-deeb6743-12ce-4621-9cd5-33e0d41cb424,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-449ff614-30c0-4be9-84ed-8f0a323a93ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-7a9f5450-0d8f-4dbd-8885-77a344026b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-410488107-172.17.0.10-1597061282829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41446,DS-bf84f78c-f9af-4259-9304-015da8adbf41,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-a5cc4237-b450-4337-a872-8f9cd7967ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-13b6a120-788d-4977-8ae4-9cdde7fd97fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-fec798a9-61de-4b97-83e0-ca347a1db9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-f2f58c43-7e31-4f1d-8043-7d1ee3e43595,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-deeb6743-12ce-4621-9cd5-33e0d41cb424,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-449ff614-30c0-4be9-84ed-8f0a323a93ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-7a9f5450-0d8f-4dbd-8885-77a344026b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793683118-172.17.0.10-1597061638040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-133ef8e1-6e10-4c64-9a7a-7c7bef8ba7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-fd11de62-2058-476d-b61c-c46c370fedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-9876a2ca-6e9b-42c6-a00c-deda43e7721b,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ebc900a7-0703-4922-8313-31453ecf4ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-0a463d6a-1ed9-477b-9933-7222621fddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-682ecca7-b529-44bd-8104-f076d5e6e348,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-922cc505-6881-4e29-9a34-1d7de095f394,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-73399ddf-d782-45a2-848a-7ae4da4f8929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793683118-172.17.0.10-1597061638040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-133ef8e1-6e10-4c64-9a7a-7c7bef8ba7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-fd11de62-2058-476d-b61c-c46c370fedf5,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-9876a2ca-6e9b-42c6-a00c-deda43e7721b,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ebc900a7-0703-4922-8313-31453ecf4ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-0a463d6a-1ed9-477b-9933-7222621fddeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-682ecca7-b529-44bd-8104-f076d5e6e348,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-922cc505-6881-4e29-9a34-1d7de095f394,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-73399ddf-d782-45a2-848a-7ae4da4f8929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141639904-172.17.0.10-1597061843464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39453,DS-bd0dccc1-82f1-4c77-8219-ee4bc0bd3c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-a927c510-e335-4007-9ab9-a3cc935408c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-5e53efb8-3324-43f2-bb3f-c262161eaa03,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-ffc26379-adfb-43ea-9bf9-60e1e09b9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-c829f92a-ed68-47a3-9a4f-c77dbeaa37d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-bb1827d2-470d-4d9f-bf28-f6a4dca60132,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-2ec85f71-863d-42c8-aa69-3d3d018d5668,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-5331e6fa-2b88-4c58-af66-cd7256471092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141639904-172.17.0.10-1597061843464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39453,DS-bd0dccc1-82f1-4c77-8219-ee4bc0bd3c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-a927c510-e335-4007-9ab9-a3cc935408c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-5e53efb8-3324-43f2-bb3f-c262161eaa03,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-ffc26379-adfb-43ea-9bf9-60e1e09b9a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-c829f92a-ed68-47a3-9a4f-c77dbeaa37d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-bb1827d2-470d-4d9f-bf28-f6a4dca60132,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-2ec85f71-863d-42c8-aa69-3d3d018d5668,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-5331e6fa-2b88-4c58-af66-cd7256471092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007134534-172.17.0.10-1597061883102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42285,DS-ad375b97-212b-4f0a-bf9b-f312d0686528,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-27708383-ae0b-4ef8-a522-17ce64a9b9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-93fc4400-69f3-4c22-897b-cb6d9c4664b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-715bb5d5-4f50-4165-ae0e-b0461efa3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-7116e68c-ad0f-4fcf-bf73-49a661a76984,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-1dae095b-9784-4479-b0fc-01c041c11fda,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-98c58016-b82d-4fc4-9496-22344ef2c154,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-910fd503-4600-4f2c-a2f4-ee8757400f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2007134534-172.17.0.10-1597061883102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42285,DS-ad375b97-212b-4f0a-bf9b-f312d0686528,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-27708383-ae0b-4ef8-a522-17ce64a9b9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-93fc4400-69f3-4c22-897b-cb6d9c4664b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-715bb5d5-4f50-4165-ae0e-b0461efa3a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-7116e68c-ad0f-4fcf-bf73-49a661a76984,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-1dae095b-9784-4479-b0fc-01c041c11fda,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-98c58016-b82d-4fc4-9496-22344ef2c154,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-910fd503-4600-4f2c-a2f4-ee8757400f57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910213153-172.17.0.10-1597061978201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-64390b12-6831-4667-b012-6836f0c81c37,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-2b62c83e-5a40-4a38-998d-7d013f3527e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-33e7be19-80c4-4afe-b243-0d0bc9e29f26,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-3fc43a75-6027-4c36-aa26-317641987246,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-dff315d2-3041-47e9-8d94-1f56f56b20e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-0fca96ea-59a0-4b27-8bc6-68ac399a1313,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-44d1b2d5-2937-44c4-b6f3-f7198729454b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-75315ebc-1aeb-48f4-b2a6-d50f3423df36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910213153-172.17.0.10-1597061978201:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33671,DS-64390b12-6831-4667-b012-6836f0c81c37,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-2b62c83e-5a40-4a38-998d-7d013f3527e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-33e7be19-80c4-4afe-b243-0d0bc9e29f26,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-3fc43a75-6027-4c36-aa26-317641987246,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-dff315d2-3041-47e9-8d94-1f56f56b20e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-0fca96ea-59a0-4b27-8bc6-68ac399a1313,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-44d1b2d5-2937-44c4-b6f3-f7198729454b,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-75315ebc-1aeb-48f4-b2a6-d50f3423df36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047993966-172.17.0.10-1597062137393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-cab6a847-5b8e-432c-80c2-4e803dc66422,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-8a774a1f-72a9-43d2-bb9f-7d03042f7ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-9d5d4930-6cdd-4df2-98c2-9ebb93f020c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-e0784bec-daad-496a-aaa7-53633d0168e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-324d95d4-678b-4a1c-8914-7240b2b47e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-28227dbe-3892-4075-8f6a-c2e53323aa31,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-bbe2f2e7-94ad-4fcb-b514-e2f009bc42d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-1a158484-45a4-43e3-8870-e31defb56d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047993966-172.17.0.10-1597062137393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40682,DS-cab6a847-5b8e-432c-80c2-4e803dc66422,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-8a774a1f-72a9-43d2-bb9f-7d03042f7ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-9d5d4930-6cdd-4df2-98c2-9ebb93f020c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-e0784bec-daad-496a-aaa7-53633d0168e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-324d95d4-678b-4a1c-8914-7240b2b47e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-28227dbe-3892-4075-8f6a-c2e53323aa31,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-bbe2f2e7-94ad-4fcb-b514-e2f009bc42d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-1a158484-45a4-43e3-8870-e31defb56d78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560553975-172.17.0.10-1597062443122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35639,DS-4fcb9a9e-3223-4ef0-b9d1-61a7aa415c62,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-32ff3b31-8547-4b37-a1c3-2d3432731684,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-cab98e5e-3b54-42c2-9623-27ef4e48de97,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-a50641d5-ed68-45e8-a86b-502c840f4c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-dad0a7c3-804f-45da-8253-37379c2e9ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-1ceff76b-860f-41b5-81e6-ad2274be01f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-a5499168-ee4d-42c2-a053-6987fc807ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-abcd334c-9f0b-4226-aa4c-3da520c224c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-560553975-172.17.0.10-1597062443122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35639,DS-4fcb9a9e-3223-4ef0-b9d1-61a7aa415c62,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-32ff3b31-8547-4b37-a1c3-2d3432731684,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-cab98e5e-3b54-42c2-9623-27ef4e48de97,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-a50641d5-ed68-45e8-a86b-502c840f4c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-dad0a7c3-804f-45da-8253-37379c2e9ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-1ceff76b-860f-41b5-81e6-ad2274be01f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-a5499168-ee4d-42c2-a053-6987fc807ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-abcd334c-9f0b-4226-aa4c-3da520c224c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687871361-172.17.0.10-1597062584064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-c3142b58-f35e-47ac-ad4e-e02e2c2e5e84,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-6ea39197-3d98-4746-9d6e-e7079ef5f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-53028ebf-8502-47e4-9635-7e9369e33fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-96d8e07b-df19-4762-98ff-dfcb875f7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-dd9e3150-1449-4441-bb05-fd0a5a4ee5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-e35595d2-ef1f-48ea-a4cd-9d8c593f58f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-ccea9ad1-f2e2-4d8c-89c1-598ffb1bed03,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-049f380b-0755-4e3a-9e86-3c19dcb6d5f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687871361-172.17.0.10-1597062584064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45617,DS-c3142b58-f35e-47ac-ad4e-e02e2c2e5e84,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-6ea39197-3d98-4746-9d6e-e7079ef5f4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-53028ebf-8502-47e4-9635-7e9369e33fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-96d8e07b-df19-4762-98ff-dfcb875f7d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-dd9e3150-1449-4441-bb05-fd0a5a4ee5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-e35595d2-ef1f-48ea-a4cd-9d8c593f58f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-ccea9ad1-f2e2-4d8c-89c1-598ffb1bed03,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-049f380b-0755-4e3a-9e86-3c19dcb6d5f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243144683-172.17.0.10-1597062733340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37232,DS-558c951f-37ee-430e-bb53-eeb5e221392f,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-027fbab7-46bd-483c-892e-006936d902f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-0e2fc114-ed93-43c2-8397-f28d128b8058,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-33b4125a-3eb8-480b-8489-319b900b4abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-a7debdcf-fc69-4a3a-9c0c-1523489003fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-a06eb93d-db40-4dac-98eb-d7a325e244bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-c574953f-bebd-4407-99a5-0844e30330e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-86b9015b-0531-4836-a278-c9d2e74b9eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-243144683-172.17.0.10-1597062733340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37232,DS-558c951f-37ee-430e-bb53-eeb5e221392f,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-027fbab7-46bd-483c-892e-006936d902f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-0e2fc114-ed93-43c2-8397-f28d128b8058,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-33b4125a-3eb8-480b-8489-319b900b4abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-a7debdcf-fc69-4a3a-9c0c-1523489003fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-a06eb93d-db40-4dac-98eb-d7a325e244bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-c574953f-bebd-4407-99a5-0844e30330e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-86b9015b-0531-4836-a278-c9d2e74b9eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677174076-172.17.0.10-1597062771133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-6e84af2a-8fc1-4a6f-998d-673d7b0c543b,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-8a365647-0206-412f-97f4-4e41b08b6241,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-d9258cc7-e896-4adc-b4dc-a0b856fd8b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-cf6df11f-4887-44fc-b442-fcd53a770afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-39d6cd4a-2a8a-4aa6-a13c-1305421c24c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-99e4de75-1b84-4fdf-a1ed-f394c57881d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-78958a03-fd21-4ce9-a007-8e9d6c1643ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-23a716f0-2486-43f5-b404-beb5ebff261a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677174076-172.17.0.10-1597062771133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-6e84af2a-8fc1-4a6f-998d-673d7b0c543b,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-8a365647-0206-412f-97f4-4e41b08b6241,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-d9258cc7-e896-4adc-b4dc-a0b856fd8b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-cf6df11f-4887-44fc-b442-fcd53a770afd,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-39d6cd4a-2a8a-4aa6-a13c-1305421c24c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-99e4de75-1b84-4fdf-a1ed-f394c57881d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-78958a03-fd21-4ce9-a007-8e9d6c1643ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-23a716f0-2486-43f5-b404-beb5ebff261a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339626223-172.17.0.10-1597062954256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43095,DS-3cbea820-67d0-430a-af04-eb2c7e9eedd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-26c96d5d-b1c8-4638-84b4-2c5a75175447,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-2d0a5b09-69cc-402b-8907-ad1dfc643b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-ab5c9e07-92b1-4c88-829c-1820cea86f53,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-74b9c14f-22ed-49df-a3a4-96996eddaee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-90b38839-0d85-4ef4-997c-19159449ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-228252b8-dbea-4ea6-8a19-d56911832a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-43e8db24-9985-46b1-9c7e-dd1712e74077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-339626223-172.17.0.10-1597062954256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43095,DS-3cbea820-67d0-430a-af04-eb2c7e9eedd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-26c96d5d-b1c8-4638-84b4-2c5a75175447,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-2d0a5b09-69cc-402b-8907-ad1dfc643b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39877,DS-ab5c9e07-92b1-4c88-829c-1820cea86f53,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-74b9c14f-22ed-49df-a3a4-96996eddaee8,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-90b38839-0d85-4ef4-997c-19159449ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-228252b8-dbea-4ea6-8a19-d56911832a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-43e8db24-9985-46b1-9c7e-dd1712e74077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730257922-172.17.0.10-1597063035127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-4af9458b-3c58-4b4e-b5da-209b067c4005,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-0b596e78-a71f-4b4e-b28a-bbf2eca5cd71,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-5a3f3b74-5599-4ed1-8060-6ba191aaac41,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-c0794dd5-77ad-4df2-a479-a597f7f4784f,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-73ca061f-7a2a-4724-9ab5-48d2d45f3f30,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-70686b6d-8c5d-474a-867b-b73fad010f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-52e2ce35-4657-4698-9a59-d2340165c988,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-b5e089d1-b3a0-40b8-9e6f-e351ed633d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730257922-172.17.0.10-1597063035127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40214,DS-4af9458b-3c58-4b4e-b5da-209b067c4005,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-0b596e78-a71f-4b4e-b28a-bbf2eca5cd71,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-5a3f3b74-5599-4ed1-8060-6ba191aaac41,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-c0794dd5-77ad-4df2-a479-a597f7f4784f,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-73ca061f-7a2a-4724-9ab5-48d2d45f3f30,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-70686b6d-8c5d-474a-867b-b73fad010f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-52e2ce35-4657-4698-9a59-d2340165c988,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-b5e089d1-b3a0-40b8-9e6f-e351ed633d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976805762-172.17.0.10-1597063137119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38123,DS-e3fa485a-ff57-4570-a77d-5690b6267f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-97e0c722-23b6-46fd-80f3-c9caa5564c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-9b341ce5-2392-4614-b83e-82a3bd5a2a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-88ed638d-e2eb-4236-a044-19e2cf377f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-8877a4e1-89d1-47bd-b080-d90525a78b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e888e606-8dee-4762-a063-6b643fe4a32a,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-32db3fe2-0584-4c3e-8dd7-8f760f00b188,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-00d9ba37-dc0f-4737-92fb-634760da1e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976805762-172.17.0.10-1597063137119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38123,DS-e3fa485a-ff57-4570-a77d-5690b6267f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-97e0c722-23b6-46fd-80f3-c9caa5564c42,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-9b341ce5-2392-4614-b83e-82a3bd5a2a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-88ed638d-e2eb-4236-a044-19e2cf377f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38494,DS-8877a4e1-89d1-47bd-b080-d90525a78b24,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-e888e606-8dee-4762-a063-6b643fe4a32a,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-32db3fe2-0584-4c3e-8dd7-8f760f00b188,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-00d9ba37-dc0f-4737-92fb-634760da1e8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163727809-172.17.0.10-1597063657902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-b52de14c-6fa6-482b-8368-03daf966d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-d2d265f5-af9d-44bc-8be1-697901dde11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-811c5e9a-d48b-4e4c-ab1f-fd8a6bdecef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-dcfbf162-4bc7-4ebc-a6a8-610e418d4d94,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-5aaedeb1-087e-4ff0-8ee1-7ba9525f4a36,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-3b76a79d-a113-41f5-bfa8-f3d4aa26592b,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-af48c69b-500f-44fe-b6db-485485af2f59,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-d8f69dab-a0bc-47c9-bbf1-92f72f0c2b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163727809-172.17.0.10-1597063657902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-b52de14c-6fa6-482b-8368-03daf966d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-d2d265f5-af9d-44bc-8be1-697901dde11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-811c5e9a-d48b-4e4c-ab1f-fd8a6bdecef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-dcfbf162-4bc7-4ebc-a6a8-610e418d4d94,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-5aaedeb1-087e-4ff0-8ee1-7ba9525f4a36,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-3b76a79d-a113-41f5-bfa8-f3d4aa26592b,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-af48c69b-500f-44fe-b6db-485485af2f59,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-d8f69dab-a0bc-47c9-bbf1-92f72f0c2b1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358965776-172.17.0.10-1597064095643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-f1689d21-35cf-4d41-a995-b6f76bd4f3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-2e44ff86-d917-458d-823f-43b4e13d0185,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-fc0ab021-e9af-45ed-aea0-3ece4a8fdfed,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-9f1cd170-e6c8-4b15-af27-4967dc56a9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-36aa2c65-c6d4-4405-a682-574fc0d30aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-c8f6cd28-7800-47e1-996b-f96fe666b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-15041f3b-a979-4b3a-bd40-9e93f0b239f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-e0eb7474-3bee-4796-b07d-0a30d6f21de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-358965776-172.17.0.10-1597064095643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34507,DS-f1689d21-35cf-4d41-a995-b6f76bd4f3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-2e44ff86-d917-458d-823f-43b4e13d0185,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-fc0ab021-e9af-45ed-aea0-3ece4a8fdfed,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-9f1cd170-e6c8-4b15-af27-4967dc56a9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-36aa2c65-c6d4-4405-a682-574fc0d30aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-c8f6cd28-7800-47e1-996b-f96fe666b8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-15041f3b-a979-4b3a-bd40-9e93f0b239f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42113,DS-e0eb7474-3bee-4796-b07d-0a30d6f21de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952036455-172.17.0.10-1597064381633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33212,DS-1b4556a4-1aec-4b5b-afd1-e5f89a1c5f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-39eca78a-cd1e-4c61-bb9d-30e56e65bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-26884b8a-2dc9-4e62-b57e-6abeba70254f,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-2adf68f0-397c-495f-91ee-8d0b594dc8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-c6b3aab5-5c2d-4f0c-b62d-44b9ce707d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-269d3b83-6e2e-4897-9bf5-6c1929fa3c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-80e32a02-13c4-410a-96f4-d56a7dd2a7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-3335781f-dcd9-43fc-9a9e-608338addb0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952036455-172.17.0.10-1597064381633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33212,DS-1b4556a4-1aec-4b5b-afd1-e5f89a1c5f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-39eca78a-cd1e-4c61-bb9d-30e56e65bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-26884b8a-2dc9-4e62-b57e-6abeba70254f,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-2adf68f0-397c-495f-91ee-8d0b594dc8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-c6b3aab5-5c2d-4f0c-b62d-44b9ce707d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-269d3b83-6e2e-4897-9bf5-6c1929fa3c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-80e32a02-13c4-410a-96f4-d56a7dd2a7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-3335781f-dcd9-43fc-9a9e-608338addb0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027883448-172.17.0.10-1597064420613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37683,DS-5265b2b4-7d94-4b88-91af-4b3b381bb03f,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-335b8088-7847-40c3-afe1-d77d99a73fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-77a1b472-43ce-4f57-a791-4ed7ed34eff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-f8b0509c-c388-4a04-9ed1-2a2258c3d722,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-4136121c-6895-4cdd-931c-aba7bcea5b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-a6910c79-c228-4456-8ccb-b0a8049a972d,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-89c33f82-0554-49a3-9fc5-6d50752e29da,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-ea2e969a-2db0-47a4-8c37-f55eb810ad46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2027883448-172.17.0.10-1597064420613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37683,DS-5265b2b4-7d94-4b88-91af-4b3b381bb03f,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-335b8088-7847-40c3-afe1-d77d99a73fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-77a1b472-43ce-4f57-a791-4ed7ed34eff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-f8b0509c-c388-4a04-9ed1-2a2258c3d722,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-4136121c-6895-4cdd-931c-aba7bcea5b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-a6910c79-c228-4456-8ccb-b0a8049a972d,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-89c33f82-0554-49a3-9fc5-6d50752e29da,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-ea2e969a-2db0-47a4-8c37-f55eb810ad46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97304501-172.17.0.10-1597064489624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-2e6d2ba2-1a47-4ea5-85d5-6459f283f062,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a0805416-616d-4246-8970-448529eb8935,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-22016988-f205-477c-bfbd-19fc52daaba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-29573787-ebe0-4055-87d5-efd4cd35de89,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-989a643e-c884-4cee-8bfc-0475b71043be,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-95851e42-16d2-40f9-9d56-8d836c780aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-9f7b0268-da6a-4e10-b8fc-1d5163b52430,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-023e3dec-fa80-4469-9c53-a5f5a957f074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97304501-172.17.0.10-1597064489624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33941,DS-2e6d2ba2-1a47-4ea5-85d5-6459f283f062,DISK], DatanodeInfoWithStorage[127.0.0.1:45015,DS-a0805416-616d-4246-8970-448529eb8935,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-22016988-f205-477c-bfbd-19fc52daaba1,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-29573787-ebe0-4055-87d5-efd4cd35de89,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-989a643e-c884-4cee-8bfc-0475b71043be,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-95851e42-16d2-40f9-9d56-8d836c780aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-9f7b0268-da6a-4e10-b8fc-1d5163b52430,DISK], DatanodeInfoWithStorage[127.0.0.1:33425,DS-023e3dec-fa80-4469-9c53-a5f5a957f074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517544411-172.17.0.10-1597064995863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-4f84308f-f6df-410b-a58d-5ae3fde765c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-b4690125-d9a5-457a-8ae8-ca9b5b9eec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-9e6171cc-e6b2-47d6-8bbb-4b8deaedde12,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-eee27dd8-0d83-4fcc-9e1b-8a490264c0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-e0d39b60-36f7-4840-865a-02892714eb07,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-622bf888-cd7c-496d-a387-c3b40a06b397,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-36965224-5c2d-433d-9ae1-615f59251b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-398f1aaf-1a2a-4a90-a843-3dbab4bff44d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517544411-172.17.0.10-1597064995863:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-4f84308f-f6df-410b-a58d-5ae3fde765c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-b4690125-d9a5-457a-8ae8-ca9b5b9eec1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-9e6171cc-e6b2-47d6-8bbb-4b8deaedde12,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-eee27dd8-0d83-4fcc-9e1b-8a490264c0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-e0d39b60-36f7-4840-865a-02892714eb07,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-622bf888-cd7c-496d-a387-c3b40a06b397,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-36965224-5c2d-433d-9ae1-615f59251b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-398f1aaf-1a2a-4a90-a843-3dbab4bff44d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454635592-172.17.0.10-1597065326743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-36157315-3af3-4a73-be03-c77542983aea,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-4bd31dfa-df20-436c-bf3c-5f298bcccdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e9ae9ee3-f690-45da-9fb7-88830e4771e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-ab7e7ce1-fd73-477d-a011-ea78e3b56e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-e303e0c3-22ed-4982-a94a-10821b5bf0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-72d193ab-f429-41e1-bfbf-cd5b8efc6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-4ca7d36a-d9b5-41cd-9d11-0de83d22a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-95a1bd3b-2b95-4e7f-bc1d-e0ae30eeab3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-454635592-172.17.0.10-1597065326743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36136,DS-36157315-3af3-4a73-be03-c77542983aea,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-4bd31dfa-df20-436c-bf3c-5f298bcccdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-e9ae9ee3-f690-45da-9fb7-88830e4771e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-ab7e7ce1-fd73-477d-a011-ea78e3b56e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-e303e0c3-22ed-4982-a94a-10821b5bf0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-72d193ab-f429-41e1-bfbf-cd5b8efc6ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-4ca7d36a-d9b5-41cd-9d11-0de83d22a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-95a1bd3b-2b95-4e7f-bc1d-e0ae30eeab3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039704181-172.17.0.10-1597065807516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-80e7369b-77b8-4ff4-b166-b9d3a5e53a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-483f5fe4-9f71-4c0d-9368-50bb0fbef94e,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-ed7f4f7f-cf2a-4304-8ebe-14ac26ba7951,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-5411a61e-e083-4b84-a15d-771275dc2c33,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-e2aa1a80-4b0c-465a-887a-c00da52b3d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-eb6493db-28e4-4a85-b948-d3bd02c7a078,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-b9b81dda-35e8-4e5b-b6a4-e85dff4dd42c,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-022c2d0b-4e69-40d8-9418-06c519d2e84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039704181-172.17.0.10-1597065807516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-80e7369b-77b8-4ff4-b166-b9d3a5e53a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-483f5fe4-9f71-4c0d-9368-50bb0fbef94e,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-ed7f4f7f-cf2a-4304-8ebe-14ac26ba7951,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-5411a61e-e083-4b84-a15d-771275dc2c33,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-e2aa1a80-4b0c-465a-887a-c00da52b3d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-eb6493db-28e4-4a85-b948-d3bd02c7a078,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-b9b81dda-35e8-4e5b-b6a4-e85dff4dd42c,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-022c2d0b-4e69-40d8-9418-06c519d2e84e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109151255-172.17.0.10-1597065840485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-7fcd0354-7bea-4e74-96a8-67b0ca6d7a73,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-658b34d4-4d56-4a29-91c2-0a3998575ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-490b755f-b439-4838-afb6-3aa95e29dbff,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-6abd729c-ace8-412b-80b7-94ab033d4715,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-2088b83c-aaa4-4a3d-93c5-2690f715ef2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-6d707916-f5c7-4079-8e49-8a46726a6a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-6a66a0af-7573-4a7d-a8cb-cbf7da0b5257,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-ef19538e-2190-4a2b-b103-cbdfb11fe328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109151255-172.17.0.10-1597065840485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33897,DS-7fcd0354-7bea-4e74-96a8-67b0ca6d7a73,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-658b34d4-4d56-4a29-91c2-0a3998575ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-490b755f-b439-4838-afb6-3aa95e29dbff,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-6abd729c-ace8-412b-80b7-94ab033d4715,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-2088b83c-aaa4-4a3d-93c5-2690f715ef2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-6d707916-f5c7-4079-8e49-8a46726a6a46,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-6a66a0af-7573-4a7d-a8cb-cbf7da0b5257,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-ef19538e-2190-4a2b-b103-cbdfb11fe328,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115825921-172.17.0.10-1597065868768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-3f5dfa45-e211-4234-be7e-852b5438569b,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-39b38e9c-7e16-4ebf-a7bf-05d07316e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-fa30a140-44fb-4012-9c4c-5482607c3399,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-22519a5d-8db1-45b4-950c-427e576867bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-b0628330-fd83-481a-90af-f4272d47f94f,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-262474fa-f186-4336-8819-d01c0e74fed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-11ae232e-d0dc-4c33-9aa4-aaaf3a5974c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-123d9244-26e5-4415-a9a5-0c08f7c60ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115825921-172.17.0.10-1597065868768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33966,DS-3f5dfa45-e211-4234-be7e-852b5438569b,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-39b38e9c-7e16-4ebf-a7bf-05d07316e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-fa30a140-44fb-4012-9c4c-5482607c3399,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-22519a5d-8db1-45b4-950c-427e576867bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-b0628330-fd83-481a-90af-f4272d47f94f,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-262474fa-f186-4336-8819-d01c0e74fed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-11ae232e-d0dc-4c33-9aa4-aaaf3a5974c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-123d9244-26e5-4415-a9a5-0c08f7c60ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5412
