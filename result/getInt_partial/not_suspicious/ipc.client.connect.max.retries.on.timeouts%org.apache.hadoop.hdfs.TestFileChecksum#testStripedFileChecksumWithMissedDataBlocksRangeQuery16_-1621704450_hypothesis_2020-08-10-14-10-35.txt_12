reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37987663-172.17.0.3-1597069087413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-55a63dcf-25b3-4bce-8dc6-d762ed6515b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-65db43b6-6c5c-4339-afab-f3738d60b6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-c805151d-2775-4b49-89ea-5766e4331c83,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-ac2ee2ea-7d2c-4590-9b40-e0d2dea70068,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-976e1bfe-e73d-4520-992d-d1476d56e346,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-36ff04cf-9794-4e7b-a353-881ddfa6b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-e60c9caf-2096-4ca7-af68-54bac3dda67e,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-fee661c3-932a-4c95-8555-499040e0b2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-37987663-172.17.0.3-1597069087413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42092,DS-55a63dcf-25b3-4bce-8dc6-d762ed6515b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-65db43b6-6c5c-4339-afab-f3738d60b6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-c805151d-2775-4b49-89ea-5766e4331c83,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-ac2ee2ea-7d2c-4590-9b40-e0d2dea70068,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-976e1bfe-e73d-4520-992d-d1476d56e346,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-36ff04cf-9794-4e7b-a353-881ddfa6b0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-e60c9caf-2096-4ca7-af68-54bac3dda67e,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-fee661c3-932a-4c95-8555-499040e0b2e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816999629-172.17.0.3-1597069494208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39160,DS-267d5c3b-4211-4449-93f4-499f20ef3b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-3e661810-6610-4511-a15b-6062298b2db0,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-c400dab7-ed43-4ae7-8043-2fbede6c1778,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-a8a0a69c-a3eb-4427-8141-954156e697fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-596b3460-955b-475d-9cfc-f6eb3468bde5,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-183c9983-04ec-45de-b93b-b5a9ccde48bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-e2c85a4a-91c7-49ff-8a58-d7f54312ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-3597c248-9a11-4fe1-b4d5-94265f4fbb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816999629-172.17.0.3-1597069494208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39160,DS-267d5c3b-4211-4449-93f4-499f20ef3b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-3e661810-6610-4511-a15b-6062298b2db0,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-c400dab7-ed43-4ae7-8043-2fbede6c1778,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-a8a0a69c-a3eb-4427-8141-954156e697fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-596b3460-955b-475d-9cfc-f6eb3468bde5,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-183c9983-04ec-45de-b93b-b5a9ccde48bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36457,DS-e2c85a4a-91c7-49ff-8a58-d7f54312ec6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-3597c248-9a11-4fe1-b4d5-94265f4fbb6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524645629-172.17.0.3-1597070007153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-37ab687b-bd4c-4ff7-9c44-b669812c63f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-2782781b-82dc-4a54-adb2-1c73605db1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-aac66106-c5ef-40b3-a40a-046942b5b09a,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-58cf8ae2-4f2d-4d13-9348-4d93f674c5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-292c4205-4dcb-46a1-a6cd-e3fddf49fb74,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-1dfa4501-29ee-4049-9df1-0568c7adb461,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-17bf69aa-9787-48f4-97e6-b83904160464,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-75214c93-1f40-4618-917b-fd5910a0165b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524645629-172.17.0.3-1597070007153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41113,DS-37ab687b-bd4c-4ff7-9c44-b669812c63f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-2782781b-82dc-4a54-adb2-1c73605db1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-aac66106-c5ef-40b3-a40a-046942b5b09a,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-58cf8ae2-4f2d-4d13-9348-4d93f674c5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-292c4205-4dcb-46a1-a6cd-e3fddf49fb74,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-1dfa4501-29ee-4049-9df1-0568c7adb461,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-17bf69aa-9787-48f4-97e6-b83904160464,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-75214c93-1f40-4618-917b-fd5910a0165b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21687917-172.17.0.3-1597070158424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42243,DS-f2f588bb-507b-43b4-8d5c-cc95bc49c142,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-6f0b7267-392c-4e3a-8b9e-2ca982f2c486,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-e508b1b4-c1c4-472e-851b-a923fa4958cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-f7136872-0846-4f33-af32-72d1c3328a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-b8998e3b-5b96-460c-a816-b1be49bc0421,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-64fafab8-4648-4460-902e-c27b5b656e96,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-b7c17bc9-7644-448b-a506-f110004f4816,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-51e003e2-d28f-4aa2-bff5-db32c14f37a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-21687917-172.17.0.3-1597070158424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42243,DS-f2f588bb-507b-43b4-8d5c-cc95bc49c142,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-6f0b7267-392c-4e3a-8b9e-2ca982f2c486,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-e508b1b4-c1c4-472e-851b-a923fa4958cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-f7136872-0846-4f33-af32-72d1c3328a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-b8998e3b-5b96-460c-a816-b1be49bc0421,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-64fafab8-4648-4460-902e-c27b5b656e96,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-b7c17bc9-7644-448b-a506-f110004f4816,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-51e003e2-d28f-4aa2-bff5-db32c14f37a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031267876-172.17.0.3-1597071349479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-201b4464-3f1e-4a7d-833e-0b7d29275420,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-60c6e4c5-7226-463f-9f12-df8c2a61bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-87f2f59c-c741-4cec-8371-a34e694b15e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-99d51ece-47c8-481b-9e13-845c95749a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-f2456628-6ef4-4ed6-ad34-46340b472a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-d423327f-13d4-4150-8eb4-afd4bbc9d9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-031c37af-71db-429d-8607-75d09a6da558,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-40bc6b20-0d3a-4025-91f4-be12752f5a63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2031267876-172.17.0.3-1597071349479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-201b4464-3f1e-4a7d-833e-0b7d29275420,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-60c6e4c5-7226-463f-9f12-df8c2a61bd96,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-87f2f59c-c741-4cec-8371-a34e694b15e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-99d51ece-47c8-481b-9e13-845c95749a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-f2456628-6ef4-4ed6-ad34-46340b472a87,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-d423327f-13d4-4150-8eb4-afd4bbc9d9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-031c37af-71db-429d-8607-75d09a6da558,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-40bc6b20-0d3a-4025-91f4-be12752f5a63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141891825-172.17.0.3-1597071478828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43517,DS-f318f564-efed-4e38-90d6-fa3a8becae23,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-bad627cb-5c52-4749-ab4e-a7edce9ee7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-4ed97f57-573e-45cd-a96a-4b93b94be7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-4de5b054-437c-4cbc-b372-d7e43dae9e43,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-ea79e01b-5f40-440a-93d7-19ff022c64ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-4d438de3-01eb-495d-a4d4-e2d242fd1380,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-80733ee9-2660-4a10-ba54-eb5b37443316,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-a14d8731-64ed-48c6-ac55-12bc24039e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141891825-172.17.0.3-1597071478828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43517,DS-f318f564-efed-4e38-90d6-fa3a8becae23,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-bad627cb-5c52-4749-ab4e-a7edce9ee7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-4ed97f57-573e-45cd-a96a-4b93b94be7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-4de5b054-437c-4cbc-b372-d7e43dae9e43,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-ea79e01b-5f40-440a-93d7-19ff022c64ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-4d438de3-01eb-495d-a4d4-e2d242fd1380,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-80733ee9-2660-4a10-ba54-eb5b37443316,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-a14d8731-64ed-48c6-ac55-12bc24039e7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446277455-172.17.0.3-1597072678199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35381,DS-9c28d637-02c4-4e0e-9128-0358120dbc29,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-a955f47d-a5b5-4914-92e6-3089645de105,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-8108d6bd-89e5-44f1-afd1-ac026128e4af,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-01e852b2-c729-48f1-b94e-12fcff90341a,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-e73a84d2-e779-4dd8-8c5e-67acbb13577a,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-cf0d168c-7ce0-4502-bc56-413b9387ac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-c2cdf8cf-6b21-459e-80fa-3d1b548c5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-95e14bd5-6ea7-4f2a-9916-12b37c2298c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446277455-172.17.0.3-1597072678199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35381,DS-9c28d637-02c4-4e0e-9128-0358120dbc29,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-a955f47d-a5b5-4914-92e6-3089645de105,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-8108d6bd-89e5-44f1-afd1-ac026128e4af,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-01e852b2-c729-48f1-b94e-12fcff90341a,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-e73a84d2-e779-4dd8-8c5e-67acbb13577a,DISK], DatanodeInfoWithStorage[127.0.0.1:39888,DS-cf0d168c-7ce0-4502-bc56-413b9387ac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-c2cdf8cf-6b21-459e-80fa-3d1b548c5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-95e14bd5-6ea7-4f2a-9916-12b37c2298c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565686617-172.17.0.3-1597072741659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45817,DS-2cd33ccc-c79c-47f6-a76a-f0e785fad263,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-f9998261-28a5-4810-93ad-d46a22e0a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-cf720b3c-8901-4639-ab9a-508916ee67f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-ec46a15f-9e35-46e9-aad5-487bf638177f,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-3062ce15-87d7-445f-99ca-ddddb085d976,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-458fc0fa-a0f1-416d-bb74-bb31786ab560,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-7bef3845-4603-451d-8a76-994177a981af,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-298cda07-09e4-4838-9fea-149d6b0a2fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565686617-172.17.0.3-1597072741659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45817,DS-2cd33ccc-c79c-47f6-a76a-f0e785fad263,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-f9998261-28a5-4810-93ad-d46a22e0a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-cf720b3c-8901-4639-ab9a-508916ee67f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-ec46a15f-9e35-46e9-aad5-487bf638177f,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-3062ce15-87d7-445f-99ca-ddddb085d976,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-458fc0fa-a0f1-416d-bb74-bb31786ab560,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-7bef3845-4603-451d-8a76-994177a981af,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-298cda07-09e4-4838-9fea-149d6b0a2fdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378853177-172.17.0.3-1597072846396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44660,DS-faf1cbff-61d0-415a-9015-a845532d1027,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-bd02c0c5-5729-4bfc-8c40-523a3390fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-0ca0bf9f-4d5b-4c5c-aae7-a92086d9338b,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-c9f6f808-e26c-4235-a3a6-8f1ad21b1bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-24f53d41-7f72-4e8b-b99d-c3e690be661c,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-4a6f8eec-b16f-4d9b-9dcc-5754d4b40237,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-962a2731-a10d-4961-99ec-7cc6e445b077,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-1e482ffc-9bdd-444b-ad58-294abe82967d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378853177-172.17.0.3-1597072846396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44660,DS-faf1cbff-61d0-415a-9015-a845532d1027,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-bd02c0c5-5729-4bfc-8c40-523a3390fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-0ca0bf9f-4d5b-4c5c-aae7-a92086d9338b,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-c9f6f808-e26c-4235-a3a6-8f1ad21b1bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-24f53d41-7f72-4e8b-b99d-c3e690be661c,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-4a6f8eec-b16f-4d9b-9dcc-5754d4b40237,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-962a2731-a10d-4961-99ec-7cc6e445b077,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-1e482ffc-9bdd-444b-ad58-294abe82967d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43386320-172.17.0.3-1597072922785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40419,DS-4a366fae-360e-4ecd-9788-e0e5d3c735ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-783ec62c-1deb-4fa2-97ee-0dd8fedacc30,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-ff3b6aa4-546a-4621-b499-af24a2927ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-1c3121c1-c454-4072-8f00-d5eea3b7ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-133ed167-5120-4830-ac4e-de023be26a17,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-866fa1d0-2a1a-4770-8044-9b27650aff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-8fe41856-9e34-4eff-8500-2e047736b1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-5a9bc089-b3d7-4faf-b3b1-878d4eb50c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-43386320-172.17.0.3-1597072922785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40419,DS-4a366fae-360e-4ecd-9788-e0e5d3c735ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-783ec62c-1deb-4fa2-97ee-0dd8fedacc30,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-ff3b6aa4-546a-4621-b499-af24a2927ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-1c3121c1-c454-4072-8f00-d5eea3b7ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-133ed167-5120-4830-ac4e-de023be26a17,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-866fa1d0-2a1a-4770-8044-9b27650aff4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-8fe41856-9e34-4eff-8500-2e047736b1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-5a9bc089-b3d7-4faf-b3b1-878d4eb50c1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778420438-172.17.0.3-1597073092819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-891b9ec9-1008-4181-bb4b-c898db128e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-f93b6839-ea88-469f-96e8-35509fffc035,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-61856596-ab6f-473a-b05c-92159dff5ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-0a0d7cab-3952-4226-a0e8-7eb110634c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-3c6d182e-908b-4615-b13d-efb85f34fad5,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-6e48ee3a-78bb-41a1-b451-e75c53cc1964,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-445e4dce-da4d-44ce-b5ff-71b491a12d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-ff898fd2-029b-4cd9-b80e-c61990e0f508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778420438-172.17.0.3-1597073092819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-891b9ec9-1008-4181-bb4b-c898db128e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-f93b6839-ea88-469f-96e8-35509fffc035,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-61856596-ab6f-473a-b05c-92159dff5ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-0a0d7cab-3952-4226-a0e8-7eb110634c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-3c6d182e-908b-4615-b13d-efb85f34fad5,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-6e48ee3a-78bb-41a1-b451-e75c53cc1964,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-445e4dce-da4d-44ce-b5ff-71b491a12d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-ff898fd2-029b-4cd9-b80e-c61990e0f508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892304546-172.17.0.3-1597073325782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-c7f11db5-30d5-45b3-bdf8-ca3f7ac68d14,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-d8c294d3-bd94-404f-aa0e-6770c436df57,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-55664697-a852-45c8-9875-89d7aa789710,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-c7ae2780-8afc-4f58-98e7-5075c9254242,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-0d41bad3-e03d-4980-8815-b74c325dc4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-276557db-135e-46a8-8155-1637c74480a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-beae5111-3cb1-44e7-ab0e-8310f9be2bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-94882d9e-2042-4654-b41d-30b2c4fe2aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-892304546-172.17.0.3-1597073325782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34415,DS-c7f11db5-30d5-45b3-bdf8-ca3f7ac68d14,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-d8c294d3-bd94-404f-aa0e-6770c436df57,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-55664697-a852-45c8-9875-89d7aa789710,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-c7ae2780-8afc-4f58-98e7-5075c9254242,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-0d41bad3-e03d-4980-8815-b74c325dc4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-276557db-135e-46a8-8155-1637c74480a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-beae5111-3cb1-44e7-ab0e-8310f9be2bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-94882d9e-2042-4654-b41d-30b2c4fe2aec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380500253-172.17.0.3-1597073360005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-e7b6fed2-0324-4615-8db7-dd06fbc7e753,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-9cafc30e-e71f-4325-b0dc-ed312d4d2fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-5740c461-8129-40ce-9750-928dc502bef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-fc816131-14cc-454a-a238-4f72250d999b,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-cefed1d9-5270-4580-a792-9fd16efda68a,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-fdc73d74-5b3d-461d-a350-8c5898c41589,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f1621b6d-04d7-4b6c-873f-7a5eb9c736dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-ca86ac7f-45a4-422f-9aa9-73059928fc55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380500253-172.17.0.3-1597073360005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39803,DS-e7b6fed2-0324-4615-8db7-dd06fbc7e753,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-9cafc30e-e71f-4325-b0dc-ed312d4d2fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-5740c461-8129-40ce-9750-928dc502bef4,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-fc816131-14cc-454a-a238-4f72250d999b,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-cefed1d9-5270-4580-a792-9fd16efda68a,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-fdc73d74-5b3d-461d-a350-8c5898c41589,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-f1621b6d-04d7-4b6c-873f-7a5eb9c736dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-ca86ac7f-45a4-422f-9aa9-73059928fc55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries.on.timeouts
component: hdfs:DataNode
v1: 450
v2: 45
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572580566-172.17.0.3-1597073842165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35304,DS-5ba83a49-8245-4931-b115-d0421c0dcaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-8b310272-8573-46dc-b7df-406750c1782b,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-6adf5469-8880-4d28-a1e8-69d807d26b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-3320da3b-8701-48c3-88a3-44dc805f3309,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-655ede9b-9749-45ba-94a2-1560774ffebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-62f6e779-dbd5-472b-a570-b53a892f6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-b1f34266-d73c-4a81-b1d2-3c91b01970bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-abccda5e-1b53-42c7-b097-2c70f3936f43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1572580566-172.17.0.3-1597073842165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35304,DS-5ba83a49-8245-4931-b115-d0421c0dcaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-8b310272-8573-46dc-b7df-406750c1782b,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-6adf5469-8880-4d28-a1e8-69d807d26b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-3320da3b-8701-48c3-88a3-44dc805f3309,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-655ede9b-9749-45ba-94a2-1560774ffebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-62f6e779-dbd5-472b-a570-b53a892f6b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-b1f34266-d73c-4a81-b1d2-3c91b01970bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-abccda5e-1b53-42c7-b097-2c70f3936f43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5299
