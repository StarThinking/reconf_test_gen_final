reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107880901-172.17.0.13-1597183347305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-f971168b-c3e6-4cab-ad28-22f53897d272,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-3eabda31-05c4-4db5-90ae-3e6bdfd16eda,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-4c57409d-c0da-4a5e-995c-33e42dcc9011,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-6a298972-6f73-4129-b32c-061450071a39,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-0ad06889-1fc2-457f-a970-f8111867088c,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-b80999a2-c965-400d-91e8-a09ea61b604a,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-0f4dceff-3f34-49fe-9f61-b5b23104a75d,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-c41683d7-66e0-48d2-9648-c7186e78fa08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107880901-172.17.0.13-1597183347305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39061,DS-f971168b-c3e6-4cab-ad28-22f53897d272,DISK], DatanodeInfoWithStorage[127.0.0.1:33421,DS-3eabda31-05c4-4db5-90ae-3e6bdfd16eda,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-4c57409d-c0da-4a5e-995c-33e42dcc9011,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-6a298972-6f73-4129-b32c-061450071a39,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-0ad06889-1fc2-457f-a970-f8111867088c,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-b80999a2-c965-400d-91e8-a09ea61b604a,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-0f4dceff-3f34-49fe-9f61-b5b23104a75d,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-c41683d7-66e0-48d2-9648-c7186e78fa08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093912839-172.17.0.13-1597183740290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-ef9e6583-37c7-4922-8570-9ba678b0e076,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5897692d-57a1-4b26-b51a-5cdd3b0ce48d,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-545e94f1-f131-4b68-924e-12e3acbe2015,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-1cccdc52-777b-4af7-836b-6c67978c4b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-3ccd001e-6ceb-4f5c-b27a-9773ad449283,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-4e662c4f-099b-435a-8d11-c06551432ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-97f8ee71-e16d-401d-8e7b-777d84d845ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-c9bde14a-3d2f-400b-ba38-dae7ef7b1dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093912839-172.17.0.13-1597183740290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-ef9e6583-37c7-4922-8570-9ba678b0e076,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-5897692d-57a1-4b26-b51a-5cdd3b0ce48d,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-545e94f1-f131-4b68-924e-12e3acbe2015,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-1cccdc52-777b-4af7-836b-6c67978c4b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-3ccd001e-6ceb-4f5c-b27a-9773ad449283,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-4e662c4f-099b-435a-8d11-c06551432ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-97f8ee71-e16d-401d-8e7b-777d84d845ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-c9bde14a-3d2f-400b-ba38-dae7ef7b1dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255944236-172.17.0.13-1597183811960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35520,DS-59a1e758-89f8-466b-89b6-79e51332bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-0fdc1589-5404-4ac9-8d61-fabf924d48ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-7a205bd5-ed3d-4384-9e4d-9923921af006,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-bee1107f-e2f4-4bc4-949e-59299c164853,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-f5d7d391-aed8-4288-b31f-2960300bb8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-9d27d80c-6fa1-4220-bef7-1c72707a4146,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-aa2b6515-4e14-4e45-bf48-25ce44eacbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-22a8d158-e4d6-473f-be6d-fa747266ea35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255944236-172.17.0.13-1597183811960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35520,DS-59a1e758-89f8-466b-89b6-79e51332bb39,DISK], DatanodeInfoWithStorage[127.0.0.1:41480,DS-0fdc1589-5404-4ac9-8d61-fabf924d48ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-7a205bd5-ed3d-4384-9e4d-9923921af006,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-bee1107f-e2f4-4bc4-949e-59299c164853,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-f5d7d391-aed8-4288-b31f-2960300bb8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-9d27d80c-6fa1-4220-bef7-1c72707a4146,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-aa2b6515-4e14-4e45-bf48-25ce44eacbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-22a8d158-e4d6-473f-be6d-fa747266ea35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170201949-172.17.0.13-1597184438891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36658,DS-85601d97-4ee3-4538-8e91-c666d1f9903a,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-ef8ee985-d094-461d-8697-978ac97ab51b,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-5e3ee106-6628-4a47-980f-3b904dbc7a46,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-e9e4367f-3bc8-463d-9e90-55072fa7d183,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-7645ffd9-2c6a-4b0c-885f-2355aea259fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-30c53879-9f80-49f9-a2a8-855324fe45bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-7deaea97-8699-492c-9de0-466590f1263d,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-df7ad11c-d416-4ba6-9999-46a1f4b42669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170201949-172.17.0.13-1597184438891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36658,DS-85601d97-4ee3-4538-8e91-c666d1f9903a,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-ef8ee985-d094-461d-8697-978ac97ab51b,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-5e3ee106-6628-4a47-980f-3b904dbc7a46,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-e9e4367f-3bc8-463d-9e90-55072fa7d183,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-7645ffd9-2c6a-4b0c-885f-2355aea259fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-30c53879-9f80-49f9-a2a8-855324fe45bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-7deaea97-8699-492c-9de0-466590f1263d,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-df7ad11c-d416-4ba6-9999-46a1f4b42669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316214627-172.17.0.13-1597184689691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41101,DS-54bd6cea-57ce-4fc9-8fdc-8eddeb501483,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-a99ded34-c925-4daa-aebb-2414b5c39081,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-50d4f9df-e69d-4e9a-8482-6bc79395e422,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-d3caa486-9fcb-4dd0-a6be-c2dbee50fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-469b182d-9ecb-4bf9-afd8-2b2c4cc0905c,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-ceb23705-fdba-4cde-9b8f-5445c6bdca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-0295285e-fae5-4c31-8de2-c5adfdaead90,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-02912305-4fb7-47a1-b3de-58324c107898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316214627-172.17.0.13-1597184689691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41101,DS-54bd6cea-57ce-4fc9-8fdc-8eddeb501483,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-a99ded34-c925-4daa-aebb-2414b5c39081,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-50d4f9df-e69d-4e9a-8482-6bc79395e422,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-d3caa486-9fcb-4dd0-a6be-c2dbee50fb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-469b182d-9ecb-4bf9-afd8-2b2c4cc0905c,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-ceb23705-fdba-4cde-9b8f-5445c6bdca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-0295285e-fae5-4c31-8de2-c5adfdaead90,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-02912305-4fb7-47a1-b3de-58324c107898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512556870-172.17.0.13-1597184899256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38576,DS-fc6a4364-28be-4a69-af71-2b1b2cfda8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-0c495e9e-87e6-44ab-88f6-dd431844e675,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-0e3fcc8a-305a-476b-b7ab-349769f693a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-dd984a9a-869e-485f-ba40-2a395f0dfefa,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-e0b3347f-bb1b-4544-9bd6-b6a267fd7791,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-29a1b4bd-53a0-43ad-8114-d1eeead64c69,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-f7b91153-8305-4aa6-86d4-4a43ead718ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-6a88dc87-2ba9-4329-ab46-f5c729e1e94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512556870-172.17.0.13-1597184899256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38576,DS-fc6a4364-28be-4a69-af71-2b1b2cfda8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-0c495e9e-87e6-44ab-88f6-dd431844e675,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-0e3fcc8a-305a-476b-b7ab-349769f693a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-dd984a9a-869e-485f-ba40-2a395f0dfefa,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-e0b3347f-bb1b-4544-9bd6-b6a267fd7791,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-29a1b4bd-53a0-43ad-8114-d1eeead64c69,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-f7b91153-8305-4aa6-86d4-4a43ead718ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-6a88dc87-2ba9-4329-ab46-f5c729e1e94e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352671964-172.17.0.13-1597185034201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38715,DS-bfe0b160-063b-4f4f-aaee-4b32d751be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-54666ba5-d446-47eb-b515-b4774168e34a,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-4a2ac891-9784-490b-8d81-77c0469fa795,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-e843a098-394e-4412-9fcd-f722fdc05665,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-37fe4c85-fa4a-483e-b631-65ce024bc0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-262733c9-4335-40e2-b6ca-56f696283b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-2c0baf32-9609-49be-adce-c4d15a4147d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-e51539b2-d68d-4c91-be59-0b218bf296d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352671964-172.17.0.13-1597185034201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38715,DS-bfe0b160-063b-4f4f-aaee-4b32d751be0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43287,DS-54666ba5-d446-47eb-b515-b4774168e34a,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-4a2ac891-9784-490b-8d81-77c0469fa795,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-e843a098-394e-4412-9fcd-f722fdc05665,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-37fe4c85-fa4a-483e-b631-65ce024bc0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-262733c9-4335-40e2-b6ca-56f696283b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-2c0baf32-9609-49be-adce-c4d15a4147d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-e51539b2-d68d-4c91-be59-0b218bf296d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111083257-172.17.0.13-1597186127018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-16d484eb-e011-4df0-940e-6339362e3801,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-bb157a5e-143a-4377-89a3-ccfd35000aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-a5389560-1bb0-4754-b2f0-38a352b50511,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-906e5574-e33a-470c-a144-ba2db3c5929d,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-03fdedd1-870b-459e-9bd8-86f168285ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-f724643c-7fd4-4859-9de7-aff1c3183e23,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-07cc11d2-1ee4-4cce-8100-65c406a36711,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-aca3b615-d69d-41b7-ae04-f481959e4a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111083257-172.17.0.13-1597186127018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44857,DS-16d484eb-e011-4df0-940e-6339362e3801,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-bb157a5e-143a-4377-89a3-ccfd35000aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-a5389560-1bb0-4754-b2f0-38a352b50511,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-906e5574-e33a-470c-a144-ba2db3c5929d,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-03fdedd1-870b-459e-9bd8-86f168285ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-f724643c-7fd4-4859-9de7-aff1c3183e23,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-07cc11d2-1ee4-4cce-8100-65c406a36711,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-aca3b615-d69d-41b7-ae04-f481959e4a73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614012068-172.17.0.13-1597186694324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-456b91c0-5d06-4bfb-87f0-0f76113329b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-0700039e-56d9-4c81-a559-e9d4622d72c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-18df61f0-2f5c-4635-ae89-31081319e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-e15c7207-e8df-4b75-a79d-482111d22521,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-58d91ee8-ea9d-436b-8563-dd5ec926b656,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-2a26031a-f818-4396-a3ec-2359c46d1e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-1b587ce0-39fb-4d13-819b-e8c558724989,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-f276398e-50b3-4706-af40-da5fca95379f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614012068-172.17.0.13-1597186694324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40940,DS-456b91c0-5d06-4bfb-87f0-0f76113329b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-0700039e-56d9-4c81-a559-e9d4622d72c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-18df61f0-2f5c-4635-ae89-31081319e2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-e15c7207-e8df-4b75-a79d-482111d22521,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-58d91ee8-ea9d-436b-8563-dd5ec926b656,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-2a26031a-f818-4396-a3ec-2359c46d1e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-1b587ce0-39fb-4d13-819b-e8c558724989,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-f276398e-50b3-4706-af40-da5fca95379f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749670048-172.17.0.13-1597186780734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41454,DS-097ac0af-01fc-45d9-b73a-f1461174a6af,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-90358428-e99c-46be-a7a2-1ce0dd3f684b,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-de41a210-42e8-4901-9636-8037b4e23a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-95f96377-c2cf-41a3-a9cb-47584b3c4ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-31bd23f3-d0f1-4e3b-b0e4-154a24150807,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-eb24f36f-caab-4adc-bcbf-27cc15c605f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-4c4ef207-18af-44bd-8926-3407123e313d,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-114f8c13-8057-48c7-a00a-621a660d618f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749670048-172.17.0.13-1597186780734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41454,DS-097ac0af-01fc-45d9-b73a-f1461174a6af,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-90358428-e99c-46be-a7a2-1ce0dd3f684b,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-de41a210-42e8-4901-9636-8037b4e23a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39893,DS-95f96377-c2cf-41a3-a9cb-47584b3c4ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-31bd23f3-d0f1-4e3b-b0e4-154a24150807,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-eb24f36f-caab-4adc-bcbf-27cc15c605f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-4c4ef207-18af-44bd-8926-3407123e313d,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-114f8c13-8057-48c7-a00a-621a660d618f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418842902-172.17.0.13-1597187094995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-6acf99b7-48f4-4797-8360-9767c55c623d,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-10cb3271-f6a2-448b-b810-d3bf9741eac0,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-da3c8714-c29d-442d-9c0e-f716f475bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-88603131-98d8-4268-89f9-31d6f44d0dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-8ea63cea-ae0f-4716-b7d5-b0dc41230e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-2d51a700-387f-41ce-82a6-d772bf8e503d,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-a65996f4-cb08-4d35-b844-411b764ac884,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-f3e019cf-7375-4136-abb8-88b4fe6fe446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418842902-172.17.0.13-1597187094995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-6acf99b7-48f4-4797-8360-9767c55c623d,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-10cb3271-f6a2-448b-b810-d3bf9741eac0,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-da3c8714-c29d-442d-9c0e-f716f475bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:45194,DS-88603131-98d8-4268-89f9-31d6f44d0dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-8ea63cea-ae0f-4716-b7d5-b0dc41230e48,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-2d51a700-387f-41ce-82a6-d772bf8e503d,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-a65996f4-cb08-4d35-b844-411b764ac884,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-f3e019cf-7375-4136-abb8-88b4fe6fe446,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267772559-172.17.0.13-1597187269731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-67d0e143-a995-4273-9a9c-f58657a85278,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-56bb831b-23f9-44a0-981e-df426c69b4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-280556fd-bc04-4526-b2e2-b7db85cb0995,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-8885f660-7ca0-44a0-ae2f-148a61d10fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a9103583-704d-4bd7-8ce0-733cccfbcb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-36eebc14-13aa-43f4-98a7-c6249fadf57e,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-99c1aac0-7d9e-44b2-ad4c-d7487d385ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-61aed0b3-9283-43b7-be27-ca265558e9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267772559-172.17.0.13-1597187269731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33653,DS-67d0e143-a995-4273-9a9c-f58657a85278,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-56bb831b-23f9-44a0-981e-df426c69b4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37973,DS-280556fd-bc04-4526-b2e2-b7db85cb0995,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-8885f660-7ca0-44a0-ae2f-148a61d10fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-a9103583-704d-4bd7-8ce0-733cccfbcb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-36eebc14-13aa-43f4-98a7-c6249fadf57e,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-99c1aac0-7d9e-44b2-ad4c-d7487d385ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-61aed0b3-9283-43b7-be27-ca265558e9f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48453699-172.17.0.13-1597187471603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40693,DS-593b295b-4ae5-4f5b-897a-f52f99d3b3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-53c24db4-a4cd-49ad-98fb-20313805f433,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-0c98dab1-c0fa-4ae5-9b64-2206c65b6a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-52764a89-6bec-4eec-b861-5e173c7c10bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-4153e392-a182-49b9-bc66-928e300059e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-01e7af35-d148-40d9-9d0a-64a22a7b4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-4b2bb7dd-c983-4e6d-a0f5-4a610ef1ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-29588ea2-5c3a-4444-b6cf-56e9887d2540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48453699-172.17.0.13-1597187471603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40693,DS-593b295b-4ae5-4f5b-897a-f52f99d3b3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-53c24db4-a4cd-49ad-98fb-20313805f433,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-0c98dab1-c0fa-4ae5-9b64-2206c65b6a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-52764a89-6bec-4eec-b861-5e173c7c10bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-4153e392-a182-49b9-bc66-928e300059e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-01e7af35-d148-40d9-9d0a-64a22a7b4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-4b2bb7dd-c983-4e6d-a0f5-4a610ef1ccbc,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-29588ea2-5c3a-4444-b6cf-56e9887d2540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572079061-172.17.0.13-1597188150693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33747,DS-19da478a-d854-4357-ac62-7f1e05ff889b,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-ff9ff7d8-e3ae-4de5-8f4d-13cb408703c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-de0dcf7e-2afd-45c6-a560-d0fe61e1ba74,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-5064e5e6-3fe7-4349-9d44-527d03b783b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-173bb969-0034-4a92-a58d-f5a7cceef58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-a2bb0ca5-ed12-4d4b-9f9a-a72c48f08b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-e09a0ba2-96de-414c-a602-276aa0f34ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-c77587dd-3b57-4eaa-941f-23b7a224170b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572079061-172.17.0.13-1597188150693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33747,DS-19da478a-d854-4357-ac62-7f1e05ff889b,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-ff9ff7d8-e3ae-4de5-8f4d-13cb408703c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-de0dcf7e-2afd-45c6-a560-d0fe61e1ba74,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-5064e5e6-3fe7-4349-9d44-527d03b783b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-173bb969-0034-4a92-a58d-f5a7cceef58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-a2bb0ca5-ed12-4d4b-9f9a-a72c48f08b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-e09a0ba2-96de-414c-a602-276aa0f34ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-c77587dd-3b57-4eaa-941f-23b7a224170b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308009678-172.17.0.13-1597189093525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-83830727-8622-4b07-aa80-1b4a66fefc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-c098156e-40e8-44c3-8e65-9b30defbdda9,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-21b36528-d6f2-49e4-9a8e-f654a54c6cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-ebf67176-9c9d-4166-80cb-7d44aa51df03,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-1aef1994-4a6a-4f17-a76d-77237a4f0b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-b05753ad-b5dc-45be-9016-b052f7909942,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-41a6f390-31d8-4a1c-b970-128f0e289c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-7022c210-8e03-4930-97e7-bcc8c2aa5d52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308009678-172.17.0.13-1597189093525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37783,DS-83830727-8622-4b07-aa80-1b4a66fefc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-c098156e-40e8-44c3-8e65-9b30defbdda9,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-21b36528-d6f2-49e4-9a8e-f654a54c6cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-ebf67176-9c9d-4166-80cb-7d44aa51df03,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-1aef1994-4a6a-4f17-a76d-77237a4f0b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-b05753ad-b5dc-45be-9016-b052f7909942,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-41a6f390-31d8-4a1c-b970-128f0e289c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-7022c210-8e03-4930-97e7-bcc8c2aa5d52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.min-replication
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653216477-172.17.0.13-1597189130052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-2ca69fd9-6ed2-4d8f-a029-3e9f2f9acba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-221f7ef5-ad23-4ed8-9f76-f5babf5c7dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-5ad9fbed-1057-4e2d-ba54-f80e718aa635,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-b35ccb49-e18c-4ad0-a21d-a694ddd861b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-7c853e7f-ef3d-4576-950f-c90b522b65aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-383d68ae-aa10-4a35-bb70-adb85de7ed49,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-1143087d-9a3a-4e72-95e9-5f052b55c62b,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-950dcc4d-59d1-43d2-9183-cf1d522600af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653216477-172.17.0.13-1597189130052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41568,DS-2ca69fd9-6ed2-4d8f-a029-3e9f2f9acba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-221f7ef5-ad23-4ed8-9f76-f5babf5c7dac,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-5ad9fbed-1057-4e2d-ba54-f80e718aa635,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-b35ccb49-e18c-4ad0-a21d-a694ddd861b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-7c853e7f-ef3d-4576-950f-c90b522b65aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-383d68ae-aa10-4a35-bb70-adb85de7ed49,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-1143087d-9a3a-4e72-95e9-5f052b55c62b,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-950dcc4d-59d1-43d2-9183-cf1d522600af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6457
