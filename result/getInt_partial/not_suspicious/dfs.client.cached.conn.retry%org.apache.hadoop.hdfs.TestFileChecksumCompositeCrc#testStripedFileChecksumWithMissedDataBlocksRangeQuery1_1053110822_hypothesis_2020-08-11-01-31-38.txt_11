reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306708665-172.17.0.20-1597109615312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40807,DS-5b3df12e-5e72-4c77-8d8c-b231c80dd95f,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-3d4e2403-4d8f-488f-96c1-d94250166173,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-5a2f90b2-5618-4f11-8ec7-907ffb16c80b,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-4d3a9e69-ffa5-45e8-af55-e727b252e06a,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-0502d04e-a3c7-4bf3-901e-3cca0cf5f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-e5d4b43f-020c-4c7d-8599-25b65b57209d,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-38802ad1-0e51-4b1f-959b-d842dd757541,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-0d1a280c-1818-40a7-9bd7-0885edb1b320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306708665-172.17.0.20-1597109615312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40807,DS-5b3df12e-5e72-4c77-8d8c-b231c80dd95f,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-3d4e2403-4d8f-488f-96c1-d94250166173,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-5a2f90b2-5618-4f11-8ec7-907ffb16c80b,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-4d3a9e69-ffa5-45e8-af55-e727b252e06a,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-0502d04e-a3c7-4bf3-901e-3cca0cf5f87a,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-e5d4b43f-020c-4c7d-8599-25b65b57209d,DISK], DatanodeInfoWithStorage[127.0.0.1:45111,DS-38802ad1-0e51-4b1f-959b-d842dd757541,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-0d1a280c-1818-40a7-9bd7-0885edb1b320,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830227763-172.17.0.20-1597109904607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-8ba39577-6b0b-47f3-bceb-927c0ce94bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-b687d0bb-61bf-4848-83fc-3fd4ef1c4c99,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-b5526af7-e78b-43a4-8b7b-02bb7facdf94,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-283ec46b-317a-4918-ab01-36cc0c95c968,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-e661f302-ed14-40d4-bd07-4379dcb6666c,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-0301f5e7-df0f-44f1-a1ed-b35a1f1bc37d,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-bf7aa037-db30-46e1-becd-026dae024c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-220915e6-2083-491d-b168-20236fc4930c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830227763-172.17.0.20-1597109904607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43181,DS-8ba39577-6b0b-47f3-bceb-927c0ce94bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-b687d0bb-61bf-4848-83fc-3fd4ef1c4c99,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-b5526af7-e78b-43a4-8b7b-02bb7facdf94,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-283ec46b-317a-4918-ab01-36cc0c95c968,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-e661f302-ed14-40d4-bd07-4379dcb6666c,DISK], DatanodeInfoWithStorage[127.0.0.1:41404,DS-0301f5e7-df0f-44f1-a1ed-b35a1f1bc37d,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-bf7aa037-db30-46e1-becd-026dae024c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-220915e6-2083-491d-b168-20236fc4930c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987244409-172.17.0.20-1597110333346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40204,DS-7c6a1648-99ba-460b-b495-4f041a6b917a,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-8a29d3dd-911a-4f14-8c34-5303e605d4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-33a5977d-a3cb-417c-bbfe-fe882d8ebcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-0a5aa2e9-3be6-4f43-be79-a955173c7a00,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-301f1c74-eeb3-42fb-bb7e-6845c6d37256,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-fefb6097-3213-452e-aa80-f4240c46f40e,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-aa971a7e-548d-4021-98e9-11ac21e410a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-b6b1d38e-2572-4263-97dc-e2b039e32355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1987244409-172.17.0.20-1597110333346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40204,DS-7c6a1648-99ba-460b-b495-4f041a6b917a,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-8a29d3dd-911a-4f14-8c34-5303e605d4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-33a5977d-a3cb-417c-bbfe-fe882d8ebcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-0a5aa2e9-3be6-4f43-be79-a955173c7a00,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-301f1c74-eeb3-42fb-bb7e-6845c6d37256,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-fefb6097-3213-452e-aa80-f4240c46f40e,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-aa971a7e-548d-4021-98e9-11ac21e410a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-b6b1d38e-2572-4263-97dc-e2b039e32355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457672834-172.17.0.20-1597110807451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-efefbf0e-fc98-4535-887a-ea9d1ad70a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-e5aac642-d410-46fa-b9fa-76182b1e1134,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-1200d740-57e8-4b0d-9073-45b102346432,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-d0163eca-9a2f-4222-b2a5-c22cdc7e2435,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-58b84bec-c53b-4381-b452-0aff2e76f0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-8669b580-7a99-4a04-982a-bf541b53d165,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-9bd84a2f-d4ff-420a-8072-ed12ab7af89d,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-9aa70c50-cd3b-4bdd-a22f-5e1ed068f75a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457672834-172.17.0.20-1597110807451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43815,DS-efefbf0e-fc98-4535-887a-ea9d1ad70a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-e5aac642-d410-46fa-b9fa-76182b1e1134,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-1200d740-57e8-4b0d-9073-45b102346432,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-d0163eca-9a2f-4222-b2a5-c22cdc7e2435,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-58b84bec-c53b-4381-b452-0aff2e76f0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-8669b580-7a99-4a04-982a-bf541b53d165,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-9bd84a2f-d4ff-420a-8072-ed12ab7af89d,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-9aa70c50-cd3b-4bdd-a22f-5e1ed068f75a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983300816-172.17.0.20-1597111073549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-066f1d1d-a73b-4bad-a8f7-7282aab583c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-a55e1ff8-f258-4682-a92b-a332d90c93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-3b67743f-a080-4c69-b2a4-4bd68c74662e,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-76a61fbd-9306-41d6-8f58-0828a119634d,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-fe7b9c2e-1789-4e8e-9b03-51c38a6c5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-32774743-c964-4613-bea4-98bad2ae2058,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-a17cb932-c69b-485b-bb87-1580ef0b387c,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-d341d3f0-017d-4803-a581-0068777768cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-983300816-172.17.0.20-1597111073549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-066f1d1d-a73b-4bad-a8f7-7282aab583c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-a55e1ff8-f258-4682-a92b-a332d90c93c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-3b67743f-a080-4c69-b2a4-4bd68c74662e,DISK], DatanodeInfoWithStorage[127.0.0.1:39942,DS-76a61fbd-9306-41d6-8f58-0828a119634d,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-fe7b9c2e-1789-4e8e-9b03-51c38a6c5b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-32774743-c964-4613-bea4-98bad2ae2058,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-a17cb932-c69b-485b-bb87-1580ef0b387c,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-d341d3f0-017d-4803-a581-0068777768cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257935397-172.17.0.20-1597111474715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41324,DS-5d03d7c5-6c80-4489-9495-9c7000ce6caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-5bd9cea1-2630-427e-84b1-832518f9ed55,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-2fa85746-bcdb-433c-98cd-18b0b371f67b,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-3ac0ce72-1531-4d51-a7c4-9c71fdde2f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-5fbb5bbf-1c4e-4485-b1b2-218eada8fbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-1ec21357-1160-45c1-97ab-939db684bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-419a1ecf-5dc0-4944-9990-8572762c9770,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-a8178adf-1278-4cfe-8a13-f1e04bf02065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257935397-172.17.0.20-1597111474715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41324,DS-5d03d7c5-6c80-4489-9495-9c7000ce6caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-5bd9cea1-2630-427e-84b1-832518f9ed55,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-2fa85746-bcdb-433c-98cd-18b0b371f67b,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-3ac0ce72-1531-4d51-a7c4-9c71fdde2f91,DISK], DatanodeInfoWithStorage[127.0.0.1:37439,DS-5fbb5bbf-1c4e-4485-b1b2-218eada8fbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-1ec21357-1160-45c1-97ab-939db684bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-419a1ecf-5dc0-4944-9990-8572762c9770,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-a8178adf-1278-4cfe-8a13-f1e04bf02065,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35222-172.17.0.20-1597111768729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-3772dba3-d035-4334-bf5e-56b74a9ee0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-61355dc4-9b13-4a51-909d-cc960c59126d,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-daa2d3ed-c2e7-4ee9-9a11-880380f3a78a,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-70fe252c-7b58-4cd4-a991-f4f7a76998a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-aa6115e0-c1ca-4777-b697-f51587ee7005,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-8ca7508b-1630-4024-8608-612c904d1336,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-4dff09da-4626-440d-a5c9-c7e362df0dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-06cfc297-2915-4df9-b291-b6d8227cbf74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35222-172.17.0.20-1597111768729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-3772dba3-d035-4334-bf5e-56b74a9ee0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-61355dc4-9b13-4a51-909d-cc960c59126d,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-daa2d3ed-c2e7-4ee9-9a11-880380f3a78a,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-70fe252c-7b58-4cd4-a991-f4f7a76998a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-aa6115e0-c1ca-4777-b697-f51587ee7005,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-8ca7508b-1630-4024-8608-612c904d1336,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-4dff09da-4626-440d-a5c9-c7e362df0dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-06cfc297-2915-4df9-b291-b6d8227cbf74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834484465-172.17.0.20-1597112166210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39995,DS-f3c0b46b-2494-400f-84b4-dcf6b7b5a640,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-8d98cd5f-0bdf-4f23-b390-9fe906f61852,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-13da495a-4ec4-4b6a-be99-2e7de9866e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-c0281aeb-19c1-447e-b9b3-2a6a871352a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-f4652a07-4eee-405d-86ac-f15f6fb84206,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-cf03ccea-ecfc-442a-bcc0-cb33d3844e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-0d1336c0-62b9-42d2-bb85-bc0b8f5f8001,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-daa23c0d-1133-495c-8a08-5ad6ae5cb4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-834484465-172.17.0.20-1597112166210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39995,DS-f3c0b46b-2494-400f-84b4-dcf6b7b5a640,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-8d98cd5f-0bdf-4f23-b390-9fe906f61852,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-13da495a-4ec4-4b6a-be99-2e7de9866e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-c0281aeb-19c1-447e-b9b3-2a6a871352a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-f4652a07-4eee-405d-86ac-f15f6fb84206,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-cf03ccea-ecfc-442a-bcc0-cb33d3844e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-0d1336c0-62b9-42d2-bb85-bc0b8f5f8001,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-daa23c0d-1133-495c-8a08-5ad6ae5cb4ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265760973-172.17.0.20-1597112199017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-e6820264-7c3a-4893-9b48-20efe055bdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-0654ce36-3681-4e75-aa01-4effd4f2494b,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-3f22bbc7-3020-47a7-bf3c-b17f80ebb7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-1d225dd8-1bf1-45fd-a287-3e430559ad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-2eb18a1f-fb05-4a1e-b68d-c90ec8c315eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-01cd8931-37ab-4f58-826b-fcc5cfb0674b,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-fe8ad190-d1db-4f97-bc71-79c2cc3ca052,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-7b4d9a6d-6301-416e-8506-3bb50326ef21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-265760973-172.17.0.20-1597112199017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38512,DS-e6820264-7c3a-4893-9b48-20efe055bdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-0654ce36-3681-4e75-aa01-4effd4f2494b,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-3f22bbc7-3020-47a7-bf3c-b17f80ebb7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-1d225dd8-1bf1-45fd-a287-3e430559ad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-2eb18a1f-fb05-4a1e-b68d-c90ec8c315eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-01cd8931-37ab-4f58-826b-fcc5cfb0674b,DISK], DatanodeInfoWithStorage[127.0.0.1:41705,DS-fe8ad190-d1db-4f97-bc71-79c2cc3ca052,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-7b4d9a6d-6301-416e-8506-3bb50326ef21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648884770-172.17.0.20-1597112242908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42154,DS-a42cb0d3-a827-4980-80de-be32b116c696,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-a2817325-8d7e-40c0-8373-077c6359ee01,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-83b49f1c-8df3-4087-bf07-6b267a4cb5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-dc44acc7-21d1-4d0a-9c60-652811b35b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-b562fd1d-53e4-4fe5-9c05-9cd1904962c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-3edf1299-3dfe-4a2d-9bcc-0eada7824758,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-6d58f2f2-290c-4f6c-8194-b1c9c34a1a40,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-bfb991b1-02a3-440c-87cc-b7c40342f32b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648884770-172.17.0.20-1597112242908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42154,DS-a42cb0d3-a827-4980-80de-be32b116c696,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-a2817325-8d7e-40c0-8373-077c6359ee01,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-83b49f1c-8df3-4087-bf07-6b267a4cb5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-dc44acc7-21d1-4d0a-9c60-652811b35b06,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-b562fd1d-53e4-4fe5-9c05-9cd1904962c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-3edf1299-3dfe-4a2d-9bcc-0eada7824758,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-6d58f2f2-290c-4f6c-8194-b1c9c34a1a40,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-bfb991b1-02a3-440c-87cc-b7c40342f32b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793391884-172.17.0.20-1597112643592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38767,DS-6fe89fb5-f452-4c77-8d99-173bb975dfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-16ff0187-b9ca-4b35-9ad5-80e7d61cb1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-3e3b8f15-e135-4c41-af5c-60b0b009459a,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-f29689be-0ff9-4d39-805b-5e5c233b14f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-57c49e59-98f6-483b-b126-5037a2faa50b,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-56ee9816-340a-4c25-9f9f-6e17e3d21e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-2d880859-f98f-49db-b752-a368080e2219,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-7a067272-58da-4f63-b117-540e99769518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793391884-172.17.0.20-1597112643592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38767,DS-6fe89fb5-f452-4c77-8d99-173bb975dfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-16ff0187-b9ca-4b35-9ad5-80e7d61cb1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-3e3b8f15-e135-4c41-af5c-60b0b009459a,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-f29689be-0ff9-4d39-805b-5e5c233b14f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-57c49e59-98f6-483b-b126-5037a2faa50b,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-56ee9816-340a-4c25-9f9f-6e17e3d21e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-2d880859-f98f-49db-b752-a368080e2219,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-7a067272-58da-4f63-b117-540e99769518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090151960-172.17.0.20-1597112874498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34402,DS-5d087872-f072-4c17-a5d6-2f7786793aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-ae43f41e-9dc1-43f1-87ee-2e5edbe82c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-9caeabb3-746f-4f83-9a08-f4a856e26871,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-1e527729-7a64-4ece-80a5-5f4acc3471fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-e2ba3510-2f13-4cce-9163-a6193ed1d808,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-5423970d-bbaf-46a3-a105-db8719c6c063,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-3ee2028c-696a-4d00-812b-3363de6bb6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-9932f038-091f-47b2-94b0-98c25944cefc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090151960-172.17.0.20-1597112874498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34402,DS-5d087872-f072-4c17-a5d6-2f7786793aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-ae43f41e-9dc1-43f1-87ee-2e5edbe82c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-9caeabb3-746f-4f83-9a08-f4a856e26871,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-1e527729-7a64-4ece-80a5-5f4acc3471fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-e2ba3510-2f13-4cce-9163-a6193ed1d808,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-5423970d-bbaf-46a3-a105-db8719c6c063,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-3ee2028c-696a-4d00-812b-3363de6bb6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-9932f038-091f-47b2-94b0-98c25944cefc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280401056-172.17.0.20-1597113644093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-10980066-d937-48c1-aac9-bb0fb5140d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-527fb608-bcb4-4521-a9b9-c3c363ce4f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-52860758-b4a6-40d1-a12c-b30facfa9243,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-8e4adabf-cf44-4119-a19e-840d9ef58294,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-06cf0a19-1c8f-4ba0-b477-0b40b0af3ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-438b65ba-51ec-4d7c-ab7b-221cf357ce41,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-43665f06-1578-4bbd-b92e-7f885428b5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-a58c87cb-da8a-4120-9335-0794438dfaca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280401056-172.17.0.20-1597113644093:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42948,DS-10980066-d937-48c1-aac9-bb0fb5140d38,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-527fb608-bcb4-4521-a9b9-c3c363ce4f40,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-52860758-b4a6-40d1-a12c-b30facfa9243,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-8e4adabf-cf44-4119-a19e-840d9ef58294,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-06cf0a19-1c8f-4ba0-b477-0b40b0af3ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-438b65ba-51ec-4d7c-ab7b-221cf357ce41,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-43665f06-1578-4bbd-b92e-7f885428b5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-a58c87cb-da8a-4120-9335-0794438dfaca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358608434-172.17.0.20-1597113780535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-416b967a-7ef4-4ba5-87b4-157f8b3d6590,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-a68334a5-9027-4731-a9e5-99367689094b,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-fadf6285-e950-498a-85a6-ec1cffdb4f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-372fb039-7d48-4887-b094-774aa5401617,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-105991f9-387b-49a0-a392-55e27e90cb91,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-a60643fe-b0c1-4581-884a-447e92e5a762,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-3c07f710-943f-4609-8606-8a0937ac7a87,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-c018970f-c497-4c61-85d6-677b8111d48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358608434-172.17.0.20-1597113780535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-416b967a-7ef4-4ba5-87b4-157f8b3d6590,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-a68334a5-9027-4731-a9e5-99367689094b,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-fadf6285-e950-498a-85a6-ec1cffdb4f12,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-372fb039-7d48-4887-b094-774aa5401617,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-105991f9-387b-49a0-a392-55e27e90cb91,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-a60643fe-b0c1-4581-884a-447e92e5a762,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-3c07f710-943f-4609-8606-8a0937ac7a87,DISK], DatanodeInfoWithStorage[127.0.0.1:44547,DS-c018970f-c497-4c61-85d6-677b8111d48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905729639-172.17.0.20-1597114107346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43853,DS-a0a92d83-a746-4d3a-927f-f208f83c83d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-29bd0bcf-9b56-4904-8c25-61bb22bece84,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-04d9838a-c5e0-472b-bea5-5181312064c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-518e3d9f-447d-481a-9729-e067233d297d,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-963c9d1b-3d27-41b6-8b0c-98298906ee19,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-a6b6c2eb-7727-48e0-9dd2-6087b3117876,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-232481bf-a3b6-43ac-ad6b-cc0fe5df13b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-f8171fe8-d333-4de9-ac21-d3f8b439844a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905729639-172.17.0.20-1597114107346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43853,DS-a0a92d83-a746-4d3a-927f-f208f83c83d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-29bd0bcf-9b56-4904-8c25-61bb22bece84,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-04d9838a-c5e0-472b-bea5-5181312064c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-518e3d9f-447d-481a-9729-e067233d297d,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-963c9d1b-3d27-41b6-8b0c-98298906ee19,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-a6b6c2eb-7727-48e0-9dd2-6087b3117876,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-232481bf-a3b6-43ac-ad6b-cc0fe5df13b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-f8171fe8-d333-4de9-ac21-d3f8b439844a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cached.conn.retry
component: hdfs:NameNode
v1: 1
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485343281-172.17.0.20-1597114946448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35724,DS-3e08d33b-ed4c-41fe-b360-555d988e2723,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-20530c6e-256f-4c39-b01e-6ffdadfc530b,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-93ddd2a6-4262-4e3d-a1b8-23cc9ef53c92,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-b78099de-03ea-460a-bcf2-3f74a3487385,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-a7298a9a-e577-4aff-b780-a64d56f17068,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-0f49d597-45b5-4cea-bcd6-a875e5c2850b,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-c2b2d8fb-51ff-4eb9-bf41-7128b7c58ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-ba2d5687-4612-4914-ac20-3b2bbc30a823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485343281-172.17.0.20-1597114946448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35724,DS-3e08d33b-ed4c-41fe-b360-555d988e2723,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-20530c6e-256f-4c39-b01e-6ffdadfc530b,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-93ddd2a6-4262-4e3d-a1b8-23cc9ef53c92,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-b78099de-03ea-460a-bcf2-3f74a3487385,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-a7298a9a-e577-4aff-b780-a64d56f17068,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-0f49d597-45b5-4cea-bcd6-a875e5c2850b,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-c2b2d8fb-51ff-4eb9-bf41-7128b7c58ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-ba2d5687-4612-4914-ac20-3b2bbc30a823,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5576
