reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269788247-172.17.0.18-1597043244448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-1aab3621-d9c0-4023-929f-8a4c72a437bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a5ecd119-cc1e-4a93-bd86-92a276dfbee7,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-d3cef048-1f30-4722-b8b1-b49be3aff1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-9aa45c64-1b3d-4500-8cdf-9569ad1656f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-21c43693-6e73-444e-b0f8-49d9777c32f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-156d02c3-10bf-490c-ada1-b4c15226c55c,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-0b0f055b-f2c9-4557-a43b-aa906f7894a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-1f84dbd4-ad7c-448a-9570-12b0994a8d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269788247-172.17.0.18-1597043244448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35767,DS-1aab3621-d9c0-4023-929f-8a4c72a437bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-a5ecd119-cc1e-4a93-bd86-92a276dfbee7,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-d3cef048-1f30-4722-b8b1-b49be3aff1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-9aa45c64-1b3d-4500-8cdf-9569ad1656f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-21c43693-6e73-444e-b0f8-49d9777c32f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-156d02c3-10bf-490c-ada1-b4c15226c55c,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-0b0f055b-f2c9-4557-a43b-aa906f7894a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-1f84dbd4-ad7c-448a-9570-12b0994a8d21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011281806-172.17.0.18-1597043425233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43838,DS-4b5f1167-8152-4483-829e-e0e0627429c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-36e7e58b-af5c-4feb-b7cc-1508f71b8db4,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-aff7b378-4d8c-40c6-a0f5-bcbdb87abdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-84bf3616-6bf3-493f-82b8-897b413a59d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-4d089bff-5302-4d89-bae7-b8ccf5cc3514,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-95525d5e-f9ef-4f80-a994-de49b6748109,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-c4061dd0-6c01-4574-8e7e-fef6e708bb33,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-9ade8827-a73f-46e9-8796-b6fb5f88f241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011281806-172.17.0.18-1597043425233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43838,DS-4b5f1167-8152-4483-829e-e0e0627429c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-36e7e58b-af5c-4feb-b7cc-1508f71b8db4,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-aff7b378-4d8c-40c6-a0f5-bcbdb87abdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-84bf3616-6bf3-493f-82b8-897b413a59d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-4d089bff-5302-4d89-bae7-b8ccf5cc3514,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-95525d5e-f9ef-4f80-a994-de49b6748109,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-c4061dd0-6c01-4574-8e7e-fef6e708bb33,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-9ade8827-a73f-46e9-8796-b6fb5f88f241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269625990-172.17.0.18-1597044156440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-1b04fa4d-600b-43cf-828e-bfe01749b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-7b28ea0e-a9a3-4522-a060-fe66ff82e556,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-c4b3bb35-c21d-4009-aef8-d2cd6fdad78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-bc9a06b2-546e-4e5e-928f-ddcc41ccd727,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-b3f8216f-679b-4ec9-a578-9b9df5f0d73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-09f2078b-6b7c-4bdb-8877-49f1c56014f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-2d056c91-c179-4f33-8ce0-c3cdf6157fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-714928ed-602a-4321-abbf-8c0a19da8d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269625990-172.17.0.18-1597044156440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37480,DS-1b04fa4d-600b-43cf-828e-bfe01749b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-7b28ea0e-a9a3-4522-a060-fe66ff82e556,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-c4b3bb35-c21d-4009-aef8-d2cd6fdad78c,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-bc9a06b2-546e-4e5e-928f-ddcc41ccd727,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-b3f8216f-679b-4ec9-a578-9b9df5f0d73c,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-09f2078b-6b7c-4bdb-8877-49f1c56014f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-2d056c91-c179-4f33-8ce0-c3cdf6157fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-714928ed-602a-4321-abbf-8c0a19da8d3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42425298-172.17.0.18-1597045076694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-b5d41e80-54f3-461d-a23a-d874adc28e10,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-ee6f98b4-f0dc-4233-bec8-96fae7529c75,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-4bbe6c06-1abd-4ffc-9920-12daa0342312,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-e736a950-3592-487d-93d7-2e8b00913b80,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-d816055a-39db-470e-9931-415edc4c658e,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-0afadb2d-59b0-418c-a129-efbe00553d93,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-bdf21dcf-2183-4826-939f-96c123acdfab,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-73e1d136-272f-449a-840b-79682f52c2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-42425298-172.17.0.18-1597045076694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45829,DS-b5d41e80-54f3-461d-a23a-d874adc28e10,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-ee6f98b4-f0dc-4233-bec8-96fae7529c75,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-4bbe6c06-1abd-4ffc-9920-12daa0342312,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-e736a950-3592-487d-93d7-2e8b00913b80,DISK], DatanodeInfoWithStorage[127.0.0.1:41010,DS-d816055a-39db-470e-9931-415edc4c658e,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-0afadb2d-59b0-418c-a129-efbe00553d93,DISK], DatanodeInfoWithStorage[127.0.0.1:46467,DS-bdf21dcf-2183-4826-939f-96c123acdfab,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-73e1d136-272f-449a-840b-79682f52c2cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246756177-172.17.0.18-1597045484424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-981513ed-fb98-4ca7-8498-7a07f36da91c,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-2cf75160-7641-43ff-b083-3f78ec1272bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-6bfd071b-a7bd-4c7b-bb60-8441a891afc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-aaa2150e-1c43-4fd4-b287-9033a091e29c,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-04a5a97e-28da-4bd6-b758-7d1568bb73bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-fedd8d27-4538-4337-92b7-dca044c88cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-09311e5d-8636-45cb-873b-4a1e09714d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-b98eda41-1a03-4e97-a958-2a48d434572a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246756177-172.17.0.18-1597045484424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36994,DS-981513ed-fb98-4ca7-8498-7a07f36da91c,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-2cf75160-7641-43ff-b083-3f78ec1272bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-6bfd071b-a7bd-4c7b-bb60-8441a891afc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-aaa2150e-1c43-4fd4-b287-9033a091e29c,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-04a5a97e-28da-4bd6-b758-7d1568bb73bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37690,DS-fedd8d27-4538-4337-92b7-dca044c88cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-09311e5d-8636-45cb-873b-4a1e09714d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-b98eda41-1a03-4e97-a958-2a48d434572a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943880543-172.17.0.18-1597046172575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40375,DS-1bba1ecc-4d0c-47e7-8408-e3247b55bd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-fd6a9ec8-4f03-4117-988e-030150b51fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-5e558d34-7d7f-45be-a7b4-3b99df9e24b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-3c8b118c-6b63-4df1-b141-06e0a64649e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-1b72b54d-f181-4033-927f-70722615e7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-c97a7b83-0c78-47ef-ac65-325ebaedca48,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-64e4b20e-f55f-4caa-b975-83af30547ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-148cf2cf-d7cc-4450-bcac-5896bacd0254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943880543-172.17.0.18-1597046172575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40375,DS-1bba1ecc-4d0c-47e7-8408-e3247b55bd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-fd6a9ec8-4f03-4117-988e-030150b51fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-5e558d34-7d7f-45be-a7b4-3b99df9e24b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-3c8b118c-6b63-4df1-b141-06e0a64649e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-1b72b54d-f181-4033-927f-70722615e7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-c97a7b83-0c78-47ef-ac65-325ebaedca48,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-64e4b20e-f55f-4caa-b975-83af30547ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-148cf2cf-d7cc-4450-bcac-5896bacd0254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649912451-172.17.0.18-1597046435016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33169,DS-da3224bf-413e-46c4-b2cd-e8a3ae635164,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-22edaa82-e003-48b7-9a04-0444fc150710,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-e9ad3a15-33d3-4bf6-a93b-36bc8bb64c35,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-e8f5bfd9-e58a-4b3a-bfae-1476d962008b,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-a8f8be5f-420a-4de8-9a76-6cbb90e28141,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-e773d9ce-3077-4659-a317-3539f0e25dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-33c840be-4717-453d-9c5f-fd04f1a87521,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-248e3f3e-9367-4ee7-8baa-33931060d85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-649912451-172.17.0.18-1597046435016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33169,DS-da3224bf-413e-46c4-b2cd-e8a3ae635164,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-22edaa82-e003-48b7-9a04-0444fc150710,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-e9ad3a15-33d3-4bf6-a93b-36bc8bb64c35,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-e8f5bfd9-e58a-4b3a-bfae-1476d962008b,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-a8f8be5f-420a-4de8-9a76-6cbb90e28141,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-e773d9ce-3077-4659-a317-3539f0e25dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-33c840be-4717-453d-9c5f-fd04f1a87521,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-248e3f3e-9367-4ee7-8baa-33931060d85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140489969-172.17.0.18-1597046588633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-7b139caa-6e3b-483e-99a2-7d7b9216217f,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-3bc61a5c-bf10-475c-b491-e545075eba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-95810228-39e2-45a1-bfcd-6aa9a33faa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-4cca5268-196f-4a14-afac-4af959cf4011,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-4e0a9fbf-5808-4a84-9e0f-e9d6c7f374b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-46669599-a6f7-4757-a2d7-d5b013a9b4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-35671d21-d759-44db-bf4c-860015691212,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-ade125eb-18c0-4e00-80b6-1cb3cdc9c1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1140489969-172.17.0.18-1597046588633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-7b139caa-6e3b-483e-99a2-7d7b9216217f,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-3bc61a5c-bf10-475c-b491-e545075eba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-95810228-39e2-45a1-bfcd-6aa9a33faa3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-4cca5268-196f-4a14-afac-4af959cf4011,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-4e0a9fbf-5808-4a84-9e0f-e9d6c7f374b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-46669599-a6f7-4757-a2d7-d5b013a9b4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-35671d21-d759-44db-bf4c-860015691212,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-ade125eb-18c0-4e00-80b6-1cb3cdc9c1c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426600988-172.17.0.18-1597047422972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39117,DS-0e968366-e49f-42be-a8df-11cacba39589,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-197db0f5-8c54-42a5-ba56-21fb570334d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-9f8aafc7-296a-4979-a46c-e241daecbd97,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-84875108-7371-4a10-b57c-b18eb01c2372,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-0888f8ed-3dcd-4ad1-b0ee-5ebe0e8eda88,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-229c9c61-c450-4be3-ae45-0145e74da76a,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-7d28b658-82b2-47e7-afa6-e7d2ff3fb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-7221b92c-3757-4d95-b162-274bdd5d127d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426600988-172.17.0.18-1597047422972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39117,DS-0e968366-e49f-42be-a8df-11cacba39589,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-197db0f5-8c54-42a5-ba56-21fb570334d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-9f8aafc7-296a-4979-a46c-e241daecbd97,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-84875108-7371-4a10-b57c-b18eb01c2372,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-0888f8ed-3dcd-4ad1-b0ee-5ebe0e8eda88,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-229c9c61-c450-4be3-ae45-0145e74da76a,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-7d28b658-82b2-47e7-afa6-e7d2ff3fb4c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-7221b92c-3757-4d95-b162-274bdd5d127d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405821240-172.17.0.18-1597047964138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-f5623371-8235-4c7d-a7a2-3e3c03054d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-140c4e13-7322-466d-95fb-5f3acb5ad652,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-ca938fe4-4386-48bc-870d-8399bd394864,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-8143d7a4-3a01-4914-a7ff-1001118837bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-34f9340c-f174-4ef9-88c7-132e45627aad,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-2f6a1c0a-fd6c-4e93-816e-dabc197982ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-afac9212-1193-447b-8d83-fbbd41721fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-b09d3d6e-d644-4b0d-ba30-2b5d2395427e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405821240-172.17.0.18-1597047964138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-f5623371-8235-4c7d-a7a2-3e3c03054d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-140c4e13-7322-466d-95fb-5f3acb5ad652,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-ca938fe4-4386-48bc-870d-8399bd394864,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-8143d7a4-3a01-4914-a7ff-1001118837bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-34f9340c-f174-4ef9-88c7-132e45627aad,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-2f6a1c0a-fd6c-4e93-816e-dabc197982ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-afac9212-1193-447b-8d83-fbbd41721fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-b09d3d6e-d644-4b0d-ba30-2b5d2395427e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410937087-172.17.0.18-1597048180385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32846,DS-6630f47a-dde8-4f8c-b578-50ce5fd9f6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-d92ffd99-89d6-4b3f-b65d-3ce5ccea9d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-f00b94cd-5bd1-49c0-a271-9c753e3ea1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-32feb90b-1730-4898-a197-a3201b26525d,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-4c9f282a-9d11-4bee-a955-dba0a2ff4712,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-2ea80a3a-cd46-42f1-8e4f-a3ad63d0d0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-3bad6c5a-594a-4e2c-b253-9603590528af,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-9fb58bf6-311a-4128-8bd0-51c0a7606a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1410937087-172.17.0.18-1597048180385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32846,DS-6630f47a-dde8-4f8c-b578-50ce5fd9f6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-d92ffd99-89d6-4b3f-b65d-3ce5ccea9d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-f00b94cd-5bd1-49c0-a271-9c753e3ea1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43755,DS-32feb90b-1730-4898-a197-a3201b26525d,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-4c9f282a-9d11-4bee-a955-dba0a2ff4712,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-2ea80a3a-cd46-42f1-8e4f-a3ad63d0d0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-3bad6c5a-594a-4e2c-b253-9603590528af,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-9fb58bf6-311a-4128-8bd0-51c0a7606a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075447058-172.17.0.18-1597048273208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38640,DS-0a49de4e-257b-4284-a36a-c9216e8daf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-a9012b9f-951d-4add-ad2d-8b21dabad610,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-9f323272-c543-4f39-9e7e-c6987c94208d,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-f8678fdb-c6ac-4270-a532-db4b643b85f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-896d3628-6fd1-466b-9d02-c1d348c16420,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-3017f8ef-25ff-4d43-b27b-301d18015bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-6df88a54-9ef3-43c0-94c9-23bfa7f3c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-534c2b1e-02b2-4c18-bc57-15f6e6f4dbf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075447058-172.17.0.18-1597048273208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38640,DS-0a49de4e-257b-4284-a36a-c9216e8daf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-a9012b9f-951d-4add-ad2d-8b21dabad610,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-9f323272-c543-4f39-9e7e-c6987c94208d,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-f8678fdb-c6ac-4270-a532-db4b643b85f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-896d3628-6fd1-466b-9d02-c1d348c16420,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-3017f8ef-25ff-4d43-b27b-301d18015bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-6df88a54-9ef3-43c0-94c9-23bfa7f3c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-534c2b1e-02b2-4c18-bc57-15f6e6f4dbf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.network.counts.cache.max.size
component: hdfs:DataNode
v1: 2097151
v2: 2147483647
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762745491-172.17.0.18-1597048477108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-6a1e65fd-d302-4f43-91a8-f0288069783e,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-213c2d88-ed5f-41e3-856d-cd42bc17e748,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-b8a6c9a3-1429-4ec7-98e0-687ec737bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-6088545f-ce1b-408f-a818-200a37100972,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8e85f1c7-bf87-4f42-836c-00fffe86073e,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-683e65d5-b26e-4ea7-9216-8bfd59767667,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-9125dec3-e6f2-4bba-ac1a-47d956b36052,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-3a9e4c68-44db-4a0a-b0a4-630e6b63e626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762745491-172.17.0.18-1597048477108:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-6a1e65fd-d302-4f43-91a8-f0288069783e,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-213c2d88-ed5f-41e3-856d-cd42bc17e748,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-b8a6c9a3-1429-4ec7-98e0-687ec737bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-6088545f-ce1b-408f-a818-200a37100972,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-8e85f1c7-bf87-4f42-836c-00fffe86073e,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-683e65d5-b26e-4ea7-9216-8bfd59767667,DISK], DatanodeInfoWithStorage[127.0.0.1:33394,DS-9125dec3-e6f2-4bba-ac1a-47d956b36052,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-3a9e4c68-44db-4a0a-b0a4-630e6b63e626,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5420
