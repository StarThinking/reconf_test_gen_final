reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632143325-172.17.0.17-1597110132172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-3683eb61-28ba-4c6a-acd9-d8662c88117c,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-d5135364-70b0-40a5-aaac-a207dd6decd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-033e44f0-6c01-4456-8161-75bf99b26090,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-ddca2029-7508-45c9-a4cf-5f69b594156e,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-2138772d-39a4-414c-ba14-c6f2b46d9807,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-22ac4134-5155-44dd-ae5e-2706a1b4fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-6b05fe09-8e10-4301-af6f-db06d61fc5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-ded5564c-024f-4671-b186-8e5d78620a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632143325-172.17.0.17-1597110132172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-3683eb61-28ba-4c6a-acd9-d8662c88117c,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-d5135364-70b0-40a5-aaac-a207dd6decd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-033e44f0-6c01-4456-8161-75bf99b26090,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-ddca2029-7508-45c9-a4cf-5f69b594156e,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-2138772d-39a4-414c-ba14-c6f2b46d9807,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-22ac4134-5155-44dd-ae5e-2706a1b4fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-6b05fe09-8e10-4301-af6f-db06d61fc5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-ded5564c-024f-4671-b186-8e5d78620a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475701625-172.17.0.17-1597110374666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39675,DS-2fe46910-1918-4c8b-9c39-52ad79bd2587,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-c6650a40-6e26-4b80-9432-30d8ac37e988,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-41fc826e-8662-4d3f-b980-4df5819f5a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-01eb746e-121b-41db-a84e-6b5cf5b8f5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-9ab959e4-8df8-401e-8d2f-380cbbbfe224,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-c1d372b1-8136-4061-ab2c-7dbe2b9b838a,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-2719bbb5-b2bc-41e7-8489-cdc69a325eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-cca9b797-57ee-4807-83c7-54e527cadad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475701625-172.17.0.17-1597110374666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39675,DS-2fe46910-1918-4c8b-9c39-52ad79bd2587,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-c6650a40-6e26-4b80-9432-30d8ac37e988,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-41fc826e-8662-4d3f-b980-4df5819f5a75,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-01eb746e-121b-41db-a84e-6b5cf5b8f5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-9ab959e4-8df8-401e-8d2f-380cbbbfe224,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-c1d372b1-8136-4061-ab2c-7dbe2b9b838a,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-2719bbb5-b2bc-41e7-8489-cdc69a325eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-cca9b797-57ee-4807-83c7-54e527cadad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271132823-172.17.0.17-1597111012762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46023,DS-cd96d26b-2577-44cf-a260-d8bc65ef87d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-cba93424-cde2-4f24-95c2-d0988589fef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-bc26a907-1166-43be-be0a-1224a88bbf95,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-bbded422-f92b-4f24-af9f-37340a0241ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-8c6c741b-a678-4637-ac7d-129470c0ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-42d34586-ce86-43f6-87cc-9c0a4c4f61c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-f843805f-5e4f-4c33-9859-191183678908,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-397ba4f0-cba7-479a-a9b0-70ea68989fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271132823-172.17.0.17-1597111012762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46023,DS-cd96d26b-2577-44cf-a260-d8bc65ef87d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-cba93424-cde2-4f24-95c2-d0988589fef4,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-bc26a907-1166-43be-be0a-1224a88bbf95,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-bbded422-f92b-4f24-af9f-37340a0241ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-8c6c741b-a678-4637-ac7d-129470c0ff01,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-42d34586-ce86-43f6-87cc-9c0a4c4f61c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-f843805f-5e4f-4c33-9859-191183678908,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-397ba4f0-cba7-479a-a9b0-70ea68989fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39263887-172.17.0.17-1597111670379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-b009de60-8df5-49f1-a31a-22d66e11af24,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-aa5f3885-489e-40d6-9898-b3be88a5b405,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-70f26bc1-fb8c-4b8f-b49d-f942f45f43a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-6db94f76-e694-41a7-a6a1-b430a027e3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-7484a091-fc1e-4d79-ba15-f719e9c82aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-9bfbb07f-c5eb-4a77-8cf8-52e6b21e11cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-d8ead8ee-8e79-4a9e-8559-a172e5414906,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-06a64ec5-e67d-4949-85b4-5e0340a437b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39263887-172.17.0.17-1597111670379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36066,DS-b009de60-8df5-49f1-a31a-22d66e11af24,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-aa5f3885-489e-40d6-9898-b3be88a5b405,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-70f26bc1-fb8c-4b8f-b49d-f942f45f43a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-6db94f76-e694-41a7-a6a1-b430a027e3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-7484a091-fc1e-4d79-ba15-f719e9c82aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-9bfbb07f-c5eb-4a77-8cf8-52e6b21e11cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-d8ead8ee-8e79-4a9e-8559-a172e5414906,DISK], DatanodeInfoWithStorage[127.0.0.1:35365,DS-06a64ec5-e67d-4949-85b4-5e0340a437b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666473923-172.17.0.17-1597112425999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-ac4f19e1-1cb1-4e02-aa96-776da98e0584,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-5e860e8f-30bd-4def-acc0-f2a999ce5483,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-9fd327d4-073b-4f1d-8b88-38ab444c879f,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-8cb26124-0c02-4a09-9a15-804bc81b9288,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-88c9b29f-ac74-4c2e-a413-5af3bb2d19a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-62e7ec62-0eac-48d8-814b-35fc2ea498de,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-3515a12c-c1b0-4569-9090-3c3b13887f74,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-12598f73-fd9f-4c66-82e8-cd1f7b24e27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-666473923-172.17.0.17-1597112425999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-ac4f19e1-1cb1-4e02-aa96-776da98e0584,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-5e860e8f-30bd-4def-acc0-f2a999ce5483,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-9fd327d4-073b-4f1d-8b88-38ab444c879f,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-8cb26124-0c02-4a09-9a15-804bc81b9288,DISK], DatanodeInfoWithStorage[127.0.0.1:37200,DS-88c9b29f-ac74-4c2e-a413-5af3bb2d19a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-62e7ec62-0eac-48d8-814b-35fc2ea498de,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-3515a12c-c1b0-4569-9090-3c3b13887f74,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-12598f73-fd9f-4c66-82e8-cd1f7b24e27d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765419797-172.17.0.17-1597112635033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-3bdcb3fa-e3d7-4350-8bfb-b43021a699f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-3247cf15-8376-4bbd-b943-c125aa4c26fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-658aba15-99a6-4d7b-b196-a3a08ae1f7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-172fdca5-a8ca-4b90-abc9-745745e5805e,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-04111e0d-3208-423a-98ab-aeb8a6a1c256,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-edb18a4f-eb3d-40e3-85f9-b19a09a0f51f,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-4dec269a-90d0-4824-abcd-b3590bacffab,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-9a355095-4962-484c-9b6e-6f87ec6ceb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765419797-172.17.0.17-1597112635033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44238,DS-3bdcb3fa-e3d7-4350-8bfb-b43021a699f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-3247cf15-8376-4bbd-b943-c125aa4c26fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-658aba15-99a6-4d7b-b196-a3a08ae1f7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-172fdca5-a8ca-4b90-abc9-745745e5805e,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-04111e0d-3208-423a-98ab-aeb8a6a1c256,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-edb18a4f-eb3d-40e3-85f9-b19a09a0f51f,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-4dec269a-90d0-4824-abcd-b3590bacffab,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-9a355095-4962-484c-9b6e-6f87ec6ceb29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545540046-172.17.0.17-1597112855678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43315,DS-1c9bbfff-3b2f-4176-8784-ba5403e774d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-59f0be50-18ab-4b33-88c2-f0ce63d6aee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-873e9275-7f1b-46d8-9852-e34b42e66b45,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-0456e85e-e62d-4a94-969c-04135a0a34ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-f750c3c0-b09a-4fca-bd92-1e17afdafe5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-770f63d0-af64-4aec-a207-07af320eb3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-c8c1d0d1-be09-4797-a5ae-0c69a913a172,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-b3868798-b624-4453-bae5-9fd97b63dd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545540046-172.17.0.17-1597112855678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43315,DS-1c9bbfff-3b2f-4176-8784-ba5403e774d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-59f0be50-18ab-4b33-88c2-f0ce63d6aee5,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-873e9275-7f1b-46d8-9852-e34b42e66b45,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-0456e85e-e62d-4a94-969c-04135a0a34ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-f750c3c0-b09a-4fca-bd92-1e17afdafe5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-770f63d0-af64-4aec-a207-07af320eb3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42441,DS-c8c1d0d1-be09-4797-a5ae-0c69a913a172,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-b3868798-b624-4453-bae5-9fd97b63dd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133463010-172.17.0.17-1597113038426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38123,DS-41c8c862-85b9-40ec-be6b-08120f78463e,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-8d16b283-905e-4f67-9bdb-ceb543c577e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-3391ad82-9899-478f-bcae-5c2363f802ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-dab98531-49a9-4bba-897e-84624a568398,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-1e65334f-1cbf-4981-ab24-bb8eaffe8760,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-b9c6a55a-62f9-49b8-b04a-5c5c40e3b14e,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-31144dd2-fee4-4465-bdb5-2926b5037be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-2c42e758-5264-4e00-a4f7-00148fa9c321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1133463010-172.17.0.17-1597113038426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38123,DS-41c8c862-85b9-40ec-be6b-08120f78463e,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-8d16b283-905e-4f67-9bdb-ceb543c577e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-3391ad82-9899-478f-bcae-5c2363f802ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-dab98531-49a9-4bba-897e-84624a568398,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-1e65334f-1cbf-4981-ab24-bb8eaffe8760,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-b9c6a55a-62f9-49b8-b04a-5c5c40e3b14e,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-31144dd2-fee4-4465-bdb5-2926b5037be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-2c42e758-5264-4e00-a4f7-00148fa9c321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854364904-172.17.0.17-1597113778021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38925,DS-600fdd03-abbc-4462-8917-5664b6817323,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-0a16e2b2-b3ff-4fb0-abca-76bf9371032c,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-5e61c87e-f954-462d-987a-f1421d056876,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-ad7670ae-d99b-4443-8f06-5bcd6ec5cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-e5bb5e60-b38d-471d-8be4-9bbcef482efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-2f7c210b-9ea6-483d-8fa9-be50899acd12,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-1bd567b7-02b3-4fe2-b9a4-8db92e9aa830,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-9544f6df-05ab-4fec-98e9-629cfdbede35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854364904-172.17.0.17-1597113778021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38925,DS-600fdd03-abbc-4462-8917-5664b6817323,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-0a16e2b2-b3ff-4fb0-abca-76bf9371032c,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-5e61c87e-f954-462d-987a-f1421d056876,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-ad7670ae-d99b-4443-8f06-5bcd6ec5cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-e5bb5e60-b38d-471d-8be4-9bbcef482efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-2f7c210b-9ea6-483d-8fa9-be50899acd12,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-1bd567b7-02b3-4fe2-b9a4-8db92e9aa830,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-9544f6df-05ab-4fec-98e9-629cfdbede35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59371868-172.17.0.17-1597114541755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45815,DS-813ce261-5dd5-41be-ae84-fdcc28b9703e,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-97c683e0-cfe1-40f3-8f9f-fd5979cdca12,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-4463c778-15f8-4811-bc33-c43eba894dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-a2d972c9-cc32-485a-9d05-3be1ea075cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-e7ae3086-3f44-4d5d-8a02-866a9c559d20,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-e2ddabc4-08c5-4632-9a7d-7a7419c0b1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-6c37f940-af46-46ea-86f1-2cd8d716ae3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-fc93e6f5-2c5a-4dc3-b830-01de72df07d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59371868-172.17.0.17-1597114541755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45815,DS-813ce261-5dd5-41be-ae84-fdcc28b9703e,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-97c683e0-cfe1-40f3-8f9f-fd5979cdca12,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-4463c778-15f8-4811-bc33-c43eba894dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-a2d972c9-cc32-485a-9d05-3be1ea075cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-e7ae3086-3f44-4d5d-8a02-866a9c559d20,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-e2ddabc4-08c5-4632-9a7d-7a7419c0b1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-6c37f940-af46-46ea-86f1-2cd8d716ae3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40214,DS-fc93e6f5-2c5a-4dc3-b830-01de72df07d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5417
