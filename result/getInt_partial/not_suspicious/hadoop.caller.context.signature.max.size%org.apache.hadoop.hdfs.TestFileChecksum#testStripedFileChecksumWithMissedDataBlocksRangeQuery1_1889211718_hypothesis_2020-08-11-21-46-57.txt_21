reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144603458-172.17.0.6-1597183208491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43090,DS-d282fd98-6273-4846-9407-690a4b41f3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-c093702a-f407-4b9a-bf05-e90bdaed3767,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-0a774951-3551-4eb1-9a0e-43e1314a4f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-09057ba9-0b72-470b-b38b-7ace50577214,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-0ef0a331-a3e6-4e89-b6cc-007ad31f297f,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-61f9b7cb-844a-4dc8-9c8a-070daeb9ebe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-ac41d419-0dbc-4268-b9ed-f92918d7be49,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-010779f0-00ac-4637-915a-d0853121cebb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144603458-172.17.0.6-1597183208491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43090,DS-d282fd98-6273-4846-9407-690a4b41f3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-c093702a-f407-4b9a-bf05-e90bdaed3767,DISK], DatanodeInfoWithStorage[127.0.0.1:44988,DS-0a774951-3551-4eb1-9a0e-43e1314a4f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-09057ba9-0b72-470b-b38b-7ace50577214,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-0ef0a331-a3e6-4e89-b6cc-007ad31f297f,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-61f9b7cb-844a-4dc8-9c8a-070daeb9ebe8,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-ac41d419-0dbc-4268-b9ed-f92918d7be49,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-010779f0-00ac-4637-915a-d0853121cebb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011741026-172.17.0.6-1597183553481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38316,DS-809279e0-1584-4569-b549-1a68cd1dc426,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-a636773b-1c89-48d1-aa98-839434724a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-a37f3e94-6cbb-45da-bdf5-720326647fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-6b9a8438-7edc-486b-ae77-af1cdf18653e,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-5fb484f2-efb8-4ff9-89f6-d5e5feeefd34,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-a7a695e6-d00a-4b7a-b723-6e9314b52070,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-fb8035e3-64fa-4cfe-8f46-c0ada90fe07c,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-a9e859a1-350c-497a-84a5-c9e4f66944a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2011741026-172.17.0.6-1597183553481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38316,DS-809279e0-1584-4569-b549-1a68cd1dc426,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-a636773b-1c89-48d1-aa98-839434724a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-a37f3e94-6cbb-45da-bdf5-720326647fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-6b9a8438-7edc-486b-ae77-af1cdf18653e,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-5fb484f2-efb8-4ff9-89f6-d5e5feeefd34,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-a7a695e6-d00a-4b7a-b723-6e9314b52070,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-fb8035e3-64fa-4cfe-8f46-c0ada90fe07c,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-a9e859a1-350c-497a-84a5-c9e4f66944a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610154578-172.17.0.6-1597184401417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34708,DS-d2cef7a5-96a9-4a35-91f7-6af9d25405cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-f6ced220-59d1-4924-81fb-bc176f31e900,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-35e8a7bf-3523-4d8f-ba4a-e62139c6f23d,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-4f895770-5e8c-45dc-9ac5-a781d463ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-df43ab37-08c2-4967-8e7d-de3b623a367c,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-5f3c8547-458a-4a72-be1b-535f7a5033cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-3a00f3e8-1c3d-4fb2-8ea2-1e1eaabc7be2,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-9dc029f4-e0bd-4a39-94eb-9cef24bebf4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610154578-172.17.0.6-1597184401417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34708,DS-d2cef7a5-96a9-4a35-91f7-6af9d25405cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34908,DS-f6ced220-59d1-4924-81fb-bc176f31e900,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-35e8a7bf-3523-4d8f-ba4a-e62139c6f23d,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-4f895770-5e8c-45dc-9ac5-a781d463ec77,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-df43ab37-08c2-4967-8e7d-de3b623a367c,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-5f3c8547-458a-4a72-be1b-535f7a5033cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-3a00f3e8-1c3d-4fb2-8ea2-1e1eaabc7be2,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-9dc029f4-e0bd-4a39-94eb-9cef24bebf4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71603164-172.17.0.6-1597185816922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-21d4df16-250a-4f9e-b79f-a7a23136338e,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-df300cca-e4d9-4943-aad4-14005f91482e,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-280dce94-0b43-4bb4-aabb-cc75ada35da7,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-ff546b69-fcfe-45a5-91ae-aa593c5959ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-c22e4db8-16e4-42a3-853a-8dee6372365d,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-40e7c9c6-4bbe-4adc-b6cc-19df55748bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-c01543a0-230c-482f-84ea-9006f07f142a,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-709d85a3-9ac2-412c-b25d-76e3c4985277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71603164-172.17.0.6-1597185816922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-21d4df16-250a-4f9e-b79f-a7a23136338e,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-df300cca-e4d9-4943-aad4-14005f91482e,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-280dce94-0b43-4bb4-aabb-cc75ada35da7,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-ff546b69-fcfe-45a5-91ae-aa593c5959ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-c22e4db8-16e4-42a3-853a-8dee6372365d,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-40e7c9c6-4bbe-4adc-b6cc-19df55748bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45166,DS-c01543a0-230c-482f-84ea-9006f07f142a,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-709d85a3-9ac2-412c-b25d-76e3c4985277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603468040-172.17.0.6-1597186012237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-ae91cdd9-a876-4978-b13d-066c372138bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-2a9db3d9-b1a0-4d50-8546-04f12fa21571,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-39424020-9aae-41a4-8ad8-7dbbf55b267c,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-8a6ab30e-0135-4df7-9257-94577f0fb012,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-d3485af5-71bf-4219-a34b-15d362bb6681,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-67e7f9fa-8305-4b79-b370-74d9922cd73a,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-7831c522-2f17-462e-9252-345038091b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-e0aaf0f5-6da3-4ed8-a93a-b1211cb39f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603468040-172.17.0.6-1597186012237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-ae91cdd9-a876-4978-b13d-066c372138bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-2a9db3d9-b1a0-4d50-8546-04f12fa21571,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-39424020-9aae-41a4-8ad8-7dbbf55b267c,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-8a6ab30e-0135-4df7-9257-94577f0fb012,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-d3485af5-71bf-4219-a34b-15d362bb6681,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-67e7f9fa-8305-4b79-b370-74d9922cd73a,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-7831c522-2f17-462e-9252-345038091b62,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-e0aaf0f5-6da3-4ed8-a93a-b1211cb39f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818686740-172.17.0.6-1597186354767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40772,DS-7f578a6d-f683-4319-bd3e-fdce47c2c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-17cb09bd-7202-4054-9624-b24f96bbac04,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-231ff4fd-89cf-4cc1-9d1a-ec4926c0a3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-0572f8c5-3ce8-473b-b3c3-4e3932631f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-8488d3de-1fa4-4f0a-b2e2-2d9883cbd979,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-cc19fc49-62e7-4af3-8658-95dd54c1a048,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-575eae45-ebe8-43e6-b5c6-be4088ee3937,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-88a0909b-b2c8-418d-be7a-b7c7b5e1a49c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818686740-172.17.0.6-1597186354767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40772,DS-7f578a6d-f683-4319-bd3e-fdce47c2c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-17cb09bd-7202-4054-9624-b24f96bbac04,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-231ff4fd-89cf-4cc1-9d1a-ec4926c0a3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-0572f8c5-3ce8-473b-b3c3-4e3932631f11,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-8488d3de-1fa4-4f0a-b2e2-2d9883cbd979,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-cc19fc49-62e7-4af3-8658-95dd54c1a048,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-575eae45-ebe8-43e6-b5c6-be4088ee3937,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-88a0909b-b2c8-418d-be7a-b7c7b5e1a49c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952357116-172.17.0.6-1597186872058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46696,DS-b4d90a7e-4940-44b7-b622-0875fcf9e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-8b419295-2745-4bfa-8fbc-19ff24d0348e,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-75a2e6f3-5418-462b-9c50-4d50083204ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-c9c8009d-a590-4289-a367-96f87cbf70ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-a0a41308-48e1-4ffd-86c8-63e8ccebedd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-aff9ff9a-76c7-4db4-8a9e-22eaaa40dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-7681b04e-5ea7-4291-9039-00ba20350aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-063bf71a-577c-41be-a066-04c6bd690f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952357116-172.17.0.6-1597186872058:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46696,DS-b4d90a7e-4940-44b7-b622-0875fcf9e4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-8b419295-2745-4bfa-8fbc-19ff24d0348e,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-75a2e6f3-5418-462b-9c50-4d50083204ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-c9c8009d-a590-4289-a367-96f87cbf70ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-a0a41308-48e1-4ffd-86c8-63e8ccebedd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-aff9ff9a-76c7-4db4-8a9e-22eaaa40dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-7681b04e-5ea7-4291-9039-00ba20350aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-063bf71a-577c-41be-a066-04c6bd690f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569021236-172.17.0.6-1597186966658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-9e177bb6-36e0-46a2-b6d2-301fe2cbb2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-17938182-afa3-48f7-a69d-03c442d661a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-8faba094-9d50-4ef7-902c-24f9c1c3d24a,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-e0d4ffd7-86cc-4c25-9a30-cc966cb6c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-bb5092ee-d313-400f-bb9e-9e46ab293b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-1a954320-ae8e-449a-a7d6-f9bb1c4dad34,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-25dc2c7e-7b6a-4647-a31d-63b07a103ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-61e7bcac-3ad3-4c1d-bce4-d2d46c75e152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1569021236-172.17.0.6-1597186966658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-9e177bb6-36e0-46a2-b6d2-301fe2cbb2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-17938182-afa3-48f7-a69d-03c442d661a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-8faba094-9d50-4ef7-902c-24f9c1c3d24a,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-e0d4ffd7-86cc-4c25-9a30-cc966cb6c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-bb5092ee-d313-400f-bb9e-9e46ab293b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-1a954320-ae8e-449a-a7d6-f9bb1c4dad34,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-25dc2c7e-7b6a-4647-a31d-63b07a103ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-61e7bcac-3ad3-4c1d-bce4-d2d46c75e152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340888323-172.17.0.6-1597187651632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-34c74d1c-7ed0-4fff-a82c-320aa40f9356,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-c5b0b532-d3f7-4fcb-8feb-1b55a92e8df6,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-ec105d62-5608-4d40-a0e5-b8b412c54d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-dc1a17ab-b335-4f3a-bd44-74afc4be5855,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-01bf1f4c-fa4a-40cf-992a-8d3bebacf79f,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-1c38bc14-bcfc-4e7f-9733-98b10207f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-6d224f53-1d3e-47ce-85d7-f94420c0f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-eba0a1e2-7dbf-4e2a-957c-399a068098ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1340888323-172.17.0.6-1597187651632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-34c74d1c-7ed0-4fff-a82c-320aa40f9356,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-c5b0b532-d3f7-4fcb-8feb-1b55a92e8df6,DISK], DatanodeInfoWithStorage[127.0.0.1:37463,DS-ec105d62-5608-4d40-a0e5-b8b412c54d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-dc1a17ab-b335-4f3a-bd44-74afc4be5855,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-01bf1f4c-fa4a-40cf-992a-8d3bebacf79f,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-1c38bc14-bcfc-4e7f-9733-98b10207f3df,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-6d224f53-1d3e-47ce-85d7-f94420c0f6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-eba0a1e2-7dbf-4e2a-957c-399a068098ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864448882-172.17.0.6-1597187777520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46693,DS-4fd6e8a3-95e3-4f45-a1ef-1290e719ac8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-0032e476-c3ae-4ec5-87af-cae27b901399,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-86ffaeeb-4908-4814-8bbc-6f4bd6a2e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-69b73a77-017f-4e91-890a-db11bcf8510b,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-6cc43da0-1825-49b4-8a1e-a73ffb8a601e,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-f9a5fd76-3ce7-4654-93cc-68ec2b56f744,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-7495078b-fcf0-4d7e-9634-1b45dcce83ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-27938f7d-3d42-4761-b47d-1fa8299aef23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864448882-172.17.0.6-1597187777520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46693,DS-4fd6e8a3-95e3-4f45-a1ef-1290e719ac8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-0032e476-c3ae-4ec5-87af-cae27b901399,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-86ffaeeb-4908-4814-8bbc-6f4bd6a2e5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-69b73a77-017f-4e91-890a-db11bcf8510b,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-6cc43da0-1825-49b4-8a1e-a73ffb8a601e,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-f9a5fd76-3ce7-4654-93cc-68ec2b56f744,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-7495078b-fcf0-4d7e-9634-1b45dcce83ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-27938f7d-3d42-4761-b47d-1fa8299aef23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524385921-172.17.0.6-1597187869838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-5ba8c946-0b22-4a56-805f-5bdb8264ee94,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-7b771710-a190-46d1-abee-f5547e22c70f,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-d936e4f7-cb4c-4117-9fb1-75988b82039d,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-59d4922f-a346-4b96-89e8-cfbdecc77533,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-75f1383b-4fca-4b67-abe1-21c57cec3b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-cc5b4542-efd5-4b9e-9892-3a1e684f69e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-b59af2a6-e303-45d2-ac2c-5df29a360f91,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-f83e6849-0536-4f9f-b942-b5fbe8781462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1524385921-172.17.0.6-1597187869838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42195,DS-5ba8c946-0b22-4a56-805f-5bdb8264ee94,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-7b771710-a190-46d1-abee-f5547e22c70f,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-d936e4f7-cb4c-4117-9fb1-75988b82039d,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-59d4922f-a346-4b96-89e8-cfbdecc77533,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-75f1383b-4fca-4b67-abe1-21c57cec3b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-cc5b4542-efd5-4b9e-9892-3a1e684f69e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-b59af2a6-e303-45d2-ac2c-5df29a360f91,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-f83e6849-0536-4f9f-b942-b5fbe8781462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202079017-172.17.0.6-1597187998137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45725,DS-d769dda6-50e7-4964-bfd8-a1a54db141ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-dc87c296-43b6-42b9-af54-daa03f2300bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-6321354c-ab37-428c-993c-92a73c2ff30b,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-61766f3b-e63d-406b-ad88-169c4a83fe85,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-5457b946-fbcb-4df3-b213-a95b32eb9af5,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-86ec2e11-2268-421a-b7d6-3a749a73326f,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-59732866-210f-4f30-b754-de2b5a0560f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-18065d84-aaf0-44c0-88aa-1c817de82b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202079017-172.17.0.6-1597187998137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45725,DS-d769dda6-50e7-4964-bfd8-a1a54db141ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-dc87c296-43b6-42b9-af54-daa03f2300bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-6321354c-ab37-428c-993c-92a73c2ff30b,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-61766f3b-e63d-406b-ad88-169c4a83fe85,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-5457b946-fbcb-4df3-b213-a95b32eb9af5,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-86ec2e11-2268-421a-b7d6-3a749a73326f,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-59732866-210f-4f30-b754-de2b5a0560f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40742,DS-18065d84-aaf0-44c0-88aa-1c817de82b22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13404573-172.17.0.6-1597188296140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-0952eecc-391a-426f-b609-ce36b66efa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-36383426-d048-405c-978e-fbaf6b2deb31,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-691ae5dc-ef51-42be-8ceb-062b0bdc3a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-02c1634a-f5c2-45e1-b419-3223239eabcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-495e0717-f75a-4685-8ef9-b5abf153f9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-1c2df506-f666-4b1e-892b-0ba1872e15a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-4167f049-719a-4166-b60d-745d80a3a294,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-b4c9c42f-bc39-4f39-8acf-d9218a9ca1b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13404573-172.17.0.6-1597188296140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40852,DS-0952eecc-391a-426f-b609-ce36b66efa9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-36383426-d048-405c-978e-fbaf6b2deb31,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-691ae5dc-ef51-42be-8ceb-062b0bdc3a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-02c1634a-f5c2-45e1-b419-3223239eabcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41856,DS-495e0717-f75a-4685-8ef9-b5abf153f9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-1c2df506-f666-4b1e-892b-0ba1872e15a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-4167f049-719a-4166-b60d-745d80a3a294,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-b4c9c42f-bc39-4f39-8acf-d9218a9ca1b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247594227-172.17.0.6-1597188333973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37997,DS-cbaee5d1-b1c3-4e3c-8614-06d8745670f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-e38cf189-c668-49ad-af29-b8b5db7a69e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-6f9868cb-91d6-447e-bbf9-9ff753292a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-62940ef0-4550-4dd9-a227-c5237b99bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-5aca7c43-8ccf-476b-b80b-e8d221b2571d,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-48ffaf3c-d90b-4af3-b4ef-06b04afd5bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-ea9e22d9-0b7e-4195-a110-2981d441225c,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-4f6cb84e-e432-4cc0-b242-5af68afe4a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247594227-172.17.0.6-1597188333973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37997,DS-cbaee5d1-b1c3-4e3c-8614-06d8745670f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-e38cf189-c668-49ad-af29-b8b5db7a69e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-6f9868cb-91d6-447e-bbf9-9ff753292a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-62940ef0-4550-4dd9-a227-c5237b99bdf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-5aca7c43-8ccf-476b-b80b-e8d221b2571d,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-48ffaf3c-d90b-4af3-b4ef-06b04afd5bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-ea9e22d9-0b7e-4195-a110-2981d441225c,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-4f6cb84e-e432-4cc0-b242-5af68afe4a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.signature.max.size
component: hdfs:NameNode
v1: 40
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797588495-172.17.0.6-1597188648730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-de7eb609-4f95-4b24-8b4d-b2c882ad5648,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-f60e21b0-d076-408e-b046-54086a27cbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-c0e38fce-f1d3-4387-aed4-35a41108a636,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-b0c89c35-16e9-4ba7-be33-7e13187add06,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-2a6a7964-3b2f-4700-9d04-4f0d3a782efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-dc94d576-5fb7-4b91-a6c0-9313c2619dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-d6aa8c05-33f6-4b78-b2b0-3274c28c24ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-d59eb55e-e1c7-4ba8-a0fc-d4bcf2687e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797588495-172.17.0.6-1597188648730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-de7eb609-4f95-4b24-8b4d-b2c882ad5648,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-f60e21b0-d076-408e-b046-54086a27cbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-c0e38fce-f1d3-4387-aed4-35a41108a636,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-b0c89c35-16e9-4ba7-be33-7e13187add06,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-2a6a7964-3b2f-4700-9d04-4f0d3a782efe,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-dc94d576-5fb7-4b91-a6c0-9313c2619dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-d6aa8c05-33f6-4b78-b2b0-3274c28c24ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-d59eb55e-e1c7-4ba8-a0fc-d4bcf2687e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 6621
