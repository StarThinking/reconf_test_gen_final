reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869730117-172.17.0.14-1597135922312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-504143cc-b77d-41be-928c-d41d9234dc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-405a3af9-c72b-49af-af44-515a0f32fbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-93555574-0518-47bb-8dad-d23b4c4e2add,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-c6ef7479-13ed-4be9-8e5c-f5f6d649c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-20eb3bf9-1ea6-4553-98cf-339c62af87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-11e635ec-9806-46d2-ad5e-95642933c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-3b9932a5-2c70-4d67-baa8-db1081300c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-e58fd50b-1f91-409b-b438-377300edf7bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869730117-172.17.0.14-1597135922312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-504143cc-b77d-41be-928c-d41d9234dc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-405a3af9-c72b-49af-af44-515a0f32fbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-93555574-0518-47bb-8dad-d23b4c4e2add,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-c6ef7479-13ed-4be9-8e5c-f5f6d649c2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-20eb3bf9-1ea6-4553-98cf-339c62af87ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-11e635ec-9806-46d2-ad5e-95642933c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-3b9932a5-2c70-4d67-baa8-db1081300c87,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-e58fd50b-1f91-409b-b438-377300edf7bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931884760-172.17.0.14-1597136005418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-e384fa0f-3199-4db0-9715-f278519cf460,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-6b80438b-db94-4f6a-8555-4d81e8b0f503,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-68788799-b5c8-4709-b8d0-9eb5f8a2a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-aa3c7e2d-ec07-4633-a9b7-b9b0040480ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-dcd3d306-7cce-4082-8f51-a3d1a8d91da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-32509ffe-bf92-4cc3-bc55-1266ccaadbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-0b3e91b8-96d5-467b-b89b-20b7d08a4e69,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-582304a5-d86a-4e49-a01d-d15ae9c2f236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-931884760-172.17.0.14-1597136005418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-e384fa0f-3199-4db0-9715-f278519cf460,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-6b80438b-db94-4f6a-8555-4d81e8b0f503,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-68788799-b5c8-4709-b8d0-9eb5f8a2a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-aa3c7e2d-ec07-4633-a9b7-b9b0040480ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-dcd3d306-7cce-4082-8f51-a3d1a8d91da1,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-32509ffe-bf92-4cc3-bc55-1266ccaadbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-0b3e91b8-96d5-467b-b89b-20b7d08a4e69,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-582304a5-d86a-4e49-a01d-d15ae9c2f236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040506981-172.17.0.14-1597136397230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44807,DS-332905dc-ea3b-4950-8ef9-5a589a61b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-3bde8ee6-f425-4fbf-b6a1-b213b2c11b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-5d2e4c70-f21d-42fa-a79d-12b595054141,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-14774cd4-2fef-43a6-adf4-98f3e27f096b,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-aa26c2e7-7f00-4426-81d5-4d62402ac12a,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-ad05b301-2681-4b14-bb57-759477331bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-97531048-28af-4cc7-9a0a-130ad96c72e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-a9e4ac51-c64d-4706-a36f-f8bc9b81d913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040506981-172.17.0.14-1597136397230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44807,DS-332905dc-ea3b-4950-8ef9-5a589a61b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-3bde8ee6-f425-4fbf-b6a1-b213b2c11b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-5d2e4c70-f21d-42fa-a79d-12b595054141,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-14774cd4-2fef-43a6-adf4-98f3e27f096b,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-aa26c2e7-7f00-4426-81d5-4d62402ac12a,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-ad05b301-2681-4b14-bb57-759477331bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-97531048-28af-4cc7-9a0a-130ad96c72e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-a9e4ac51-c64d-4706-a36f-f8bc9b81d913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527622886-172.17.0.14-1597136461362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-c43b2740-98dc-4840-a4f6-b0972817c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-732904ec-7564-4ece-898d-c6fea5688c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-3579c3c2-7e3d-4079-8b96-efff87957e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-80f00867-0e1b-4f93-aa4b-230c5667a453,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-54c1a198-7cbb-4e46-956d-6652d330d481,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-cce1acbb-d696-41bc-bb70-31b53a04c2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-5eee8beb-7264-46fe-9e07-a2b491842f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-53c2094b-e6a1-4bcb-ad8c-590487f449b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527622886-172.17.0.14-1597136461362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-c43b2740-98dc-4840-a4f6-b0972817c2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-732904ec-7564-4ece-898d-c6fea5688c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-3579c3c2-7e3d-4079-8b96-efff87957e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-80f00867-0e1b-4f93-aa4b-230c5667a453,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-54c1a198-7cbb-4e46-956d-6652d330d481,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-cce1acbb-d696-41bc-bb70-31b53a04c2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-5eee8beb-7264-46fe-9e07-a2b491842f65,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-53c2094b-e6a1-4bcb-ad8c-590487f449b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200644853-172.17.0.14-1597136797176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42113,DS-899b922d-02e6-4fdc-80f9-9d6bd7c4d8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-5f547c54-a829-4172-a84c-3b30aaa185e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-b35bca8d-8f73-4467-a467-b0ab1a0f999f,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-1788f80d-a61b-434b-ae48-b9cff62f0fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-1cc1f79c-920c-4d7b-adf5-dfe72f75c196,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-33c5cbce-8597-42f8-a3a2-938a8f17943a,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-5b7b98b4-9b50-46fa-9165-e9fcbc2a0871,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-d14a1b22-ddd9-431b-9fa3-6ac0439ce557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200644853-172.17.0.14-1597136797176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42113,DS-899b922d-02e6-4fdc-80f9-9d6bd7c4d8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-5f547c54-a829-4172-a84c-3b30aaa185e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-b35bca8d-8f73-4467-a467-b0ab1a0f999f,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-1788f80d-a61b-434b-ae48-b9cff62f0fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-1cc1f79c-920c-4d7b-adf5-dfe72f75c196,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-33c5cbce-8597-42f8-a3a2-938a8f17943a,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-5b7b98b4-9b50-46fa-9165-e9fcbc2a0871,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-d14a1b22-ddd9-431b-9fa3-6ac0439ce557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929274614-172.17.0.14-1597136832919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-80c644d4-db1c-450d-a38e-5250f4f07a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-a85e6ecf-ae03-49b8-8e66-982e6c70cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-1cd61689-a7c0-44eb-9c05-c77a27399b05,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-4b6bdd01-d52f-4d77-8f7a-3fc8ecf06777,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-6f63aecf-9613-46d5-b184-0112637c1874,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-f4986b4b-2dcc-4566-8d71-d10e70a3e43d,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-b425a812-2201-41c0-b59e-9c25d1ddcf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-7f134d46-d255-4869-83d1-81f03296add8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929274614-172.17.0.14-1597136832919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42058,DS-80c644d4-db1c-450d-a38e-5250f4f07a70,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-a85e6ecf-ae03-49b8-8e66-982e6c70cf63,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-1cd61689-a7c0-44eb-9c05-c77a27399b05,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-4b6bdd01-d52f-4d77-8f7a-3fc8ecf06777,DISK], DatanodeInfoWithStorage[127.0.0.1:36615,DS-6f63aecf-9613-46d5-b184-0112637c1874,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-f4986b4b-2dcc-4566-8d71-d10e70a3e43d,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-b425a812-2201-41c0-b59e-9c25d1ddcf2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-7f134d46-d255-4869-83d1-81f03296add8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484678010-172.17.0.14-1597137016769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-3cd57b50-c4b1-4bc2-9ac4-a3483444d518,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-6b9abc45-c2ae-46a2-abcd-277138b9d918,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-91e665e7-b7fb-4eca-b059-90044ffd1808,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-d072eafa-c9a4-4965-9b3e-dbcd261dcb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-0f354f53-c67f-4582-ab3e-f51c81258318,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-43765c52-6c85-495a-bfb2-37da07fa6570,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-a45ca053-936e-4ae1-a1a3-e3fdeab694df,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-4d889173-f4a2-4aa9-b80f-17765eaaed90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484678010-172.17.0.14-1597137016769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-3cd57b50-c4b1-4bc2-9ac4-a3483444d518,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-6b9abc45-c2ae-46a2-abcd-277138b9d918,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-91e665e7-b7fb-4eca-b059-90044ffd1808,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-d072eafa-c9a4-4965-9b3e-dbcd261dcb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-0f354f53-c67f-4582-ab3e-f51c81258318,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-43765c52-6c85-495a-bfb2-37da07fa6570,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-a45ca053-936e-4ae1-a1a3-e3fdeab694df,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-4d889173-f4a2-4aa9-b80f-17765eaaed90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093324465-172.17.0.14-1597137052532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37015,DS-b2ee83b0-2f86-4914-b46c-ab402c32dc98,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-241c87cf-29a9-4fb2-b6db-a415c9edb9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-29daa8d4-87a7-46a4-8e33-7651b8e1a97e,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-2ef2e085-fd94-4dc6-ae0f-c17ff30ca4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-65827d38-2576-48bb-92a3-63117ba08b15,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-c1de1285-5bac-4718-b478-9d0af498bc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-1609854a-1db4-4918-afc5-14df0ed0a9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-d339c379-8fb6-4e33-aff3-ac6bad685a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093324465-172.17.0.14-1597137052532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37015,DS-b2ee83b0-2f86-4914-b46c-ab402c32dc98,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-241c87cf-29a9-4fb2-b6db-a415c9edb9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43493,DS-29daa8d4-87a7-46a4-8e33-7651b8e1a97e,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-2ef2e085-fd94-4dc6-ae0f-c17ff30ca4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-65827d38-2576-48bb-92a3-63117ba08b15,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-c1de1285-5bac-4718-b478-9d0af498bc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-1609854a-1db4-4918-afc5-14df0ed0a9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-d339c379-8fb6-4e33-aff3-ac6bad685a35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723267719-172.17.0.14-1597137232224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-490091a1-5c0a-49f9-a0c3-483675cf37f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-32fd9372-bd51-4a91-819c-cd00967639e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-312c0c27-c356-48d0-8a1e-0f3cce14a372,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-6c24dce0-fe17-4a44-993a-7f663ece12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-c56c52b1-f967-46c2-81aa-28eed1d2920a,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-16b66855-ac4a-4729-af1b-0b6159e38533,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-adf0cf58-871e-45ab-89a9-38c5f6a50060,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-315dfbb9-cb55-4d6d-b10a-09e9a692dc15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723267719-172.17.0.14-1597137232224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45019,DS-490091a1-5c0a-49f9-a0c3-483675cf37f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-32fd9372-bd51-4a91-819c-cd00967639e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-312c0c27-c356-48d0-8a1e-0f3cce14a372,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-6c24dce0-fe17-4a44-993a-7f663ece12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-c56c52b1-f967-46c2-81aa-28eed1d2920a,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-16b66855-ac4a-4729-af1b-0b6159e38533,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-adf0cf58-871e-45ab-89a9-38c5f6a50060,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-315dfbb9-cb55-4d6d-b10a-09e9a692dc15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979016326-172.17.0.14-1597137962276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43594,DS-2ad38718-ce15-4b36-ae14-0c9d82b4ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-2ef53f7a-75a5-4e69-a115-f8c8eb985564,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-e2591b6a-dc51-4073-93b0-9ab7ac2e2962,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-76f46b09-0f93-46d4-9a53-1566ec9def14,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-dc0e2336-3309-4a54-8c98-f6654ba195ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-b2a7241a-a344-4f6b-a941-ddd3a832c581,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-be68280f-e2a2-4477-849b-89d7fe1fa3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-fb32fcfe-ad17-4a27-844c-eb08a650e483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979016326-172.17.0.14-1597137962276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43594,DS-2ad38718-ce15-4b36-ae14-0c9d82b4ea49,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-2ef53f7a-75a5-4e69-a115-f8c8eb985564,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-e2591b6a-dc51-4073-93b0-9ab7ac2e2962,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-76f46b09-0f93-46d4-9a53-1566ec9def14,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-dc0e2336-3309-4a54-8c98-f6654ba195ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-b2a7241a-a344-4f6b-a941-ddd3a832c581,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-be68280f-e2a2-4477-849b-89d7fe1fa3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-fb32fcfe-ad17-4a27-844c-eb08a650e483,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675366643-172.17.0.14-1597138579824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-7f1f24ac-6397-46de-bb96-2111da14cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-5cf5176e-2777-4965-b197-a4beaf208cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-8e57d39d-6910-4dec-8a92-6dc79c0a4903,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-ad7d4fe0-03b9-4d07-8025-eff0d93fedaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-8f8b9c44-db84-4a81-b197-28ea3eef4ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-f22311fa-bb8b-4f24-8537-90be2b01304a,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-e2523ee1-ce4c-4ba0-9fce-a5a41309582a,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-84d07b80-6ebd-4ccf-8a4f-ddfc338b6ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675366643-172.17.0.14-1597138579824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33396,DS-7f1f24ac-6397-46de-bb96-2111da14cd18,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-5cf5176e-2777-4965-b197-a4beaf208cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-8e57d39d-6910-4dec-8a92-6dc79c0a4903,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-ad7d4fe0-03b9-4d07-8025-eff0d93fedaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-8f8b9c44-db84-4a81-b197-28ea3eef4ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:44594,DS-f22311fa-bb8b-4f24-8537-90be2b01304a,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-e2523ee1-ce4c-4ba0-9fce-a5a41309582a,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-84d07b80-6ebd-4ccf-8a4f-ddfc338b6ae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704611685-172.17.0.14-1597139347331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-9bbe6ad0-ef37-4e29-95b4-62bcc685c977,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-4e904731-d608-4752-9e8a-0651f235e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-10d9a048-7639-4e2e-9d35-b713828d5f64,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-ef3b2371-d1e9-4deb-a2b5-9623e4715687,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-e558a3db-02c1-43de-a895-9cb3057efc70,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-8390482a-6ea0-4729-8cec-1ce0a58af197,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-e2d6d004-5682-4618-88ef-523f170f7a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-d3444210-3366-42c9-b686-fd02df1b98a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1704611685-172.17.0.14-1597139347331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-9bbe6ad0-ef37-4e29-95b4-62bcc685c977,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-4e904731-d608-4752-9e8a-0651f235e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-10d9a048-7639-4e2e-9d35-b713828d5f64,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-ef3b2371-d1e9-4deb-a2b5-9623e4715687,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-e558a3db-02c1-43de-a895-9cb3057efc70,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-8390482a-6ea0-4729-8cec-1ce0a58af197,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-e2d6d004-5682-4618-88ef-523f170f7a79,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-d3444210-3366-42c9-b686-fd02df1b98a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1705749789-172.17.0.14-1597139381081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39760,DS-60e63ad0-2d5b-49f4-928a-4b950da0b846,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-091d7bc9-fae3-4439-9a9c-8ce22aad75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-5b241a70-4849-4c6a-af22-f2cd5a60c4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-24146775-6b9d-42c9-bfbb-0b35f7f53e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-b1889a32-b8e1-408b-b92a-317a5a90e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-9097d5c2-50dc-4001-aa98-bfa42f02840e,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-739c2de0-b8e6-423d-b713-ee498d81f1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-a864d97c-7c1f-4824-a7b4-e25b93aa00cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1705749789-172.17.0.14-1597139381081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39760,DS-60e63ad0-2d5b-49f4-928a-4b950da0b846,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-091d7bc9-fae3-4439-9a9c-8ce22aad75b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43178,DS-5b241a70-4849-4c6a-af22-f2cd5a60c4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-24146775-6b9d-42c9-bfbb-0b35f7f53e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-b1889a32-b8e1-408b-b92a-317a5a90e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-9097d5c2-50dc-4001-aa98-bfa42f02840e,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-739c2de0-b8e6-423d-b713-ee498d81f1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-a864d97c-7c1f-4824-a7b4-e25b93aa00cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923123432-172.17.0.14-1597139701644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-0222c4d9-c5af-4e71-8eff-d20381180186,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-5a08ef48-f189-4ecd-8962-811ac36e50fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-e83515b7-3dfd-4cb0-b1f2-f0d7f4858876,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-86fc006f-00fa-4b59-bd6f-8ff3b4998acd,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-63a4d9c4-3f86-4104-9484-8a6fd3035b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-7c36316f-05a9-4e18-b373-0582e78bdb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-59439717-5730-4414-a879-358485bce857,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-c488fe01-e486-43d1-a2c0-b6337ad914d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923123432-172.17.0.14-1597139701644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-0222c4d9-c5af-4e71-8eff-d20381180186,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-5a08ef48-f189-4ecd-8962-811ac36e50fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43533,DS-e83515b7-3dfd-4cb0-b1f2-f0d7f4858876,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-86fc006f-00fa-4b59-bd6f-8ff3b4998acd,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-63a4d9c4-3f86-4104-9484-8a6fd3035b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-7c36316f-05a9-4e18-b373-0582e78bdb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33755,DS-59439717-5730-4414-a879-358485bce857,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-c488fe01-e486-43d1-a2c0-b6337ad914d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977897011-172.17.0.14-1597139887905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36031,DS-346ef686-4de8-4827-ab83-bcb8a696fa76,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-5ddb48de-2106-4d12-8983-a93c489731e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-86290d8f-52f5-4db3-9195-4f254015b719,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-74f6e937-02cb-464a-9375-9e3039a8cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-41e94a02-1bf9-4c71-8b19-63a5b6bc0d07,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-b82cc5d7-d00e-43f2-885d-edbdf2180a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-29793af3-78b8-425e-a839-7c65b2d914bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-d39e97bc-4f1f-4b1c-8dac-9e31a0efd1c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977897011-172.17.0.14-1597139887905:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36031,DS-346ef686-4de8-4827-ab83-bcb8a696fa76,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-5ddb48de-2106-4d12-8983-a93c489731e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-86290d8f-52f5-4db3-9195-4f254015b719,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-74f6e937-02cb-464a-9375-9e3039a8cbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-41e94a02-1bf9-4c71-8b19-63a5b6bc0d07,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-b82cc5d7-d00e-43f2-885d-edbdf2180a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-29793af3-78b8-425e-a839-7c65b2d914bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-d39e97bc-4f1f-4b1c-8dac-9e31a0efd1c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855086002-172.17.0.14-1597140009708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36877,DS-01cbd131-e959-49d5-9c1b-596c77e51406,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-c77b2d70-aa66-4b55-820d-96b5b9b26704,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-f3020a51-035b-4b2e-ae07-fa03fde23b24,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-b090a032-62f1-44ba-8aeb-3873f16c58ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-8204cece-0c04-4ea3-b7ce-fd721a76699c,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-632346e6-181f-4029-973d-5752c2594e86,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-5c5fa683-d7c9-467c-ad27-04703cdd1819,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-7c0d2b48-2cad-47b3-9303-a1a539a4ba19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855086002-172.17.0.14-1597140009708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36877,DS-01cbd131-e959-49d5-9c1b-596c77e51406,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-c77b2d70-aa66-4b55-820d-96b5b9b26704,DISK], DatanodeInfoWithStorage[127.0.0.1:38644,DS-f3020a51-035b-4b2e-ae07-fa03fde23b24,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-b090a032-62f1-44ba-8aeb-3873f16c58ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-8204cece-0c04-4ea3-b7ce-fd721a76699c,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-632346e6-181f-4029-973d-5752c2594e86,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-5c5fa683-d7c9-467c-ad27-04703cdd1819,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-7c0d2b48-2cad-47b3-9303-a1a539a4ba19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193349097-172.17.0.14-1597140800741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-bb0626e2-375a-4cad-b992-b9a09e7df3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-76956434-cc69-4eec-a180-2afe2a228a64,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-50d52008-b28d-4653-9e8a-523ee8faa4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-182413ff-31a1-46b3-af30-9b2497805d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-569124f9-936c-4651-9749-f03c311bdc16,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-a39ddbfc-0c68-4552-a81e-ce6a0637986e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-d31f849e-d4af-41ff-8b14-d8d8b4ef3c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-1ef84598-68bf-427c-a50d-c7c95e284fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193349097-172.17.0.14-1597140800741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-bb0626e2-375a-4cad-b992-b9a09e7df3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-76956434-cc69-4eec-a180-2afe2a228a64,DISK], DatanodeInfoWithStorage[127.0.0.1:36984,DS-50d52008-b28d-4653-9e8a-523ee8faa4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-182413ff-31a1-46b3-af30-9b2497805d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-569124f9-936c-4651-9749-f03c311bdc16,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-a39ddbfc-0c68-4552-a81e-ce6a0637986e,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-d31f849e-d4af-41ff-8b14-d8d8b4ef3c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-1ef84598-68bf-427c-a50d-c7c95e284fdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.ec.reconstruction.threads
component: hdfs:DataNode
v1: 8
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597910122-172.17.0.14-1597141031134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33816,DS-3d9f92e3-1e82-4732-92f7-aec1c6f6e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-e874ef5c-8faa-4e4d-bdf4-f9b6a99086a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-3229f7ad-3302-4a87-be7c-4a15b18f7b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-63211de7-9a2f-440b-bd93-9caeaa02aa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-3deb439a-828d-40c8-a763-b99ee04dd8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-1d3a47fb-1666-4e34-95ce-1d365b3053cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-c41dd962-c7f6-4d7c-85de-5e1848a3c425,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-c402d2bf-fdf3-4131-baef-c8fa3b702a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597910122-172.17.0.14-1597141031134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33816,DS-3d9f92e3-1e82-4732-92f7-aec1c6f6e4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-e874ef5c-8faa-4e4d-bdf4-f9b6a99086a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-3229f7ad-3302-4a87-be7c-4a15b18f7b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-63211de7-9a2f-440b-bd93-9caeaa02aa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-3deb439a-828d-40c8-a763-b99ee04dd8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-1d3a47fb-1666-4e34-95ce-1d365b3053cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-c41dd962-c7f6-4d7c-85de-5e1848a3c425,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-c402d2bf-fdf3-4131-baef-c8fa3b702a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5545
