reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962111617-172.17.0.9-1597108699009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42034,DS-348ace49-9fdc-4b6b-9f21-8f3d95b4441d,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-fd6dbfa1-14d2-415d-93b1-08aa06a15707,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-745c82cb-9906-4939-831a-cec2e03a932e,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-bf4f3bb9-d97e-4e90-89e8-daeb4416abf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-808918ed-d2eb-4860-9a5e-c00a6e1bf4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-1a93b831-619f-436f-ac1c-206035de93e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-06d61f5b-5832-4253-84c0-712f18565e06,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-2152eefc-459a-412f-9dac-eeaf90b685a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962111617-172.17.0.9-1597108699009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42034,DS-348ace49-9fdc-4b6b-9f21-8f3d95b4441d,DISK], DatanodeInfoWithStorage[127.0.0.1:41668,DS-fd6dbfa1-14d2-415d-93b1-08aa06a15707,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-745c82cb-9906-4939-831a-cec2e03a932e,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-bf4f3bb9-d97e-4e90-89e8-daeb4416abf3,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-808918ed-d2eb-4860-9a5e-c00a6e1bf4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-1a93b831-619f-436f-ac1c-206035de93e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-06d61f5b-5832-4253-84c0-712f18565e06,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-2152eefc-459a-412f-9dac-eeaf90b685a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946880326-172.17.0.9-1597109011782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34028,DS-d16694dc-b117-4b82-8240-4deb33e4eb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-98ec5423-0f3b-4153-88fc-38965263a813,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-4ddc1b65-7f48-4665-991f-5b5c6939d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-4aa920d5-bc90-4b03-80e1-9aca00963dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-53448d9b-8fa1-4223-bd91-fc27d4bcc805,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-4a958565-55a3-4fd2-983b-1e26d96da63e,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-cb9840a0-ef7e-4403-8643-bcaf77cc246b,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-f3c8c98d-69f0-496f-9f60-cf69249144d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946880326-172.17.0.9-1597109011782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34028,DS-d16694dc-b117-4b82-8240-4deb33e4eb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-98ec5423-0f3b-4153-88fc-38965263a813,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-4ddc1b65-7f48-4665-991f-5b5c6939d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:44896,DS-4aa920d5-bc90-4b03-80e1-9aca00963dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-53448d9b-8fa1-4223-bd91-fc27d4bcc805,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-4a958565-55a3-4fd2-983b-1e26d96da63e,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-cb9840a0-ef7e-4403-8643-bcaf77cc246b,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-f3c8c98d-69f0-496f-9f60-cf69249144d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246171141-172.17.0.9-1597109313825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32972,DS-157281fe-a56d-4504-80a0-5ca0cb981907,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-7cc0d268-d164-407c-bcd0-c16d9f81fef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-5dcdd35b-c1e7-422d-baa9-58bdafd046c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-ff4e2687-bf71-4b9d-95a5-94adbb5c38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-9e9e4554-641b-403e-a6d9-6a544ee9adb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-e734eff8-8ee0-4647-8782-bbb5f649d320,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-ea704000-5859-448b-abf7-4b26565ceefe,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-c9a3143b-d4a6-47fd-bd81-363de01b7ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-246171141-172.17.0.9-1597109313825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32972,DS-157281fe-a56d-4504-80a0-5ca0cb981907,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-7cc0d268-d164-407c-bcd0-c16d9f81fef5,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-5dcdd35b-c1e7-422d-baa9-58bdafd046c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-ff4e2687-bf71-4b9d-95a5-94adbb5c38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-9e9e4554-641b-403e-a6d9-6a544ee9adb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-e734eff8-8ee0-4647-8782-bbb5f649d320,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-ea704000-5859-448b-abf7-4b26565ceefe,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-c9a3143b-d4a6-47fd-bd81-363de01b7ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398489124-172.17.0.9-1597109634418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42084,DS-84da5e36-4ad9-4553-a998-66505b6f55c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-a5ff0883-dbae-466b-9b94-e20e2804b1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-675433ce-c655-488f-9d2c-39be627cfb26,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-7407d32c-282f-4642-b192-067edd4010d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-362c57f3-1c6b-420e-9f28-e65a38078dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-8161ea30-fe36-4a41-a61d-64f8230e9698,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-a2faa452-a07d-47fa-b8a8-d876d2199d18,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-3fd06986-0e2c-4772-9440-7be5b59a4d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1398489124-172.17.0.9-1597109634418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42084,DS-84da5e36-4ad9-4553-a998-66505b6f55c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-a5ff0883-dbae-466b-9b94-e20e2804b1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-675433ce-c655-488f-9d2c-39be627cfb26,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-7407d32c-282f-4642-b192-067edd4010d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-362c57f3-1c6b-420e-9f28-e65a38078dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-8161ea30-fe36-4a41-a61d-64f8230e9698,DISK], DatanodeInfoWithStorage[127.0.0.1:46694,DS-a2faa452-a07d-47fa-b8a8-d876d2199d18,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-3fd06986-0e2c-4772-9440-7be5b59a4d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855238925-172.17.0.9-1597109808249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-44a2024b-2d37-42bb-8486-9d369e434a09,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-d9ce654c-ab44-40c2-8638-05f7711d5ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-c645b7c1-f05f-46af-893b-62f8feb08229,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-bd4d4ab9-79f7-4316-bc13-295db377b0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-ef76870f-e9a3-4922-ae4c-9b9425e746e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-105b39cb-2f36-4cf1-9fa7-b44e5b5714de,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-088660da-24f9-4004-a2a4-dc9ca5bcade2,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-c386b025-3892-4603-8173-71efcc660da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855238925-172.17.0.9-1597109808249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-44a2024b-2d37-42bb-8486-9d369e434a09,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-d9ce654c-ab44-40c2-8638-05f7711d5ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-c645b7c1-f05f-46af-893b-62f8feb08229,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-bd4d4ab9-79f7-4316-bc13-295db377b0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-ef76870f-e9a3-4922-ae4c-9b9425e746e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-105b39cb-2f36-4cf1-9fa7-b44e5b5714de,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-088660da-24f9-4004-a2a4-dc9ca5bcade2,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-c386b025-3892-4603-8173-71efcc660da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590290998-172.17.0.9-1597109906673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-8e494e8d-0dc2-4a17-bf3e-bfcc19807bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-f53dee84-7b0f-4286-8041-110f1bc6bfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-3be86eb7-779c-416a-b3f7-2aeeb13ffa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-36a76e5e-1134-4521-8668-e401a615bb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-b0c333f5-683e-4719-b2e0-61a5a3a840be,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-24b852f7-6d4d-4331-9a67-b9edf997948e,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-d5b908d3-6fb8-4537-9c92-cec86ed060d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-4db3e0c5-c455-4b18-b02e-170e2ee091c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590290998-172.17.0.9-1597109906673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35292,DS-8e494e8d-0dc2-4a17-bf3e-bfcc19807bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-f53dee84-7b0f-4286-8041-110f1bc6bfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38137,DS-3be86eb7-779c-416a-b3f7-2aeeb13ffa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-36a76e5e-1134-4521-8668-e401a615bb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44026,DS-b0c333f5-683e-4719-b2e0-61a5a3a840be,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-24b852f7-6d4d-4331-9a67-b9edf997948e,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-d5b908d3-6fb8-4537-9c92-cec86ed060d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-4db3e0c5-c455-4b18-b02e-170e2ee091c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116215967-172.17.0.9-1597110484134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-33d8acaa-8482-415f-a5fa-313a40bfebda,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-287b4aca-1243-4511-9506-39defae9424b,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-09762ba8-68c7-4154-a829-bbcdd9d4cb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-1d2e94ab-a9bc-4732-b08a-94e849d7a0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-91328984-04fc-42db-bee7-971106f4b28c,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-ecbeff20-1a0e-4edb-b0f0-ddd78a1d9e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-875658c8-234d-4007-9e23-9ceddd5fa85c,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-8b44295c-9443-44cc-af07-80ec598d8892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116215967-172.17.0.9-1597110484134:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-33d8acaa-8482-415f-a5fa-313a40bfebda,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-287b4aca-1243-4511-9506-39defae9424b,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-09762ba8-68c7-4154-a829-bbcdd9d4cb4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-1d2e94ab-a9bc-4732-b08a-94e849d7a0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-91328984-04fc-42db-bee7-971106f4b28c,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-ecbeff20-1a0e-4edb-b0f0-ddd78a1d9e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-875658c8-234d-4007-9e23-9ceddd5fa85c,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-8b44295c-9443-44cc-af07-80ec598d8892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321743786-172.17.0.9-1597110513368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-aa96b23a-d663-4e39-9514-6ae5e93df028,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-a9845f3b-f0b4-4be0-8fc4-9c6fbba2f746,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-30f0d00a-3f49-4f74-8531-2c49bd03c1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-3e93e58f-5785-44b2-b598-aeaf36b77172,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-5038cf5c-7b4a-405d-b2ad-f0204152e229,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-75f14a95-1161-4e69-9026-cc29485e8790,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-ebbbbbcf-ba5b-4d3f-aa65-b1d336835664,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-9ab60716-6318-4ba9-8102-c27181fae7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321743786-172.17.0.9-1597110513368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42375,DS-aa96b23a-d663-4e39-9514-6ae5e93df028,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-a9845f3b-f0b4-4be0-8fc4-9c6fbba2f746,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-30f0d00a-3f49-4f74-8531-2c49bd03c1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39765,DS-3e93e58f-5785-44b2-b598-aeaf36b77172,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-5038cf5c-7b4a-405d-b2ad-f0204152e229,DISK], DatanodeInfoWithStorage[127.0.0.1:46050,DS-75f14a95-1161-4e69-9026-cc29485e8790,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-ebbbbbcf-ba5b-4d3f-aa65-b1d336835664,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-9ab60716-6318-4ba9-8102-c27181fae7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751981688-172.17.0.9-1597110821553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-95aca6c4-6ec7-4430-9697-54ecaa5a6075,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-5369b342-23d8-4441-86e7-52eb9c93c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-190045e6-c8bc-4c95-abb8-739ea132889c,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-2b0fae6d-dd7b-49ba-bf38-7cba95a640c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-a6d753c6-1242-4fa9-aaa5-c58c33267958,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-94ecef39-5960-4844-9043-58d52fba5bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-6f5d653d-2344-46be-a31e-d4969e0ca171,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-5b625c3d-16bd-487a-8662-2db6a6a8073e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751981688-172.17.0.9-1597110821553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-95aca6c4-6ec7-4430-9697-54ecaa5a6075,DISK], DatanodeInfoWithStorage[127.0.0.1:39309,DS-5369b342-23d8-4441-86e7-52eb9c93c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-190045e6-c8bc-4c95-abb8-739ea132889c,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-2b0fae6d-dd7b-49ba-bf38-7cba95a640c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-a6d753c6-1242-4fa9-aaa5-c58c33267958,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-94ecef39-5960-4844-9043-58d52fba5bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35789,DS-6f5d653d-2344-46be-a31e-d4969e0ca171,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-5b625c3d-16bd-487a-8662-2db6a6a8073e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009534326-172.17.0.9-1597111080127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45799,DS-ec8a6493-2b43-4c8d-833c-be6308b67372,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-b7de174a-849e-4335-8398-3a91cb2d76a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-c9b42877-7f33-43d8-b7a3-a1a745d46eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-f060507c-2a77-40ce-866a-a6a85e278e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-da30f152-9bd4-44a1-b7ee-d6fcb97df3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-cf3d4c57-6183-4fc0-879d-90206e93d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-efec4650-95b7-4957-93b8-146b99a9218e,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-3ca77e3f-e9f6-4fe9-b515-07eec8847f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009534326-172.17.0.9-1597111080127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45799,DS-ec8a6493-2b43-4c8d-833c-be6308b67372,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-b7de174a-849e-4335-8398-3a91cb2d76a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-c9b42877-7f33-43d8-b7a3-a1a745d46eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-f060507c-2a77-40ce-866a-a6a85e278e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-da30f152-9bd4-44a1-b7ee-d6fcb97df3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-cf3d4c57-6183-4fc0-879d-90206e93d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-efec4650-95b7-4957-93b8-146b99a9218e,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-3ca77e3f-e9f6-4fe9-b515-07eec8847f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390331269-172.17.0.9-1597111635239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43134,DS-ab6d8b3a-c7b8-404c-98cd-a4d77aab4506,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-8897b2ac-991f-4bad-9735-b328ceea2bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-62d2b7bb-b43f-4e5f-afa8-a86383093140,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-84697aff-cbb8-47b5-8b62-4a108db2017c,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-a6653395-5ab7-46f8-ba42-d2b8aba7062a,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-c74b4a8e-6768-442f-be73-d0ac625f5881,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-583bab28-cc94-491c-a2a0-c4a202452e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-90db1671-131d-4cc9-b32a-be46cb624592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390331269-172.17.0.9-1597111635239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43134,DS-ab6d8b3a-c7b8-404c-98cd-a4d77aab4506,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-8897b2ac-991f-4bad-9735-b328ceea2bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-62d2b7bb-b43f-4e5f-afa8-a86383093140,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-84697aff-cbb8-47b5-8b62-4a108db2017c,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-a6653395-5ab7-46f8-ba42-d2b8aba7062a,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-c74b4a8e-6768-442f-be73-d0ac625f5881,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-583bab28-cc94-491c-a2a0-c4a202452e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-90db1671-131d-4cc9-b32a-be46cb624592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070348921-172.17.0.9-1597111772645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-afbdc209-7dca-43e9-8a2d-4b57e1c8705e,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-0f196819-16fa-42c7-841d-bf04c74fda60,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-c0894412-8db2-4757-8a17-37938284f084,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-0f86c4fd-6ed6-44ec-8531-bf8c83592ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-e02eb6f3-ca82-47e6-aafd-adaf3b25d4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-c1c1e303-ad5e-41fd-ba95-10e1d4f062e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-7dc1fc11-05eb-4222-9f5d-9c4ededfd4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-1fbc93b4-ab84-4412-96b9-2190fdb6d376,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070348921-172.17.0.9-1597111772645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38329,DS-afbdc209-7dca-43e9-8a2d-4b57e1c8705e,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-0f196819-16fa-42c7-841d-bf04c74fda60,DISK], DatanodeInfoWithStorage[127.0.0.1:45403,DS-c0894412-8db2-4757-8a17-37938284f084,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-0f86c4fd-6ed6-44ec-8531-bf8c83592ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-e02eb6f3-ca82-47e6-aafd-adaf3b25d4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-c1c1e303-ad5e-41fd-ba95-10e1d4f062e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40955,DS-7dc1fc11-05eb-4222-9f5d-9c4ededfd4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-1fbc93b4-ab84-4412-96b9-2190fdb6d376,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956766789-172.17.0.9-1597111801883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44063,DS-fc3b93b6-e711-4a25-afdb-9ba03ceb7300,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-de9a310d-8061-48fe-bf3c-69c09c4aeb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-defbeb1e-98e3-4477-863e-abcd85544d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-2727d6b3-e9e5-45d2-9390-cf061bdebe77,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-71b6fd41-9ab6-4a99-b583-495b7bd0e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-d48eceec-e94c-4a4f-a0ac-230e2b14acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-a2225d1d-4dc1-4608-af2f-69e25306c372,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-363287c4-5c0a-4e36-be1d-6eb33c71f970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956766789-172.17.0.9-1597111801883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44063,DS-fc3b93b6-e711-4a25-afdb-9ba03ceb7300,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-de9a310d-8061-48fe-bf3c-69c09c4aeb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-defbeb1e-98e3-4477-863e-abcd85544d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-2727d6b3-e9e5-45d2-9390-cf061bdebe77,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-71b6fd41-9ab6-4a99-b583-495b7bd0e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-d48eceec-e94c-4a4f-a0ac-230e2b14acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-a2225d1d-4dc1-4608-af2f-69e25306c372,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-363287c4-5c0a-4e36-be1d-6eb33c71f970,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782637730-172.17.0.9-1597112023175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42651,DS-0c9187c3-599a-48a5-8681-2324ea586d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-daf8634c-02b7-4666-96bb-42c65a76c357,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-bafcd5f3-25db-4046-b53f-b849a504ffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-9f18cac2-20d8-4365-bc2c-0d2b0508e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-058cd5bc-cc05-4944-81ac-fd7866a8d186,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-3f00473e-a42c-4c4a-a3c7-f45034d49329,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-a6500b5f-be8a-4899-b6d0-ff8a2ddcacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-64d476a4-f6cb-40f0-a380-65a79b3f7452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1782637730-172.17.0.9-1597112023175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42651,DS-0c9187c3-599a-48a5-8681-2324ea586d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-daf8634c-02b7-4666-96bb-42c65a76c357,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-bafcd5f3-25db-4046-b53f-b849a504ffdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-9f18cac2-20d8-4365-bc2c-0d2b0508e6db,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-058cd5bc-cc05-4944-81ac-fd7866a8d186,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-3f00473e-a42c-4c4a-a3c7-f45034d49329,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-a6500b5f-be8a-4899-b6d0-ff8a2ddcacbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-64d476a4-f6cb-40f0-a380-65a79b3f7452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476028646-172.17.0.9-1597112061674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43109,DS-ffc208b0-c25f-4a57-a3e9-33f5e12b38f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-40678a94-fee2-4380-95db-9e66f1c9a746,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-06deb4c9-7c0b-41ef-8550-4347c68af132,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-01c3a2b9-6ab0-406d-82a8-b2f064f7f49b,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-7da933fd-be44-4f49-8ebc-f931b7c0d6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-f134aaee-bf0f-407b-991a-bdf63fd52f67,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-76efa4b1-04b6-4ba4-9188-8e0bd49c8f03,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-5a207652-4463-4c8c-8a4a-d2bd07947ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476028646-172.17.0.9-1597112061674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43109,DS-ffc208b0-c25f-4a57-a3e9-33f5e12b38f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-40678a94-fee2-4380-95db-9e66f1c9a746,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-06deb4c9-7c0b-41ef-8550-4347c68af132,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-01c3a2b9-6ab0-406d-82a8-b2f064f7f49b,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-7da933fd-be44-4f49-8ebc-f931b7c0d6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-f134aaee-bf0f-407b-991a-bdf63fd52f67,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-76efa4b1-04b6-4ba4-9188-8e0bd49c8f03,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-5a207652-4463-4c8c-8a4a-d2bd07947ba1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945567922-172.17.0.9-1597112166832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-085fa63f-7e19-4471-849b-5f660a9d26bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-b3618db1-b4a4-4454-acf1-088b6d142960,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-588953bd-8a06-454c-8cf2-954a1fc16237,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-9ea9e501-9633-4aac-a11c-b1186e5ce526,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-22edfc8c-956d-451f-bcf8-d582621fc36f,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-eeee2e58-e57a-4b33-a964-1263339f7494,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-f44ec699-178e-4413-a586-1a57485606a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-8fec18da-25ef-4bc5-aa4b-dd5447e1f92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945567922-172.17.0.9-1597112166832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37552,DS-085fa63f-7e19-4471-849b-5f660a9d26bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-b3618db1-b4a4-4454-acf1-088b6d142960,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-588953bd-8a06-454c-8cf2-954a1fc16237,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-9ea9e501-9633-4aac-a11c-b1186e5ce526,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-22edfc8c-956d-451f-bcf8-d582621fc36f,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-eeee2e58-e57a-4b33-a964-1263339f7494,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-f44ec699-178e-4413-a586-1a57485606a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-8fec18da-25ef-4bc5-aa4b-dd5447e1f92d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009230190-172.17.0.9-1597112374177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-fe660506-c8f6-4075-96a0-20cc7ae82742,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-e824738b-a925-4e27-940c-a41117277534,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-a4f40d9d-4b00-474e-b66a-09f643caf0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-13427c50-fafc-4674-a951-dcb94281466c,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-e29b1565-b32d-4d6a-b43f-cb60b97606fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-8f5a805f-5ac1-4485-83fb-b1df5e86cb95,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-810b540d-0224-4379-843d-6ce645d87974,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-f66b6a3a-6535-42c3-82bc-5a41cd33ac64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009230190-172.17.0.9-1597112374177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-fe660506-c8f6-4075-96a0-20cc7ae82742,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-e824738b-a925-4e27-940c-a41117277534,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-a4f40d9d-4b00-474e-b66a-09f643caf0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-13427c50-fafc-4674-a951-dcb94281466c,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-e29b1565-b32d-4d6a-b43f-cb60b97606fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-8f5a805f-5ac1-4485-83fb-b1df5e86cb95,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-810b540d-0224-4379-843d-6ce645d87974,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-f66b6a3a-6535-42c3-82bc-5a41cd33ac64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575928822-172.17.0.9-1597112940136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46679,DS-d2b0f7ee-a00a-4c78-b136-2a75a3ed231f,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-e78fa1ed-91f7-400d-9652-a3ce189e9fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-60d85be3-e4fd-4456-bb05-03b097483dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-c41f949f-b16a-4466-9ed6-61bb89a5794f,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-baf965e8-d38d-4a1d-86d4-c94a1a389e74,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-30922dc3-58a2-4e89-a559-56fbe5428f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-7e3cbe4b-8897-4293-bc8a-3cab9c8da99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-01a3fefa-187d-4465-91a1-3e3cd8cc246c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575928822-172.17.0.9-1597112940136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46679,DS-d2b0f7ee-a00a-4c78-b136-2a75a3ed231f,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-e78fa1ed-91f7-400d-9652-a3ce189e9fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44946,DS-60d85be3-e4fd-4456-bb05-03b097483dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-c41f949f-b16a-4466-9ed6-61bb89a5794f,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-baf965e8-d38d-4a1d-86d4-c94a1a389e74,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-30922dc3-58a2-4e89-a559-56fbe5428f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-7e3cbe4b-8897-4293-bc8a-3cab9c8da99d,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-01a3fefa-187d-4465-91a1-3e3cd8cc246c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.threads
component: hdfs:DataNode
v1: -1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437666840-172.17.0.9-1597112979829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34523,DS-65a9a2b6-923e-4a32-8e6e-9b815e155ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-280471af-b2b7-4bcc-98d7-1923efd39071,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-5b94b021-840b-4dd9-b74f-0c49beae26f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-6a43e1da-765d-4703-aa3a-22e9cc6f2fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-ca34f20d-3bf6-4880-a78a-6b59ee2779a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-9d020155-51c4-4e34-921d-8b08aab39212,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-f8e1a3f3-d513-48ce-a3db-33de53e2a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-2866d4f3-70f0-4620-9f45-2bfd8e725e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437666840-172.17.0.9-1597112979829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34523,DS-65a9a2b6-923e-4a32-8e6e-9b815e155ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-280471af-b2b7-4bcc-98d7-1923efd39071,DISK], DatanodeInfoWithStorage[127.0.0.1:39067,DS-5b94b021-840b-4dd9-b74f-0c49beae26f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-6a43e1da-765d-4703-aa3a-22e9cc6f2fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-ca34f20d-3bf6-4880-a78a-6b59ee2779a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-9d020155-51c4-4e34-921d-8b08aab39212,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-f8e1a3f3-d513-48ce-a3db-33de53e2a74a,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-2866d4f3-70f0-4620-9f45-2bfd8e725e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5250
