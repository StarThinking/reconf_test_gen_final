reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1455085542-172.17.0.18-1597126507920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39946,DS-a8bf41ec-2bb7-4982-983e-e84ef877b9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-478f71ff-607f-48e3-8dc3-4c16b95e4819,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-b935dfc8-f91d-42ac-8a82-8a645d0ee0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-b0703993-72bc-4d88-b07f-f9beefa17103,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-cad32cf9-8aba-43b2-a557-712859eb4666,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-eb40011e-15d9-44ae-a062-da1a2e7f4f89,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-8f41ef94-e471-4b47-a3b2-85a19873760a,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-be35fc19-08c5-4571-a188-fe7a621dda03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1455085542-172.17.0.18-1597126507920:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39946,DS-a8bf41ec-2bb7-4982-983e-e84ef877b9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-478f71ff-607f-48e3-8dc3-4c16b95e4819,DISK], DatanodeInfoWithStorage[127.0.0.1:42671,DS-b935dfc8-f91d-42ac-8a82-8a645d0ee0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-b0703993-72bc-4d88-b07f-f9beefa17103,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-cad32cf9-8aba-43b2-a557-712859eb4666,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-eb40011e-15d9-44ae-a062-da1a2e7f4f89,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-8f41ef94-e471-4b47-a3b2-85a19873760a,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-be35fc19-08c5-4571-a188-fe7a621dda03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782458798-172.17.0.18-1597127372667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-bee95733-0266-49d8-a191-a1fbb10b6b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-e738deb3-48e9-4ac7-826d-fb5f5edb61d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-fcf573bd-fd42-4582-a25f-faa1168f9e98,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-b676b421-cf43-4f5a-b526-526fffa9e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-2dd61c41-9b06-4d90-99c7-588d61e9d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-ff994045-4ce0-4e8b-bcc4-9e6998443cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-0e234ebe-839c-42a4-8a82-ce27cf8ecaea,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-3a6ba940-ce30-4b18-84a1-e3aec68a49cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782458798-172.17.0.18-1597127372667:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-bee95733-0266-49d8-a191-a1fbb10b6b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-e738deb3-48e9-4ac7-826d-fb5f5edb61d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-fcf573bd-fd42-4582-a25f-faa1168f9e98,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-b676b421-cf43-4f5a-b526-526fffa9e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-2dd61c41-9b06-4d90-99c7-588d61e9d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-ff994045-4ce0-4e8b-bcc4-9e6998443cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-0e234ebe-839c-42a4-8a82-ce27cf8ecaea,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-3a6ba940-ce30-4b18-84a1-e3aec68a49cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30916495-172.17.0.18-1597127529205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-8970b55b-6d9e-40aa-a251-7946b235b37f,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-64cdfbfd-62f7-4f8e-8d06-ab42b4d4d91e,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-928a326e-0b10-4c24-84b9-2a5d64e83106,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-986b9cf0-3f09-4235-8a06-701f5ce005c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-7553494f-e8de-40de-b6da-2278b1174a47,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-576a4ffe-7532-4067-a1dc-6cdecf885de5,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-a5619d9c-3818-43e3-a64a-c1c0b5be9250,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-f39e0b8c-637c-490a-9412-5f1a1ad7d73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30916495-172.17.0.18-1597127529205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44384,DS-8970b55b-6d9e-40aa-a251-7946b235b37f,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-64cdfbfd-62f7-4f8e-8d06-ab42b4d4d91e,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-928a326e-0b10-4c24-84b9-2a5d64e83106,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-986b9cf0-3f09-4235-8a06-701f5ce005c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-7553494f-e8de-40de-b6da-2278b1174a47,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-576a4ffe-7532-4067-a1dc-6cdecf885de5,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-a5619d9c-3818-43e3-a64a-c1c0b5be9250,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-f39e0b8c-637c-490a-9412-5f1a1ad7d73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066446376-172.17.0.18-1597127748171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38581,DS-84ac032d-4d62-4ad8-9fb5-f7948b5043e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-e497e196-b9c7-447a-856c-27325ef6395c,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-b949173d-c653-453b-b6e8-5ab1d00d71d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-9a756722-b2f0-4aeb-83f5-fe35e17ef518,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-8a30bca4-b2e6-4946-afd8-b49428a26870,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-e6cb095d-0437-4ac4-8873-9ea2ae7c5394,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-427d8577-8ecd-4843-a9de-42be698eae14,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-a8b1527b-2503-4cb8-b6c9-82264aaaa154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066446376-172.17.0.18-1597127748171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38581,DS-84ac032d-4d62-4ad8-9fb5-f7948b5043e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-e497e196-b9c7-447a-856c-27325ef6395c,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-b949173d-c653-453b-b6e8-5ab1d00d71d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-9a756722-b2f0-4aeb-83f5-fe35e17ef518,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-8a30bca4-b2e6-4946-afd8-b49428a26870,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-e6cb095d-0437-4ac4-8873-9ea2ae7c5394,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-427d8577-8ecd-4843-a9de-42be698eae14,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-a8b1527b-2503-4cb8-b6c9-82264aaaa154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525003878-172.17.0.18-1597127820976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-8a68f41e-be3b-4cfb-8e1a-7143c555b930,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-af0f9124-4592-413f-a753-37488fb22674,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-14c54d1b-51cf-4aa3-b75e-8b8c863b6bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-353c5204-eae3-4249-b25c-e5c9836a2c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-5b879573-9253-416d-b86e-0b7b72e34fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-d5c8210c-4af9-47b6-9b64-a3a7bcce6750,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-4290422d-77e9-4c3d-81f5-176754287e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-022100c6-f728-4759-b962-c611047eb706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1525003878-172.17.0.18-1597127820976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45383,DS-8a68f41e-be3b-4cfb-8e1a-7143c555b930,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-af0f9124-4592-413f-a753-37488fb22674,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-14c54d1b-51cf-4aa3-b75e-8b8c863b6bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-353c5204-eae3-4249-b25c-e5c9836a2c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-5b879573-9253-416d-b86e-0b7b72e34fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-d5c8210c-4af9-47b6-9b64-a3a7bcce6750,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-4290422d-77e9-4c3d-81f5-176754287e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-022100c6-f728-4759-b962-c611047eb706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335073517-172.17.0.18-1597128129961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-f839028f-d7bb-44c6-9a67-3880b227dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-5b352948-0ba7-4fc1-837f-3a17c923efa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-cd7b9228-21a3-4f7f-893b-972223e070e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-20b4913a-f890-41c5-958e-0ec9fabe1016,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-4515a176-d8bf-44da-8578-902c840ce0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-2fa8f486-f751-4de4-a919-c2d97639f07c,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-3d6f9bbe-7a4f-44ce-8d7c-f0311d6fb8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-632909b4-5ede-4fee-bd86-ba91a60160e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335073517-172.17.0.18-1597128129961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46051,DS-f839028f-d7bb-44c6-9a67-3880b227dcac,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-5b352948-0ba7-4fc1-837f-3a17c923efa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-cd7b9228-21a3-4f7f-893b-972223e070e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-20b4913a-f890-41c5-958e-0ec9fabe1016,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-4515a176-d8bf-44da-8578-902c840ce0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-2fa8f486-f751-4de4-a919-c2d97639f07c,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-3d6f9bbe-7a4f-44ce-8d7c-f0311d6fb8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-632909b4-5ede-4fee-bd86-ba91a60160e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266767275-172.17.0.18-1597128403094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42965,DS-5431a460-6de7-4949-a6a6-3f8507c5c478,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-23620c07-7186-46e0-81a6-e6f5d9a2ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-01dc5f9c-43a1-47f6-9409-c6c47f70accc,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-5ea4fd87-9bf9-454f-a6e0-b6bf0c74ff23,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-621916d1-4a54-4f96-9d8b-37f6f88112cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-447c7c95-caab-49c9-a524-89671a035d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-bbbfc28f-0766-42c5-bf9c-01e4bb70613b,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-7bfe0909-34e4-42a5-a3d7-006af00870b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266767275-172.17.0.18-1597128403094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42965,DS-5431a460-6de7-4949-a6a6-3f8507c5c478,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-23620c07-7186-46e0-81a6-e6f5d9a2ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-01dc5f9c-43a1-47f6-9409-c6c47f70accc,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-5ea4fd87-9bf9-454f-a6e0-b6bf0c74ff23,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-621916d1-4a54-4f96-9d8b-37f6f88112cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-447c7c95-caab-49c9-a524-89671a035d93,DISK], DatanodeInfoWithStorage[127.0.0.1:45470,DS-bbbfc28f-0766-42c5-bf9c-01e4bb70613b,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-7bfe0909-34e4-42a5-a3d7-006af00870b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542161048-172.17.0.18-1597128702311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-b364b963-7c07-40d0-8942-54013fee02c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-f9321cb0-5155-4da8-a29a-32cd960c8363,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-864281a6-a051-459e-a00b-4332992827f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-96cc95ff-adb4-46ff-a1e8-8faa34365d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b7322109-d364-46d0-9f2b-10936b1ff616,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-35dada9c-f92e-4c58-ad80-d894ccd243f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-5bd6ba28-c975-4b36-bc34-573fec45e3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-adc35bb3-0640-4b02-8506-013ecd8d1ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1542161048-172.17.0.18-1597128702311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-b364b963-7c07-40d0-8942-54013fee02c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-f9321cb0-5155-4da8-a29a-32cd960c8363,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-864281a6-a051-459e-a00b-4332992827f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-96cc95ff-adb4-46ff-a1e8-8faa34365d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-b7322109-d364-46d0-9f2b-10936b1ff616,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-35dada9c-f92e-4c58-ad80-d894ccd243f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-5bd6ba28-c975-4b36-bc34-573fec45e3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-adc35bb3-0640-4b02-8506-013ecd8d1ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401568854-172.17.0.18-1597129289348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45350,DS-8fb24aca-235c-44f3-890a-fa969841efb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-6288af81-cc7b-4872-b7e5-f569c53be7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-d4fb8aa9-701e-4e63-8f30-c26fdf4145c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-40b6c721-b853-4511-bac4-b1b305802087,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-ed1b8622-1d25-4b58-8225-98637f237034,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-c6060e41-145e-4148-9fa4-84b5b79b49d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-c0c4d7e9-091e-40a8-b6af-1b6910148573,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-915a1529-dcc3-40ad-95fd-539feb5572a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401568854-172.17.0.18-1597129289348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45350,DS-8fb24aca-235c-44f3-890a-fa969841efb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-6288af81-cc7b-4872-b7e5-f569c53be7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-d4fb8aa9-701e-4e63-8f30-c26fdf4145c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-40b6c721-b853-4511-bac4-b1b305802087,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-ed1b8622-1d25-4b58-8225-98637f237034,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-c6060e41-145e-4148-9fa4-84b5b79b49d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-c0c4d7e9-091e-40a8-b6af-1b6910148573,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-915a1529-dcc3-40ad-95fd-539feb5572a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244535905-172.17.0.18-1597130957353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-624dc920-b0be-42f4-9fc4-6c7aa8849db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-1eb27ace-fff9-45c0-a9ab-4d15cb5fb37a,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-96938dcb-1a56-428e-9be1-294ece74290c,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-7d46c22c-dd30-43c2-9625-a6dcfcecf97b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-3ba28abf-d38e-4151-8f1a-b00a20f6795f,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-5eb3a690-f55f-4230-932e-d24a38709f03,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-7d8e6c60-cebb-47b4-97c1-d53e9ae72749,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-781fcbcf-8253-40f8-a6ee-2fda3e9f2f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244535905-172.17.0.18-1597130957353:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46598,DS-624dc920-b0be-42f4-9fc4-6c7aa8849db7,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-1eb27ace-fff9-45c0-a9ab-4d15cb5fb37a,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-96938dcb-1a56-428e-9be1-294ece74290c,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-7d46c22c-dd30-43c2-9625-a6dcfcecf97b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-3ba28abf-d38e-4151-8f1a-b00a20f6795f,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-5eb3a690-f55f-4230-932e-d24a38709f03,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-7d8e6c60-cebb-47b4-97c1-d53e9ae72749,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-781fcbcf-8253-40f8-a6ee-2fda3e9f2f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138990914-172.17.0.18-1597130987912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-a006d992-c27c-4427-929d-51a057cfe867,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-e9687a34-0b23-425e-b31e-e9c8a93c5b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-2309a4c6-538a-4c5f-bab8-d43b35cbb431,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-c1ce43c6-586c-4029-af82-41be9687a339,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-5ab1283c-a5ac-40ac-8adb-4685b861c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-8e14c2f7-15a1-4722-8f6d-7bb76f72f433,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-4188900d-2d5c-4096-8533-5ef8eb205ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-51023313-ade9-4297-8b68-dfb5bb34ed18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138990914-172.17.0.18-1597130987912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-a006d992-c27c-4427-929d-51a057cfe867,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-e9687a34-0b23-425e-b31e-e9c8a93c5b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34465,DS-2309a4c6-538a-4c5f-bab8-d43b35cbb431,DISK], DatanodeInfoWithStorage[127.0.0.1:35442,DS-c1ce43c6-586c-4029-af82-41be9687a339,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-5ab1283c-a5ac-40ac-8adb-4685b861c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41280,DS-8e14c2f7-15a1-4722-8f6d-7bb76f72f433,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-4188900d-2d5c-4096-8533-5ef8eb205ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-51023313-ade9-4297-8b68-dfb5bb34ed18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709508847-172.17.0.18-1597131024187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-c9c82875-a0d5-43e4-98bd-20cb0b4f7251,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-735b351c-3286-4bce-910e-cdf2a00b5417,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-e526e5d4-c453-49aa-845c-f5cedecddbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-9c5bedc2-229d-41ec-a988-d5b745092ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-b2461da1-62d3-48ae-a92d-e0510fda53e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-3a472dc8-1809-469e-bd98-4c3dbcce88ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-272e2a3f-65ff-4f83-92d3-87baa78575ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-65046c7c-1289-4ddb-ac6d-351db967c340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-709508847-172.17.0.18-1597131024187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42527,DS-c9c82875-a0d5-43e4-98bd-20cb0b4f7251,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-735b351c-3286-4bce-910e-cdf2a00b5417,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-e526e5d4-c453-49aa-845c-f5cedecddbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-9c5bedc2-229d-41ec-a988-d5b745092ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-b2461da1-62d3-48ae-a92d-e0510fda53e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-3a472dc8-1809-469e-bd98-4c3dbcce88ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-272e2a3f-65ff-4f83-92d3-87baa78575ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-65046c7c-1289-4ddb-ac6d-351db967c340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320191051-172.17.0.18-1597131321367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36357,DS-a5ae98eb-4d56-421a-b022-f2e3c2c0b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-fc9980a6-26de-4ecf-a94c-64e250a2ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-99dd9226-157e-4150-9588-c30e49e00f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-c91d1aee-4b3a-4842-9bcb-23b236570f52,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-c7aa633d-b2e3-4f72-9d00-d4d3c1bd0c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-1d89df61-7ac9-498a-b465-56c1eb3311c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-414fc72a-d356-40f3-bdec-c196638b5021,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-e104b368-313f-494b-a7e9-0a0590450f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-320191051-172.17.0.18-1597131321367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36357,DS-a5ae98eb-4d56-421a-b022-f2e3c2c0b2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-fc9980a6-26de-4ecf-a94c-64e250a2ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-99dd9226-157e-4150-9588-c30e49e00f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-c91d1aee-4b3a-4842-9bcb-23b236570f52,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-c7aa633d-b2e3-4f72-9d00-d4d3c1bd0c88,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-1d89df61-7ac9-498a-b465-56c1eb3311c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-414fc72a-d356-40f3-bdec-c196638b5021,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-e104b368-313f-494b-a7e9-0a0590450f9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722153736-172.17.0.18-1597131662364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41323,DS-1835dbee-d227-423f-9749-3efe7f30d5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-9d43dcae-2335-48b3-869f-b790f670b7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-f0c55498-1edc-4a97-b0bc-f22aa90f6143,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-d779cc83-c499-4433-9730-45cfb8d896f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-69a8b7ef-f564-4394-81b3-998f24bba240,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-00935514-234d-40af-8bdc-9aeead76a0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-9d93c251-f5b0-4749-b7f0-9327105d4f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-469362d1-0a44-4728-bf53-c43ebfcabd55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722153736-172.17.0.18-1597131662364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41323,DS-1835dbee-d227-423f-9749-3efe7f30d5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-9d43dcae-2335-48b3-869f-b790f670b7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-f0c55498-1edc-4a97-b0bc-f22aa90f6143,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-d779cc83-c499-4433-9730-45cfb8d896f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-69a8b7ef-f564-4394-81b3-998f24bba240,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-00935514-234d-40af-8bdc-9aeead76a0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45879,DS-9d93c251-f5b0-4749-b7f0-9327105d4f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-469362d1-0a44-4728-bf53-c43ebfcabd55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579343863-172.17.0.18-1597131705343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-21c92d7a-b559-4eb1-b8e3-ec7633873188,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-23d7a1fa-e64a-4917-8f97-50de3cf96b29,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-f06a06c5-eb41-4413-b546-40901608cbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-db0fbfee-5d10-4eb9-86dd-4f06bbb80f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-029e0aff-1b65-4a20-99a0-e00549e9db30,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-25c6a3c9-5bad-4a5e-923d-4bdd70069b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-74a94b28-0227-4c7d-90c5-a0667aeb793b,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-3b892900-4da1-43c3-b47f-ff78f9b25aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1579343863-172.17.0.18-1597131705343:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45407,DS-21c92d7a-b559-4eb1-b8e3-ec7633873188,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-23d7a1fa-e64a-4917-8f97-50de3cf96b29,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-f06a06c5-eb41-4413-b546-40901608cbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-db0fbfee-5d10-4eb9-86dd-4f06bbb80f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-029e0aff-1b65-4a20-99a0-e00549e9db30,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-25c6a3c9-5bad-4a5e-923d-4bdd70069b33,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-74a94b28-0227-4c7d-90c5-a0667aeb793b,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-3b892900-4da1-43c3-b47f-ff78f9b25aea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746184062-172.17.0.18-1597131766772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40814,DS-73f13eee-72d1-4eb2-bd85-db9570c077a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-cf7569f7-255b-4398-84ca-2b12c89c6655,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-3dbbe006-b0e9-41ba-a2d3-fe0c27bcde23,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-05d6d021-0429-4e4e-b69c-906974bc7662,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-0501b787-691e-4e95-a3ed-3371d5002f61,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-5746e36d-3e17-4d8d-904a-85e13e3ab0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-2cba51be-eb03-4e82-9213-a015a263056d,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-16cf1165-de2c-4832-8ef8-866bd8bf70ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746184062-172.17.0.18-1597131766772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40814,DS-73f13eee-72d1-4eb2-bd85-db9570c077a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-cf7569f7-255b-4398-84ca-2b12c89c6655,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-3dbbe006-b0e9-41ba-a2d3-fe0c27bcde23,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-05d6d021-0429-4e4e-b69c-906974bc7662,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-0501b787-691e-4e95-a3ed-3371d5002f61,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-5746e36d-3e17-4d8d-904a-85e13e3ab0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-2cba51be-eb03-4e82-9213-a015a263056d,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-16cf1165-de2c-4832-8ef8-866bd8bf70ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.balance.max.concurrent.moves
component: hdfs:DataNode
v1: 300
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456025803-172.17.0.18-1597131916766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36008,DS-4045fd1e-3de8-4935-a4ba-c71ecc7dcc01,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-8508db22-b32e-452d-b806-489169d7564e,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-177e2309-3f11-4c10-b7c9-9240f64784a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-00565de7-8729-4ee4-8568-7bef608f733f,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-ea230028-c7e0-4522-a06f-871ba47d850f,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-fe799284-90ba-4d4f-8f58-7e2947a0fdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-cc4d687a-69f8-4490-aecd-21ed246cc881,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-034c2d19-ac2b-44eb-a226-f16c7baa3482,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456025803-172.17.0.18-1597131916766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36008,DS-4045fd1e-3de8-4935-a4ba-c71ecc7dcc01,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-8508db22-b32e-452d-b806-489169d7564e,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-177e2309-3f11-4c10-b7c9-9240f64784a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-00565de7-8729-4ee4-8568-7bef608f733f,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-ea230028-c7e0-4522-a06f-871ba47d850f,DISK], DatanodeInfoWithStorage[127.0.0.1:37272,DS-fe799284-90ba-4d4f-8f58-7e2947a0fdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-cc4d687a-69f8-4490-aecd-21ed246cc881,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-034c2d19-ac2b-44eb-a226-f16c7baa3482,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5626
