reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443630341-172.17.0.11-1597188715595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-02bfcd16-00c4-4a08-8f1a-01d7b3d6012c,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-f6afc40e-c3b2-447b-90c6-53b692ceee54,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-1218d038-0855-45e4-842b-8a65bfcf7af9,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-638ebe01-6551-4840-a8db-cd7c86dc062f,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-50d4ecea-20b3-4383-a60e-b180be4d0c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-972b7957-1fa4-47ba-b8fd-c843d7112ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-1f6f725d-e713-4a63-ba05-a6fe070e79c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-f1642e8b-0b00-4c39-ab1b-9d7831aa3684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-443630341-172.17.0.11-1597188715595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41543,DS-02bfcd16-00c4-4a08-8f1a-01d7b3d6012c,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-f6afc40e-c3b2-447b-90c6-53b692ceee54,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-1218d038-0855-45e4-842b-8a65bfcf7af9,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-638ebe01-6551-4840-a8db-cd7c86dc062f,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-50d4ecea-20b3-4383-a60e-b180be4d0c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37075,DS-972b7957-1fa4-47ba-b8fd-c843d7112ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-1f6f725d-e713-4a63-ba05-a6fe070e79c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-f1642e8b-0b00-4c39-ab1b-9d7831aa3684,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354973957-172.17.0.11-1597189183741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37362,DS-eee4d2c1-f5aa-4527-a041-6782f250b537,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-d9a15f54-3601-49d3-b323-b7b399b7688e,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-40cff410-0bdd-4f72-9dc9-aa144d3ed352,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-70c24c6c-66d5-494a-9f0b-48df5a290439,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-d42ce299-f971-4ed3-8bdd-3d73e3e3c128,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-2e271d84-170d-4503-838d-30d015594634,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-4022cc4a-ec37-463e-b478-bdb8e51ca78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-d3acf83d-8df8-402e-9cf9-171d82f00ba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1354973957-172.17.0.11-1597189183741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37362,DS-eee4d2c1-f5aa-4527-a041-6782f250b537,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-d9a15f54-3601-49d3-b323-b7b399b7688e,DISK], DatanodeInfoWithStorage[127.0.0.1:37090,DS-40cff410-0bdd-4f72-9dc9-aa144d3ed352,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-70c24c6c-66d5-494a-9f0b-48df5a290439,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-d42ce299-f971-4ed3-8bdd-3d73e3e3c128,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-2e271d84-170d-4503-838d-30d015594634,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-4022cc4a-ec37-463e-b478-bdb8e51ca78c,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-d3acf83d-8df8-402e-9cf9-171d82f00ba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102767277-172.17.0.11-1597189838165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-ffdc01dd-442b-4522-a4b3-376f4e30f25b,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-3a76ae0e-ebb8-416c-a9fd-145aef2ee0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-bcf33357-796c-44b5-9e71-d7ddeb10797c,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-6938170b-d825-49ae-8a88-b7473d97dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-93f2bc8b-0f35-463f-a29b-9effa5109d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-38b168dd-ea12-4f8d-ad0c-1218f587025b,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-81dbedca-f989-43bb-a1f6-63cf6248e1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-7a727685-b841-4564-97ca-065ea4996992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102767277-172.17.0.11-1597189838165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-ffdc01dd-442b-4522-a4b3-376f4e30f25b,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-3a76ae0e-ebb8-416c-a9fd-145aef2ee0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-bcf33357-796c-44b5-9e71-d7ddeb10797c,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-6938170b-d825-49ae-8a88-b7473d97dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-93f2bc8b-0f35-463f-a29b-9effa5109d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-38b168dd-ea12-4f8d-ad0c-1218f587025b,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-81dbedca-f989-43bb-a1f6-63cf6248e1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-7a727685-b841-4564-97ca-065ea4996992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638023280-172.17.0.11-1597189913772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-a04a82b7-9f7a-4351-8ef6-5d4f4af31865,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-7d6ae755-54bc-48d7-8e6b-3b79dee547e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-6a41fdce-91fa-4338-a344-d390382ca658,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-230650f4-0710-49da-a42d-b241a6a73d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-e75c08e8-6f7a-4ef4-91b5-07c72ff8f8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-954b3d51-ea3e-4155-b0b1-8efa4c423aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-315478ca-910b-4eb5-89a0-e50e9751c6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-3a284d57-4be3-4561-bc98-4dd642e0be1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1638023280-172.17.0.11-1597189913772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-a04a82b7-9f7a-4351-8ef6-5d4f4af31865,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-7d6ae755-54bc-48d7-8e6b-3b79dee547e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45468,DS-6a41fdce-91fa-4338-a344-d390382ca658,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-230650f4-0710-49da-a42d-b241a6a73d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-e75c08e8-6f7a-4ef4-91b5-07c72ff8f8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-954b3d51-ea3e-4155-b0b1-8efa4c423aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-315478ca-910b-4eb5-89a0-e50e9751c6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-3a284d57-4be3-4561-bc98-4dd642e0be1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565619080-172.17.0.11-1597190410380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43987,DS-d949fd75-6e33-469f-8f3a-c4176bc4a68b,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-77d8162c-7c41-4416-9b69-01e5a74d8664,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-e0f53e20-94de-4a23-9637-96da85ac5449,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-1bc43f38-7ab4-46b9-909d-10d0e5574c18,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-2e70ceba-7ded-4d2e-8d90-acea0cc26588,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-f9074c7a-fbe7-4211-a8d1-a46a42957d89,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-065c5ce9-4113-4279-89d5-03ae5e217fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-4e9532a3-0b31-4904-b59b-c041189b8a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565619080-172.17.0.11-1597190410380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43987,DS-d949fd75-6e33-469f-8f3a-c4176bc4a68b,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-77d8162c-7c41-4416-9b69-01e5a74d8664,DISK], DatanodeInfoWithStorage[127.0.0.1:34590,DS-e0f53e20-94de-4a23-9637-96da85ac5449,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-1bc43f38-7ab4-46b9-909d-10d0e5574c18,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-2e70ceba-7ded-4d2e-8d90-acea0cc26588,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-f9074c7a-fbe7-4211-a8d1-a46a42957d89,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-065c5ce9-4113-4279-89d5-03ae5e217fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-4e9532a3-0b31-4904-b59b-c041189b8a11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871872104-172.17.0.11-1597190835580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41909,DS-6460134b-8cda-4ba3-ad05-0ab92d5afc28,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-9ff44e7d-a669-4989-b565-e8b2e0c5617c,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-8f32f2f7-578a-454e-b31e-746ab2db6dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-211e6e97-e465-4110-8fb0-9b6e931a0b45,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-89d5b985-e93c-4da8-82a9-bc266c2ba18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-acff6456-8cf2-4343-b7c6-b2d7b01436db,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-43498632-5dbf-46b4-ac4e-5c71db28cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-41fe75c6-c5d3-44d2-9a51-bb77f01f1999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871872104-172.17.0.11-1597190835580:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41909,DS-6460134b-8cda-4ba3-ad05-0ab92d5afc28,DISK], DatanodeInfoWithStorage[127.0.0.1:41830,DS-9ff44e7d-a669-4989-b565-e8b2e0c5617c,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-8f32f2f7-578a-454e-b31e-746ab2db6dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-211e6e97-e465-4110-8fb0-9b6e931a0b45,DISK], DatanodeInfoWithStorage[127.0.0.1:43437,DS-89d5b985-e93c-4da8-82a9-bc266c2ba18e,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-acff6456-8cf2-4343-b7c6-b2d7b01436db,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-43498632-5dbf-46b4-ac4e-5c71db28cacd,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-41fe75c6-c5d3-44d2-9a51-bb77f01f1999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888195146-172.17.0.11-1597192432758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-22eebd9a-7f64-4bf2-ad50-236b8ce6768b,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-1511b76c-aad2-4b5d-8292-d4b9f02542cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-dcded4d5-e62b-485f-adbc-985177073b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-5b94101c-0dfb-417b-ab14-dc1861ea5053,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4d3ac5ed-9b62-4e94-96ef-0f543262d8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-63cf5196-1cd4-43c4-b71c-82e0968fc0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-1db18e16-ec74-4ad0-aa34-94624a5986c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-e771ea35-efb1-4bb3-9526-6157505081cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888195146-172.17.0.11-1597192432758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37357,DS-22eebd9a-7f64-4bf2-ad50-236b8ce6768b,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-1511b76c-aad2-4b5d-8292-d4b9f02542cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-dcded4d5-e62b-485f-adbc-985177073b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-5b94101c-0dfb-417b-ab14-dc1861ea5053,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4d3ac5ed-9b62-4e94-96ef-0f543262d8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-63cf5196-1cd4-43c4-b71c-82e0968fc0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-1db18e16-ec74-4ad0-aa34-94624a5986c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-e771ea35-efb1-4bb3-9526-6157505081cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811982275-172.17.0.11-1597192577259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-e513cc12-32a2-4326-9404-a403be2bbfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-5d70c98b-0f97-4c18-b53e-a7206683e30b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-7f16066d-7c3a-4fe0-af22-c79f52b1c775,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-5c7a4987-07f6-485e-b786-67b6aab0312e,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-75a09629-457f-49f4-a43a-357c6a17c427,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-05bd6372-a8b7-4aa0-8e98-e0f899dc5721,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-4eee1bdd-4b14-4a34-9458-7be3b24671ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-b67ca64b-bc47-43df-ad92-5203585a3eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811982275-172.17.0.11-1597192577259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36155,DS-e513cc12-32a2-4326-9404-a403be2bbfc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-5d70c98b-0f97-4c18-b53e-a7206683e30b,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-7f16066d-7c3a-4fe0-af22-c79f52b1c775,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-5c7a4987-07f6-485e-b786-67b6aab0312e,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-75a09629-457f-49f4-a43a-357c6a17c427,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-05bd6372-a8b7-4aa0-8e98-e0f899dc5721,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-4eee1bdd-4b14-4a34-9458-7be3b24671ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-b67ca64b-bc47-43df-ad92-5203585a3eef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345398077-172.17.0.11-1597193046872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45036,DS-0c525267-219d-4b61-919f-81d91671e6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-96178283-bb89-4336-8bd8-616880d010b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-656f2542-be65-497a-adc0-fb45f1fa25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-f7be44fa-f261-4486-92aa-9b919129e36b,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-cd6d46ea-82e9-4902-a0a7-5357e7c4e533,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-a528564b-7099-4a02-9435-4555a5b53a82,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-89e2e4b9-d36d-40d9-b7cc-550897ea8fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-3b3eeb17-b156-498f-8e78-74269ef90a54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345398077-172.17.0.11-1597193046872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45036,DS-0c525267-219d-4b61-919f-81d91671e6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-96178283-bb89-4336-8bd8-616880d010b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-656f2542-be65-497a-adc0-fb45f1fa25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-f7be44fa-f261-4486-92aa-9b919129e36b,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-cd6d46ea-82e9-4902-a0a7-5357e7c4e533,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-a528564b-7099-4a02-9435-4555a5b53a82,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-89e2e4b9-d36d-40d9-b7cc-550897ea8fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-3b3eeb17-b156-498f-8e78-74269ef90a54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148667985-172.17.0.11-1597193122492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-e9ab8531-9b11-4b67-8727-bd24045b9979,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-0e14eb00-b172-4aea-bec6-63a8cd90037e,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-bef6a694-87c5-4100-acf2-3d326f112b76,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-51e2cd03-78e4-45bd-9fd3-697cc71740fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-3b00367a-0e4e-4dd4-8b46-a5b198086186,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-4250cbf8-63e8-47e8-8c96-e93afb63f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-d26a7dfc-254a-41fc-918a-2001f4483324,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-7679461c-4a4d-4846-9d7e-ed58c41dd833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148667985-172.17.0.11-1597193122492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39195,DS-e9ab8531-9b11-4b67-8727-bd24045b9979,DISK], DatanodeInfoWithStorage[127.0.0.1:36443,DS-0e14eb00-b172-4aea-bec6-63a8cd90037e,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-bef6a694-87c5-4100-acf2-3d326f112b76,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-51e2cd03-78e4-45bd-9fd3-697cc71740fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-3b00367a-0e4e-4dd4-8b46-a5b198086186,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-4250cbf8-63e8-47e8-8c96-e93afb63f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-d26a7dfc-254a-41fc-918a-2001f4483324,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-7679461c-4a4d-4846-9d7e-ed58c41dd833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951755800-172.17.0.11-1597193638066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36689,DS-ff7ac09f-af46-48f9-9e61-aee619d91357,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-10e32f6b-53c2-4502-9028-dd9cd8f68eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-d99ac149-0a39-40fa-b3a2-605930cf7b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-2b83b590-f902-4b3f-a679-06cde12d029f,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-29c4452f-1a8e-42da-8044-475dfcc0d18d,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-e0e7fb38-0921-4b0d-8ff1-047f19efd329,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-8df26425-7050-45f0-a302-476cf8826c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-1b884c96-7e6d-4105-b626-49666d4faf3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951755800-172.17.0.11-1597193638066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36689,DS-ff7ac09f-af46-48f9-9e61-aee619d91357,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-10e32f6b-53c2-4502-9028-dd9cd8f68eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-d99ac149-0a39-40fa-b3a2-605930cf7b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-2b83b590-f902-4b3f-a679-06cde12d029f,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-29c4452f-1a8e-42da-8044-475dfcc0d18d,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-e0e7fb38-0921-4b0d-8ff1-047f19efd329,DISK], DatanodeInfoWithStorage[127.0.0.1:45205,DS-8df26425-7050-45f0-a302-476cf8826c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-1b884c96-7e6d-4105-b626-49666d4faf3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.write.timeout
component: hdfs:DataNode
v1: 480000
v2: 960000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016082083-172.17.0.11-1597193910776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44108,DS-c1049630-67da-4afd-8f83-202dc6ace50c,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-647fdcba-bad6-43d8-b0e4-843adb0deb20,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-e4f19f15-537f-4d3b-9c29-62f5c0bdd983,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-0c89249c-e82f-4e12-b9f4-a1b39ea2b783,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-6cb87c73-87eb-4d7b-8939-96e3bb619aec,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-11ba35fc-3b9b-4aa7-8959-4e68e96cab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-2a7c431d-cf1e-49a8-bd37-545989229fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-29130f2f-9aaf-4bcf-972c-6ac70702bd66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016082083-172.17.0.11-1597193910776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44108,DS-c1049630-67da-4afd-8f83-202dc6ace50c,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-647fdcba-bad6-43d8-b0e4-843adb0deb20,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-e4f19f15-537f-4d3b-9c29-62f5c0bdd983,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-0c89249c-e82f-4e12-b9f4-a1b39ea2b783,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-6cb87c73-87eb-4d7b-8939-96e3bb619aec,DISK], DatanodeInfoWithStorage[127.0.0.1:46633,DS-11ba35fc-3b9b-4aa7-8959-4e68e96cab2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-2a7c431d-cf1e-49a8-bd37-545989229fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-29130f2f-9aaf-4bcf-972c-6ac70702bd66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5742
