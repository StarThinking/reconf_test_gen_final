reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788818-172.17.0.16-1597085197782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-0e513dd4-99e6-4c3e-b308-641adae5cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-8df45371-49e1-4c47-8e60-2f87a9d38fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-6f9fbdc5-b70c-46ad-9e6c-3896a0fef1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-f70aaf87-9722-44c3-b3e9-499b2fb86b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-9904b18a-c372-4235-9ec8-d124f5def075,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-2fea01bd-9bcd-40fc-9e0b-890d67268449,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-9f2527f7-36e8-4ea0-a6fd-3b899d7248f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-7fe7ec3a-c3cf-4b84-8cfc-3d1b4ab68307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788818-172.17.0.16-1597085197782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-0e513dd4-99e6-4c3e-b308-641adae5cbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-8df45371-49e1-4c47-8e60-2f87a9d38fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-6f9fbdc5-b70c-46ad-9e6c-3896a0fef1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-f70aaf87-9722-44c3-b3e9-499b2fb86b11,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-9904b18a-c372-4235-9ec8-d124f5def075,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-2fea01bd-9bcd-40fc-9e0b-890d67268449,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-9f2527f7-36e8-4ea0-a6fd-3b899d7248f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-7fe7ec3a-c3cf-4b84-8cfc-3d1b4ab68307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919899681-172.17.0.16-1597085833707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45610,DS-3bd0be4c-fd12-47d5-aab0-2fa482c41a49,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-b7c79b38-34a2-4ecf-a11a-b023bc3c9a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-2b4381dc-0ea2-4715-b881-4eaacea9a5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-0a79dbc8-4cc0-48b7-8b04-b87efe16bd65,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-091819d6-4ea3-49dd-b070-2050d598b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-d6710571-20ac-45bf-b559-0dd827e03191,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-1cf02624-1047-48b2-92a3-84b9a8058558,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-54385b6a-11d2-4419-92e9-46b891d5d073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919899681-172.17.0.16-1597085833707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45610,DS-3bd0be4c-fd12-47d5-aab0-2fa482c41a49,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-b7c79b38-34a2-4ecf-a11a-b023bc3c9a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-2b4381dc-0ea2-4715-b881-4eaacea9a5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-0a79dbc8-4cc0-48b7-8b04-b87efe16bd65,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-091819d6-4ea3-49dd-b070-2050d598b82a,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-d6710571-20ac-45bf-b559-0dd827e03191,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-1cf02624-1047-48b2-92a3-84b9a8058558,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-54385b6a-11d2-4419-92e9-46b891d5d073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746502283-172.17.0.16-1597086223396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-bef7ba7a-6eff-4b7f-beb8-6c4ccd4dca77,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-90b2c2ea-d487-4d04-94d6-c6219e3b2f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-6dddd823-4556-4c77-b466-5bdadbb884dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-0b0652bf-fc42-4836-989c-c7f857d754d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-fc1c73fe-585e-4609-bf23-f13db1be75af,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-4c83cd49-5ef9-402c-a890-7223bc3fb894,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-73dd21ec-d194-4d79-ba8a-1271abdbbee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-0326723f-9426-4ff7-b8a1-606d7f8a9ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746502283-172.17.0.16-1597086223396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-bef7ba7a-6eff-4b7f-beb8-6c4ccd4dca77,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-90b2c2ea-d487-4d04-94d6-c6219e3b2f96,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-6dddd823-4556-4c77-b466-5bdadbb884dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-0b0652bf-fc42-4836-989c-c7f857d754d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-fc1c73fe-585e-4609-bf23-f13db1be75af,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-4c83cd49-5ef9-402c-a890-7223bc3fb894,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-73dd21ec-d194-4d79-ba8a-1271abdbbee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41603,DS-0326723f-9426-4ff7-b8a1-606d7f8a9ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321240293-172.17.0.16-1597086509519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44925,DS-eef3e4c7-7d05-47e6-8018-70730788e905,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-a9804fe8-7ab9-46ab-8de4-d7cbb7dd357c,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-b523533b-6d2b-45ca-97e3-23a0f7e6be02,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-0b39c15e-1185-4ab2-b6f6-b45c6ea28b69,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-532e97cd-b158-41ee-b491-f24cb8225eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-c6f41c4d-dea5-4d89-b2e4-408e914a826b,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-db423c30-9994-4a0b-96fe-372cd0b802cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-3621c0d1-951b-45dd-9d19-f356fb2bb7a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-321240293-172.17.0.16-1597086509519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44925,DS-eef3e4c7-7d05-47e6-8018-70730788e905,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-a9804fe8-7ab9-46ab-8de4-d7cbb7dd357c,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-b523533b-6d2b-45ca-97e3-23a0f7e6be02,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-0b39c15e-1185-4ab2-b6f6-b45c6ea28b69,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-532e97cd-b158-41ee-b491-f24cb8225eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-c6f41c4d-dea5-4d89-b2e4-408e914a826b,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-db423c30-9994-4a0b-96fe-372cd0b802cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-3621c0d1-951b-45dd-9d19-f356fb2bb7a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152095479-172.17.0.16-1597086604959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-c575f304-4ccf-4c1f-946c-fe20ade63de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-f4259dc7-261d-44b9-9c0f-98b6f1d5584b,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-c87d39c4-85df-448f-ac3b-01b85ac926fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-84846a12-6017-439e-a95e-d541081df66f,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-1ec4d8d5-c446-4264-8ec1-ecf987437b58,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-aa921cda-8dd7-4151-88b4-2c205e4c07f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-dde4643c-492e-4adb-bd69-44ea6f1805c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-2ea0aa25-0f34-4b07-a35a-bb3557d3094c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152095479-172.17.0.16-1597086604959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40312,DS-c575f304-4ccf-4c1f-946c-fe20ade63de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-f4259dc7-261d-44b9-9c0f-98b6f1d5584b,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-c87d39c4-85df-448f-ac3b-01b85ac926fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-84846a12-6017-439e-a95e-d541081df66f,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-1ec4d8d5-c446-4264-8ec1-ecf987437b58,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-aa921cda-8dd7-4151-88b4-2c205e4c07f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-dde4643c-492e-4adb-bd69-44ea6f1805c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-2ea0aa25-0f34-4b07-a35a-bb3557d3094c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724815364-172.17.0.16-1597087896650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-c9adc5a3-fb24-4b67-b405-7c5e5e0be708,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-cd3b7eaf-d941-4986-a379-5046289fef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-2fe33a43-247c-42ac-a8fc-3b0e491f79a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-8449b824-4d75-4f1b-81b8-381b23a039a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-22810690-0240-4fb6-b67d-ab5d4fa3ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-7fa6cbf9-fc17-42d1-9e12-9c45ba550e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-5914c447-782e-4603-acb8-6b9b0a22eb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-eea0820f-59bb-4d2b-a3b6-35dc1a8fb017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1724815364-172.17.0.16-1597087896650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35249,DS-c9adc5a3-fb24-4b67-b405-7c5e5e0be708,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-cd3b7eaf-d941-4986-a379-5046289fef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-2fe33a43-247c-42ac-a8fc-3b0e491f79a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-8449b824-4d75-4f1b-81b8-381b23a039a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-22810690-0240-4fb6-b67d-ab5d4fa3ef06,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-7fa6cbf9-fc17-42d1-9e12-9c45ba550e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-5914c447-782e-4603-acb8-6b9b0a22eb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-eea0820f-59bb-4d2b-a3b6-35dc1a8fb017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720552828-172.17.0.16-1597088163207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41172,DS-17526a13-027e-4cb6-a187-77808dcc89e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-9810a19c-571b-48cc-ab41-159ab01b7181,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-9174e4c6-bcd5-4f4f-af66-dd2d3c12a3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-dbe97d9c-f9f4-42be-8f43-5c2f59c83659,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-38c33c6f-abb7-4dd5-a09f-a0119959fbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-ad0d96ab-108b-49b8-9bb5-508267d66001,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-e2a77dd3-a7c1-43f3-b0e1-971f56b16c21,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-edf4192c-d148-411f-a5dc-163c8ae4106d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1720552828-172.17.0.16-1597088163207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41172,DS-17526a13-027e-4cb6-a187-77808dcc89e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-9810a19c-571b-48cc-ab41-159ab01b7181,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-9174e4c6-bcd5-4f4f-af66-dd2d3c12a3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-dbe97d9c-f9f4-42be-8f43-5c2f59c83659,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-38c33c6f-abb7-4dd5-a09f-a0119959fbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-ad0d96ab-108b-49b8-9bb5-508267d66001,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-e2a77dd3-a7c1-43f3-b0e1-971f56b16c21,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-edf4192c-d148-411f-a5dc-163c8ae4106d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682710169-172.17.0.16-1597088519113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43794,DS-411405b8-e9c2-4364-a43f-2f2d7393cac2,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-71dad1d2-db76-46a4-9f27-c11ebf1977d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-fa8318fa-5800-4c20-9705-c88b32b2c4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a1f4b33f-70ce-4ee6-9b8e-51f69cd6be95,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-8ffe6a6f-300b-4e27-b67c-e59a3918f225,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-d6c1d7c5-9508-450f-ae4d-91b4beba4bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-4ab376a6-f93b-4d0d-b085-aba85adde94f,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-c7300f13-97eb-4c52-a02f-aeec28fbad07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682710169-172.17.0.16-1597088519113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43794,DS-411405b8-e9c2-4364-a43f-2f2d7393cac2,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-71dad1d2-db76-46a4-9f27-c11ebf1977d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-fa8318fa-5800-4c20-9705-c88b32b2c4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a1f4b33f-70ce-4ee6-9b8e-51f69cd6be95,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-8ffe6a6f-300b-4e27-b67c-e59a3918f225,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-d6c1d7c5-9508-450f-ae4d-91b4beba4bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-4ab376a6-f93b-4d0d-b085-aba85adde94f,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-c7300f13-97eb-4c52-a02f-aeec28fbad07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514569327-172.17.0.16-1597088616995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38056,DS-691fb7be-2b23-411a-9e2a-32c2c06e7c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-dc820c5a-89eb-4622-8b38-37ebe38c3146,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-bb78d374-9d12-4d75-8474-f11a48b7ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-857f95a4-d783-447a-aad9-79a225494d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-62037010-ac3f-4373-b45a-b30789eb05a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-853347f8-afd9-479c-b516-53b1ec2880f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-4508d32d-bf4d-4e8b-b717-e1030977f6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-1d9c32d7-24a4-415d-b0e0-89089ca78430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1514569327-172.17.0.16-1597088616995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38056,DS-691fb7be-2b23-411a-9e2a-32c2c06e7c15,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-dc820c5a-89eb-4622-8b38-37ebe38c3146,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-bb78d374-9d12-4d75-8474-f11a48b7ec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41377,DS-857f95a4-d783-447a-aad9-79a225494d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34903,DS-62037010-ac3f-4373-b45a-b30789eb05a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-853347f8-afd9-479c-b516-53b1ec2880f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-4508d32d-bf4d-4e8b-b717-e1030977f6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-1d9c32d7-24a4-415d-b0e0-89089ca78430,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568408098-172.17.0.16-1597088933685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40211,DS-bd59dbab-f6c4-41de-80a8-4d00deef188a,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-79581e7c-5f12-4bca-95a5-5f5d4e7f98b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-dab41dc5-78a2-4282-9bae-519671ab62bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-1156debc-8881-4079-95f7-b354db1370ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-972c9425-9b63-4712-aea8-747b6d387979,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-30c52cba-a0ef-49bc-9162-546884e7da92,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-4f3120b0-5fe6-4019-9e2e-fb6dce7ae7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-54d9114d-e986-48e8-b240-843e34d5902c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1568408098-172.17.0.16-1597088933685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40211,DS-bd59dbab-f6c4-41de-80a8-4d00deef188a,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-79581e7c-5f12-4bca-95a5-5f5d4e7f98b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-dab41dc5-78a2-4282-9bae-519671ab62bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-1156debc-8881-4079-95f7-b354db1370ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-972c9425-9b63-4712-aea8-747b6d387979,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-30c52cba-a0ef-49bc-9162-546884e7da92,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-4f3120b0-5fe6-4019-9e2e-fb6dce7ae7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-54d9114d-e986-48e8-b240-843e34d5902c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503700758-172.17.0.16-1597088984917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43450,DS-df46ac05-4a6b-4e5c-a473-62880555cffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-825d710d-1bc5-4510-85c8-6b85a99ccb31,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-1db8774a-c214-48b0-9c39-98343c7ec822,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-56da2b64-d3bc-40ff-9832-993b96c20bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-22df318b-4ceb-4651-a780-e9d3a7a3107c,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-ba219d88-e4b9-4777-ab83-10df34023238,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-f63c23ea-be87-43ff-b3e2-b47242e22a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-c3daaece-f1c3-467e-b634-f859546c147d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-503700758-172.17.0.16-1597088984917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43450,DS-df46ac05-4a6b-4e5c-a473-62880555cffe,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-825d710d-1bc5-4510-85c8-6b85a99ccb31,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-1db8774a-c214-48b0-9c39-98343c7ec822,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-56da2b64-d3bc-40ff-9832-993b96c20bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-22df318b-4ceb-4651-a780-e9d3a7a3107c,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-ba219d88-e4b9-4777-ab83-10df34023238,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-f63c23ea-be87-43ff-b3e2-b47242e22a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-c3daaece-f1c3-467e-b634-f859546c147d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119082047-172.17.0.16-1597089109158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-c1848e2c-b936-4d22-90fe-70a6b75d2bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-e580b305-3d2c-410d-a8d2-fc0d2f477b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-1481eb91-db2f-423c-a0ad-c2b5e66e944b,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-1180ebb1-9d1d-4b86-b3dc-cdaf9a029e77,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-9b675209-8a9b-4799-adc6-107e1533ac63,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-add36893-9c1b-4e5a-a33c-a63eafb41eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-32f8600c-76e6-4b93-bd4b-197b66767741,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-f6005efb-7bbf-4995-b76a-b79c03fb72ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119082047-172.17.0.16-1597089109158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33975,DS-c1848e2c-b936-4d22-90fe-70a6b75d2bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-e580b305-3d2c-410d-a8d2-fc0d2f477b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-1481eb91-db2f-423c-a0ad-c2b5e66e944b,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-1180ebb1-9d1d-4b86-b3dc-cdaf9a029e77,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-9b675209-8a9b-4799-adc6-107e1533ac63,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-add36893-9c1b-4e5a-a33c-a63eafb41eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-32f8600c-76e6-4b93-bd4b-197b66767741,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-f6005efb-7bbf-4995-b76a-b79c03fb72ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022987461-172.17.0.16-1597089312697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43482,DS-09d5a499-fb5f-4dfe-a98d-61b308d391d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-b2899d86-0707-409e-b2d3-c9a78c79a3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-266462e8-7103-4e1a-be65-839784931e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-18805b80-dc93-4e8a-9761-b78a1f02c685,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-5fccb344-a325-483c-ab86-39b054da331a,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-da08609d-63db-4828-9ee2-f0455619e916,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-1a504b1b-154a-4efe-a559-f9603309b135,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-47193943-7831-498c-a00a-0fef0611ec8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022987461-172.17.0.16-1597089312697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43482,DS-09d5a499-fb5f-4dfe-a98d-61b308d391d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-b2899d86-0707-409e-b2d3-c9a78c79a3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-266462e8-7103-4e1a-be65-839784931e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-18805b80-dc93-4e8a-9761-b78a1f02c685,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-5fccb344-a325-483c-ab86-39b054da331a,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-da08609d-63db-4828-9ee2-f0455619e916,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-1a504b1b-154a-4efe-a559-f9603309b135,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-47193943-7831-498c-a00a-0fef0611ec8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644067303-172.17.0.16-1597089794482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-dc80af53-3fe7-49ce-beca-6d8f7818def1,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-684ac181-546c-48fa-9656-e02c46797ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-1bf5d886-9293-4579-9ad6-18f518a61037,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-0a3ce824-6b3c-4683-b0dd-8286bfbf183a,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-e2fc0f20-7bd9-4394-9ada-23d1911a5518,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-111e6af3-721d-4f69-99c8-4ebd6daf69bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-ba108111-374d-4931-8a7a-e9db01b1d19b,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-d5faf3c8-624b-47be-b4e6-00c097e6c1c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1644067303-172.17.0.16-1597089794482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-dc80af53-3fe7-49ce-beca-6d8f7818def1,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-684ac181-546c-48fa-9656-e02c46797ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-1bf5d886-9293-4579-9ad6-18f518a61037,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-0a3ce824-6b3c-4683-b0dd-8286bfbf183a,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-e2fc0f20-7bd9-4394-9ada-23d1911a5518,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-111e6af3-721d-4f69-99c8-4ebd6daf69bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-ba108111-374d-4931-8a7a-e9db01b1d19b,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-d5faf3c8-624b-47be-b4e6-00c097e6c1c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.ugi.expire.after.access
component: hdfs:DataNode
v1: 0
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292411188-172.17.0.16-1597091261490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-d287e525-f1d4-4a4a-a4f9-36791a8e74ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-890b2325-51f1-4367-a249-4c89c9698f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-448e2159-d16c-43d6-b404-e741a9aee896,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-73f2719c-2fac-4c51-99ba-aabc33494694,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-1d0a77fa-e08b-4366-ace6-905679c81cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-fd2f26d6-0289-4dd7-94bf-ec66631c0ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-eb827eb1-dd0b-4497-ba47-71bead81ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-52476b42-6d7f-43f3-ac22-12799c3258f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292411188-172.17.0.16-1597091261490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-d287e525-f1d4-4a4a-a4f9-36791a8e74ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-890b2325-51f1-4367-a249-4c89c9698f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-448e2159-d16c-43d6-b404-e741a9aee896,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-73f2719c-2fac-4c51-99ba-aabc33494694,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-1d0a77fa-e08b-4366-ace6-905679c81cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-fd2f26d6-0289-4dd7-94bf-ec66631c0ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-eb827eb1-dd0b-4497-ba47-71bead81ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-52476b42-6d7f-43f3-ac22-12799c3258f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6628
