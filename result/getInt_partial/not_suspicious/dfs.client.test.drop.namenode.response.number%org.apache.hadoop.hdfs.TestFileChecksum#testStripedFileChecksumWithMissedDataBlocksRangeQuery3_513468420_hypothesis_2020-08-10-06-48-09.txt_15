reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127311344-172.17.0.10-1597042621308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42749,DS-99a867ae-0650-4063-b0d1-cc102c2df2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-92aa10d5-7e4d-4998-bd4f-b5c5dc991921,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-0eb1f2bb-ccaf-4da1-8069-4c91bedc3fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-6c24a0b7-a14b-45ba-ad3d-61aef537b977,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-6bbd1600-fa84-4fc4-82f9-1cda0cbb72ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-8ff3c9ff-de37-405e-aabd-aa86a884c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-12c1b732-637f-44b7-b2e0-1607ec5e2f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-432193eb-353f-4e21-8ce4-cf2be90bf667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2127311344-172.17.0.10-1597042621308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42749,DS-99a867ae-0650-4063-b0d1-cc102c2df2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-92aa10d5-7e4d-4998-bd4f-b5c5dc991921,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-0eb1f2bb-ccaf-4da1-8069-4c91bedc3fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-6c24a0b7-a14b-45ba-ad3d-61aef537b977,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-6bbd1600-fa84-4fc4-82f9-1cda0cbb72ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-8ff3c9ff-de37-405e-aabd-aa86a884c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-12c1b732-637f-44b7-b2e0-1607ec5e2f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-432193eb-353f-4e21-8ce4-cf2be90bf667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715840171-172.17.0.10-1597042656246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44713,DS-327e986c-6aa9-4e1e-b10d-a673033e3ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-1e95c428-0296-4ce4-9ea0-2762efa7d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-820c6624-a1a9-45a5-989b-655d531d92de,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-aad6db53-8f77-468a-8956-8ca2adac6482,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-bcd8c5d5-3ed4-4049-bd9f-115de152db40,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-77b5b71f-0868-495e-a1e4-33157a1f9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-4f621fe0-68fb-4313-ba8a-165d73fbd73d,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-fc4aeef8-2d73-4b9d-b42b-01d6a77973c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715840171-172.17.0.10-1597042656246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44713,DS-327e986c-6aa9-4e1e-b10d-a673033e3ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-1e95c428-0296-4ce4-9ea0-2762efa7d9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-820c6624-a1a9-45a5-989b-655d531d92de,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-aad6db53-8f77-468a-8956-8ca2adac6482,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-bcd8c5d5-3ed4-4049-bd9f-115de152db40,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-77b5b71f-0868-495e-a1e4-33157a1f9c75,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-4f621fe0-68fb-4313-ba8a-165d73fbd73d,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-fc4aeef8-2d73-4b9d-b42b-01d6a77973c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199146949-172.17.0.10-1597042733436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-70bd9aa4-fd7c-4357-bb79-74c5c7e134fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-ad67e6d0-c32a-4619-a3cd-3f93e59ba131,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-3be08604-34cf-4a39-88a0-763d46b668cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-f8bb3b72-7fd3-40d7-bbfb-7025af6ddb48,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0c69bb09-eb27-45fc-8f8f-930e0253f799,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-bc61596f-8f00-4911-bc74-d8d962561d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-3c2bda32-e47f-4f6f-a9d1-cd5a8c7dc222,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-dc38555e-0d6e-4ee4-a065-be8715ae16b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199146949-172.17.0.10-1597042733436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34921,DS-70bd9aa4-fd7c-4357-bb79-74c5c7e134fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-ad67e6d0-c32a-4619-a3cd-3f93e59ba131,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-3be08604-34cf-4a39-88a0-763d46b668cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-f8bb3b72-7fd3-40d7-bbfb-7025af6ddb48,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0c69bb09-eb27-45fc-8f8f-930e0253f799,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-bc61596f-8f00-4911-bc74-d8d962561d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-3c2bda32-e47f-4f6f-a9d1-cd5a8c7dc222,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-dc38555e-0d6e-4ee4-a065-be8715ae16b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730822376-172.17.0.10-1597042849029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-90fd9552-e082-46f4-be59-3cc562a23c64,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-e1166949-c110-4c26-8dc8-c955bc8b513d,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-3e403d55-782c-4341-ad73-3b301f557cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-eafa6663-87ac-4903-b006-f7b68bcdad1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-18301ae0-e04d-4717-ad8e-b18ce1d18d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-180d703d-ca9c-4270-98f0-a3d5787bba01,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-220f124e-3e2f-4dc7-8c9c-c7529a087a56,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-2a29b792-11cd-4a58-912c-7e2d83e21faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730822376-172.17.0.10-1597042849029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36375,DS-90fd9552-e082-46f4-be59-3cc562a23c64,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-e1166949-c110-4c26-8dc8-c955bc8b513d,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-3e403d55-782c-4341-ad73-3b301f557cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-eafa6663-87ac-4903-b006-f7b68bcdad1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-18301ae0-e04d-4717-ad8e-b18ce1d18d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46300,DS-180d703d-ca9c-4270-98f0-a3d5787bba01,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-220f124e-3e2f-4dc7-8c9c-c7529a087a56,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-2a29b792-11cd-4a58-912c-7e2d83e21faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060709783-172.17.0.10-1597043311283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46138,DS-2ff46eaf-5b2d-4760-9396-d4d3261c3d68,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-0fd3f185-8b0e-489a-979f-5a9dd044310d,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-719361c2-2321-413b-8da8-cce587f6ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-2f0c94c1-86ae-4c71-b5dc-2ebab211e738,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-3edabbce-83c0-4992-b9ab-34c6a0f7d9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-53c9d486-fb8b-4257-a4dd-87a9cd891cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-203a013b-a957-400b-8276-9652a2c50a72,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-749dea0f-4a83-43c1-8768-cfe3d47e5561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060709783-172.17.0.10-1597043311283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46138,DS-2ff46eaf-5b2d-4760-9396-d4d3261c3d68,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-0fd3f185-8b0e-489a-979f-5a9dd044310d,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-719361c2-2321-413b-8da8-cce587f6ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-2f0c94c1-86ae-4c71-b5dc-2ebab211e738,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-3edabbce-83c0-4992-b9ab-34c6a0f7d9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-53c9d486-fb8b-4257-a4dd-87a9cd891cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-203a013b-a957-400b-8276-9652a2c50a72,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-749dea0f-4a83-43c1-8768-cfe3d47e5561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721737195-172.17.0.10-1597043665408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-6d0ed123-3e63-4e40-b207-0222a98d8c91,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-b9f4dad6-aed0-4b5a-bf22-af74f92e0ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-cdd856b0-5a59-43f4-b205-588ea3a1d0db,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-931f4ad7-b252-4e5b-a4ec-a67d84264345,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-ea1504c3-b6c7-48cf-8f4d-b9e3b3e3cc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-3f144bbe-0e6c-4f09-b222-3d8b3eee2267,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-7aed5855-0de2-4c02-aaf3-19df4581083a,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-3d1b0ec2-c395-4251-8223-6554c2c9a7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721737195-172.17.0.10-1597043665408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-6d0ed123-3e63-4e40-b207-0222a98d8c91,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-b9f4dad6-aed0-4b5a-bf22-af74f92e0ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-cdd856b0-5a59-43f4-b205-588ea3a1d0db,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-931f4ad7-b252-4e5b-a4ec-a67d84264345,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-ea1504c3-b6c7-48cf-8f4d-b9e3b3e3cc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-3f144bbe-0e6c-4f09-b222-3d8b3eee2267,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-7aed5855-0de2-4c02-aaf3-19df4581083a,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-3d1b0ec2-c395-4251-8223-6554c2c9a7cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141705193-172.17.0.10-1597044075596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36378,DS-fb0e3025-ba4c-470d-ab3b-b4a994dea415,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-6ca67b57-b6c0-4e5c-a938-3a0749ea096c,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-f79484f7-4890-49d2-be8c-99a7fdf35e83,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-9c55a102-1981-442a-a75e-fb035740ec8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-25a6f520-6b8d-4385-bfc5-5b28e53d92c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-2eabc608-0606-47e5-8d76-3f98c38073a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-2d320f54-e51f-4b21-ba31-63082e1e4ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-869fe7d1-a7d4-4d6f-84e8-08efb06b84a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141705193-172.17.0.10-1597044075596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36378,DS-fb0e3025-ba4c-470d-ab3b-b4a994dea415,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-6ca67b57-b6c0-4e5c-a938-3a0749ea096c,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-f79484f7-4890-49d2-be8c-99a7fdf35e83,DISK], DatanodeInfoWithStorage[127.0.0.1:41153,DS-9c55a102-1981-442a-a75e-fb035740ec8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-25a6f520-6b8d-4385-bfc5-5b28e53d92c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-2eabc608-0606-47e5-8d76-3f98c38073a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-2d320f54-e51f-4b21-ba31-63082e1e4ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-869fe7d1-a7d4-4d6f-84e8-08efb06b84a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457087304-172.17.0.10-1597044263579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43929,DS-4e8eb44b-605c-4761-a066-0ce8cf1b24ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-5c0e46cf-b59b-4449-9f00-3c021ad202cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-0560feeb-a808-4b57-aff4-6a76dc23ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-55e6446f-15a8-4efd-bcf7-ea13628d6c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-d8f189d4-eacd-4014-bef5-60b9a505113f,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-076d5bab-9b29-4fa4-93d4-00bce2c77cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-a99db658-35e9-4c51-80f8-4f692afdd438,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-6d04b4bd-2f0e-4b06-9e30-bf07f75ce44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457087304-172.17.0.10-1597044263579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43929,DS-4e8eb44b-605c-4761-a066-0ce8cf1b24ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-5c0e46cf-b59b-4449-9f00-3c021ad202cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-0560feeb-a808-4b57-aff4-6a76dc23ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-55e6446f-15a8-4efd-bcf7-ea13628d6c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45239,DS-d8f189d4-eacd-4014-bef5-60b9a505113f,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-076d5bab-9b29-4fa4-93d4-00bce2c77cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35188,DS-a99db658-35e9-4c51-80f8-4f692afdd438,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-6d04b4bd-2f0e-4b06-9e30-bf07f75ce44b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837929139-172.17.0.10-1597044757606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-8112fd80-1980-4caa-8405-b7f7765238c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-576d08aa-f429-4cc7-9bf3-75580c5d5435,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-75d39919-ed1b-441d-9308-0bfd27e17241,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-a122ce5e-33ad-412d-817b-e8bdd44650cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-80789db1-1324-4d91-8d15-0384a9ffcd15,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-443db89d-58aa-406c-8934-0bd33bb148dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-caf6b740-ae0b-4f85-9805-2dad54568ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-04dd69c3-a957-44eb-82b0-bf76bc5675d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837929139-172.17.0.10-1597044757606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46238,DS-8112fd80-1980-4caa-8405-b7f7765238c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-576d08aa-f429-4cc7-9bf3-75580c5d5435,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-75d39919-ed1b-441d-9308-0bfd27e17241,DISK], DatanodeInfoWithStorage[127.0.0.1:44549,DS-a122ce5e-33ad-412d-817b-e8bdd44650cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-80789db1-1324-4d91-8d15-0384a9ffcd15,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-443db89d-58aa-406c-8934-0bd33bb148dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-caf6b740-ae0b-4f85-9805-2dad54568ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-04dd69c3-a957-44eb-82b0-bf76bc5675d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918575819-172.17.0.10-1597044965525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35370,DS-2182b7b5-b31c-4979-9c58-fc6075eae627,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-14d11671-7b3b-4ace-8f16-132d143191ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-368b43c0-fb1d-44cb-97cb-86ecc28985f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-345e4ba0-0ef3-4a8d-97c2-2c4e81f8cd40,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-14d08bb5-8546-4e3b-99ab-8c2bb0e438a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-452c6162-b309-4842-92c3-9fab27d41aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-01117990-ccef-4a7d-8c7e-18fb9158061b,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-d6394494-8bbc-4c64-8baf-b8d6d37bd3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918575819-172.17.0.10-1597044965525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35370,DS-2182b7b5-b31c-4979-9c58-fc6075eae627,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-14d11671-7b3b-4ace-8f16-132d143191ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-368b43c0-fb1d-44cb-97cb-86ecc28985f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-345e4ba0-0ef3-4a8d-97c2-2c4e81f8cd40,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-14d08bb5-8546-4e3b-99ab-8c2bb0e438a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-452c6162-b309-4842-92c3-9fab27d41aac,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-01117990-ccef-4a7d-8c7e-18fb9158061b,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-d6394494-8bbc-4c64-8baf-b8d6d37bd3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097950492-172.17.0.10-1597045111610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41866,DS-d9da4088-2574-478a-af08-9c43f49c7884,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-8827e0f9-9b23-4040-9b43-6d9d6f7bfdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-dcbf329f-56fe-40f2-a1a3-ff39ad8771a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-9e621cbe-adc8-402e-9d20-97603bdb4b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-0fafcc03-ffde-4516-b5db-b4e53b37a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-0002a38f-fbc8-4f3d-ae76-b1d15f13678b,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-5f945683-087b-4ac7-b566-5382113a2657,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-aa94c859-1ee0-4555-9e4f-9fdfb673fc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097950492-172.17.0.10-1597045111610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41866,DS-d9da4088-2574-478a-af08-9c43f49c7884,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-8827e0f9-9b23-4040-9b43-6d9d6f7bfdfd,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-dcbf329f-56fe-40f2-a1a3-ff39ad8771a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-9e621cbe-adc8-402e-9d20-97603bdb4b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-0fafcc03-ffde-4516-b5db-b4e53b37a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-0002a38f-fbc8-4f3d-ae76-b1d15f13678b,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-5f945683-087b-4ac7-b566-5382113a2657,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-aa94c859-1ee0-4555-9e4f-9fdfb673fc29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465567800-172.17.0.10-1597045291742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37369,DS-622a23f6-424a-40fd-b9c6-d94eb19fd410,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-1ae6b091-82ef-4ccb-8b31-71faef0a9c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-d2cd7334-70c6-40eb-94a0-4a5059c347e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-47edac2e-7b01-4dbb-9a4b-74683e3d9916,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8fd2808a-68af-4471-a97d-ca2138438b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-c4029d41-c6b7-4f7f-87f8-fe6365c7d577,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-af3890b9-c7dc-429c-a9ca-2fff9f9efc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-70a88fe7-2fd7-4c15-9397-42ff19ed7d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465567800-172.17.0.10-1597045291742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37369,DS-622a23f6-424a-40fd-b9c6-d94eb19fd410,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-1ae6b091-82ef-4ccb-8b31-71faef0a9c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-d2cd7334-70c6-40eb-94a0-4a5059c347e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-47edac2e-7b01-4dbb-9a4b-74683e3d9916,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8fd2808a-68af-4471-a97d-ca2138438b53,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-c4029d41-c6b7-4f7f-87f8-fe6365c7d577,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-af3890b9-c7dc-429c-a9ca-2fff9f9efc1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-70a88fe7-2fd7-4c15-9397-42ff19ed7d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694422838-172.17.0.10-1597045547920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-30293aa2-33e8-4326-beaf-29abdd258434,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-0c1228b3-d7da-4a8c-8864-81db0c201725,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-458686b3-294e-4784-9896-2e0074aa0221,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-c7ff2ea8-5d3c-4bc8-b1a7-1abb1f1eb255,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-c76311f7-b889-4861-b902-82a220c1ab37,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-2df23fb6-1f2c-442f-a7c8-6092a101664d,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-7e5053c4-3344-4548-b781-f6f8f0513021,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-77a1142d-55c9-4443-98c6-cc1feca0d7da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694422838-172.17.0.10-1597045547920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-30293aa2-33e8-4326-beaf-29abdd258434,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-0c1228b3-d7da-4a8c-8864-81db0c201725,DISK], DatanodeInfoWithStorage[127.0.0.1:35017,DS-458686b3-294e-4784-9896-2e0074aa0221,DISK], DatanodeInfoWithStorage[127.0.0.1:35109,DS-c7ff2ea8-5d3c-4bc8-b1a7-1abb1f1eb255,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-c76311f7-b889-4861-b902-82a220c1ab37,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-2df23fb6-1f2c-442f-a7c8-6092a101664d,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-7e5053c4-3344-4548-b781-f6f8f0513021,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-77a1142d-55c9-4443-98c6-cc1feca0d7da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403971831-172.17.0.10-1597045765418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-615987a4-fa81-4fe6-9130-9eb1cc32a44b,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-c1f7d381-667e-48c8-b78a-4031ff5d52d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-4c411e5e-7b4d-445d-872c-6cdc8dc7150d,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-98e4f13a-81a4-426c-8e6b-154897a2ba18,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-597800b6-1035-47d2-b9cb-ea4c2e77ac40,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-1b223be0-c8ff-45e5-91ab-54af450261a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-9c0976e2-ee2f-4ec0-8455-2cce0ee3adb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-3e9f792a-c19b-4aae-9fd5-f7a435f5ed2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403971831-172.17.0.10-1597045765418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-615987a4-fa81-4fe6-9130-9eb1cc32a44b,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-c1f7d381-667e-48c8-b78a-4031ff5d52d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-4c411e5e-7b4d-445d-872c-6cdc8dc7150d,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-98e4f13a-81a4-426c-8e6b-154897a2ba18,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-597800b6-1035-47d2-b9cb-ea4c2e77ac40,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-1b223be0-c8ff-45e5-91ab-54af450261a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-9c0976e2-ee2f-4ec0-8455-2cce0ee3adb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-3e9f792a-c19b-4aae-9fd5-f7a435f5ed2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884171250-172.17.0.10-1597045918997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39241,DS-2ad25a80-39d7-4ea2-9a38-99beaa036290,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-2a2d1464-f1d2-493a-adf6-bd4039da7648,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-016a59de-6e98-4614-832d-556c10bd9851,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-8bd3c0a9-78e6-4493-8ae8-06a6829c415c,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-de986188-976e-4c06-ab85-7e69002a1409,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-21947ce5-45b6-4c8d-9fd7-819858131c98,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-0112ff9a-122d-41d3-bd1b-2d0954e61306,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-2223409f-54e1-43c6-9e18-33dddc4e8f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884171250-172.17.0.10-1597045918997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39241,DS-2ad25a80-39d7-4ea2-9a38-99beaa036290,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-2a2d1464-f1d2-493a-adf6-bd4039da7648,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-016a59de-6e98-4614-832d-556c10bd9851,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-8bd3c0a9-78e6-4493-8ae8-06a6829c415c,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-de986188-976e-4c06-ab85-7e69002a1409,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-21947ce5-45b6-4c8d-9fd7-819858131c98,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-0112ff9a-122d-41d3-bd1b-2d0954e61306,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-2223409f-54e1-43c6-9e18-33dddc4e8f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418506298-172.17.0.10-1597046054353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-b313f6ba-c6b9-4f03-a638-f69dca2678d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-e153fa67-4a6a-4219-954e-45d566919032,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-68469169-3469-4dd5-9470-349f67c26e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-e497867f-b7e7-4259-9772-9ddf235c8690,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-94533c86-e273-49cc-bcbd-f40b1a1eae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-c4d421cb-a18d-4655-8027-00fbcc373c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-deb7ed63-7f81-49c2-955b-c8641c54c937,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-49ecd8c6-4b94-448a-8f4a-1b50dbc02f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418506298-172.17.0.10-1597046054353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34892,DS-b313f6ba-c6b9-4f03-a638-f69dca2678d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-e153fa67-4a6a-4219-954e-45d566919032,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-68469169-3469-4dd5-9470-349f67c26e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-e497867f-b7e7-4259-9772-9ddf235c8690,DISK], DatanodeInfoWithStorage[127.0.0.1:36843,DS-94533c86-e273-49cc-bcbd-f40b1a1eae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-c4d421cb-a18d-4655-8027-00fbcc373c06,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-deb7ed63-7f81-49c2-955b-c8641c54c937,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-49ecd8c6-4b94-448a-8f4a-1b50dbc02f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124996076-172.17.0.10-1597046769163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-4d5d4041-bf29-4cc0-aed3-4f7474c9ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-1b891ae9-b4c0-4436-a806-8ae319de7094,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-29908d5d-e302-4ef2-bd16-895b2a53c1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-2606f2c7-89d4-425e-b4c0-9fb09bbb95dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-542d9973-153b-435d-b77a-01125fefd9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-084276f0-06cf-4179-92a8-da803bf3af90,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-f2f152a9-0c46-4106-922c-d3f6a5626942,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-1cea90fc-3e41-41ec-b581-d1fb28888a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124996076-172.17.0.10-1597046769163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-4d5d4041-bf29-4cc0-aed3-4f7474c9ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-1b891ae9-b4c0-4436-a806-8ae319de7094,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-29908d5d-e302-4ef2-bd16-895b2a53c1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-2606f2c7-89d4-425e-b4c0-9fb09bbb95dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-542d9973-153b-435d-b77a-01125fefd9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-084276f0-06cf-4179-92a8-da803bf3af90,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-f2f152a9-0c46-4106-922c-d3f6a5626942,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-1cea90fc-3e41-41ec-b581-d1fb28888a84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914731390-172.17.0.10-1597046842829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-a3c4484a-bec1-4f1a-bf62-b754e4b95003,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-619c98f6-11c6-4364-bd01-aea2a02759f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-f1178133-ae8c-4036-904e-844ed36f4f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-943e36ee-f89d-4ceb-a7c1-857af9b5ae15,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-be26583e-8076-4c68-9768-39109aa4f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-5fe1d5e2-ac22-47de-8b2a-6fc931c92999,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-e7f882cd-bcf9-415e-b9c4-0542d5cb4543,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-bab38545-af4f-4a81-977f-20e4d0dca81f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-914731390-172.17.0.10-1597046842829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39778,DS-a3c4484a-bec1-4f1a-bf62-b754e4b95003,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-619c98f6-11c6-4364-bd01-aea2a02759f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-f1178133-ae8c-4036-904e-844ed36f4f87,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-943e36ee-f89d-4ceb-a7c1-857af9b5ae15,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-be26583e-8076-4c68-9768-39109aa4f2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-5fe1d5e2-ac22-47de-8b2a-6fc931c92999,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-e7f882cd-bcf9-415e-b9c4-0542d5cb4543,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-bab38545-af4f-4a81-977f-20e4d0dca81f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337355363-172.17.0.10-1597047079384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-488e9887-008f-4856-b882-cf5da57d7fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-3173f29d-f2a0-4222-b119-7b41d4145d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-1875707f-e18d-471c-9dc9-d31234a380aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-bfef5569-25b3-4990-90ce-b253c0068c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-5aba88ed-80b5-4827-9420-0140482b61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-af92e452-84dc-4126-9eee-245edb5c0960,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-11c68076-7e0b-40e7-a06b-a896090135ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-05a37ddd-dc40-4b2a-bd10-5d405f58709f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337355363-172.17.0.10-1597047079384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43542,DS-488e9887-008f-4856-b882-cf5da57d7fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-3173f29d-f2a0-4222-b119-7b41d4145d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-1875707f-e18d-471c-9dc9-d31234a380aa,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-bfef5569-25b3-4990-90ce-b253c0068c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-5aba88ed-80b5-4827-9420-0140482b61b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-af92e452-84dc-4126-9eee-245edb5c0960,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-11c68076-7e0b-40e7-a06b-a896090135ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-05a37ddd-dc40-4b2a-bd10-5d405f58709f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578235384-172.17.0.10-1597047148470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34878,DS-947e99c9-1bd7-483f-8632-193dbb5adf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-2f904868-3e58-439f-aa4b-dbc9731a50fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-2e442381-f01b-4b3f-b679-232a92f7443d,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-fb430f97-65ec-4024-9dcc-da5d6065478b,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-e2a9176f-3703-4096-af0e-0a1bc1e1da04,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-412dbdbb-d84a-43ae-b426-b90523a900a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-940163b9-96fe-4436-897d-5bab84c65e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-95738034-2f7e-462d-ab7e-009864a2c460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578235384-172.17.0.10-1597047148470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34878,DS-947e99c9-1bd7-483f-8632-193dbb5adf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-2f904868-3e58-439f-aa4b-dbc9731a50fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-2e442381-f01b-4b3f-b679-232a92f7443d,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-fb430f97-65ec-4024-9dcc-da5d6065478b,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-e2a9176f-3703-4096-af0e-0a1bc1e1da04,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-412dbdbb-d84a-43ae-b426-b90523a900a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-940163b9-96fe-4436-897d-5bab84c65e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-95738034-2f7e-462d-ab7e-009864a2c460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.test.drop.namenode.response.number
component: hdfs:NameNode
v1: 0
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200213725-172.17.0.10-1597047304189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-0699558e-e9c4-42bd-be7d-4f4c3bb2b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-85151d66-1767-4015-b43e-fef42cdfaf15,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-44739e35-2a66-416d-b0ff-b207ed17cc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-af0ddd29-913d-49fb-9653-5b50cc086c53,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-7edfcb6e-258c-4751-8f48-e532037044d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-6cdc3352-7b49-4142-b34a-b7593cf889fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-7008354b-a8e7-4394-ba93-e584cb2d328d,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c60e8e24-55da-4180-a7ba-f281df3fbf6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200213725-172.17.0.10-1597047304189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36314,DS-0699558e-e9c4-42bd-be7d-4f4c3bb2b4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-85151d66-1767-4015-b43e-fef42cdfaf15,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-44739e35-2a66-416d-b0ff-b207ed17cc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-af0ddd29-913d-49fb-9653-5b50cc086c53,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-7edfcb6e-258c-4751-8f48-e532037044d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-6cdc3352-7b49-4142-b34a-b7593cf889fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-7008354b-a8e7-4394-ba93-e584cb2d328d,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-c60e8e24-55da-4180-a7ba-f281df3fbf6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5449
