reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865823427-172.17.0.13-1597082876552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38708,DS-0aa5b230-f3d1-45a5-8167-87bc4a1a5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-7b9c8977-8094-4d32-89ee-f9f5382e922f,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-16b7ac1e-dfe2-4607-8561-d742729bdc35,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-bc0c6b60-8261-44b8-aec5-755f847f5060,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-01c88892-8256-48cf-936c-911640581847,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-fda78a8d-57ad-4fb3-a9cc-39cd3e2c5ded,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-73934000-7443-45a8-aa25-2c024e009bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-e8b9bcb0-c6c9-4ca6-8404-9b379139157b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865823427-172.17.0.13-1597082876552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38708,DS-0aa5b230-f3d1-45a5-8167-87bc4a1a5d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-7b9c8977-8094-4d32-89ee-f9f5382e922f,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-16b7ac1e-dfe2-4607-8561-d742729bdc35,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-bc0c6b60-8261-44b8-aec5-755f847f5060,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-01c88892-8256-48cf-936c-911640581847,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-fda78a8d-57ad-4fb3-a9cc-39cd3e2c5ded,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-73934000-7443-45a8-aa25-2c024e009bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-e8b9bcb0-c6c9-4ca6-8404-9b379139157b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416452289-172.17.0.13-1597083031834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-9b961640-1278-44d8-b19c-fbb1f277339e,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-3df32397-5b80-4678-9f24-ffdd0f2a4099,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-0ad6153d-0e27-4ef9-af5d-41aef9d3c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-ea5bcc6d-e841-487e-94fe-ae07c3cd5c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-359a23f9-3ead-4e5e-8b5c-de4637ea75f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-983c64c2-5f04-4fe0-a406-4b22cc01bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-47a97bba-af93-4f24-9e05-3140e897cc16,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-3bf28fe9-21ee-4e23-b466-241448289d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416452289-172.17.0.13-1597083031834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45285,DS-9b961640-1278-44d8-b19c-fbb1f277339e,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-3df32397-5b80-4678-9f24-ffdd0f2a4099,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-0ad6153d-0e27-4ef9-af5d-41aef9d3c3df,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-ea5bcc6d-e841-487e-94fe-ae07c3cd5c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-359a23f9-3ead-4e5e-8b5c-de4637ea75f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-983c64c2-5f04-4fe0-a406-4b22cc01bb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-47a97bba-af93-4f24-9e05-3140e897cc16,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-3bf28fe9-21ee-4e23-b466-241448289d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851521283-172.17.0.13-1597083181066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-17aab09a-5550-4dd3-9d14-fb5d91e08ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-9ee765f0-14ff-42b5-ba00-8fe9fe00f306,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-05a3ecf5-cbc2-421a-af4c-728cf1dd789b,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-e2109848-414e-4eb8-906f-0dd85203f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-1a4a4dd9-7a39-40dc-ba2e-5f5b6e1c659e,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-ee90fb98-d57d-43bf-b79e-e8e6164b7630,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-63ae6f4c-b4b1-4839-abdb-a9fa224274bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-189f4296-6efe-4021-b43d-9d1b1a34a5d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851521283-172.17.0.13-1597083181066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45733,DS-17aab09a-5550-4dd3-9d14-fb5d91e08ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-9ee765f0-14ff-42b5-ba00-8fe9fe00f306,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-05a3ecf5-cbc2-421a-af4c-728cf1dd789b,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-e2109848-414e-4eb8-906f-0dd85203f9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-1a4a4dd9-7a39-40dc-ba2e-5f5b6e1c659e,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-ee90fb98-d57d-43bf-b79e-e8e6164b7630,DISK], DatanodeInfoWithStorage[127.0.0.1:35137,DS-63ae6f4c-b4b1-4839-abdb-a9fa224274bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-189f4296-6efe-4021-b43d-9d1b1a34a5d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687231315-172.17.0.13-1597083472744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-e3983b81-c380-4de0-bb79-d9c01949001a,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-8e3343e0-23ec-4feb-8616-8a3070872fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-72656c00-7261-4860-b56d-1e9ba8972f03,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-b69822a5-2327-47f3-a7b9-6d1771a02d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-93b15a78-02c1-4f93-b469-8094f48cd4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-19afed0e-ec74-4c11-b1c5-9e847b08c60e,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-10da6ce4-ee03-4fd8-981a-e50563f9e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-5d9e680b-81ea-4b58-9d85-bcc778bd177f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1687231315-172.17.0.13-1597083472744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-e3983b81-c380-4de0-bb79-d9c01949001a,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-8e3343e0-23ec-4feb-8616-8a3070872fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-72656c00-7261-4860-b56d-1e9ba8972f03,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-b69822a5-2327-47f3-a7b9-6d1771a02d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-93b15a78-02c1-4f93-b469-8094f48cd4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-19afed0e-ec74-4c11-b1c5-9e847b08c60e,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-10da6ce4-ee03-4fd8-981a-e50563f9e5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-5d9e680b-81ea-4b58-9d85-bcc778bd177f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808299447-172.17.0.13-1597083542731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-83c5c221-0184-4101-bcec-88a2de1ffbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-e3d19226-325a-42e8-816f-add9d6e63fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-4ea869d2-da34-4a09-b1bd-ec46b9be2653,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-e01036eb-9d33-441b-80a8-efb409beb15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-4ed368c4-f738-4a10-bb2c-8068002d9ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-9bbf500e-3309-4531-b868-f560a74e2fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-73d62f77-0016-429b-aaae-9a7a6363249c,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-2d67926d-616e-4cd1-a3d8-85982a5b7245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-808299447-172.17.0.13-1597083542731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39654,DS-83c5c221-0184-4101-bcec-88a2de1ffbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:38180,DS-e3d19226-325a-42e8-816f-add9d6e63fae,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-4ea869d2-da34-4a09-b1bd-ec46b9be2653,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-e01036eb-9d33-441b-80a8-efb409beb15c,DISK], DatanodeInfoWithStorage[127.0.0.1:41481,DS-4ed368c4-f738-4a10-bb2c-8068002d9ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-9bbf500e-3309-4531-b868-f560a74e2fef,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-73d62f77-0016-429b-aaae-9a7a6363249c,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-2d67926d-616e-4cd1-a3d8-85982a5b7245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449823029-172.17.0.13-1597084006526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-58edac4e-2809-4381-8d53-e2c6d14c2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-d32a9574-3c56-4289-8b62-bf810fca0218,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-c95150b6-f08a-4a24-9525-e168c46986f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-56b2727f-3717-44cb-b595-617d9efadf21,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-e12fd42e-a790-4fe3-b09b-d534d2f943f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-0f4da6dd-b0f3-4461-af89-1c429eab86fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-dde706bd-bee1-4ae4-b19c-99fb62afd63d,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-eb8d87b0-3282-4585-95c0-b56ab8938f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449823029-172.17.0.13-1597084006526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-58edac4e-2809-4381-8d53-e2c6d14c2dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-d32a9574-3c56-4289-8b62-bf810fca0218,DISK], DatanodeInfoWithStorage[127.0.0.1:36157,DS-c95150b6-f08a-4a24-9525-e168c46986f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45779,DS-56b2727f-3717-44cb-b595-617d9efadf21,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-e12fd42e-a790-4fe3-b09b-d534d2f943f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-0f4da6dd-b0f3-4461-af89-1c429eab86fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-dde706bd-bee1-4ae4-b19c-99fb62afd63d,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-eb8d87b0-3282-4585-95c0-b56ab8938f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433555937-172.17.0.13-1597084102183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42145,DS-30379974-f01a-4bbe-86b6-73aa7939c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-5a677d25-02f3-4f23-9925-0c74ff1c6a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-4e56bf77-e369-47b0-b5ca-1717dc922111,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-47632c4d-6126-4b25-a8c1-b0ffd73521be,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-3e59568e-5ede-4356-9663-7a3dfbe2032a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-dca49916-d6bf-46d7-914c-fe3f90b62615,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-f66f400d-7bd0-4da4-b0a7-19526f7b5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-6db15973-ba0a-42c6-bfde-1b6b28af9e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433555937-172.17.0.13-1597084102183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42145,DS-30379974-f01a-4bbe-86b6-73aa7939c9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-5a677d25-02f3-4f23-9925-0c74ff1c6a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-4e56bf77-e369-47b0-b5ca-1717dc922111,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-47632c4d-6126-4b25-a8c1-b0ffd73521be,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-3e59568e-5ede-4356-9663-7a3dfbe2032a,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-dca49916-d6bf-46d7-914c-fe3f90b62615,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-f66f400d-7bd0-4da4-b0a7-19526f7b5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-6db15973-ba0a-42c6-bfde-1b6b28af9e67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886004344-172.17.0.13-1597084130434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43448,DS-295766cd-33d0-4548-9298-22803fa62d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-3186a051-e260-4019-b016-c573765d8a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-2ac1584a-e18f-4127-b49d-3228c634b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-c9702140-d5c9-487d-a822-085a343d4a37,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-125d3204-5f8d-418b-9759-331b80ec1e22,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-7d0e4f3a-921d-4c2c-9d71-b00b427420ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-6f1db78d-f438-4266-b7a0-b5c2e5b170f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-d12869a6-88b6-4049-97de-fabc7d99d214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1886004344-172.17.0.13-1597084130434:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43448,DS-295766cd-33d0-4548-9298-22803fa62d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-3186a051-e260-4019-b016-c573765d8a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-2ac1584a-e18f-4127-b49d-3228c634b2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-c9702140-d5c9-487d-a822-085a343d4a37,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-125d3204-5f8d-418b-9759-331b80ec1e22,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-7d0e4f3a-921d-4c2c-9d71-b00b427420ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-6f1db78d-f438-4266-b7a0-b5c2e5b170f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-d12869a6-88b6-4049-97de-fabc7d99d214,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707419352-172.17.0.13-1597084461026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41847,DS-54951fad-0b85-4021-a6a8-6d1ed616e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-7f0e0519-f831-49d5-9620-ea0141bfa705,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-efad6950-b988-4ad1-bf3a-d5357e5f168a,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-5ed36ef5-9e70-4585-8da7-c8094ab23e53,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-99d0aad5-a36b-448b-ad16-e93eee82567c,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-471bed48-509a-4b7b-82e8-4cba886718b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-fd0d9874-9fc1-432b-98e3-1a22219f2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-2392ee5c-01df-459b-9d90-d2dd9991b380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707419352-172.17.0.13-1597084461026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41847,DS-54951fad-0b85-4021-a6a8-6d1ed616e4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-7f0e0519-f831-49d5-9620-ea0141bfa705,DISK], DatanodeInfoWithStorage[127.0.0.1:39301,DS-efad6950-b988-4ad1-bf3a-d5357e5f168a,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-5ed36ef5-9e70-4585-8da7-c8094ab23e53,DISK], DatanodeInfoWithStorage[127.0.0.1:41815,DS-99d0aad5-a36b-448b-ad16-e93eee82567c,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-471bed48-509a-4b7b-82e8-4cba886718b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-fd0d9874-9fc1-432b-98e3-1a22219f2e96,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-2392ee5c-01df-459b-9d90-d2dd9991b380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555413014-172.17.0.13-1597084553452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36918,DS-1f763ab5-1af2-44dd-89ae-c68b32eeec8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-a51f57eb-518e-43fc-9183-5fc16f1d4a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-4d328db8-e930-40a1-9e77-19a2b325f315,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-87bcde3d-e7b2-4116-ac3f-81792aeb157b,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-289c3d22-e8f9-4b5c-9ae1-e1eb7770ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f919a6fc-1514-4358-a0d0-5b6f73fe4207,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-2a0bd719-360a-4c14-9d36-86e1ecfba8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-419171ef-43b1-460f-b85b-bdae65650df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555413014-172.17.0.13-1597084553452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36918,DS-1f763ab5-1af2-44dd-89ae-c68b32eeec8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-a51f57eb-518e-43fc-9183-5fc16f1d4a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-4d328db8-e930-40a1-9e77-19a2b325f315,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-87bcde3d-e7b2-4116-ac3f-81792aeb157b,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-289c3d22-e8f9-4b5c-9ae1-e1eb7770ae4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-f919a6fc-1514-4358-a0d0-5b6f73fe4207,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-2a0bd719-360a-4c14-9d36-86e1ecfba8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-419171ef-43b1-460f-b85b-bdae65650df8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215955174-172.17.0.13-1597084616067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-54233733-8bf0-429e-bfbc-4fd3a65dfad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-fa48b903-7591-4eb5-8788-b9140132cd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-13365b83-b22b-490f-81c0-1a5ef3b9aabc,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-fcdb48bd-2d73-4fa5-8b0f-541479200e93,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-e01ac222-7942-4b27-903f-4a1ddcbec51b,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-e5546976-54bf-4195-916b-a783574abe5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-54195c3c-8392-4a8d-bc88-9b16646b46ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-c203f95f-3fe7-4d70-ae85-505e698c77f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1215955174-172.17.0.13-1597084616067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-54233733-8bf0-429e-bfbc-4fd3a65dfad5,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-fa48b903-7591-4eb5-8788-b9140132cd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-13365b83-b22b-490f-81c0-1a5ef3b9aabc,DISK], DatanodeInfoWithStorage[127.0.0.1:39109,DS-fcdb48bd-2d73-4fa5-8b0f-541479200e93,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-e01ac222-7942-4b27-903f-4a1ddcbec51b,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-e5546976-54bf-4195-916b-a783574abe5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-54195c3c-8392-4a8d-bc88-9b16646b46ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-c203f95f-3fe7-4d70-ae85-505e698c77f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558313636-172.17.0.13-1597084998496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45678,DS-396ef002-17da-4123-8ef3-9e63c2abc4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-e23e5ce5-7729-402c-9732-e687be96e503,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-9128428a-0bbc-436c-9ce4-d14bef826184,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-e77b6999-15e5-45ee-a0a7-50b585a43aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-7e9c111c-1825-41cd-9928-ee6149142532,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-d531c272-667e-4221-805b-fb4eaa48b08a,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-d8a13488-ca5f-4f39-9d76-c38d3d85f3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-73fb62a3-cba5-4bfc-be78-77ea714d2351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1558313636-172.17.0.13-1597084998496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45678,DS-396ef002-17da-4123-8ef3-9e63c2abc4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-e23e5ce5-7729-402c-9732-e687be96e503,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-9128428a-0bbc-436c-9ce4-d14bef826184,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-e77b6999-15e5-45ee-a0a7-50b585a43aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-7e9c111c-1825-41cd-9928-ee6149142532,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-d531c272-667e-4221-805b-fb4eaa48b08a,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-d8a13488-ca5f-4f39-9d76-c38d3d85f3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-73fb62a3-cba5-4bfc-be78-77ea714d2351,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013686828-172.17.0.13-1597086343610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-24989885-c0fd-45ff-bc41-10f41396984f,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-a17e36c5-ced2-4ce4-abc1-4c14870b67a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-957e83de-cbba-4896-a500-3267830a19c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-707ed14f-d184-4494-8a50-783a6a5ceb06,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-cfe3dfb7-1cd3-49da-a87e-000433bda3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-b4ce240f-cda8-47a4-95ab-6a0453c47740,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-ff13700e-6a0c-407d-915f-91113d4b930d,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-6659882e-bf1f-4039-a7b3-71a163392298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1013686828-172.17.0.13-1597086343610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-24989885-c0fd-45ff-bc41-10f41396984f,DISK], DatanodeInfoWithStorage[127.0.0.1:39790,DS-a17e36c5-ced2-4ce4-abc1-4c14870b67a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-957e83de-cbba-4896-a500-3267830a19c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-707ed14f-d184-4494-8a50-783a6a5ceb06,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-cfe3dfb7-1cd3-49da-a87e-000433bda3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-b4ce240f-cda8-47a4-95ab-6a0453c47740,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-ff13700e-6a0c-407d-915f-91113d4b930d,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-6659882e-bf1f-4039-a7b3-71a163392298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138865302-172.17.0.13-1597086732184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46350,DS-ae97a324-f957-488d-b9ce-3a68d7dbdd69,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-75b29db6-461f-4f4d-98f0-be6b1379095e,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-877c812f-ae60-4289-be94-df915684dba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-2a4af2f0-21a4-4bf0-8b1a-13ede7e0275a,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-d7a966c8-2e78-47d2-9a05-8898ac99afd8,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-0fd346f8-4e6e-4254-ab92-7de8839b35b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-50d8f72c-259b-4d37-a76a-0d3f274db39b,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-ca58801f-5cd7-4f60-b345-30d211ae1f27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2138865302-172.17.0.13-1597086732184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46350,DS-ae97a324-f957-488d-b9ce-3a68d7dbdd69,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-75b29db6-461f-4f4d-98f0-be6b1379095e,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-877c812f-ae60-4289-be94-df915684dba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-2a4af2f0-21a4-4bf0-8b1a-13ede7e0275a,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-d7a966c8-2e78-47d2-9a05-8898ac99afd8,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-0fd346f8-4e6e-4254-ab92-7de8839b35b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-50d8f72c-259b-4d37-a76a-0d3f274db39b,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-ca58801f-5cd7-4f60-b345-30d211ae1f27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034927873-172.17.0.13-1597087212704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41706,DS-b2121ef9-aaeb-476e-82a8-85ba048336a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-c2b98a32-8988-45b7-b2c9-b8668fe2332d,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-949ecb05-db50-46e0-a4b2-8f35f38a6fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-cd2aa893-ece2-47b7-994a-7483ed529760,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-688e2e0f-db26-4428-a531-977381828177,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-3432e7a2-3a2a-4263-b1ea-8caf520ac062,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-f832795e-99c1-4c05-97a8-3b6a3fb09fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-88b162b7-273c-4811-ab00-46474415808e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2034927873-172.17.0.13-1597087212704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41706,DS-b2121ef9-aaeb-476e-82a8-85ba048336a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-c2b98a32-8988-45b7-b2c9-b8668fe2332d,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-949ecb05-db50-46e0-a4b2-8f35f38a6fad,DISK], DatanodeInfoWithStorage[127.0.0.1:44771,DS-cd2aa893-ece2-47b7-994a-7483ed529760,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-688e2e0f-db26-4428-a531-977381828177,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-3432e7a2-3a2a-4263-b1ea-8caf520ac062,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-f832795e-99c1-4c05-97a8-3b6a3fb09fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-88b162b7-273c-4811-ab00-46474415808e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61557711-172.17.0.13-1597087254554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41701,DS-d20cef95-d126-4691-93e9-6e5c81e9c633,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-e69b76db-2b5c-41af-99d1-f5e555b22b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-c277e1e2-b076-4023-82ee-c0ca78269cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-c5441f35-2f20-4538-82b3-a3764502d713,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-032e1d3f-a0d1-458a-9a5e-b82dbf579ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-3895c019-3efb-44f7-8f4e-e4dec31ad4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-b3ade212-8afa-4eb8-bbc7-4f2daac63c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-65918e37-0cc6-40d1-8804-8c53861dc571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-61557711-172.17.0.13-1597087254554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41701,DS-d20cef95-d126-4691-93e9-6e5c81e9c633,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-e69b76db-2b5c-41af-99d1-f5e555b22b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-c277e1e2-b076-4023-82ee-c0ca78269cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-c5441f35-2f20-4538-82b3-a3764502d713,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-032e1d3f-a0d1-458a-9a5e-b82dbf579ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-3895c019-3efb-44f7-8f4e-e4dec31ad4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-b3ade212-8afa-4eb8-bbc7-4f2daac63c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-65918e37-0cc6-40d1-8804-8c53861dc571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 4000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662969845-172.17.0.13-1597087553977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43709,DS-eb964230-42a3-440e-b718-c78f4a8e65a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-5573e530-49fc-4bcf-afd9-cca001896c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-df47a30a-67d1-4921-a4f1-6b0b31228896,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-6aa930a1-956f-4d62-bb7a-e4bc30e1b89d,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-e884b0f6-49a4-45d7-8072-fb29640a595f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-f9a88c32-6ecf-410d-9a1c-fb6e3562d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-e4654c00-713d-40ea-bdf7-22d840e64713,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-df104d50-ff83-4362-8c30-a19639ff586e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662969845-172.17.0.13-1597087553977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43709,DS-eb964230-42a3-440e-b718-c78f4a8e65a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-5573e530-49fc-4bcf-afd9-cca001896c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-df47a30a-67d1-4921-a4f1-6b0b31228896,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-6aa930a1-956f-4d62-bb7a-e4bc30e1b89d,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-e884b0f6-49a4-45d7-8072-fb29640a595f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-f9a88c32-6ecf-410d-9a1c-fb6e3562d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33348,DS-e4654c00-713d-40ea-bdf7-22d840e64713,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-df104d50-ff83-4362-8c30-a19639ff586e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5303
