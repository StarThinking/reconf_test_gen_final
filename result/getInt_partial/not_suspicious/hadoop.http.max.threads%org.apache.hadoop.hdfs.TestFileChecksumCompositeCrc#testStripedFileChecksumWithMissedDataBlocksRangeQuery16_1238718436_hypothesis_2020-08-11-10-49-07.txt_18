reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614704407-172.17.0.2-1597143164009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45645,DS-75af2fa5-972b-4bed-8cda-f89d1b57bda1,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-1a815291-dcb2-42af-aabe-ecbd17bbec07,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-a0d941f9-86eb-49cb-aa51-49d613b7ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-cc324996-0b01-4f54-a971-1278137727f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-7de595fd-ced6-4b54-85fc-6839de7b6451,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-701526ed-30c1-492f-92a0-e8291b602aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-e665ba41-e2c3-485d-8bf7-838cc3ec1ced,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-09c8734d-1feb-4456-acdd-a0f743d4bbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614704407-172.17.0.2-1597143164009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45645,DS-75af2fa5-972b-4bed-8cda-f89d1b57bda1,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-1a815291-dcb2-42af-aabe-ecbd17bbec07,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-a0d941f9-86eb-49cb-aa51-49d613b7ddaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-cc324996-0b01-4f54-a971-1278137727f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-7de595fd-ced6-4b54-85fc-6839de7b6451,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-701526ed-30c1-492f-92a0-e8291b602aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-e665ba41-e2c3-485d-8bf7-838cc3ec1ced,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-09c8734d-1feb-4456-acdd-a0f743d4bbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759137078-172.17.0.2-1597143639676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43864,DS-cad5e37f-0a0a-4da5-bf96-122bfce75ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-aab450fa-3417-4771-a026-5851d7b17bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-db0e1db6-e704-4fe9-a245-1bb7b585ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-c60bcdf3-2338-429d-997c-28d3605e7432,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-01043ef0-a963-4f38-95eb-08178134a700,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-99a19a39-6eaf-4756-b435-8dc22b826498,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-00b53678-a716-4414-861e-8d59bdc32050,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-64ce7ead-574b-4b19-a669-d9c71230b6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1759137078-172.17.0.2-1597143639676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43864,DS-cad5e37f-0a0a-4da5-bf96-122bfce75ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-aab450fa-3417-4771-a026-5851d7b17bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-db0e1db6-e704-4fe9-a245-1bb7b585ee54,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-c60bcdf3-2338-429d-997c-28d3605e7432,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-01043ef0-a963-4f38-95eb-08178134a700,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-99a19a39-6eaf-4756-b435-8dc22b826498,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-00b53678-a716-4414-861e-8d59bdc32050,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-64ce7ead-574b-4b19-a669-d9c71230b6b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020886916-172.17.0.2-1597143741897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-bf52268c-818a-498a-ae45-b6e0b1aa0f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-8e061375-ea0a-49e1-92fe-ca90cb226522,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-a22b27b3-415c-4c5d-8ec4-ff8b90a5df40,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-1ace3642-8d64-4b7e-89e7-2153daedee29,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-7598caf8-31d6-4cb9-9efd-b68dc9cde212,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-7a7489b1-3182-4984-8d5c-0d4b51d9a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-528ba6de-7fd9-4d86-9723-ab4c168d534e,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-f72cb0cc-a0a6-45ba-b8f6-5323cf70c1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020886916-172.17.0.2-1597143741897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39901,DS-bf52268c-818a-498a-ae45-b6e0b1aa0f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-8e061375-ea0a-49e1-92fe-ca90cb226522,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-a22b27b3-415c-4c5d-8ec4-ff8b90a5df40,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-1ace3642-8d64-4b7e-89e7-2153daedee29,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-7598caf8-31d6-4cb9-9efd-b68dc9cde212,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-7a7489b1-3182-4984-8d5c-0d4b51d9a31b,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-528ba6de-7fd9-4d86-9723-ab4c168d534e,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-f72cb0cc-a0a6-45ba-b8f6-5323cf70c1d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860627296-172.17.0.2-1597144562197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42776,DS-42075071-c2ea-48d2-8f34-3d084c096454,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-fc1e8cd9-284b-4ad0-8c2a-6722c9f620eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-f9e9756f-80cd-42e1-9801-d25d92ff67f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-13d79010-a372-41bf-9147-4b03cd4b435d,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-e4a1b44a-d507-4782-bb7c-c839b0c152a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-3a75037c-32e4-4446-b659-2537c0ea3390,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-5760c9dd-6014-4239-8450-62cb6dd4b377,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-2d132156-287d-43a1-9eb2-70ef1451d82d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860627296-172.17.0.2-1597144562197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42776,DS-42075071-c2ea-48d2-8f34-3d084c096454,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-fc1e8cd9-284b-4ad0-8c2a-6722c9f620eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-f9e9756f-80cd-42e1-9801-d25d92ff67f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-13d79010-a372-41bf-9147-4b03cd4b435d,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-e4a1b44a-d507-4782-bb7c-c839b0c152a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-3a75037c-32e4-4446-b659-2537c0ea3390,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-5760c9dd-6014-4239-8450-62cb6dd4b377,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-2d132156-287d-43a1-9eb2-70ef1451d82d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33094566-172.17.0.2-1597144730095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-a930d807-364a-4197-a91f-de3d53b55203,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-515681e8-614c-4560-a021-27709fa13aac,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-26b9cb44-e364-40db-ad18-cf0344350d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-5689d705-afdc-4a38-8542-b06344530250,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-34cad7d8-9dcb-4b21-99ca-ae1f0416bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1f8f9a9f-6435-42fa-945e-86401a0c3d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-6cff2df9-296e-440b-8257-dd4bece557ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-a1101aa9-b44c-4eb8-b598-ea939e6c521d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33094566-172.17.0.2-1597144730095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36687,DS-a930d807-364a-4197-a91f-de3d53b55203,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-515681e8-614c-4560-a021-27709fa13aac,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-26b9cb44-e364-40db-ad18-cf0344350d84,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-5689d705-afdc-4a38-8542-b06344530250,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-34cad7d8-9dcb-4b21-99ca-ae1f0416bbde,DISK], DatanodeInfoWithStorage[127.0.0.1:34415,DS-1f8f9a9f-6435-42fa-945e-86401a0c3d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-6cff2df9-296e-440b-8257-dd4bece557ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-a1101aa9-b44c-4eb8-b598-ea939e6c521d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828906891-172.17.0.2-1597145538222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38704,DS-f72ab874-2dad-46e8-b990-0a2c22bc2659,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-47f7cf9c-3aa4-4c40-8349-944ec6f6fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-ccba129e-2d03-461c-b35a-49389cb11fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-c720295f-81f8-4529-ba2a-b1650e8ccb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-aaf54898-2bfe-4ecf-b418-e9650a961296,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-627e6396-66d8-44cd-950a-7a814e7e1c79,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-c19317c5-ee5b-4993-aa19-4fa2b005eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-f603123f-9f0d-4874-b931-e0dc4e70f65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828906891-172.17.0.2-1597145538222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38704,DS-f72ab874-2dad-46e8-b990-0a2c22bc2659,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-47f7cf9c-3aa4-4c40-8349-944ec6f6fa4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-ccba129e-2d03-461c-b35a-49389cb11fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-c720295f-81f8-4529-ba2a-b1650e8ccb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-aaf54898-2bfe-4ecf-b418-e9650a961296,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-627e6396-66d8-44cd-950a-7a814e7e1c79,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-c19317c5-ee5b-4993-aa19-4fa2b005eaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-f603123f-9f0d-4874-b931-e0dc4e70f65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020458703-172.17.0.2-1597146091249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42592,DS-4e6c7ea5-ef6a-4186-b3fb-5d48a87ecba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-c2171664-84eb-46f8-b6ab-3ce79e986618,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-519b594f-72e4-424a-9950-c2a0958539e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-6f84a089-3fef-4d16-af9b-f189c75c1ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-7f717ffd-39ec-44a9-9133-fa1d545c53c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-76887d94-f48d-427b-8110-275f9012eeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-20ddd11a-f2d9-4a55-8aba-fbcadffcd873,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-987272c3-c697-409f-a80e-e7c3a72fdd66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2020458703-172.17.0.2-1597146091249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42592,DS-4e6c7ea5-ef6a-4186-b3fb-5d48a87ecba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-c2171664-84eb-46f8-b6ab-3ce79e986618,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-519b594f-72e4-424a-9950-c2a0958539e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-6f84a089-3fef-4d16-af9b-f189c75c1ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-7f717ffd-39ec-44a9-9133-fa1d545c53c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-76887d94-f48d-427b-8110-275f9012eeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-20ddd11a-f2d9-4a55-8aba-fbcadffcd873,DISK], DatanodeInfoWithStorage[127.0.0.1:37580,DS-987272c3-c697-409f-a80e-e7c3a72fdd66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966478942-172.17.0.2-1597146152114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40642,DS-312dd042-909c-47f8-a804-53eeb5ddd862,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-5c119830-fba3-4acd-8a31-c5b775fa3672,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-165ff3b6-59cb-44da-8e37-59848d4e8a02,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-1c930ba1-efb3-4c82-8dfc-545280af2aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-e9c36ccf-f376-402e-bdec-6c458e27b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-bc66141f-9333-4920-b17d-807a558d6009,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-e11e1c85-688d-40b9-9d2d-2b821514de75,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-ae384158-fd92-4656-a78b-e0d3c9162a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966478942-172.17.0.2-1597146152114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40642,DS-312dd042-909c-47f8-a804-53eeb5ddd862,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-5c119830-fba3-4acd-8a31-c5b775fa3672,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-165ff3b6-59cb-44da-8e37-59848d4e8a02,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-1c930ba1-efb3-4c82-8dfc-545280af2aea,DISK], DatanodeInfoWithStorage[127.0.0.1:42090,DS-e9c36ccf-f376-402e-bdec-6c458e27b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-bc66141f-9333-4920-b17d-807a558d6009,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-e11e1c85-688d-40b9-9d2d-2b821514de75,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-ae384158-fd92-4656-a78b-e0d3c9162a59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137186754-172.17.0.2-1597146905874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32812,DS-0584ab23-9466-4b18-8c5c-42b67d0d7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-92ff1851-43f6-4dcb-813d-69e0b5e0c59c,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-d6abb9f7-292e-4ba0-861c-ce71378dd4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-4dee6e5c-428e-4ac3-ae16-9536365f8a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-edf4c940-238a-4790-a81e-dac6ff28a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-546d47ed-481b-44a1-9285-a44bb76e6fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-ac15cc30-452e-4a1b-b6bc-036c508a3753,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-a8d0a98f-6e8f-453b-9e2c-2e46a65a28f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-137186754-172.17.0.2-1597146905874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32812,DS-0584ab23-9466-4b18-8c5c-42b67d0d7e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-92ff1851-43f6-4dcb-813d-69e0b5e0c59c,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-d6abb9f7-292e-4ba0-861c-ce71378dd4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-4dee6e5c-428e-4ac3-ae16-9536365f8a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-edf4c940-238a-4790-a81e-dac6ff28a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-546d47ed-481b-44a1-9285-a44bb76e6fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-ac15cc30-452e-4a1b-b6bc-036c508a3753,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-a8d0a98f-6e8f-453b-9e2c-2e46a65a28f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698452868-172.17.0.2-1597148398899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45761,DS-9699bcba-b04b-4fd4-87fb-0d2769e5e925,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-c2eb842e-4f33-46cf-8ef9-d22bec78ad16,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-766e90f5-36e6-4318-b6ac-054761f4d74b,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-cc7f86fe-7b77-4d42-8c4b-42a7d98e1ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-b7358b21-ee6c-405e-a5be-7570d052e967,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-d2128b29-c735-4b15-b706-6e57318c6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-a30756bb-b319-46c1-a0c4-94b16c8c2dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-ea0c8804-7f11-4b25-86c0-d73d3cd401c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698452868-172.17.0.2-1597148398899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45761,DS-9699bcba-b04b-4fd4-87fb-0d2769e5e925,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-c2eb842e-4f33-46cf-8ef9-d22bec78ad16,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-766e90f5-36e6-4318-b6ac-054761f4d74b,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-cc7f86fe-7b77-4d42-8c4b-42a7d98e1ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-b7358b21-ee6c-405e-a5be-7570d052e967,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-d2128b29-c735-4b15-b706-6e57318c6aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-a30756bb-b319-46c1-a0c4-94b16c8c2dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-ea0c8804-7f11-4b25-86c0-d73d3cd401c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301575097-172.17.0.2-1597148785921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-7c245b49-ee17-4d8f-832c-85ba8b82e973,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-75e05906-c515-4ff0-bc24-6d04cc64dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-4e119b50-a2f6-4460-835d-ab5cf1b36069,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-75607667-1006-4ded-b5e2-287aa7481fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-a41cbf17-d13e-4c6b-a8ba-be84d958817b,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-6da63a9d-8ece-4892-b8b0-62bfe838b75b,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-dc887d0b-b125-4095-b6dd-53e8e549e3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-f9a6aa5d-9016-413a-af06-89788bebe498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1301575097-172.17.0.2-1597148785921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44678,DS-7c245b49-ee17-4d8f-832c-85ba8b82e973,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-75e05906-c515-4ff0-bc24-6d04cc64dd20,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-4e119b50-a2f6-4460-835d-ab5cf1b36069,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-75607667-1006-4ded-b5e2-287aa7481fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-a41cbf17-d13e-4c6b-a8ba-be84d958817b,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-6da63a9d-8ece-4892-b8b0-62bfe838b75b,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-dc887d0b-b125-4095-b6dd-53e8e549e3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-f9a6aa5d-9016-413a-af06-89788bebe498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039510145-172.17.0.2-1597149381077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-ac635884-4f1f-457c-96d6-b77c20958f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-41f903a6-3409-49ed-a407-57de253099ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-2687a9a8-3565-4951-baac-2c18c62e02dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-71ae2416-12f1-4cc2-8632-670ecaacb30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-4951b520-d47d-4e8d-99b4-d329258b07b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-616d4e78-f45f-4fc6-b3a7-bec5453f6ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-560046fb-5af4-418c-a5c5-185834fa3341,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-ef65c9a4-0ec0-4e1c-95c2-8794d7fa3127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039510145-172.17.0.2-1597149381077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41528,DS-ac635884-4f1f-457c-96d6-b77c20958f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-41f903a6-3409-49ed-a407-57de253099ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-2687a9a8-3565-4951-baac-2c18c62e02dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34310,DS-71ae2416-12f1-4cc2-8632-670ecaacb30a,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-4951b520-d47d-4e8d-99b4-d329258b07b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-616d4e78-f45f-4fc6-b3a7-bec5453f6ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-560046fb-5af4-418c-a5c5-185834fa3341,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-ef65c9a4-0ec0-4e1c-95c2-8794d7fa3127,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463236328-172.17.0.2-1597149418585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35178,DS-8e57afec-d60c-4d1c-9f9b-0ec1e62fecf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-ec2cabe9-093b-4fb8-a03b-51efb9b9ee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-47f5fcc3-6061-4105-bff7-e0a75c5e06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-ed8ee7f6-9af1-4cbe-9f25-4b0eb7c24675,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-46a527b2-d016-4a95-93a8-3d44eda1dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-8aab17b8-5bc6-40af-82cd-9bfc856cf108,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-fdbfc176-f05a-42fa-a085-81e1690787b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-3f19eca7-1401-40e5-bd58-ccb697d9ea3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463236328-172.17.0.2-1597149418585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35178,DS-8e57afec-d60c-4d1c-9f9b-0ec1e62fecf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-ec2cabe9-093b-4fb8-a03b-51efb9b9ee6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-47f5fcc3-6061-4105-bff7-e0a75c5e06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-ed8ee7f6-9af1-4cbe-9f25-4b0eb7c24675,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-46a527b2-d016-4a95-93a8-3d44eda1dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-8aab17b8-5bc6-40af-82cd-9bfc856cf108,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-fdbfc176-f05a-42fa-a085-81e1690787b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-3f19eca7-1401-40e5-bd58-ccb697d9ea3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529788761-172.17.0.2-1597149458736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37945,DS-e38ca9a0-902a-41e5-9a04-37366f4731b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-d70449c2-c20b-4f0f-85b6-e11ecd18a950,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-826b9990-f860-4056-ae38-396ced7c028a,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-cf263d53-fa41-4629-b2e6-ddb49b062bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-cba6a711-af16-4e9d-8ae5-4a8e80db7fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-365a7d30-3a21-4bb6-843e-1b5391cfa7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-0b4ecb2e-6334-4f3a-be58-4880fe456da8,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-22ea2fce-d65a-4d3d-a31c-62f0eac49db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-529788761-172.17.0.2-1597149458736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37945,DS-e38ca9a0-902a-41e5-9a04-37366f4731b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34674,DS-d70449c2-c20b-4f0f-85b6-e11ecd18a950,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-826b9990-f860-4056-ae38-396ced7c028a,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-cf263d53-fa41-4629-b2e6-ddb49b062bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-cba6a711-af16-4e9d-8ae5-4a8e80db7fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-365a7d30-3a21-4bb6-843e-1b5391cfa7d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-0b4ecb2e-6334-4f3a-be58-4880fe456da8,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-22ea2fce-d65a-4d3d-a31c-62f0eac49db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.threads
component: hdfs:NameNode
v1: 2000
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518413701-172.17.0.2-1597149544597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-6e473957-f8ab-4866-a586-aac04f714041,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-f342509a-44bd-43e3-b41d-3d0d8bfae21c,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-d6b0750d-6137-4a9c-a4e7-b8a3597062cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-0f0c4265-0fec-4120-bf0f-2de0537c9d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-280680ae-25d5-44bb-ad2e-f209ef2329ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-022b8af8-b8f7-460d-8b2d-03e909879bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-c86caca3-a73f-40aa-9e5f-3465c2fa233d,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-57607839-b81a-4a20-b881-7aeb2a9563e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-518413701-172.17.0.2-1597149544597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44378,DS-6e473957-f8ab-4866-a586-aac04f714041,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-f342509a-44bd-43e3-b41d-3d0d8bfae21c,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-d6b0750d-6137-4a9c-a4e7-b8a3597062cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-0f0c4265-0fec-4120-bf0f-2de0537c9d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-280680ae-25d5-44bb-ad2e-f209ef2329ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-022b8af8-b8f7-460d-8b2d-03e909879bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-c86caca3-a73f-40aa-9e5f-3465c2fa233d,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-57607839-b81a-4a20-b881-7aeb2a9563e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6998
