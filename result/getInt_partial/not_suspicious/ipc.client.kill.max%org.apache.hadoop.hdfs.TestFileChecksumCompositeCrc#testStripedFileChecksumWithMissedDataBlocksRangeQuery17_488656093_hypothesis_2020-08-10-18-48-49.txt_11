reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225349757-172.17.0.6-1597085472336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-0c495690-76e0-4df6-bc30-9c0947f3b522,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-868bf019-7859-4729-98c3-32ff64a97596,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-84f1dc4b-e202-40ac-b953-7157aba57254,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-675c1086-5187-445d-b5bb-4890914d1a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-c9b54b2e-0f3c-44ee-8bbb-42cc05d41e56,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-2c4b541a-d96f-4377-a513-41f177ad064d,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-fca5d3ee-68a7-441a-8cc1-d9cd5f433e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-e109f7a2-c49f-42c5-b398-6e0b57698fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-225349757-172.17.0.6-1597085472336:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42406,DS-0c495690-76e0-4df6-bc30-9c0947f3b522,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-868bf019-7859-4729-98c3-32ff64a97596,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-84f1dc4b-e202-40ac-b953-7157aba57254,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-675c1086-5187-445d-b5bb-4890914d1a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-c9b54b2e-0f3c-44ee-8bbb-42cc05d41e56,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-2c4b541a-d96f-4377-a513-41f177ad064d,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-fca5d3ee-68a7-441a-8cc1-d9cd5f433e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-e109f7a2-c49f-42c5-b398-6e0b57698fd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1417733665-172.17.0.6-1597085897372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-d8cdc867-aa43-4aa8-b93b-d817ba0ac728,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-4155c1cc-0b65-4f48-940c-a408c59d1959,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-986bddab-fe38-4b4b-8c96-ca734e9eb901,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c1753d50-495f-4140-acac-fbb58cd528b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-876cb56d-0ee7-4da8-99d8-312ee13895c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-1b5a5a32-3aaf-4941-95b1-d59b7ef97997,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-69c85433-e901-4668-a838-b407f1db2b00,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-644f9fcf-f9a3-4566-bfb5-eb2cbf3f2efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1417733665-172.17.0.6-1597085897372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-d8cdc867-aa43-4aa8-b93b-d817ba0ac728,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-4155c1cc-0b65-4f48-940c-a408c59d1959,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-986bddab-fe38-4b4b-8c96-ca734e9eb901,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-c1753d50-495f-4140-acac-fbb58cd528b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45459,DS-876cb56d-0ee7-4da8-99d8-312ee13895c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-1b5a5a32-3aaf-4941-95b1-d59b7ef97997,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-69c85433-e901-4668-a838-b407f1db2b00,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-644f9fcf-f9a3-4566-bfb5-eb2cbf3f2efc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518625819-172.17.0.6-1597086108822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-c8550ccd-3861-470f-9136-ea06025c55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-3424787c-4bfa-4082-a1e8-8fdeb1aaf136,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-3b0d871a-16a4-46da-bdb2-9846f804115d,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-a52a2b7c-62ba-4748-866a-08b747930259,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-87af0384-6be3-4a68-890a-0736b307faba,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-f793ab9f-9b7c-4815-ba81-9580ab0fab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-42364c9e-0eab-4fc2-831f-80d5c0776bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-7c7cbe8d-dc62-491a-bed0-bb1aabb2bbd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518625819-172.17.0.6-1597086108822:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40826,DS-c8550ccd-3861-470f-9136-ea06025c55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-3424787c-4bfa-4082-a1e8-8fdeb1aaf136,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-3b0d871a-16a4-46da-bdb2-9846f804115d,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-a52a2b7c-62ba-4748-866a-08b747930259,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-87af0384-6be3-4a68-890a-0736b307faba,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-f793ab9f-9b7c-4815-ba81-9580ab0fab7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39598,DS-42364c9e-0eab-4fc2-831f-80d5c0776bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38000,DS-7c7cbe8d-dc62-491a-bed0-bb1aabb2bbd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626556075-172.17.0.6-1597086650080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-fd0b3908-ecef-4307-ac25-664acc50ee9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-3f0dc8a1-3fd1-4fb9-ac01-091d5dad5451,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-10eb0be1-24fc-420e-8982-9812c2d48029,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-df80ead8-7c44-40dc-a800-9c602def32de,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-0ac772be-ed66-41f6-adbe-4ca59494a590,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-e7988f44-391d-435f-a0af-e4a0538cf708,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-9bdda200-e162-4250-9dc3-3c3363eeac5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-7e7d81df-29c4-4f06-9115-35316e4fc25b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-626556075-172.17.0.6-1597086650080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45528,DS-fd0b3908-ecef-4307-ac25-664acc50ee9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-3f0dc8a1-3fd1-4fb9-ac01-091d5dad5451,DISK], DatanodeInfoWithStorage[127.0.0.1:34684,DS-10eb0be1-24fc-420e-8982-9812c2d48029,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-df80ead8-7c44-40dc-a800-9c602def32de,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-0ac772be-ed66-41f6-adbe-4ca59494a590,DISK], DatanodeInfoWithStorage[127.0.0.1:41151,DS-e7988f44-391d-435f-a0af-e4a0538cf708,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-9bdda200-e162-4250-9dc3-3c3363eeac5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-7e7d81df-29c4-4f06-9115-35316e4fc25b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842605503-172.17.0.6-1597087880999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-e4c741da-9385-4e53-b2e9-9836f46e17a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-d8ae4ef9-d6a5-4abe-bce8-b60ffde02aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-10325b46-af5a-41af-a0d3-77c0c1c52b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-d4e59a46-cbe7-4500-89d8-15b4cb0a24c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-7ec8bbf6-0df5-4a25-84bc-1142baaefedd,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-36805461-632e-408b-9c05-ec8d94b0b873,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-8168e569-2f07-4102-b220-0723a24def01,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-ee0cd6b2-a92e-4c33-836d-a52dbc956991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842605503-172.17.0.6-1597087880999:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-e4c741da-9385-4e53-b2e9-9836f46e17a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-d8ae4ef9-d6a5-4abe-bce8-b60ffde02aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-10325b46-af5a-41af-a0d3-77c0c1c52b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-d4e59a46-cbe7-4500-89d8-15b4cb0a24c4,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-7ec8bbf6-0df5-4a25-84bc-1142baaefedd,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-36805461-632e-408b-9c05-ec8d94b0b873,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-8168e569-2f07-4102-b220-0723a24def01,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-ee0cd6b2-a92e-4c33-836d-a52dbc956991,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11255589-172.17.0.6-1597088323900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-c98bfd53-4dba-47e1-b987-41b21f5de458,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-71e9f1d7-0dc0-4a14-878e-9aa7482ebc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-7a2e9e00-4a44-46b7-8116-f857da549207,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-84d0cb46-312d-43a9-9422-1cacd6c4de14,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-8a992b82-ce4f-498a-a2c7-583f42ecd6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-1d691fb2-6de4-46e0-bc59-2996eb3855d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-bf83dfe6-687f-41bb-8ab8-c21103dad055,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-36349af4-9632-4f85-b074-75fe23a87af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11255589-172.17.0.6-1597088323900:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-c98bfd53-4dba-47e1-b987-41b21f5de458,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-71e9f1d7-0dc0-4a14-878e-9aa7482ebc5c,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-7a2e9e00-4a44-46b7-8116-f857da549207,DISK], DatanodeInfoWithStorage[127.0.0.1:33358,DS-84d0cb46-312d-43a9-9422-1cacd6c4de14,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-8a992b82-ce4f-498a-a2c7-583f42ecd6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-1d691fb2-6de4-46e0-bc59-2996eb3855d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-bf83dfe6-687f-41bb-8ab8-c21103dad055,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-36349af4-9632-4f85-b074-75fe23a87af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008340946-172.17.0.6-1597088357237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34162,DS-ed61f662-a64d-426a-ba38-e04aa7531179,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-f2154ccb-453c-415b-a49d-4382002940f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-2fd12c11-60fd-4877-b660-2eedc74d111d,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-13ebdbc7-aa87-477b-8ee1-92db6fb96d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-44b26c6a-62ff-4e70-952d-a1f333fede73,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-8f5277a8-9390-4c78-b626-ffe3a2a8751c,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-8b03e9c7-c224-4810-828a-99fa87e14d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-9c56ad74-2b52-4180-ba2e-90e47a09bc65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008340946-172.17.0.6-1597088357237:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34162,DS-ed61f662-a64d-426a-ba38-e04aa7531179,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-f2154ccb-453c-415b-a49d-4382002940f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-2fd12c11-60fd-4877-b660-2eedc74d111d,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-13ebdbc7-aa87-477b-8ee1-92db6fb96d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-44b26c6a-62ff-4e70-952d-a1f333fede73,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-8f5277a8-9390-4c78-b626-ffe3a2a8751c,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-8b03e9c7-c224-4810-828a-99fa87e14d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42699,DS-9c56ad74-2b52-4180-ba2e-90e47a09bc65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043435635-172.17.0.6-1597088846448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32945,DS-205ddd5f-7f57-4668-ab54-9eeebaeb8e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-3ab937e6-c3f5-4017-81e7-7c5b77448892,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-9f79cc07-84a9-4af6-a930-49d840b48fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-da208b75-eb8c-4bb5-b500-93b012235958,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-15914cb6-ac8d-4975-95ee-1ea723252898,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-edbc2c9e-3157-4f4a-ad23-e13341d19994,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-bddd008e-de33-41b9-a5bd-c1787f9cdf00,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-450b52b9-25d4-441e-bf8f-16b34e5a8bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043435635-172.17.0.6-1597088846448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32945,DS-205ddd5f-7f57-4668-ab54-9eeebaeb8e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-3ab937e6-c3f5-4017-81e7-7c5b77448892,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-9f79cc07-84a9-4af6-a930-49d840b48fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-da208b75-eb8c-4bb5-b500-93b012235958,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-15914cb6-ac8d-4975-95ee-1ea723252898,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-edbc2c9e-3157-4f4a-ad23-e13341d19994,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-bddd008e-de33-41b9-a5bd-c1787f9cdf00,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-450b52b9-25d4-441e-bf8f-16b34e5a8bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000449358-172.17.0.6-1597089111626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-f5c2758f-4154-4f5f-a97d-7d99c6aeb91b,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-80dc444f-8b02-4e17-b15c-dd1b5abbccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-9cbfaf2f-4414-4bda-aeb2-681a7b62ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-0ef50fe6-11de-4e06-aec8-8ca35e8f981f,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-aaffcb45-7ff3-4e71-b0c7-63568aa73bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-417586ba-4438-4565-a1ff-d6d738166131,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-bd2a553f-7911-40e1-b831-441e44efe9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-73265a5c-2e9b-4a9f-ae1e-8e978745525a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1000449358-172.17.0.6-1597089111626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34835,DS-f5c2758f-4154-4f5f-a97d-7d99c6aeb91b,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-80dc444f-8b02-4e17-b15c-dd1b5abbccfe,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-9cbfaf2f-4414-4bda-aeb2-681a7b62ab54,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-0ef50fe6-11de-4e06-aec8-8ca35e8f981f,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-aaffcb45-7ff3-4e71-b0c7-63568aa73bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-417586ba-4438-4565-a1ff-d6d738166131,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-bd2a553f-7911-40e1-b831-441e44efe9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-73265a5c-2e9b-4a9f-ae1e-8e978745525a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636517949-172.17.0.6-1597089330545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42120,DS-302e2ba7-24e1-468b-9a62-6ce49d64940c,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-db8a1996-7b9d-4b01-9261-f4441046ba47,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-0e0613ea-bdab-4a51-bbf7-729af81de11f,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-e2afaeb7-e998-4864-854f-fae2efa39c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-3f600a5b-f94d-45b7-a971-2a9e99b3615b,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-be7df530-7491-4785-b855-00cbf130dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-55f1a842-6df9-4d78-ab96-b9fbc690f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-51a1c1f9-f4fa-4a92-97fa-cd8beea9fad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636517949-172.17.0.6-1597089330545:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42120,DS-302e2ba7-24e1-468b-9a62-6ce49d64940c,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-db8a1996-7b9d-4b01-9261-f4441046ba47,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-0e0613ea-bdab-4a51-bbf7-729af81de11f,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-e2afaeb7-e998-4864-854f-fae2efa39c26,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-3f600a5b-f94d-45b7-a971-2a9e99b3615b,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-be7df530-7491-4785-b855-00cbf130dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-55f1a842-6df9-4d78-ab96-b9fbc690f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-51a1c1f9-f4fa-4a92-97fa-cd8beea9fad3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641207642-172.17.0.6-1597089519244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33130,DS-a164b59a-eebd-44cb-bb14-12d49d1c4f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-591dd950-241d-462f-ae81-bc7b44277197,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-3af20f64-d173-4fd1-b405-3a0924100b59,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-f43475ba-cde9-4ae4-8981-a98b3cb29a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-9b220324-66fd-4f33-8f0e-e124fa1f5733,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-a2e60d2d-e2e8-40a9-801e-b09066b38065,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-8e39a2f8-a1b3-48c1-ac9b-9c606ef41445,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-6756c9db-3bc3-47bf-bede-4300496a2a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641207642-172.17.0.6-1597089519244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33130,DS-a164b59a-eebd-44cb-bb14-12d49d1c4f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-591dd950-241d-462f-ae81-bc7b44277197,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-3af20f64-d173-4fd1-b405-3a0924100b59,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-f43475ba-cde9-4ae4-8981-a98b3cb29a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-9b220324-66fd-4f33-8f0e-e124fa1f5733,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-a2e60d2d-e2e8-40a9-801e-b09066b38065,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-8e39a2f8-a1b3-48c1-ac9b-9c606ef41445,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-6756c9db-3bc3-47bf-bede-4300496a2a56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385013071-172.17.0.6-1597089807578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34095,DS-98f6c21b-2065-499e-8a4c-5e62d8cc53ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-1484d9fb-7c51-444d-a5a9-c75abae610f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-3a3e0f90-962c-4b66-84a8-98353ad925c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-18d270ca-c0ea-4562-8a86-a1e99cf62223,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-57ae6fe3-bfa1-47a0-8044-ab148d7bac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-a6d09200-5f2d-4cf6-a9d9-667d8f1c1f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e0419ba7-8a8a-4cd4-904a-b582373801a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-5e1992dd-b342-419f-b54e-c61749fa3298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-385013071-172.17.0.6-1597089807578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34095,DS-98f6c21b-2065-499e-8a4c-5e62d8cc53ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-1484d9fb-7c51-444d-a5a9-c75abae610f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-3a3e0f90-962c-4b66-84a8-98353ad925c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-18d270ca-c0ea-4562-8a86-a1e99cf62223,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-57ae6fe3-bfa1-47a0-8044-ab148d7bac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-a6d09200-5f2d-4cf6-a9d9-667d8f1c1f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e0419ba7-8a8a-4cd4-904a-b582373801a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-5e1992dd-b342-419f-b54e-c61749fa3298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113771096-172.17.0.6-1597089949763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-85f87923-ba5c-428e-834e-81bccc71985b,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-9b29ab7d-c8a5-43a1-8cf7-f9b9669081c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-da9264a4-a304-4a4a-9de0-5f355edb16cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-b9458320-930d-4ea0-8f8e-560cd612b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-68f64598-fa15-4297-b8d8-c9705d411d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-db980816-bb35-48ab-9880-d93a503f400f,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-5191973b-a597-4a57-8b65-f47c8ff5e31b,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-becc8803-f3a6-44ce-9ee0-c581b392363c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113771096-172.17.0.6-1597089949763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33468,DS-85f87923-ba5c-428e-834e-81bccc71985b,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-9b29ab7d-c8a5-43a1-8cf7-f9b9669081c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-da9264a4-a304-4a4a-9de0-5f355edb16cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-b9458320-930d-4ea0-8f8e-560cd612b6a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-68f64598-fa15-4297-b8d8-c9705d411d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-db980816-bb35-48ab-9880-d93a503f400f,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-5191973b-a597-4a57-8b65-f47c8ff5e31b,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-becc8803-f3a6-44ce-9ee0-c581b392363c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119816576-172.17.0.6-1597090101071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-df3a711a-f7c8-48f0-89b4-29c84209517e,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-14135b0c-e68f-4953-9703-95f8f345309c,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-2b24f096-b95f-4ba8-a50b-e2d88a0851e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-e57115b3-f218-4cf0-be1a-04efdaa71776,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-9ea489be-3dbf-4b32-90e4-b33926ce2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-251d77ac-f558-422b-acb2-61bb69c6988b,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-695511ce-1af9-486e-9013-0e5d8b337538,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-41c0ab3c-ba78-4f56-8240-6fa7be95b6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119816576-172.17.0.6-1597090101071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-df3a711a-f7c8-48f0-89b4-29c84209517e,DISK], DatanodeInfoWithStorage[127.0.0.1:46844,DS-14135b0c-e68f-4953-9703-95f8f345309c,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-2b24f096-b95f-4ba8-a50b-e2d88a0851e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-e57115b3-f218-4cf0-be1a-04efdaa71776,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-9ea489be-3dbf-4b32-90e4-b33926ce2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42927,DS-251d77ac-f558-422b-acb2-61bb69c6988b,DISK], DatanodeInfoWithStorage[127.0.0.1:39008,DS-695511ce-1af9-486e-9013-0e5d8b337538,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-41c0ab3c-ba78-4f56-8240-6fa7be95b6c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5381
