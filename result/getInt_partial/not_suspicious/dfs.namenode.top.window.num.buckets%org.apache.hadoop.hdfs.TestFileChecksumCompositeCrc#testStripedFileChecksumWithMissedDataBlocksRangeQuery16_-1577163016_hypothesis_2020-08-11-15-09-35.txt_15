reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-258171935-172.17.0.11-1597158635262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33352,DS-2da4b856-4b1e-4545-a534-8d314eb42fba,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-8b697e2b-73e2-43f1-a8bb-897b9a133d31,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-9d6060b6-0108-4453-9892-ed47c759a028,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-41d26cc2-8e31-4574-9ac8-14b29d64e759,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-f60afc1d-9422-4f97-a656-7003bf63bcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-02225324-bc21-4e43-abaf-9eaac5be2bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-f1b356b0-306c-4bb6-9f42-98b626f3640c,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-89d4ace9-a684-4cee-b3d7-1475228d11e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-258171935-172.17.0.11-1597158635262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33352,DS-2da4b856-4b1e-4545-a534-8d314eb42fba,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-8b697e2b-73e2-43f1-a8bb-897b9a133d31,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-9d6060b6-0108-4453-9892-ed47c759a028,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-41d26cc2-8e31-4574-9ac8-14b29d64e759,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-f60afc1d-9422-4f97-a656-7003bf63bcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-02225324-bc21-4e43-abaf-9eaac5be2bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-f1b356b0-306c-4bb6-9f42-98b626f3640c,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-89d4ace9-a684-4cee-b3d7-1475228d11e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035136607-172.17.0.11-1597158675306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40695,DS-ebba82b0-7464-4924-868e-64c0065cf37f,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-8205b3d2-4059-4d69-b7cf-bd5766540f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-7f2abb86-699f-4d84-9e42-665742044541,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-474c5f63-e46f-4989-b88a-49f7ff68d718,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-d93fd979-765f-427f-9201-3cbfb176571a,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-87f3d84f-4586-4599-8cfe-273b938f7616,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-fba77f68-8de2-498f-9911-84c013194967,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-83069de1-5cff-40e7-a9f5-fc90ec7af45b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035136607-172.17.0.11-1597158675306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40695,DS-ebba82b0-7464-4924-868e-64c0065cf37f,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-8205b3d2-4059-4d69-b7cf-bd5766540f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-7f2abb86-699f-4d84-9e42-665742044541,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-474c5f63-e46f-4989-b88a-49f7ff68d718,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-d93fd979-765f-427f-9201-3cbfb176571a,DISK], DatanodeInfoWithStorage[127.0.0.1:45974,DS-87f3d84f-4586-4599-8cfe-273b938f7616,DISK], DatanodeInfoWithStorage[127.0.0.1:38296,DS-fba77f68-8de2-498f-9911-84c013194967,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-83069de1-5cff-40e7-a9f5-fc90ec7af45b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8633914-172.17.0.11-1597158802427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-45d538d5-592d-4df2-8a66-32865fe507c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-0dd60964-1bff-46c7-bc6f-5759645c4e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-0a7c498d-6add-4d77-9d55-e3b3e8bb3ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-3e02c7cf-1f4c-4d6f-a2c5-3cff22d49685,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-d032ae46-f64b-4a15-bc69-d71ed36cf529,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-d5a138ef-38da-4630-944f-938b28cfe0da,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-eeba5372-de6f-495b-b3a1-c009fe7564e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-47a6b3b1-b443-442d-bcce-3d9812b4b0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8633914-172.17.0.11-1597158802427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-45d538d5-592d-4df2-8a66-32865fe507c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-0dd60964-1bff-46c7-bc6f-5759645c4e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-0a7c498d-6add-4d77-9d55-e3b3e8bb3ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-3e02c7cf-1f4c-4d6f-a2c5-3cff22d49685,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-d032ae46-f64b-4a15-bc69-d71ed36cf529,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-d5a138ef-38da-4630-944f-938b28cfe0da,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-eeba5372-de6f-495b-b3a1-c009fe7564e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-47a6b3b1-b443-442d-bcce-3d9812b4b0cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069037959-172.17.0.11-1597159470128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-d7ed8108-78f7-4d9e-8d37-f2c88c6b552b,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-a409843d-b0e4-4473-a791-ac13dd26f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-7f1eb220-6590-4137-adb3-01c5e85f5313,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-6591a018-4965-469c-972b-b9c5f9aee62f,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-925d7c60-ee33-4875-9697-c22ce1caff39,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-074a16ef-3f10-40f6-84bf-c9575e79f759,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-1b7bc9c0-35aa-4a80-b205-b6dfd233107a,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-a5433e02-c6ef-427e-87d0-81a8ca0d2bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069037959-172.17.0.11-1597159470128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-d7ed8108-78f7-4d9e-8d37-f2c88c6b552b,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-a409843d-b0e4-4473-a791-ac13dd26f26c,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-7f1eb220-6590-4137-adb3-01c5e85f5313,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-6591a018-4965-469c-972b-b9c5f9aee62f,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-925d7c60-ee33-4875-9697-c22ce1caff39,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-074a16ef-3f10-40f6-84bf-c9575e79f759,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-1b7bc9c0-35aa-4a80-b205-b6dfd233107a,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-a5433e02-c6ef-427e-87d0-81a8ca0d2bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966557645-172.17.0.11-1597159544001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34779,DS-87d0534a-0bff-43e2-8655-b4a508b96edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-065470da-1e81-4d28-8903-ccacbc048973,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-a54ba8a8-d16a-411c-b0a0-1fbf5d2ae050,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-6f5c4a1f-93ca-42cf-8b47-c037c9c9aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-7579e4ce-967f-4a15-b67f-1d7a61925515,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-4c6bce36-6bea-49be-9968-26ffc4d85166,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-94261048-b63c-4475-afe0-edff34f5827f,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-ec6acf37-4bca-436a-a98e-aea6ff88fa88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966557645-172.17.0.11-1597159544001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34779,DS-87d0534a-0bff-43e2-8655-b4a508b96edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-065470da-1e81-4d28-8903-ccacbc048973,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-a54ba8a8-d16a-411c-b0a0-1fbf5d2ae050,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-6f5c4a1f-93ca-42cf-8b47-c037c9c9aae9,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-7579e4ce-967f-4a15-b67f-1d7a61925515,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-4c6bce36-6bea-49be-9968-26ffc4d85166,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-94261048-b63c-4475-afe0-edff34f5827f,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-ec6acf37-4bca-436a-a98e-aea6ff88fa88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22909835-172.17.0.11-1597159634200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33667,DS-e687e17f-b1c4-4ccf-be3c-de598190d818,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-2a3d5fab-7937-4959-9087-68f3a733e916,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-47fd540b-833b-4670-a220-88cd5acb09be,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-f4b7d95a-58eb-48e5-a3ce-4984df860bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-a971cc57-b736-49fd-b9fc-79f837a2050c,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-1ce81c5d-e729-40ad-92db-e7097088d32a,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-f9426f18-5857-471a-9e0a-b2990befb69d,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-fe14bb42-efb3-4609-90b6-c7bcd3a2cff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22909835-172.17.0.11-1597159634200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33667,DS-e687e17f-b1c4-4ccf-be3c-de598190d818,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-2a3d5fab-7937-4959-9087-68f3a733e916,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-47fd540b-833b-4670-a220-88cd5acb09be,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-f4b7d95a-58eb-48e5-a3ce-4984df860bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-a971cc57-b736-49fd-b9fc-79f837a2050c,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-1ce81c5d-e729-40ad-92db-e7097088d32a,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-f9426f18-5857-471a-9e0a-b2990befb69d,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-fe14bb42-efb3-4609-90b6-c7bcd3a2cff6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866529428-172.17.0.11-1597159936701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41489,DS-7e5cfa8f-c23f-4f06-b9b5-83a5d39448eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-81a26875-21e4-4949-90ee-15aa8861ba80,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-cfd270b3-0e71-42c9-b16c-81acfa145f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-6b14f182-29c2-4f4a-86ec-6cb338964556,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-0bbf57d0-81cf-4b48-9685-25968bf74113,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-c3408014-5be2-4a72-8de3-c2dbccb3870f,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-c289c4e8-bd43-40f6-947b-fa4190af79ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-1527565d-64cc-4c68-b556-91f6a37b3e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1866529428-172.17.0.11-1597159936701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41489,DS-7e5cfa8f-c23f-4f06-b9b5-83a5d39448eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-81a26875-21e4-4949-90ee-15aa8861ba80,DISK], DatanodeInfoWithStorage[127.0.0.1:42527,DS-cfd270b3-0e71-42c9-b16c-81acfa145f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-6b14f182-29c2-4f4a-86ec-6cb338964556,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-0bbf57d0-81cf-4b48-9685-25968bf74113,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-c3408014-5be2-4a72-8de3-c2dbccb3870f,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-c289c4e8-bd43-40f6-947b-fa4190af79ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-1527565d-64cc-4c68-b556-91f6a37b3e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352211515-172.17.0.11-1597160107051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-da5bf565-6c57-4870-a73e-65e3fee871f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-0a05af69-d2b1-4211-a295-7502d531f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-c423371e-4e77-4c8a-b8f1-9c4e24f5128f,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-3ad07e61-9ba7-4aec-809f-307c5de4f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-5719a7ed-9892-42e3-ba8b-8a94875becae,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-942eefe6-11c0-491f-93a0-33906701c038,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-96bfeed1-68aa-4a1c-9496-89ea80f70efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-6bc3d4a8-030c-4513-98bc-ce2a021ba0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352211515-172.17.0.11-1597160107051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42354,DS-da5bf565-6c57-4870-a73e-65e3fee871f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-0a05af69-d2b1-4211-a295-7502d531f7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46320,DS-c423371e-4e77-4c8a-b8f1-9c4e24f5128f,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-3ad07e61-9ba7-4aec-809f-307c5de4f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-5719a7ed-9892-42e3-ba8b-8a94875becae,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-942eefe6-11c0-491f-93a0-33906701c038,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-96bfeed1-68aa-4a1c-9496-89ea80f70efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-6bc3d4a8-030c-4513-98bc-ce2a021ba0b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161759824-172.17.0.11-1597160242454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41643,DS-037d99af-8791-4f9e-8655-5dd50bf34766,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-724d17af-65a5-4202-a5b2-4c0a949740d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-89f26daf-60da-4697-9ff0-44114c328945,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-679a283e-46a0-4dcf-a4b6-df187d40d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-20bc59b1-3b70-4e2d-b2f6-19b5d03fdf39,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-4fb71654-e303-46ac-9d7d-26ad3f11eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-469a77db-db32-4d48-affc-46b8e2a9808d,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-69e9a27c-febe-40f5-b5dd-d1d4ca0be2c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161759824-172.17.0.11-1597160242454:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41643,DS-037d99af-8791-4f9e-8655-5dd50bf34766,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-724d17af-65a5-4202-a5b2-4c0a949740d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-89f26daf-60da-4697-9ff0-44114c328945,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-679a283e-46a0-4dcf-a4b6-df187d40d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-20bc59b1-3b70-4e2d-b2f6-19b5d03fdf39,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-4fb71654-e303-46ac-9d7d-26ad3f11eee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-469a77db-db32-4d48-affc-46b8e2a9808d,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-69e9a27c-febe-40f5-b5dd-d1d4ca0be2c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554289500-172.17.0.11-1597160372407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-577d9677-87a5-4f2e-a6de-5184215983fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-ee85325b-d592-4bcd-91dd-4ab45180b264,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-026adcc1-76a0-45e5-a91c-ee4e6971a80d,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-f3a2790e-e91a-43a2-8835-259ce2067c65,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-63e990f0-d0ef-42e7-ae93-ace7445f2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-612b4d21-8828-4824-a609-64e275361aad,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-74f510db-6a2d-4a11-9759-c7bf211b258b,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-14fc805a-397c-4b16-83da-d095e76f74dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554289500-172.17.0.11-1597160372407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44451,DS-577d9677-87a5-4f2e-a6de-5184215983fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-ee85325b-d592-4bcd-91dd-4ab45180b264,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-026adcc1-76a0-45e5-a91c-ee4e6971a80d,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-f3a2790e-e91a-43a2-8835-259ce2067c65,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-63e990f0-d0ef-42e7-ae93-ace7445f2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-612b4d21-8828-4824-a609-64e275361aad,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-74f510db-6a2d-4a11-9759-c7bf211b258b,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-14fc805a-397c-4b16-83da-d095e76f74dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119969134-172.17.0.11-1597160535366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-d38d229a-1997-4e2a-8cca-8ac0a42f86b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-81db2118-7b90-4ecc-9e34-a92a163e7b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-5a59ca28-124d-4237-b225-989190ff9989,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-c80c3e46-7826-49a0-8838-28c3f6c42eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-10b065a1-2858-4f86-966c-2c3b9aaec280,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-0b91d4f4-0fd8-4c64-b7b1-013a32d1fa46,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1c28043d-d699-4e95-ba87-73c5383bb322,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-b8aea9de-fe49-498b-bfdb-f49e517678ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1119969134-172.17.0.11-1597160535366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37058,DS-d38d229a-1997-4e2a-8cca-8ac0a42f86b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-81db2118-7b90-4ecc-9e34-a92a163e7b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-5a59ca28-124d-4237-b225-989190ff9989,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-c80c3e46-7826-49a0-8838-28c3f6c42eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-10b065a1-2858-4f86-966c-2c3b9aaec280,DISK], DatanodeInfoWithStorage[127.0.0.1:38560,DS-0b91d4f4-0fd8-4c64-b7b1-013a32d1fa46,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-1c28043d-d699-4e95-ba87-73c5383bb322,DISK], DatanodeInfoWithStorage[127.0.0.1:37082,DS-b8aea9de-fe49-498b-bfdb-f49e517678ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613738229-172.17.0.11-1597160919512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-8169bee8-6124-4244-818c-2c261220ad40,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-2338c3b7-bc1b-4ef3-8041-e22057866719,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-f79f4ff7-c6cf-4eaa-b427-77e11db27f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-a42ec55b-3d0d-4dec-92bd-b7722d3f3465,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-4a2bf432-56aa-4f6a-a0e6-df1bdef0dbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-c0fe73f2-bd15-4086-8dc5-6d0e2462acb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-fe4d1487-5f15-4b4c-8b6f-44f80565c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-89c76b6e-8a52-4ed7-bfa0-d07b98500cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613738229-172.17.0.11-1597160919512:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-8169bee8-6124-4244-818c-2c261220ad40,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-2338c3b7-bc1b-4ef3-8041-e22057866719,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-f79f4ff7-c6cf-4eaa-b427-77e11db27f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-a42ec55b-3d0d-4dec-92bd-b7722d3f3465,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-4a2bf432-56aa-4f6a-a0e6-df1bdef0dbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-c0fe73f2-bd15-4086-8dc5-6d0e2462acb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-fe4d1487-5f15-4b4c-8b6f-44f80565c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-89c76b6e-8a52-4ed7-bfa0-d07b98500cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053330149-172.17.0.11-1597161008813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42021,DS-97ab8b46-5af6-4b58-980a-0e4b6811e198,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-493a2061-118e-42aa-ab6b-075efd05793c,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-7e729e08-c0c2-425b-b79f-f2d4b7b71740,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-71c55ae8-bbe7-4e05-9e9b-9a06c2aeecd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-6316a771-c0d9-42c3-b114-2e74cdb94e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-fd1e20e0-2384-4684-9011-a6d36125f869,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-83ee2a6c-b53d-48a8-8053-a9a257471e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-d9d1914c-f220-427e-bded-21551e0bd39c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2053330149-172.17.0.11-1597161008813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42021,DS-97ab8b46-5af6-4b58-980a-0e4b6811e198,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-493a2061-118e-42aa-ab6b-075efd05793c,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-7e729e08-c0c2-425b-b79f-f2d4b7b71740,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-71c55ae8-bbe7-4e05-9e9b-9a06c2aeecd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-6316a771-c0d9-42c3-b114-2e74cdb94e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-fd1e20e0-2384-4684-9011-a6d36125f869,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-83ee2a6c-b53d-48a8-8053-a9a257471e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-d9d1914c-f220-427e-bded-21551e0bd39c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499851795-172.17.0.11-1597162706966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40892,DS-87874c56-09a6-48ed-8501-04d226f5ba86,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-7489bb08-1831-43a5-87e2-36da0f11fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-aa5e560e-c394-4dd7-bc75-706916f5dba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-0bffd5d0-6b13-407b-a620-591f2c7d83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-b60c967b-e11e-4c20-b985-50ee97e2f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-ea6fa70c-214f-4124-a8bf-aa2f985914ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-5ad18ba0-c059-48c2-8cba-4bbeeb0497e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-e043582e-8cf1-4962-bd6f-228d95fc317f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-499851795-172.17.0.11-1597162706966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40892,DS-87874c56-09a6-48ed-8501-04d226f5ba86,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-7489bb08-1831-43a5-87e2-36da0f11fed8,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-aa5e560e-c394-4dd7-bc75-706916f5dba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-0bffd5d0-6b13-407b-a620-591f2c7d83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-b60c967b-e11e-4c20-b985-50ee97e2f4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-ea6fa70c-214f-4124-a8bf-aa2f985914ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-5ad18ba0-c059-48c2-8cba-4bbeeb0497e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-e043582e-8cf1-4962-bd6f-228d95fc317f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535195054-172.17.0.11-1597162791064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42116,DS-05e7a48a-fb6e-4053-b112-fc63c3418085,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-a002ba53-4851-496f-b415-02458179808e,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-06844792-f15c-443c-abb6-a5f621d065b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-bfadc579-22f9-4474-8d5c-86e91262d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-b93edb79-43b2-405f-943b-b85a5d59cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-e25e340e-ec3b-4e93-bc78-bb263a0ab6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-5e41067c-1edf-44eb-8360-00d7b1a7fc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-7be24329-df16-4e3f-8cb1-390c9a090101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-535195054-172.17.0.11-1597162791064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42116,DS-05e7a48a-fb6e-4053-b112-fc63c3418085,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-a002ba53-4851-496f-b415-02458179808e,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-06844792-f15c-443c-abb6-a5f621d065b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-bfadc579-22f9-4474-8d5c-86e91262d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-b93edb79-43b2-405f-943b-b85a5d59cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-e25e340e-ec3b-4e93-bc78-bb263a0ab6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-5e41067c-1edf-44eb-8360-00d7b1a7fc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-7be24329-df16-4e3f-8cb1-390c9a090101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134315072-172.17.0.11-1597163205489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-a611048c-8a0d-4b38-b65e-a41d8d2f7fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-71961d62-2f05-4206-b09a-0bb7736108ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-fd243962-cb4d-44f7-8ebc-dbde3a64a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-ca5ade04-b45c-4726-b433-98b2b7450a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-47276fe5-bf71-4e5f-a4d6-37837c6bc35c,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-cb2a6335-c05a-41b7-a1f3-1a596ed50ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-2373a847-f0f6-49ad-a40a-27cc008b1821,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-f267bd08-cc33-47c1-9f84-e45386aea412,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2134315072-172.17.0.11-1597163205489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-a611048c-8a0d-4b38-b65e-a41d8d2f7fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-71961d62-2f05-4206-b09a-0bb7736108ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-fd243962-cb4d-44f7-8ebc-dbde3a64a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-ca5ade04-b45c-4726-b433-98b2b7450a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-47276fe5-bf71-4e5f-a4d6-37837c6bc35c,DISK], DatanodeInfoWithStorage[127.0.0.1:43154,DS-cb2a6335-c05a-41b7-a1f3-1a596ed50ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-2373a847-f0f6-49ad-a40a-27cc008b1821,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-f267bd08-cc33-47c1-9f84-e45386aea412,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49333578-172.17.0.11-1597163292820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42760,DS-e66552ed-72e7-49d1-99b6-525333f8c5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-797614df-761d-4bd6-bcdd-b29538b9c945,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-d9ae8140-b337-47d4-886d-668e2886ea17,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-22cfaaa3-0b24-4683-a1d1-fdaf9685200f,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-f56a43cc-76de-450e-81d3-b139c459a773,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-981804b1-8e2a-4e52-9265-927a4e357a91,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-1799f135-b177-4ec8-b289-3bac2bcf1635,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-91d1aec1-0163-4f97-ac7b-25b76e417f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49333578-172.17.0.11-1597163292820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42760,DS-e66552ed-72e7-49d1-99b6-525333f8c5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-797614df-761d-4bd6-bcdd-b29538b9c945,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-d9ae8140-b337-47d4-886d-668e2886ea17,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-22cfaaa3-0b24-4683-a1d1-fdaf9685200f,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-f56a43cc-76de-450e-81d3-b139c459a773,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-981804b1-8e2a-4e52-9265-927a4e357a91,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-1799f135-b177-4ec8-b289-3bac2bcf1635,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-91d1aec1-0163-4f97-ac7b-25b76e417f32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116342918-172.17.0.11-1597163945460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-6968411c-19cc-45c5-b122-7e67c7cbde94,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-9c0dfd2a-3c41-48e5-8323-67455cfaa08c,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-6beeac83-841c-4d6d-8b54-7cd55b511718,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-92cbe963-259e-45af-abd2-13d4c60c1875,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-4b9b5d96-d304-4400-b1c9-c062a1a1c787,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-de88cb2d-6ecf-492e-9385-34f4bc620faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-0c868413-b341-493d-958f-0a59c684336d,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-3570eedf-4d21-4d99-a9cf-8514f2a6177e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116342918-172.17.0.11-1597163945460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-6968411c-19cc-45c5-b122-7e67c7cbde94,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-9c0dfd2a-3c41-48e5-8323-67455cfaa08c,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-6beeac83-841c-4d6d-8b54-7cd55b511718,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-92cbe963-259e-45af-abd2-13d4c60c1875,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-4b9b5d96-d304-4400-b1c9-c062a1a1c787,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-de88cb2d-6ecf-492e-9385-34f4bc620faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-0c868413-b341-493d-958f-0a59c684336d,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-3570eedf-4d21-4d99-a9cf-8514f2a6177e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281301336-172.17.0.11-1597163990176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-c6478164-ce16-4aba-9410-665e4f1da27c,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-b2966f5e-a219-4842-a65a-a4801a152b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-08801d67-3967-4b02-99ac-1f18d9ed29d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-7f9f95f9-6d89-4eaf-937a-9771ba99cfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-6c727a81-c35a-4c4a-9117-9a12521d0297,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-9adfc649-f0f8-4ad0-925e-278544a66012,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-13d64258-4efe-4338-b951-dafa0f0a3914,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-8e81a581-2a58-4279-8334-4452e3949a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281301336-172.17.0.11-1597163990176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43054,DS-c6478164-ce16-4aba-9410-665e4f1da27c,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-b2966f5e-a219-4842-a65a-a4801a152b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-08801d67-3967-4b02-99ac-1f18d9ed29d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-7f9f95f9-6d89-4eaf-937a-9771ba99cfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-6c727a81-c35a-4c4a-9117-9a12521d0297,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-9adfc649-f0f8-4ad0-925e-278544a66012,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-13d64258-4efe-4338-b951-dafa0f0a3914,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-8e81a581-2a58-4279-8334-4452e3949a6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115319201-172.17.0.11-1597164078837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-226f2e10-4f0b-46c0-8cc9-d3be5412951d,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-659e7333-3ed3-47cf-8d84-35ee59804c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-206981e8-7ca1-44d4-b78b-74946f58d567,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-70d30ce2-d811-4122-8501-d1d9cf3ea441,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-00b39436-66d2-43de-87a3-a34f103324f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-65416a47-7f65-4f22-8864-ca97eca1348c,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-965a1542-6bed-4920-a103-9bae43dff445,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-fb3c0a04-cbf7-4267-8c79-214677cc9265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115319201-172.17.0.11-1597164078837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39473,DS-226f2e10-4f0b-46c0-8cc9-d3be5412951d,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-659e7333-3ed3-47cf-8d84-35ee59804c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-206981e8-7ca1-44d4-b78b-74946f58d567,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-70d30ce2-d811-4122-8501-d1d9cf3ea441,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-00b39436-66d2-43de-87a3-a34f103324f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-65416a47-7f65-4f22-8864-ca97eca1348c,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-965a1542-6bed-4920-a103-9bae43dff445,DISK], DatanodeInfoWithStorage[127.0.0.1:35021,DS-fb3c0a04-cbf7-4267-8c79-214677cc9265,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224803874-172.17.0.11-1597164390165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-f67382f2-ee54-40a2-91c8-6ec8824478ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-b666c597-470c-4556-aaba-58dbf96bad86,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-ef9d2e60-52c7-4ed9-b4e5-ca2f1401b831,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-57699304-d6d1-4820-9f6a-cb74c5232818,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-9d25727f-f7c6-4e5b-959f-f5d765aadcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-a462e7f1-1b0d-4665-b880-5c1bf7d97eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-023c5477-e1b9-4d87-9a26-fc62ca297ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-4380fea6-5c01-48a5-b2a6-23792669fc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224803874-172.17.0.11-1597164390165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41189,DS-f67382f2-ee54-40a2-91c8-6ec8824478ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-b666c597-470c-4556-aaba-58dbf96bad86,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-ef9d2e60-52c7-4ed9-b4e5-ca2f1401b831,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-57699304-d6d1-4820-9f6a-cb74c5232818,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-9d25727f-f7c6-4e5b-959f-f5d765aadcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-a462e7f1-1b0d-4665-b880-5c1bf7d97eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34792,DS-023c5477-e1b9-4d87-9a26-fc62ca297ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-4380fea6-5c01-48a5-b2a6-23792669fc2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042070454-172.17.0.11-1597164553699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-f4db548f-9a91-4c3a-bd4a-57ca74332c77,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-5fc17a90-97e3-43d6-9de0-781a367b2a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-c523ad08-1bc7-448b-a28d-acb5237ccfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-2f993d7b-952d-46c4-a980-b5fd3f314bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-8f57abfc-43e0-4af7-b868-7b60a0d5394a,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-83f09439-9749-4616-bae7-7c65abda76a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-ef357155-a8af-46c6-a82c-77130b5ba493,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-f3623b1f-0994-4ed4-8e4b-bcd8cc92debf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042070454-172.17.0.11-1597164553699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-f4db548f-9a91-4c3a-bd4a-57ca74332c77,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-5fc17a90-97e3-43d6-9de0-781a367b2a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-c523ad08-1bc7-448b-a28d-acb5237ccfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-2f993d7b-952d-46c4-a980-b5fd3f314bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36058,DS-8f57abfc-43e0-4af7-b868-7b60a0d5394a,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-83f09439-9749-4616-bae7-7c65abda76a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-ef357155-a8af-46c6-a82c-77130b5ba493,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-f3623b1f-0994-4ed4-8e4b-bcd8cc92debf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375251482-172.17.0.11-1597164714609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-80a34d59-2805-45c6-b2fd-56e379d926f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-44135ea3-700c-4a10-9bc1-77e4aca1ed97,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-a82afb3d-50a9-4c82-932d-17e429cb6e20,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-34e641ae-edc6-4465-b960-81587a969818,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-87abdbf1-c513-4649-96ec-0411691fd54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-d9fe4f6d-8f6b-4bb3-82ce-9be18e9483f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-5ed2c378-5a43-44ba-81ab-2a3ca6c81ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-7c3153ff-4712-4f6a-9ad9-c804290058de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1375251482-172.17.0.11-1597164714609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33049,DS-80a34d59-2805-45c6-b2fd-56e379d926f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-44135ea3-700c-4a10-9bc1-77e4aca1ed97,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-a82afb3d-50a9-4c82-932d-17e429cb6e20,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-34e641ae-edc6-4465-b960-81587a969818,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-87abdbf1-c513-4649-96ec-0411691fd54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-d9fe4f6d-8f6b-4bb3-82ce-9be18e9483f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-5ed2c378-5a43-44ba-81ab-2a3ca6c81ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-7c3153ff-4712-4f6a-9ad9-c804290058de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.window.num.buckets
component: hdfs:NameNode
v1: 1
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728174198-172.17.0.11-1597164787622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41238,DS-3558adf2-7a80-4330-8567-4ea4c92bd394,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-5b675c7e-f551-4c82-bec7-41d976b83218,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-7d736f31-6c5b-46b7-b558-10cc36630a34,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-fc675e94-2b5f-497f-95be-fd8661ca5754,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-67184474-cd99-411d-bb6f-dc35ab2c731c,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-3063c9c9-12f1-4973-93f5-ce7a0c369a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-aec610e6-8d0c-4d25-96a7-11f2c8c16cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e0522197-45e6-4729-9921-edff7ce58c73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728174198-172.17.0.11-1597164787622:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41238,DS-3558adf2-7a80-4330-8567-4ea4c92bd394,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-5b675c7e-f551-4c82-bec7-41d976b83218,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-7d736f31-6c5b-46b7-b558-10cc36630a34,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-fc675e94-2b5f-497f-95be-fd8661ca5754,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-67184474-cd99-411d-bb6f-dc35ab2c731c,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-3063c9c9-12f1-4973-93f5-ce7a0c369a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-aec610e6-8d0c-4d25-96a7-11f2c8c16cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:39212,DS-e0522197-45e6-4729-9921-edff7ce58c73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6327
