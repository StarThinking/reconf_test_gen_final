reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747354287-172.17.0.13-1597108411945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-6f53267b-f232-4765-b0e7-b21d6f448d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-1a40f164-b1ab-42a4-994c-bcdc44725c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-665d01da-80ba-48fb-9f3c-086869c357af,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-fc61600f-5bf8-4372-a4bb-abe0e22414f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-e77cc0e8-3df0-4a46-9f66-4fd65c56a5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-b6585c96-b2a8-4043-818a-de9ca96ac8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-9cc7584d-f898-4748-ac42-1ab34ff951af,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-bdd490e4-a275-4466-99e3-b6537c1fb29a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747354287-172.17.0.13-1597108411945:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-6f53267b-f232-4765-b0e7-b21d6f448d30,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-1a40f164-b1ab-42a4-994c-bcdc44725c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-665d01da-80ba-48fb-9f3c-086869c357af,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-fc61600f-5bf8-4372-a4bb-abe0e22414f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-e77cc0e8-3df0-4a46-9f66-4fd65c56a5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-b6585c96-b2a8-4043-818a-de9ca96ac8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45862,DS-9cc7584d-f898-4748-ac42-1ab34ff951af,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-bdd490e4-a275-4466-99e3-b6537c1fb29a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228039056-172.17.0.13-1597109013836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39957,DS-fa140a3e-e738-4753-9981-c0c612ef1903,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-3f732f00-8dd4-41c8-8bcc-25351b3c26b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-5bc70ce3-01e0-4350-b5b7-6df164a10a91,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-f1badc51-a1e9-4604-a4d7-d4c2876cca08,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-97204d9b-30fd-4c22-a4a4-ce2ad99a1760,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-81e80db6-77c7-4208-8950-69908e2ab8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-f83d7eee-a307-46a3-b53b-dc1b840d27cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-71dad6c2-e28c-497e-8e22-bb25de878212,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228039056-172.17.0.13-1597109013836:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39957,DS-fa140a3e-e738-4753-9981-c0c612ef1903,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-3f732f00-8dd4-41c8-8bcc-25351b3c26b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-5bc70ce3-01e0-4350-b5b7-6df164a10a91,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-f1badc51-a1e9-4604-a4d7-d4c2876cca08,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-97204d9b-30fd-4c22-a4a4-ce2ad99a1760,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-81e80db6-77c7-4208-8950-69908e2ab8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-f83d7eee-a307-46a3-b53b-dc1b840d27cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-71dad6c2-e28c-497e-8e22-bb25de878212,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617863513-172.17.0.13-1597109299478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41371,DS-13ec70c6-6785-46b7-897c-122614757ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-3932d57b-214d-4531-ba16-f8f2418185ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-1bd923b8-726a-4904-a1c7-bcf26eb72e47,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-13fe4f54-44f2-424a-bcbd-59fac2c1a612,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-cc4fd295-bd3f-473c-942e-9271bf81f844,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-720b8ff5-535a-4551-bd7a-012777c7c8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-a84f3788-ca9a-4d29-8976-d33f6d308728,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-8c993cd4-8ddf-4ee4-9a89-8403ac7d5988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617863513-172.17.0.13-1597109299478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41371,DS-13ec70c6-6785-46b7-897c-122614757ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-3932d57b-214d-4531-ba16-f8f2418185ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-1bd923b8-726a-4904-a1c7-bcf26eb72e47,DISK], DatanodeInfoWithStorage[127.0.0.1:46058,DS-13fe4f54-44f2-424a-bcbd-59fac2c1a612,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-cc4fd295-bd3f-473c-942e-9271bf81f844,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-720b8ff5-535a-4551-bd7a-012777c7c8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-a84f3788-ca9a-4d29-8976-d33f6d308728,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-8c993cd4-8ddf-4ee4-9a89-8403ac7d5988,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097091331-172.17.0.13-1597109448343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39111,DS-75bbbf61-968f-4f26-aa26-7e9d8cc17cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-755bac11-36c2-4025-ab07-ff51ad50387d,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-332fd2af-766b-4162-9ec2-dabffab2839a,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-e39452ca-9221-4555-845d-e889de9ce198,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-3586cb13-55c6-46e4-9f27-29da90350dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-6d8cf807-feea-44e9-b55b-850f789cbd20,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-a181ff06-bcfe-4901-91ef-56f9d4aaecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-62f5963f-19d8-4c40-a2da-ccca4fd9da70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097091331-172.17.0.13-1597109448343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39111,DS-75bbbf61-968f-4f26-aa26-7e9d8cc17cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-755bac11-36c2-4025-ab07-ff51ad50387d,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-332fd2af-766b-4162-9ec2-dabffab2839a,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-e39452ca-9221-4555-845d-e889de9ce198,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-3586cb13-55c6-46e4-9f27-29da90350dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-6d8cf807-feea-44e9-b55b-850f789cbd20,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-a181ff06-bcfe-4901-91ef-56f9d4aaecf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-62f5963f-19d8-4c40-a2da-ccca4fd9da70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368403284-172.17.0.13-1597109546633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35309,DS-8a75ca7f-302b-4a2e-ae84-3fd81c934621,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-a073137a-5005-4993-abac-f647b3607ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-393fc4e5-8115-4a70-93b4-cafe752e7569,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-021b1489-f2cd-4502-81af-c6252e1d3c79,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-5c97b600-4b5e-45d2-9ce7-6b48495f7a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-8bdc79ba-45af-4806-adeb-d36cc4ce8323,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-92e630a8-402b-4827-9818-4457771b6464,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-50b660c2-e39b-4c1e-b8e6-052b1d36b95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368403284-172.17.0.13-1597109546633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35309,DS-8a75ca7f-302b-4a2e-ae84-3fd81c934621,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-a073137a-5005-4993-abac-f647b3607ace,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-393fc4e5-8115-4a70-93b4-cafe752e7569,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-021b1489-f2cd-4502-81af-c6252e1d3c79,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-5c97b600-4b5e-45d2-9ce7-6b48495f7a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-8bdc79ba-45af-4806-adeb-d36cc4ce8323,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-92e630a8-402b-4827-9818-4457771b6464,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-50b660c2-e39b-4c1e-b8e6-052b1d36b95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988236711-172.17.0.13-1597109636701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-2e6b8bd1-cc83-4b08-b991-027d29986280,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-54844dc4-95bc-4a4d-8cea-86760751d289,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-31c9adf3-f1fd-4526-8c60-92b97648971e,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-e2313b42-2983-4f44-948b-d3793dc0afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-33eab7b7-4be0-4d58-96ed-070c46664d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-4a23119a-3926-4fa3-bebd-fe618a548d97,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-5fec67c6-9ed5-4ee8-bd16-3b69ddcb95b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-e6ed9a28-de8a-4289-9185-91d77ebbc1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988236711-172.17.0.13-1597109636701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40953,DS-2e6b8bd1-cc83-4b08-b991-027d29986280,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-54844dc4-95bc-4a4d-8cea-86760751d289,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-31c9adf3-f1fd-4526-8c60-92b97648971e,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-e2313b42-2983-4f44-948b-d3793dc0afe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-33eab7b7-4be0-4d58-96ed-070c46664d05,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-4a23119a-3926-4fa3-bebd-fe618a548d97,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-5fec67c6-9ed5-4ee8-bd16-3b69ddcb95b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-e6ed9a28-de8a-4289-9185-91d77ebbc1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294638189-172.17.0.13-1597109730570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-d49a5807-1535-4ca4-b20a-c3d683ef4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-347203d6-db5a-4bea-8d9e-dc57fb225875,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-63fd30ba-dc9f-40fe-8297-200263c89877,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-c0e61e99-3ce8-4495-9328-d17e9f1bf2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-4e0d3653-77af-4dcb-a009-c7340c05ec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-aae4ab5f-e06e-4918-beea-fcc67b001246,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-e6968ab2-3169-40e4-b353-4925a4ea7f24,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-92e203cb-6d75-4031-bd8c-7cfa4a31e7eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294638189-172.17.0.13-1597109730570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36662,DS-d49a5807-1535-4ca4-b20a-c3d683ef4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-347203d6-db5a-4bea-8d9e-dc57fb225875,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-63fd30ba-dc9f-40fe-8297-200263c89877,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-c0e61e99-3ce8-4495-9328-d17e9f1bf2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-4e0d3653-77af-4dcb-a009-c7340c05ec8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-aae4ab5f-e06e-4918-beea-fcc67b001246,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-e6968ab2-3169-40e4-b353-4925a4ea7f24,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-92e203cb-6d75-4031-bd8c-7cfa4a31e7eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763960406-172.17.0.13-1597110160925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-659f5d05-e9cc-453a-91d1-4b22646abd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-1d837036-e177-4283-8d2b-0422aacba353,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-c423652d-814e-4b9d-959e-599cd7619ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-9f10a2ae-e665-4e22-8c14-7718d499247d,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-e9065b3c-2e87-47c2-9abc-9d28acd26af7,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-349ac6da-8bb6-4516-a343-515bc4d29e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-7ca8f672-9351-45ae-9506-a0ee0f2dbf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-6c754930-5a6d-4189-b4db-3d4119162e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763960406-172.17.0.13-1597110160925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-659f5d05-e9cc-453a-91d1-4b22646abd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40509,DS-1d837036-e177-4283-8d2b-0422aacba353,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-c423652d-814e-4b9d-959e-599cd7619ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-9f10a2ae-e665-4e22-8c14-7718d499247d,DISK], DatanodeInfoWithStorage[127.0.0.1:34486,DS-e9065b3c-2e87-47c2-9abc-9d28acd26af7,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-349ac6da-8bb6-4516-a343-515bc4d29e24,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-7ca8f672-9351-45ae-9506-a0ee0f2dbf7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-6c754930-5a6d-4189-b4db-3d4119162e54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370667211-172.17.0.13-1597110679078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-175a8266-c113-4232-a703-b04a50716f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-e2e25645-ae55-4aa4-ab0c-6ec858e02a05,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-4c2fd7f7-d642-4bf7-b331-c2027be02abe,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-0a1bb698-3c17-4781-856e-ccc0d002d111,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-77922a83-a84e-4d80-9e7e-351ba5277ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-c48ebd0c-dfd4-4b9f-ae4f-15d4586e1ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-91050f68-bb12-4eae-9487-86933083053a,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-77a09234-1317-4f4a-b42f-ee3edcdecd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370667211-172.17.0.13-1597110679078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-175a8266-c113-4232-a703-b04a50716f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-e2e25645-ae55-4aa4-ab0c-6ec858e02a05,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-4c2fd7f7-d642-4bf7-b331-c2027be02abe,DISK], DatanodeInfoWithStorage[127.0.0.1:40407,DS-0a1bb698-3c17-4781-856e-ccc0d002d111,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-77922a83-a84e-4d80-9e7e-351ba5277ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-c48ebd0c-dfd4-4b9f-ae4f-15d4586e1ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-91050f68-bb12-4eae-9487-86933083053a,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-77a09234-1317-4f4a-b42f-ee3edcdecd45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109636174-172.17.0.13-1597111271197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-a2f8ae70-1724-4dd4-9d7f-acf2b9c79364,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-89da842b-589c-45e4-9e34-cb693d06656a,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-99dc271e-4ad7-4708-bac9-f3d957aff12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-6f5004a1-0763-45b2-b6a2-8b7bf094bdad,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-28a0369c-ac4b-46af-bb48-41f98f4c3184,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-a31e348c-b933-4af4-8f9e-53920830adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-86aa4275-c6a0-42ad-a1db-74c4d73ff79c,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-acc493c3-046f-4402-90c6-d5e69dc3b0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109636174-172.17.0.13-1597111271197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43410,DS-a2f8ae70-1724-4dd4-9d7f-acf2b9c79364,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-89da842b-589c-45e4-9e34-cb693d06656a,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-99dc271e-4ad7-4708-bac9-f3d957aff12b,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-6f5004a1-0763-45b2-b6a2-8b7bf094bdad,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-28a0369c-ac4b-46af-bb48-41f98f4c3184,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-a31e348c-b933-4af4-8f9e-53920830adc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-86aa4275-c6a0-42ad-a1db-74c4d73ff79c,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-acc493c3-046f-4402-90c6-d5e69dc3b0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874658020-172.17.0.13-1597111857712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-5d75806c-158b-4180-8094-2874dd925632,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-ac9947b6-edd8-4496-8fe4-896722f616c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-e40fb23e-e962-49c9-a454-4d9777dfb385,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-534bce6f-94d9-441a-ac93-5b7ae7794d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-3c49cf51-2fae-400a-8d42-709c93266b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-51726821-6b24-4310-8601-c79eac25b266,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-458aff70-a725-4e83-af39-32caccc678de,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-28b8da32-32dd-423e-a854-df91569e4b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-874658020-172.17.0.13-1597111857712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-5d75806c-158b-4180-8094-2874dd925632,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-ac9947b6-edd8-4496-8fe4-896722f616c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39777,DS-e40fb23e-e962-49c9-a454-4d9777dfb385,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-534bce6f-94d9-441a-ac93-5b7ae7794d88,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-3c49cf51-2fae-400a-8d42-709c93266b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-51726821-6b24-4310-8601-c79eac25b266,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-458aff70-a725-4e83-af39-32caccc678de,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-28b8da32-32dd-423e-a854-df91569e4b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515172167-172.17.0.13-1597112202689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37856,DS-0f79f950-bf8e-4a35-947f-a25fce8070c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-296796f7-752f-4204-b0d7-c51590653b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-bee88505-642c-43b0-b31c-c5b8c7f8f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-d5fd9fa2-36e5-4cc9-a469-499324c8767d,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-0c009bf9-5763-4a9a-aaab-a10325b543da,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-2bb7f5a7-ce00-4b99-a575-4ac627a03328,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-5cb2075a-ed34-463b-b53c-8c259689edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-687d40db-9fa7-4012-a9cb-b38b8cf2321b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-515172167-172.17.0.13-1597112202689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37856,DS-0f79f950-bf8e-4a35-947f-a25fce8070c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-296796f7-752f-4204-b0d7-c51590653b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-bee88505-642c-43b0-b31c-c5b8c7f8f6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-d5fd9fa2-36e5-4cc9-a469-499324c8767d,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-0c009bf9-5763-4a9a-aaab-a10325b543da,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-2bb7f5a7-ce00-4b99-a575-4ac627a03328,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-5cb2075a-ed34-463b-b53c-8c259689edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-687d40db-9fa7-4012-a9cb-b38b8cf2321b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312708318-172.17.0.13-1597112782785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-3e9f4b30-b1aa-49dc-96de-ee02ab6422f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-c55ad81a-41d5-4d47-8dd6-7eb8000e097a,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-1186cf92-4681-40f9-a748-f17575bd57b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-bafc6e16-fc5e-488c-b204-a366261eb28b,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-00ae74d4-ed4b-4dbb-92ac-7033c2a2c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-0bece408-c909-43ac-981b-ab54fade6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-0201ca98-9701-438e-b762-4ab368b5e050,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-60221541-37d7-48bc-9161-fddfefe23c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1312708318-172.17.0.13-1597112782785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-3e9f4b30-b1aa-49dc-96de-ee02ab6422f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41031,DS-c55ad81a-41d5-4d47-8dd6-7eb8000e097a,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-1186cf92-4681-40f9-a748-f17575bd57b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-bafc6e16-fc5e-488c-b204-a366261eb28b,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-00ae74d4-ed4b-4dbb-92ac-7033c2a2c0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-0bece408-c909-43ac-981b-ab54fade6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-0201ca98-9701-438e-b762-4ab368b5e050,DISK], DatanodeInfoWithStorage[127.0.0.1:34304,DS-60221541-37d7-48bc-9161-fddfefe23c5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245695429-172.17.0.13-1597112887616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41384,DS-556c7d81-4826-4422-9c94-a7bf79ef5d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-3acee22d-c3e6-4398-b0a9-8af8885e55c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-3f2e2544-0d61-44cb-bfeb-6f9bd4b2f271,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-e2f751c6-cf07-470e-8591-2372a4b2b955,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-0a318923-a328-4bde-b583-0afe7d6bad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-5e947dde-c159-45f3-b329-84cf0f8dea1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-bab8cb3a-ae3c-4cbd-8746-12f54db02f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-9d51d206-8e63-47f3-a4ef-4c49bb310cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245695429-172.17.0.13-1597112887616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41384,DS-556c7d81-4826-4422-9c94-a7bf79ef5d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-3acee22d-c3e6-4398-b0a9-8af8885e55c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-3f2e2544-0d61-44cb-bfeb-6f9bd4b2f271,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-e2f751c6-cf07-470e-8591-2372a4b2b955,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-0a318923-a328-4bde-b583-0afe7d6bad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-5e947dde-c159-45f3-b329-84cf0f8dea1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-bab8cb3a-ae3c-4cbd-8746-12f54db02f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-9d51d206-8e63-47f3-a4ef-4c49bb310cc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387638327-172.17.0.13-1597113874996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-44ffc9d4-85c1-4d7c-ba0f-73d2409a9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-4bd6d588-f9e8-4521-831d-a4663fa9fb29,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-bd52aa09-cc4b-4cca-9df7-be2384ba3f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-bdcce60c-3da2-4287-911a-6b617073d225,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-d607b5a5-92cd-4b04-bc42-34184e651929,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-e18d83c6-0eac-41c3-84ba-6c0147fcfc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-14e57b58-19c4-4757-b80a-1b24085ee8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-d327befe-331f-462b-b35d-5dd035722c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1387638327-172.17.0.13-1597113874996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38046,DS-44ffc9d4-85c1-4d7c-ba0f-73d2409a9a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-4bd6d588-f9e8-4521-831d-a4663fa9fb29,DISK], DatanodeInfoWithStorage[127.0.0.1:40198,DS-bd52aa09-cc4b-4cca-9df7-be2384ba3f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-bdcce60c-3da2-4287-911a-6b617073d225,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-d607b5a5-92cd-4b04-bc42-34184e651929,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-e18d83c6-0eac-41c3-84ba-6c0147fcfc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-14e57b58-19c4-4757-b80a-1b24085ee8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-d327befe-331f-462b-b35d-5dd035722c8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769993306-172.17.0.13-1597113961662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44648,DS-ddc90710-9259-41e1-878e-317b50ff0ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-600d2d94-3f2b-438c-9ead-9d328225a5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-b7e231da-507b-4133-9c77-e05896d2bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-c03db666-c211-4b3e-a069-d62de5b89980,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-c1a28426-f799-49da-904d-731e5bc7ca30,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-4c4263bd-c815-441c-8b93-3bd658ef778c,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-ef63b6d1-d2f0-4f76-b984-bf2cf0d4bb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-71a8ccf4-2d49-4478-8eea-ad9e8ecc8bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769993306-172.17.0.13-1597113961662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44648,DS-ddc90710-9259-41e1-878e-317b50ff0ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-600d2d94-3f2b-438c-9ead-9d328225a5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-b7e231da-507b-4133-9c77-e05896d2bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-c03db666-c211-4b3e-a069-d62de5b89980,DISK], DatanodeInfoWithStorage[127.0.0.1:42933,DS-c1a28426-f799-49da-904d-731e5bc7ca30,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-4c4263bd-c815-441c-8b93-3bd658ef778c,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-ef63b6d1-d2f0-4f76-b984-bf2cf0d4bb77,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-71a8ccf4-2d49-4478-8eea-ad9e8ecc8bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096577027-172.17.0.13-1597114040310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43081,DS-3528fb18-532d-4a3e-bfc5-59e8b2805830,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-86d59b9d-df5e-4586-b757-328332feced5,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-d4944b99-9faa-4afc-9acd-ec74a3f5d3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-898daaff-518a-4a0b-80d5-f0cb224a17f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-b5438913-4721-4d80-9776-2ed5cf227037,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-314ae87b-490a-43e9-bc88-080fb815b4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-081463f1-3d2a-4e9c-b6f1-9a6c51468df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-34a9d80c-d32e-4d71-8f29-efe6a6562290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096577027-172.17.0.13-1597114040310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43081,DS-3528fb18-532d-4a3e-bfc5-59e8b2805830,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-86d59b9d-df5e-4586-b757-328332feced5,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-d4944b99-9faa-4afc-9acd-ec74a3f5d3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-898daaff-518a-4a0b-80d5-f0cb224a17f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-b5438913-4721-4d80-9776-2ed5cf227037,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-314ae87b-490a-43e9-bc88-080fb815b4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-081463f1-3d2a-4e9c-b6f1-9a6c51468df3,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-34a9d80c-d32e-4d71-8f29-efe6a6562290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228121852-172.17.0.13-1597114348663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40516,DS-47807257-bd25-4461-a3bc-41550418864d,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-dbae0a82-4f89-4847-bed2-4cd32132d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-297501dc-a5f9-406d-9e7e-acd7c38bee53,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-94b3813b-d53d-4f79-81c5-8bdcf02f7d95,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-ac4ea467-d088-4208-9fd8-9733d8840042,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-5f3cccfd-4045-4fcf-bf06-da1e890994dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-4e5e3493-e7cd-432c-b762-e10b894c9af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-eba8a6b7-1d5a-449a-9a6f-5f03795ad951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228121852-172.17.0.13-1597114348663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40516,DS-47807257-bd25-4461-a3bc-41550418864d,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-dbae0a82-4f89-4847-bed2-4cd32132d1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-297501dc-a5f9-406d-9e7e-acd7c38bee53,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-94b3813b-d53d-4f79-81c5-8bdcf02f7d95,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-ac4ea467-d088-4208-9fd8-9733d8840042,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-5f3cccfd-4045-4fcf-bf06-da1e890994dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36178,DS-4e5e3493-e7cd-432c-b762-e10b894c9af8,DISK], DatanodeInfoWithStorage[127.0.0.1:43621,DS-eba8a6b7-1d5a-449a-9a6f-5f03795ad951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652299241-172.17.0.13-1597114472235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-d3f16438-bb2e-4f29-b3b9-207ebd2b9c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-ae0b913e-4277-46eb-8063-67fb72001005,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-fa9d2311-f551-49ca-b929-aaf40530ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-f539380f-ea1e-42a1-9e15-f9878ea4da87,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-0a66cd96-1144-4909-8743-cf3104a64a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-7d02b835-90a0-47ed-8467-c3a21eb81055,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-2b221351-dcba-4b14-a6c6-9520869fad55,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-24691a55-f029-4ce1-9e1c-e9554946721b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-652299241-172.17.0.13-1597114472235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-d3f16438-bb2e-4f29-b3b9-207ebd2b9c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39021,DS-ae0b913e-4277-46eb-8063-67fb72001005,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-fa9d2311-f551-49ca-b929-aaf40530ede5,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-f539380f-ea1e-42a1-9e15-f9878ea4da87,DISK], DatanodeInfoWithStorage[127.0.0.1:42430,DS-0a66cd96-1144-4909-8743-cf3104a64a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-7d02b835-90a0-47ed-8467-c3a21eb81055,DISK], DatanodeInfoWithStorage[127.0.0.1:33580,DS-2b221351-dcba-4b14-a6c6-9520869fad55,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-24691a55-f029-4ce1-9e1c-e9554946721b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14877293-172.17.0.13-1597114598029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-8135f43a-6149-47cb-981d-fd5278c4e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-05e97bbf-ef2d-46e7-beb5-1489be9250ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-8726bcbf-1972-4270-a11c-cc2fe707d349,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-6aaf4b3a-3916-4ab0-a4d0-89f6e6a05aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-51332818-77eb-449d-b6c6-d7d89a88c729,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-527f407c-b50e-41a2-8014-d39ba8f46d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-140d04eb-94f9-4db5-9997-2cd2ac0f6640,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-0af94ffa-b20c-4342-9605-0fb85ac34a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14877293-172.17.0.13-1597114598029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-8135f43a-6149-47cb-981d-fd5278c4e2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-05e97bbf-ef2d-46e7-beb5-1489be9250ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-8726bcbf-1972-4270-a11c-cc2fe707d349,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-6aaf4b3a-3916-4ab0-a4d0-89f6e6a05aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-51332818-77eb-449d-b6c6-d7d89a88c729,DISK], DatanodeInfoWithStorage[127.0.0.1:40872,DS-527f407c-b50e-41a2-8014-d39ba8f46d30,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-140d04eb-94f9-4db5-9997-2cd2ac0f6640,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-0af94ffa-b20c-4342-9605-0fb85ac34a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271670511-172.17.0.13-1597114764932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33773,DS-8b0c385e-6158-4b85-b6cd-c0bea097091b,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-4510d319-7db2-4386-a949-0f5453500601,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-f4a6a756-39f7-425a-91ad-a60322218432,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-dc63fb3a-f363-4ace-b5b4-32df28130722,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-d832d7fa-9fe7-49ec-b243-b441da95770c,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-634e41c0-c1e2-4e3f-8b78-2f97f0680de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-8bf3784d-950a-421e-af29-0b4ceaa42fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-07875f76-5716-4cc4-b501-97d6a1509a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271670511-172.17.0.13-1597114764932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33773,DS-8b0c385e-6158-4b85-b6cd-c0bea097091b,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-4510d319-7db2-4386-a949-0f5453500601,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-f4a6a756-39f7-425a-91ad-a60322218432,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-dc63fb3a-f363-4ace-b5b4-32df28130722,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-d832d7fa-9fe7-49ec-b243-b441da95770c,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-634e41c0-c1e2-4e3f-8b78-2f97f0680de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-8bf3784d-950a-421e-af29-0b4ceaa42fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-07875f76-5716-4cc4-b501-97d6a1509a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 500
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403346024-172.17.0.13-1597115143116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-79f45f2e-67cb-4965-880d-4d4e41006c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-681c5aa4-ecc1-4ce7-baf9-89af55c75a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-ea4efe32-3742-47d2-a93b-30ca16219dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-933560a5-c3d0-4ccf-985f-ef7cd2af6029,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-c8dbff24-832e-4586-bae6-005ba89286a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-5a5ac058-df04-4f95-bb25-45d0ee77c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-d9358c66-26cf-437e-88c9-4a7d922272b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-512203c1-2e8a-4f29-83cb-ae1644da8cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403346024-172.17.0.13-1597115143116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35681,DS-79f45f2e-67cb-4965-880d-4d4e41006c92,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-681c5aa4-ecc1-4ce7-baf9-89af55c75a43,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-ea4efe32-3742-47d2-a93b-30ca16219dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-933560a5-c3d0-4ccf-985f-ef7cd2af6029,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-c8dbff24-832e-4586-bae6-005ba89286a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-5a5ac058-df04-4f95-bb25-45d0ee77c7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-d9358c66-26cf-437e-88c9-4a7d922272b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44484,DS-512203c1-2e8a-4f29-83cb-ae1644da8cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 6814
