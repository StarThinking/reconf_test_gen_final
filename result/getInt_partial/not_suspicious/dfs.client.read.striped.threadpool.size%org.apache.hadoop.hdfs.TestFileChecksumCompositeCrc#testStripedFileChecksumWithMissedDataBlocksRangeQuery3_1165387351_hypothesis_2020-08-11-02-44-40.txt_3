reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995882823-172.17.0.5-1597113928786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-ba365f20-789d-4eaa-976d-95b6a80f827f,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-b7ad25cb-039f-4786-9996-520674dc1792,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-d1865595-2e93-43da-a029-a91223af6936,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-173dba01-f6ea-4ebe-8c50-a19f89360b05,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-294fe022-b55d-4c52-80c2-c367a1b22674,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-1e2c6f0e-a3a1-4217-a878-c18ae1b911a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-af8c30e3-53fe-49be-867c-b321d28276ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-180fae1b-63dd-43ca-8115-bc04f4f112cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1995882823-172.17.0.5-1597113928786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-ba365f20-789d-4eaa-976d-95b6a80f827f,DISK], DatanodeInfoWithStorage[127.0.0.1:39634,DS-b7ad25cb-039f-4786-9996-520674dc1792,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-d1865595-2e93-43da-a029-a91223af6936,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-173dba01-f6ea-4ebe-8c50-a19f89360b05,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-294fe022-b55d-4c52-80c2-c367a1b22674,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-1e2c6f0e-a3a1-4217-a878-c18ae1b911a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-af8c30e3-53fe-49be-867c-b321d28276ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-180fae1b-63dd-43ca-8115-bc04f4f112cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129670186-172.17.0.5-1597113969677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-7e3babb2-99b1-45ff-8f82-0680a9245020,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-a77764f5-1b9b-4661-9a98-4f36f252aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-e5c68b3f-f114-47e3-94d4-34cbf298c550,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-94a16976-70dc-4fbc-a3a6-202d19e466b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-25f16a06-85c8-4a76-b16b-843b664d4c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-4ea24200-b745-4a94-b6b2-64a17f107673,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-ac870c16-0acc-40f0-a499-00a333459c75,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-12bf6249-0435-4fd6-af9c-4cc6178f7fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129670186-172.17.0.5-1597113969677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43919,DS-7e3babb2-99b1-45ff-8f82-0680a9245020,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-a77764f5-1b9b-4661-9a98-4f36f252aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-e5c68b3f-f114-47e3-94d4-34cbf298c550,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-94a16976-70dc-4fbc-a3a6-202d19e466b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-25f16a06-85c8-4a76-b16b-843b664d4c78,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-4ea24200-b745-4a94-b6b2-64a17f107673,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-ac870c16-0acc-40f0-a499-00a333459c75,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-12bf6249-0435-4fd6-af9c-4cc6178f7fcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127753936-172.17.0.5-1597114218491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-052ce090-8c34-4049-b812-2aad6b14c960,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-8f2490e7-9266-4fc0-be6d-c35341654df5,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-3703e693-a045-462e-b652-d1ab9d673d52,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-368c4811-6e65-4147-9fd3-329bda670ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-8b3b9a98-c739-43dd-a569-ffb51cbf1491,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-047bb6f7-6b79-439b-8bc5-dee21544f349,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-504caff4-8527-4de4-9599-20dc9cf58622,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-4d463c08-425a-4caa-a3dd-686b3b1b396f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127753936-172.17.0.5-1597114218491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43832,DS-052ce090-8c34-4049-b812-2aad6b14c960,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-8f2490e7-9266-4fc0-be6d-c35341654df5,DISK], DatanodeInfoWithStorage[127.0.0.1:43559,DS-3703e693-a045-462e-b652-d1ab9d673d52,DISK], DatanodeInfoWithStorage[127.0.0.1:35894,DS-368c4811-6e65-4147-9fd3-329bda670ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-8b3b9a98-c739-43dd-a569-ffb51cbf1491,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-047bb6f7-6b79-439b-8bc5-dee21544f349,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-504caff4-8527-4de4-9599-20dc9cf58622,DISK], DatanodeInfoWithStorage[127.0.0.1:39397,DS-4d463c08-425a-4caa-a3dd-686b3b1b396f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655025371-172.17.0.5-1597114358097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-a3b50a55-097e-4ebb-94f9-fac200e17e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-9c07032b-3356-4263-8122-c6efd53af0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-51a4eeb1-dfa2-4003-b8e7-5790f5cd1681,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-1642c3bc-330f-433e-a1e5-4cb8f484d9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-852bfb06-96e5-41fb-8fcd-33ba796813e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-42fc34cb-9605-49d0-a918-c8246cbcf2df,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-e4100dc0-d9ff-4f5c-825e-17aecbce1e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-8ec1fbcf-d667-4d4c-aeae-b19980db8c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655025371-172.17.0.5-1597114358097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40219,DS-a3b50a55-097e-4ebb-94f9-fac200e17e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-9c07032b-3356-4263-8122-c6efd53af0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-51a4eeb1-dfa2-4003-b8e7-5790f5cd1681,DISK], DatanodeInfoWithStorage[127.0.0.1:46332,DS-1642c3bc-330f-433e-a1e5-4cb8f484d9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-852bfb06-96e5-41fb-8fcd-33ba796813e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-42fc34cb-9605-49d0-a918-c8246cbcf2df,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-e4100dc0-d9ff-4f5c-825e-17aecbce1e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44816,DS-8ec1fbcf-d667-4d4c-aeae-b19980db8c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076120133-172.17.0.5-1597115476107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-a393363b-f3e0-4711-b3db-a6a699db8a41,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-f04bb236-9e5c-4c46-8f24-684344f9cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-3ed97fc6-8a7a-4119-a2e5-ecb196c1fe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-71e68060-1426-4542-9a20-3894dbb2b708,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-8a13e4dd-33de-41ef-92dd-c2e093107ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-ebe68a9f-f37a-41ec-b4c8-d6a591865313,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-7173ed07-8060-4755-ac74-2154749078cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-8c1c70e5-bcce-473d-babe-407609e983c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076120133-172.17.0.5-1597115476107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45590,DS-a393363b-f3e0-4711-b3db-a6a699db8a41,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-f04bb236-9e5c-4c46-8f24-684344f9cbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-3ed97fc6-8a7a-4119-a2e5-ecb196c1fe8f,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-71e68060-1426-4542-9a20-3894dbb2b708,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-8a13e4dd-33de-41ef-92dd-c2e093107ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-ebe68a9f-f37a-41ec-b4c8-d6a591865313,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-7173ed07-8060-4755-ac74-2154749078cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34323,DS-8c1c70e5-bcce-473d-babe-407609e983c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013885988-172.17.0.5-1597115514176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-11754453-7d61-4517-adab-dbd8c9e95c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-2b6032db-821a-4a59-9fda-02221db8ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-23017ce8-7f04-421b-bd62-2ff42a5c60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-b8d2ef4d-1cf9-4285-9fd4-3067c58cabb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-19c714bb-baf9-4b4f-bceb-d1d5f3c024cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-f13f85c3-753d-4ecd-921d-ddd329bac0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-672d269b-967d-4a07-92e1-5976b4e2e8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-357f3d75-17e7-4e99-a6a4-1191dc410812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013885988-172.17.0.5-1597115514176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-11754453-7d61-4517-adab-dbd8c9e95c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-2b6032db-821a-4a59-9fda-02221db8ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-23017ce8-7f04-421b-bd62-2ff42a5c60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-b8d2ef4d-1cf9-4285-9fd4-3067c58cabb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40574,DS-19c714bb-baf9-4b4f-bceb-d1d5f3c024cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-f13f85c3-753d-4ecd-921d-ddd329bac0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-672d269b-967d-4a07-92e1-5976b4e2e8cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-357f3d75-17e7-4e99-a6a4-1191dc410812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57692608-172.17.0.5-1597116019220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40652,DS-988a02e4-fae5-43f2-a781-979419e15d14,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-034f7ac8-9dbe-4316-ae01-555bb23d3158,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-1a6987fc-f3cd-4129-a221-9605ca558ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-fd491903-3dab-4a10-8df6-97a3334ff580,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e00c5ab0-03a9-4512-a158-c1dda9cf3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-3a6719e3-c72b-43d7-8c79-bae9ebe3e99d,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-ea7be1e9-9f35-4ca6-b45a-49d98809b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-5998fb6d-3af4-45c6-8e30-445991f315f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57692608-172.17.0.5-1597116019220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40652,DS-988a02e4-fae5-43f2-a781-979419e15d14,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-034f7ac8-9dbe-4316-ae01-555bb23d3158,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-1a6987fc-f3cd-4129-a221-9605ca558ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33182,DS-fd491903-3dab-4a10-8df6-97a3334ff580,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-e00c5ab0-03a9-4512-a158-c1dda9cf3a26,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-3a6719e3-c72b-43d7-8c79-bae9ebe3e99d,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-ea7be1e9-9f35-4ca6-b45a-49d98809b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-5998fb6d-3af4-45c6-8e30-445991f315f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682586487-172.17.0.5-1597116126315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43384,DS-c2bdf599-4e5c-4289-89a3-c276363a038e,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-ecd825c7-39f7-4a48-a09d-e82a2f19e259,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-b2b1ac4b-4183-4cf8-81ea-9014b09566f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-9c8756a4-af5e-4c16-9ea7-141b1459ad11,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-4b61542e-5cf4-404f-b537-e7541f1eb84d,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-852a76ed-f9e2-4898-9f91-f8226b309356,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-4181ea38-b741-4c67-9b77-6177e24dd015,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-d8c08734-2ea9-44c2-8fc3-1eb048b1fe4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682586487-172.17.0.5-1597116126315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43384,DS-c2bdf599-4e5c-4289-89a3-c276363a038e,DISK], DatanodeInfoWithStorage[127.0.0.1:37022,DS-ecd825c7-39f7-4a48-a09d-e82a2f19e259,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-b2b1ac4b-4183-4cf8-81ea-9014b09566f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-9c8756a4-af5e-4c16-9ea7-141b1459ad11,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-4b61542e-5cf4-404f-b537-e7541f1eb84d,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-852a76ed-f9e2-4898-9f91-f8226b309356,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-4181ea38-b741-4c67-9b77-6177e24dd015,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-d8c08734-2ea9-44c2-8fc3-1eb048b1fe4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035124522-172.17.0.5-1597116579226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39373,DS-769527dc-b9bf-479f-9a76-ca23c2f4ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-9ae1000b-553d-4ee3-8c90-1f74fe7303ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-4a5ba373-52ad-41cb-a788-3f063f751e54,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-0b604440-cbb6-403c-9212-a280ffa2f488,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-1e4411a5-8aa0-4bb2-8b53-ae14b07d0511,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-e2024e78-a012-42eb-acf8-dac81d8d955d,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-db20a1ab-fdf1-4a53-90e0-2a203c0930e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-759e14ff-b9c6-47b7-b02d-fffc4367da28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2035124522-172.17.0.5-1597116579226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39373,DS-769527dc-b9bf-479f-9a76-ca23c2f4ca2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-9ae1000b-553d-4ee3-8c90-1f74fe7303ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-4a5ba373-52ad-41cb-a788-3f063f751e54,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-0b604440-cbb6-403c-9212-a280ffa2f488,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-1e4411a5-8aa0-4bb2-8b53-ae14b07d0511,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-e2024e78-a012-42eb-acf8-dac81d8d955d,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-db20a1ab-fdf1-4a53-90e0-2a203c0930e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41748,DS-759e14ff-b9c6-47b7-b02d-fffc4367da28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522636140-172.17.0.5-1597116925248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43575,DS-80a7afa6-bfd2-44d3-a9da-a7e4befa58c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-810aa05f-e520-41c9-8860-6ef76f4bb572,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-8f27f59d-fe03-4488-a594-d96132b29ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-c3f285f7-8529-4aa8-8027-5b77f5ef3b46,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-b26f94cd-8351-433c-95ef-e3ca748ee5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-8019fa06-7f6a-41fa-a78c-becb42d04855,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-a4fb7bde-7f6f-4cdc-9461-e55234857912,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-a571d9d5-cc77-485f-bdcd-a9d41a288a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522636140-172.17.0.5-1597116925248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43575,DS-80a7afa6-bfd2-44d3-a9da-a7e4befa58c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-810aa05f-e520-41c9-8860-6ef76f4bb572,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-8f27f59d-fe03-4488-a594-d96132b29ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-c3f285f7-8529-4aa8-8027-5b77f5ef3b46,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-b26f94cd-8351-433c-95ef-e3ca748ee5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-8019fa06-7f6a-41fa-a78c-becb42d04855,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-a4fb7bde-7f6f-4cdc-9461-e55234857912,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-a571d9d5-cc77-485f-bdcd-a9d41a288a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865395062-172.17.0.5-1597117510513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42000,DS-33666d99-7e4c-4425-8717-ed9e77fa1eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-17ebd3a9-01e9-46f1-8d3b-f2cae314fbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-35c6f79a-88c3-43fb-b964-58535cde91eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-d05473f7-fd88-4e91-908c-419b79d5fefb,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-5da6de2a-5e9a-42f2-8095-ec8e59aeaf03,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-a159c521-aa48-4aeb-ad80-2f660f8e20d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-eb2bb172-8263-4b84-97ec-e8c9db05893a,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-b55a8415-fe89-45ab-94ba-c7ffb24fa706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865395062-172.17.0.5-1597117510513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42000,DS-33666d99-7e4c-4425-8717-ed9e77fa1eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-17ebd3a9-01e9-46f1-8d3b-f2cae314fbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-35c6f79a-88c3-43fb-b964-58535cde91eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-d05473f7-fd88-4e91-908c-419b79d5fefb,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-5da6de2a-5e9a-42f2-8095-ec8e59aeaf03,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-a159c521-aa48-4aeb-ad80-2f660f8e20d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-eb2bb172-8263-4b84-97ec-e8c9db05893a,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-b55a8415-fe89-45ab-94ba-c7ffb24fa706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382309791-172.17.0.5-1597118161334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32865,DS-6d6a88ee-b473-4c0a-ac96-5ae87380053d,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-3f984789-db5e-4caf-b4fe-9075483d4683,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-a8bae5bd-9bf9-4835-be25-ca7245ff3b72,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-ab0fb34e-a55f-4113-8f91-a994930c0211,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-116905d0-b6db-430f-9517-8c87534a642f,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-2cebd9de-a70d-48dc-8f8f-93fad7e4eb72,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-bc46f4ce-d92d-4845-b169-3aa7fede0460,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-b455dcd2-b3ac-43ea-9ec5-1229fcbd1a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382309791-172.17.0.5-1597118161334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32865,DS-6d6a88ee-b473-4c0a-ac96-5ae87380053d,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-3f984789-db5e-4caf-b4fe-9075483d4683,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-a8bae5bd-9bf9-4835-be25-ca7245ff3b72,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-ab0fb34e-a55f-4113-8f91-a994930c0211,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-116905d0-b6db-430f-9517-8c87534a642f,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-2cebd9de-a70d-48dc-8f8f-93fad7e4eb72,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-bc46f4ce-d92d-4845-b169-3aa7fede0460,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-b455dcd2-b3ac-43ea-9ec5-1229fcbd1a34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177544490-172.17.0.5-1597118306699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-f8fe4d39-af3b-44de-a453-a6718fece0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-4dd4dcbd-3451-4f2d-8d28-4458d633d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-1dc7118e-12e8-4755-83eb-e3e5d9d88e46,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-f2a59d1e-f6ca-461c-882f-79c1bcb2f595,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-0bb66ff3-f5c9-4dcf-9ff0-00930dceda7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-5aece2b1-3ae6-425e-927f-8b94b42d03b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-62fcac6e-379d-47d9-95cd-754754a70f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-527b0651-6f6c-4824-9eae-2baa586b8525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177544490-172.17.0.5-1597118306699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-f8fe4d39-af3b-44de-a453-a6718fece0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-4dd4dcbd-3451-4f2d-8d28-4458d633d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-1dc7118e-12e8-4755-83eb-e3e5d9d88e46,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-f2a59d1e-f6ca-461c-882f-79c1bcb2f595,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-0bb66ff3-f5c9-4dcf-9ff0-00930dceda7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-5aece2b1-3ae6-425e-927f-8b94b42d03b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-62fcac6e-379d-47d9-95cd-754754a70f96,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-527b0651-6f6c-4824-9eae-2baa586b8525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.striped.threadpool.size
component: hdfs:NameNode
v1: 18
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329528596-172.17.0.5-1597119135061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-ab5c3d57-edcc-4f70-8dbd-9a5244f9572d,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-514d8087-6fc9-4cc4-b033-49258fc40c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-49f0ec53-5254-44e2-9abb-0e94fe02bfda,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-80f39196-8660-4e8b-9ce1-418b75634bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-34d754ee-6273-4fb8-ad4a-0c97bd69e5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-cb4aac4c-ed13-4353-b2a0-116b209d8cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-769cc4dc-7e3c-4c2f-b07a-12bc53547fca,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-29b4ae3a-84b1-4250-ae73-1486f420eb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329528596-172.17.0.5-1597119135061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41217,DS-ab5c3d57-edcc-4f70-8dbd-9a5244f9572d,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-514d8087-6fc9-4cc4-b033-49258fc40c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-49f0ec53-5254-44e2-9abb-0e94fe02bfda,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-80f39196-8660-4e8b-9ce1-418b75634bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-34d754ee-6273-4fb8-ad4a-0c97bd69e5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41709,DS-cb4aac4c-ed13-4353-b2a0-116b209d8cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-769cc4dc-7e3c-4c2f-b07a-12bc53547fca,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-29b4ae3a-84b1-4250-ae73-1486f420eb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5509
