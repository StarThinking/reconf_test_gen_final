reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346191659-172.17.0.19-1597081665573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45172,DS-c313a0aa-33ac-4382-ba0e-68ebe2035161,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-55c93546-91a2-464e-816a-3b52a7233141,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-d46a43d4-52d8-4a99-af8e-266300ca55ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-56175a2f-762e-43c4-875e-fa62a85c17f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-29972580-a497-4397-aa9e-b343d6bfc8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-d6fe4080-4b46-46e5-a5f3-8df77b0b85f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-02374a74-13cf-424e-9b68-b7a0bacf2a58,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-5bb05dcf-2ba1-448c-bb94-acf2db8c6417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346191659-172.17.0.19-1597081665573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45172,DS-c313a0aa-33ac-4382-ba0e-68ebe2035161,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-55c93546-91a2-464e-816a-3b52a7233141,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-d46a43d4-52d8-4a99-af8e-266300ca55ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-56175a2f-762e-43c4-875e-fa62a85c17f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-29972580-a497-4397-aa9e-b343d6bfc8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-d6fe4080-4b46-46e5-a5f3-8df77b0b85f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-02374a74-13cf-424e-9b68-b7a0bacf2a58,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-5bb05dcf-2ba1-448c-bb94-acf2db8c6417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024228448-172.17.0.19-1597081747491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35544,DS-aee829d3-78a0-4790-bf17-2055f0bf0d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-8cabbd1a-4c7e-49bd-adec-671995c0fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-ed398405-039f-4709-85b4-bc7659941dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-fe43c78e-f5ce-42c6-abfd-e4265af7993e,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-996fde0d-627b-40d3-b785-56b86c26f752,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-00026a8f-a4b6-483d-9560-133bbd6742cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-0eb564bf-2758-43c4-8204-6ba52f640b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-9c78e594-db51-49b2-9a10-6312b9c79f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1024228448-172.17.0.19-1597081747491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35544,DS-aee829d3-78a0-4790-bf17-2055f0bf0d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-8cabbd1a-4c7e-49bd-adec-671995c0fcf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-ed398405-039f-4709-85b4-bc7659941dad,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-fe43c78e-f5ce-42c6-abfd-e4265af7993e,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-996fde0d-627b-40d3-b785-56b86c26f752,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-00026a8f-a4b6-483d-9560-133bbd6742cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-0eb564bf-2758-43c4-8204-6ba52f640b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-9c78e594-db51-49b2-9a10-6312b9c79f5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842670158-172.17.0.19-1597081784646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44454,DS-5d79fd73-2d3e-475e-be55-8ddd9538bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-f739faa1-1dfd-4a81-8f37-78ddf5d0f528,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-5656a931-8238-44e3-9306-d94e7152e290,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-abd25797-0aa3-4035-8923-3d9789247949,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-bfb512d5-a807-4ec9-8804-2c34cf8f01f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-42361c6b-bd98-440d-b57f-2b9945acd58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-500dd814-d0ab-4fc5-91b4-434b90bbb2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-2138f88e-6885-4bd9-a150-4363be1dd8dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1842670158-172.17.0.19-1597081784646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44454,DS-5d79fd73-2d3e-475e-be55-8ddd9538bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-f739faa1-1dfd-4a81-8f37-78ddf5d0f528,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-5656a931-8238-44e3-9306-d94e7152e290,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-abd25797-0aa3-4035-8923-3d9789247949,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-bfb512d5-a807-4ec9-8804-2c34cf8f01f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-42361c6b-bd98-440d-b57f-2b9945acd58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-500dd814-d0ab-4fc5-91b4-434b90bbb2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-2138f88e-6885-4bd9-a150-4363be1dd8dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839980826-172.17.0.19-1597082803357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-3c7643c6-12ba-4d22-bc1d-89468dc47d57,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-0d959f89-efbb-4f28-b7da-775a7693d863,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-b435e088-df5f-41b0-bf0c-424aa182068f,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-d6773ebc-1d09-4f7d-a888-5314844a2124,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-f129f751-8346-4e8d-af17-96d15fd4adab,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-62d3dbc3-78ce-431d-b24d-04c695c421fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-0fb6461e-a5cf-4100-bbbf-c00fb6bbaade,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-185895c9-ab5e-4f56-b410-4a87a340eca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-839980826-172.17.0.19-1597082803357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35116,DS-3c7643c6-12ba-4d22-bc1d-89468dc47d57,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-0d959f89-efbb-4f28-b7da-775a7693d863,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-b435e088-df5f-41b0-bf0c-424aa182068f,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-d6773ebc-1d09-4f7d-a888-5314844a2124,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-f129f751-8346-4e8d-af17-96d15fd4adab,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-62d3dbc3-78ce-431d-b24d-04c695c421fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-0fb6461e-a5cf-4100-bbbf-c00fb6bbaade,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-185895c9-ab5e-4f56-b410-4a87a340eca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160770004-172.17.0.19-1597082958505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36046,DS-27428f97-6b02-407c-8893-9da40eee8428,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-b3b746e2-84a6-44fb-84ed-c6e1482233e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-9bf95bea-bbe1-4690-84e3-3fc9ec4268bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-68ea4ad0-6ed1-4d90-a980-38a992e53c38,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-370b763e-0789-4edd-8fc2-0193e27406f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-0a5f1070-b10b-4c85-bcc9-e4b76cf1ff7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-92025123-6a06-4a39-862f-d8171e5bdf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-85a5275e-109d-4ea4-832a-edb86a39d085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160770004-172.17.0.19-1597082958505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36046,DS-27428f97-6b02-407c-8893-9da40eee8428,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-b3b746e2-84a6-44fb-84ed-c6e1482233e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-9bf95bea-bbe1-4690-84e3-3fc9ec4268bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-68ea4ad0-6ed1-4d90-a980-38a992e53c38,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-370b763e-0789-4edd-8fc2-0193e27406f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-0a5f1070-b10b-4c85-bcc9-e4b76cf1ff7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-92025123-6a06-4a39-862f-d8171e5bdf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35830,DS-85a5275e-109d-4ea4-832a-edb86a39d085,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628771347-172.17.0.19-1597083727731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38158,DS-c394e1d3-17d3-4c0d-bb44-e923f2b67dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-b4926c04-a877-4c44-81fa-b58115478d00,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-290e7135-2ac9-47f7-9efe-3968956b2d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-98a96256-ca74-4c20-89ca-0393cbd409f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-73f3c023-ab31-4e0a-aa31-ec8994f052fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-d9665f97-feee-402b-9c22-58aee9f3f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-2da29105-0ec2-4924-a074-7464aa86d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-5ade6971-a49c-42be-9f00-3d88e2e02a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628771347-172.17.0.19-1597083727731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38158,DS-c394e1d3-17d3-4c0d-bb44-e923f2b67dce,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-b4926c04-a877-4c44-81fa-b58115478d00,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-290e7135-2ac9-47f7-9efe-3968956b2d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-98a96256-ca74-4c20-89ca-0393cbd409f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-73f3c023-ab31-4e0a-aa31-ec8994f052fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-d9665f97-feee-402b-9c22-58aee9f3f9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-2da29105-0ec2-4924-a074-7464aa86d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-5ade6971-a49c-42be-9f00-3d88e2e02a9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122616013-172.17.0.19-1597084877818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46259,DS-4ef65f32-f5f9-45d8-a04f-0bcb8fd0d585,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-24db373a-8be3-49fc-aa9e-b99562e3fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-44abf779-bd2a-49d3-a6b8-f6169da765a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-d03c2519-c3d1-4366-9046-49160f3d2780,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-1625a081-fd5d-459b-aac0-e30e0772c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-78f1e32b-26f2-4257-be9a-26c75f25bb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-db66018d-4c7c-40ff-99c7-95f5ab250407,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-54eace29-06a3-4f07-a766-63d98b8819a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122616013-172.17.0.19-1597084877818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46259,DS-4ef65f32-f5f9-45d8-a04f-0bcb8fd0d585,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-24db373a-8be3-49fc-aa9e-b99562e3fb15,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-44abf779-bd2a-49d3-a6b8-f6169da765a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-d03c2519-c3d1-4366-9046-49160f3d2780,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-1625a081-fd5d-459b-aac0-e30e0772c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-78f1e32b-26f2-4257-be9a-26c75f25bb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-db66018d-4c7c-40ff-99c7-95f5ab250407,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-54eace29-06a3-4f07-a766-63d98b8819a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042652112-172.17.0.19-1597085075477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-9fb6ec1d-5cdd-4921-903e-66f3d103b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-4b1a6c18-c1f9-4bd4-afa4-f7ff64c1574a,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-19ac66e8-76f2-46d2-8968-d953c7862350,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-ae30228f-45c0-4f7f-9f4c-34e4a925faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-6de515b2-9982-46c3-af26-19a48cea08f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-4407295c-0ff6-4730-896f-308f37dcd55d,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-c4d90143-7c53-49b8-abf0-447707eb6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-936d0b76-c7b6-48d7-a0d4-28f4aac1a52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042652112-172.17.0.19-1597085075477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-9fb6ec1d-5cdd-4921-903e-66f3d103b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-4b1a6c18-c1f9-4bd4-afa4-f7ff64c1574a,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-19ac66e8-76f2-46d2-8968-d953c7862350,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-ae30228f-45c0-4f7f-9f4c-34e4a925faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-6de515b2-9982-46c3-af26-19a48cea08f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35238,DS-4407295c-0ff6-4730-896f-308f37dcd55d,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-c4d90143-7c53-49b8-abf0-447707eb6c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-936d0b76-c7b6-48d7-a0d4-28f4aac1a52a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990442169-172.17.0.19-1597085158523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36078,DS-a154cc25-95f0-48a0-a03a-032c8e5426c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-5a9f5a4a-9403-4841-a849-5448192b42d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-0a6ec178-93e8-4307-a84a-8af46c2b8971,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-9607b35c-9ab9-4b6e-b1a3-750e9c331d83,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-df9c91fb-73ef-49d0-a886-b48274bb1592,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-b38a842b-3ba3-4a6f-9dae-a569eefbd7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-825898af-1347-4b1f-a4bf-092759b5ab42,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-67e2e2b7-e68c-452b-8079-d43a9f8b1713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990442169-172.17.0.19-1597085158523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36078,DS-a154cc25-95f0-48a0-a03a-032c8e5426c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-5a9f5a4a-9403-4841-a849-5448192b42d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-0a6ec178-93e8-4307-a84a-8af46c2b8971,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-9607b35c-9ab9-4b6e-b1a3-750e9c331d83,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-df9c91fb-73ef-49d0-a886-b48274bb1592,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-b38a842b-3ba3-4a6f-9dae-a569eefbd7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-825898af-1347-4b1f-a4bf-092759b5ab42,DISK], DatanodeInfoWithStorage[127.0.0.1:44444,DS-67e2e2b7-e68c-452b-8079-d43a9f8b1713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773784259-172.17.0.19-1597085743035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-ae4f88c4-06fc-4a17-836f-2c00363505b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-c789d672-6785-4281-be76-ab17059849e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-140ff323-4df4-46ef-8e1a-b10ac0427ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-f08d46e7-d341-4e61-8186-41b77be5c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-f16d058f-04b6-49a0-b897-494041b2aae4,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-f6d9eeeb-fe23-4887-8791-8a51e64e970d,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-23910dbf-8a18-4018-b028-b4a6fb19a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-3ab14bca-1170-4afb-b53b-ab81b3340385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773784259-172.17.0.19-1597085743035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40466,DS-ae4f88c4-06fc-4a17-836f-2c00363505b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-c789d672-6785-4281-be76-ab17059849e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-140ff323-4df4-46ef-8e1a-b10ac0427ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-f08d46e7-d341-4e61-8186-41b77be5c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:37721,DS-f16d058f-04b6-49a0-b897-494041b2aae4,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-f6d9eeeb-fe23-4887-8791-8a51e64e970d,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-23910dbf-8a18-4018-b028-b4a6fb19a3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-3ab14bca-1170-4afb-b53b-ab81b3340385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401468967-172.17.0.19-1597085885786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43645,DS-a984e91e-964c-4173-a093-d9fdb22f939e,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-739fd70a-ff54-4eca-ad8e-87a5ec46b847,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-7762f621-a2f8-41ba-bc4e-a7a458216aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-6991bc40-4b24-4e01-9e34-c3c46d1999a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-16866f7e-4646-441e-a7cd-bb14287ced61,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-cb38a434-e9ed-46b9-876c-051a63e8750c,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-7cea5f46-94f3-48dd-bec8-ad058b02f518,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-c70b6aed-27e2-47d4-875d-e7b45225ccdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-401468967-172.17.0.19-1597085885786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43645,DS-a984e91e-964c-4173-a093-d9fdb22f939e,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-739fd70a-ff54-4eca-ad8e-87a5ec46b847,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-7762f621-a2f8-41ba-bc4e-a7a458216aef,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-6991bc40-4b24-4e01-9e34-c3c46d1999a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-16866f7e-4646-441e-a7cd-bb14287ced61,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-cb38a434-e9ed-46b9-876c-051a63e8750c,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-7cea5f46-94f3-48dd-bec8-ad058b02f518,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-c70b6aed-27e2-47d4-875d-e7b45225ccdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822502245-172.17.0.19-1597086076749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-0f67c7c3-c067-4059-91f4-46855b357c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-5fd86b95-3e43-49d6-b086-94b4de5c8aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-e95a79a9-3362-47c6-b6a3-dc0f3f3a1424,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-7e6606ee-eba9-44dd-85bf-aaab481f5df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-750cf267-3bae-47f8-826d-19580d322e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-d0b12e4b-b8c0-4582-99ca-c6b12c7f3597,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-06a73894-5764-4108-8bb5-f02c835b8157,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-3e3256c5-5b07-400a-9a31-23cac292355f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822502245-172.17.0.19-1597086076749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33205,DS-0f67c7c3-c067-4059-91f4-46855b357c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-5fd86b95-3e43-49d6-b086-94b4de5c8aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-e95a79a9-3362-47c6-b6a3-dc0f3f3a1424,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-7e6606ee-eba9-44dd-85bf-aaab481f5df0,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-750cf267-3bae-47f8-826d-19580d322e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-d0b12e4b-b8c0-4582-99ca-c6b12c7f3597,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-06a73894-5764-4108-8bb5-f02c835b8157,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-3e3256c5-5b07-400a-9a31-23cac292355f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464673160-172.17.0.19-1597086107484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-c32927b3-6753-4ad0-828e-e47f24023d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-daf4d789-a84f-4b5c-85bc-b2af0b21adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-778b80cb-0aa4-4541-a5fb-bb947bc2e7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-312ca1fb-4cbb-4254-9c0b-88c67a62e522,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-1019cbd8-54ea-477e-80b6-16ed8aa8a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-0e89cd50-ccf4-4301-9ac7-b6bd14d91d50,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-2c81a5c4-9e4c-4799-806b-8a80ca7d6d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-8f04dc3c-ec06-49c3-b1b6-b10b3f95961b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-464673160-172.17.0.19-1597086107484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41372,DS-c32927b3-6753-4ad0-828e-e47f24023d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-daf4d789-a84f-4b5c-85bc-b2af0b21adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-778b80cb-0aa4-4541-a5fb-bb947bc2e7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-312ca1fb-4cbb-4254-9c0b-88c67a62e522,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-1019cbd8-54ea-477e-80b6-16ed8aa8a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-0e89cd50-ccf4-4301-9ac7-b6bd14d91d50,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-2c81a5c4-9e4c-4799-806b-8a80ca7d6d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-8f04dc3c-ec06-49c3-b1b6-b10b3f95961b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082908843-172.17.0.19-1597086255279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-d76b272e-4b22-499b-b36e-1d07f974a288,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-29fde402-47eb-481b-94d6-f3c983c92373,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-bfd881ba-aaa3-4d1e-88bc-c5a64dca15be,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-6867144f-ef4c-4930-a98d-60143dc92de4,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-2b57c44a-1cca-4194-bf32-41e79c23976d,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-3a881636-8af2-456b-abf6-80fffeffeeff,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-0057e23c-953b-4ae7-8b86-99dbf8eaa697,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-26d6f7ea-297d-488f-9978-bf8f5890395c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1082908843-172.17.0.19-1597086255279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43350,DS-d76b272e-4b22-499b-b36e-1d07f974a288,DISK], DatanodeInfoWithStorage[127.0.0.1:33949,DS-29fde402-47eb-481b-94d6-f3c983c92373,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-bfd881ba-aaa3-4d1e-88bc-c5a64dca15be,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-6867144f-ef4c-4930-a98d-60143dc92de4,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-2b57c44a-1cca-4194-bf32-41e79c23976d,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-3a881636-8af2-456b-abf6-80fffeffeeff,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-0057e23c-953b-4ae7-8b86-99dbf8eaa697,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-26d6f7ea-297d-488f-9978-bf8f5890395c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.socket.reuse.keepalive
component: hdfs:DataNode
v1: 40
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167735953-172.17.0.19-1597086920675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45087,DS-fb1d3fd5-a352-4f84-8ade-22c4cecfa7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-de67bb26-0e27-4446-ab30-cb6cd4dd1d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-9dce09bb-c4aa-48fc-bc85-ef77aa581db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-eb551556-4b05-4483-950b-a1407dd26596,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-3f928b45-5f37-4f6c-837e-b6d8bdbd94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-b873cc9c-cc3e-4a94-a79a-e0e08595cc86,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-039751a9-1427-4046-afce-57c35d1fe645,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-4f4fdf03-4fcc-4efb-a3a5-5db129e38ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167735953-172.17.0.19-1597086920675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45087,DS-fb1d3fd5-a352-4f84-8ade-22c4cecfa7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-de67bb26-0e27-4446-ab30-cb6cd4dd1d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-9dce09bb-c4aa-48fc-bc85-ef77aa581db8,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-eb551556-4b05-4483-950b-a1407dd26596,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-3f928b45-5f37-4f6c-837e-b6d8bdbd94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-b873cc9c-cc3e-4a94-a79a-e0e08595cc86,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-039751a9-1427-4046-afce-57c35d1fe645,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-4f4fdf03-4fcc-4efb-a3a5-5db129e38ec0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5630
