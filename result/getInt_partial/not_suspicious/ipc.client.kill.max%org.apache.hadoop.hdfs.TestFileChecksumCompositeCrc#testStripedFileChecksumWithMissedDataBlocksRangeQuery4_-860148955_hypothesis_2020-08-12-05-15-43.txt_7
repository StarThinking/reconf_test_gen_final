reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182356172-172.17.0.7-1597209965319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45635,DS-5421e5d5-ef41-4d97-926d-1b5f25e11d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-20d3e884-db11-4b8b-ae62-36112fcfe5af,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-4fb0d992-6faa-4d7e-b0ef-28740505fc64,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-03668eed-725c-4331-8cfe-de55b8da6b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-f75f0692-d68c-4e91-b78b-a37ed3c8f650,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-5604e239-3dc3-43b6-9db3-32225cb4a4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-747ffdb1-c3d6-4b10-b8a8-8acd2196e605,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-f2197123-7083-4a6b-b50b-b21ffb9dd4fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182356172-172.17.0.7-1597209965319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45635,DS-5421e5d5-ef41-4d97-926d-1b5f25e11d44,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-20d3e884-db11-4b8b-ae62-36112fcfe5af,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-4fb0d992-6faa-4d7e-b0ef-28740505fc64,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-03668eed-725c-4331-8cfe-de55b8da6b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-f75f0692-d68c-4e91-b78b-a37ed3c8f650,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-5604e239-3dc3-43b6-9db3-32225cb4a4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-747ffdb1-c3d6-4b10-b8a8-8acd2196e605,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-f2197123-7083-4a6b-b50b-b21ffb9dd4fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85526387-172.17.0.7-1597210108087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-c7e48850-56da-4785-98a6-2253c3a0006b,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-ec8eb4d3-d6e1-4b28-b77b-26b1969c797f,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-91c2f1b0-7a6b-42f1-beb4-7fb52604ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-345dba01-4b9b-47b9-8d05-c2cb1eb2f629,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-c50ca49d-f474-4e05-9d5c-3e941c19330d,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-78dbd449-ac5f-44b8-99c1-e5481a3db9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-ddd8c974-4de3-4e67-b6a9-e8c478b1fd35,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-9fd66541-3667-4e53-9fbc-3d4740eba34b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85526387-172.17.0.7-1597210108087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40373,DS-c7e48850-56da-4785-98a6-2253c3a0006b,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-ec8eb4d3-d6e1-4b28-b77b-26b1969c797f,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-91c2f1b0-7a6b-42f1-beb4-7fb52604ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-345dba01-4b9b-47b9-8d05-c2cb1eb2f629,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-c50ca49d-f474-4e05-9d5c-3e941c19330d,DISK], DatanodeInfoWithStorage[127.0.0.1:35991,DS-78dbd449-ac5f-44b8-99c1-e5481a3db9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-ddd8c974-4de3-4e67-b6a9-e8c478b1fd35,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-9fd66541-3667-4e53-9fbc-3d4740eba34b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080821370-172.17.0.7-1597210831428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35802,DS-da8f683c-6b1f-4674-9023-655b0abc3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-cd3672c9-ad36-4803-b651-4deee005b62f,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-e0b7b2da-54f9-432f-80d0-cd14fc82e216,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-1b847bee-287d-4797-a3c9-576f94651cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-90d00efc-a6ff-4d66-af8d-190483940abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-4ad69a18-6a6f-4e2d-8081-480cbd85311b,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-c660e71f-fdb2-42dd-a011-3688e78feaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-569b551e-8fe4-417e-ae65-1bf95083d587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080821370-172.17.0.7-1597210831428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35802,DS-da8f683c-6b1f-4674-9023-655b0abc3bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-cd3672c9-ad36-4803-b651-4deee005b62f,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-e0b7b2da-54f9-432f-80d0-cd14fc82e216,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-1b847bee-287d-4797-a3c9-576f94651cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-90d00efc-a6ff-4d66-af8d-190483940abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-4ad69a18-6a6f-4e2d-8081-480cbd85311b,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-c660e71f-fdb2-42dd-a011-3688e78feaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-569b551e-8fe4-417e-ae65-1bf95083d587,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719182540-172.17.0.7-1597211581736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37202,DS-d4d6fd92-de04-4ece-9774-7a01409dd1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-e0099c45-3c9f-4cf2-b0ab-7d83c54b6911,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-94fe909c-2a15-4046-a94b-9f116b0023ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-255130fe-66ba-4102-b534-b138bde18780,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-45caaff4-a24f-4e39-b149-1c96ec065960,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-534fab90-9631-4bcc-b88e-b81a39dc1fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-d07eb2c7-92fe-4b4c-8dd1-35be7689dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-79e1c87b-44df-4a7e-a3f6-980953ec310a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1719182540-172.17.0.7-1597211581736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37202,DS-d4d6fd92-de04-4ece-9774-7a01409dd1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-e0099c45-3c9f-4cf2-b0ab-7d83c54b6911,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-94fe909c-2a15-4046-a94b-9f116b0023ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-255130fe-66ba-4102-b534-b138bde18780,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-45caaff4-a24f-4e39-b149-1c96ec065960,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-534fab90-9631-4bcc-b88e-b81a39dc1fad,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-d07eb2c7-92fe-4b4c-8dd1-35be7689dd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-79e1c87b-44df-4a7e-a3f6-980953ec310a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219164299-172.17.0.7-1597211625006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33503,DS-d6e11fa2-ecc5-4282-97b1-fe390c02180b,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-8a34a718-d7e5-462e-bde7-efae7981706f,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-2095d2c9-4c11-4384-91ee-051c69d2d69d,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-c3950578-0e2c-48ba-9f82-f9957b1641da,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-db3945c5-0c91-44b5-8ab4-780e2448eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-f481a847-6c6d-4d36-b1e8-7a66b3db4fae,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-d7dc53e7-2df2-4387-9264-7cf39c72ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-bdf7e6a2-a5c6-4096-96a9-9c90950af689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219164299-172.17.0.7-1597211625006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33503,DS-d6e11fa2-ecc5-4282-97b1-fe390c02180b,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-8a34a718-d7e5-462e-bde7-efae7981706f,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-2095d2c9-4c11-4384-91ee-051c69d2d69d,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-c3950578-0e2c-48ba-9f82-f9957b1641da,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-db3945c5-0c91-44b5-8ab4-780e2448eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-f481a847-6c6d-4d36-b1e8-7a66b3db4fae,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-d7dc53e7-2df2-4387-9264-7cf39c72ac7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-bdf7e6a2-a5c6-4096-96a9-9c90950af689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564992235-172.17.0.7-1597211755660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-a7a422f3-1499-481c-923b-a8a9ea90c585,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-8877cd40-0723-47ef-a74d-5468d60f9134,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-2a4aa7af-7cd8-4fca-8ff7-bd02406e1381,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-66105952-ee1c-4722-a8fa-f8aa76807e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-7cad82f8-c667-4420-b1a7-61e1ecd6395d,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-34777b17-6d36-4b74-ae01-c305e9d775fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-eb306132-5365-4ace-adfc-245e66a04760,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-3fb96f75-1ea3-4eb1-a935-da4d08ce4bbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1564992235-172.17.0.7-1597211755660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35781,DS-a7a422f3-1499-481c-923b-a8a9ea90c585,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-8877cd40-0723-47ef-a74d-5468d60f9134,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-2a4aa7af-7cd8-4fca-8ff7-bd02406e1381,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-66105952-ee1c-4722-a8fa-f8aa76807e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-7cad82f8-c667-4420-b1a7-61e1ecd6395d,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-34777b17-6d36-4b74-ae01-c305e9d775fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-eb306132-5365-4ace-adfc-245e66a04760,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-3fb96f75-1ea3-4eb1-a935-da4d08ce4bbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512285313-172.17.0.7-1597212492717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-ba72e772-a2c3-400c-92b2-631b1cf73970,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-dfd660d0-b43f-46b2-8218-e8f711d364ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-9ea7abbc-01ec-4e1d-9f82-7d84b3c017bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-41a4a1ff-a81c-4e88-973e-54c9ec71eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-77d77b4c-0175-4110-883c-69212329ea90,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-3a6f3613-0ce6-4c37-b72f-46d7307656f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-e0f0084e-e6bb-4b1f-9142-95a84589f6df,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-44a1d716-d564-4465-a579-e158514996f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512285313-172.17.0.7-1597212492717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45774,DS-ba72e772-a2c3-400c-92b2-631b1cf73970,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-dfd660d0-b43f-46b2-8218-e8f711d364ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-9ea7abbc-01ec-4e1d-9f82-7d84b3c017bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-41a4a1ff-a81c-4e88-973e-54c9ec71eedb,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-77d77b4c-0175-4110-883c-69212329ea90,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-3a6f3613-0ce6-4c37-b72f-46d7307656f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-e0f0084e-e6bb-4b1f-9142-95a84589f6df,DISK], DatanodeInfoWithStorage[127.0.0.1:44972,DS-44a1d716-d564-4465-a579-e158514996f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370082030-172.17.0.7-1597212541627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-c7af5869-b056-41e4-9b2e-f4cdc793da17,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2a2c4570-c20a-40d0-b4e3-245c90c25c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-ec0f7bcf-3746-4800-bd07-33cd7fa709d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-c42c3c97-c6aa-4138-84b8-31a9561f2960,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-8b0516d8-1206-499d-8901-da6dfd38a17a,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-e1d2e22d-7f4c-4bef-af40-27f67ffc6f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-ec1198e5-e39b-4e70-8a9d-b5da90030e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-13b49907-e185-4ee3-929a-f53887f28223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1370082030-172.17.0.7-1597212541627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45713,DS-c7af5869-b056-41e4-9b2e-f4cdc793da17,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2a2c4570-c20a-40d0-b4e3-245c90c25c60,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-ec0f7bcf-3746-4800-bd07-33cd7fa709d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-c42c3c97-c6aa-4138-84b8-31a9561f2960,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-8b0516d8-1206-499d-8901-da6dfd38a17a,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-e1d2e22d-7f4c-4bef-af40-27f67ffc6f95,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-ec1198e5-e39b-4e70-8a9d-b5da90030e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39033,DS-13b49907-e185-4ee3-929a-f53887f28223,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539477120-172.17.0.7-1597212759468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-0b75d184-8d43-43be-b909-4023b05b759f,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-8ce07870-c0e3-4cec-88dd-525d149bd26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-1871df8d-4e16-4731-bfe3-b515b055a962,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-04d9c533-a917-4fd2-8aba-b500aad2f13b,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-c8e5e503-d5f3-484e-8ed4-8ef1fb6f3cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-3ce84323-8fea-4388-a84c-36aab58af50c,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-51cc41bf-97a2-49c9-b7c7-124957fd3f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-aeb5061a-6557-4bc1-a8b8-5aba26826de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539477120-172.17.0.7-1597212759468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33735,DS-0b75d184-8d43-43be-b909-4023b05b759f,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-8ce07870-c0e3-4cec-88dd-525d149bd26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-1871df8d-4e16-4731-bfe3-b515b055a962,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-04d9c533-a917-4fd2-8aba-b500aad2f13b,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-c8e5e503-d5f3-484e-8ed4-8ef1fb6f3cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36278,DS-3ce84323-8fea-4388-a84c-36aab58af50c,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-51cc41bf-97a2-49c9-b7c7-124957fd3f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-aeb5061a-6557-4bc1-a8b8-5aba26826de9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050595459-172.17.0.7-1597213271392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-73d4c280-a66f-496d-92cb-6f92bc500a94,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-6da46403-50ec-4c00-b029-14571c375961,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-7e01914d-2dff-42e2-8555-b28e16616ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-8a6e5a0b-f956-497d-a47c-4260a2d6b8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-c88ae56a-54d1-44f8-8415-4cabcab235c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-bd8c64eb-8955-4937-8165-34deae11cec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-458be40e-4e65-4aa6-a088-66df64cd9d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-bde93bf9-3994-4bcf-a457-a158782e801c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050595459-172.17.0.7-1597213271392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-73d4c280-a66f-496d-92cb-6f92bc500a94,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-6da46403-50ec-4c00-b029-14571c375961,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-7e01914d-2dff-42e2-8555-b28e16616ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-8a6e5a0b-f956-497d-a47c-4260a2d6b8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-c88ae56a-54d1-44f8-8415-4cabcab235c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-bd8c64eb-8955-4937-8165-34deae11cec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-458be40e-4e65-4aa6-a088-66df64cd9d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-bde93bf9-3994-4bcf-a457-a158782e801c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347792173-172.17.0.7-1597213498455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-08796c13-233a-4f72-82da-8aec07938ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-ba425bb1-c428-4958-83f9-9e986f4ff90b,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-9df9367b-61f3-47a3-80d3-57c629881af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-d3b25393-2a5a-4b38-a3d6-b63b98261524,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-d9c42370-7b4f-4606-9075-2f69f7f1533d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-c132d834-33fe-4724-a789-b8d2f76e027d,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-7fe3a7ae-acbe-48e1-b83d-34dae9b6d685,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-2e0fb7a9-e9cd-49a8-922e-0fcf0acd26f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347792173-172.17.0.7-1597213498455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-08796c13-233a-4f72-82da-8aec07938ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46182,DS-ba425bb1-c428-4958-83f9-9e986f4ff90b,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-9df9367b-61f3-47a3-80d3-57c629881af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-d3b25393-2a5a-4b38-a3d6-b63b98261524,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-d9c42370-7b4f-4606-9075-2f69f7f1533d,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-c132d834-33fe-4724-a789-b8d2f76e027d,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-7fe3a7ae-acbe-48e1-b83d-34dae9b6d685,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-2e0fb7a9-e9cd-49a8-922e-0fcf0acd26f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1102764308-172.17.0.7-1597214027035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46880,DS-2e3ea71e-1d79-4c91-8f48-78047599c161,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-c7b60ba6-db85-4184-8fc4-e9845f1eeb04,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-68e8ec10-d3b6-4c3a-a1d1-ede49acfed96,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-2bb91c31-0b72-4cdd-a848-c53d8a7cb39b,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-be56ac62-deea-4c0a-9d46-09dad2a5c138,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-2791e442-a374-423a-986b-961de9322770,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-266e04d4-679d-4b8d-bf09-f4d84b28aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-1b8f1dc8-2c8d-45d3-b95d-99c7927a9693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1102764308-172.17.0.7-1597214027035:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46880,DS-2e3ea71e-1d79-4c91-8f48-78047599c161,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-c7b60ba6-db85-4184-8fc4-e9845f1eeb04,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-68e8ec10-d3b6-4c3a-a1d1-ede49acfed96,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-2bb91c31-0b72-4cdd-a848-c53d8a7cb39b,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-be56ac62-deea-4c0a-9d46-09dad2a5c138,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-2791e442-a374-423a-986b-961de9322770,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-266e04d4-679d-4b8d-bf09-f4d84b28aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-1b8f1dc8-2c8d-45d3-b95d-99c7927a9693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999031831-172.17.0.7-1597214791365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42880,DS-338eaaf4-7f44-4d02-a303-2c03f1a07eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-15c7befa-e705-4d32-a869-aa0c2a462304,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-43e469ce-bbcd-4a7b-ae17-34fb29da3925,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-bd54b75a-94e1-4fcb-b325-37096a7d7e25,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-c62625ff-7eef-4bbd-974d-fa72652a3e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-6208a789-1289-4c42-851c-cf5375757225,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-3ef3e457-f044-4ab2-ad78-86cf07e9e812,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-a3c4b517-6eb3-49b4-b428-1e75c7fa0098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999031831-172.17.0.7-1597214791365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42880,DS-338eaaf4-7f44-4d02-a303-2c03f1a07eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-15c7befa-e705-4d32-a869-aa0c2a462304,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-43e469ce-bbcd-4a7b-ae17-34fb29da3925,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-bd54b75a-94e1-4fcb-b325-37096a7d7e25,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-c62625ff-7eef-4bbd-974d-fa72652a3e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-6208a789-1289-4c42-851c-cf5375757225,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-3ef3e457-f044-4ab2-ad78-86cf07e9e812,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-a3c4b517-6eb3-49b4-b428-1e75c7fa0098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958865625-172.17.0.7-1597214996050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46356,DS-4f8cf0ca-8d85-41a6-acec-23e838d7207b,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-043e25cd-09c7-4656-b8da-fd73f614a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-7d7a7455-e9ef-4703-8ac0-c64629d0403e,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-93060194-531b-4e2b-b7a3-39f9bcb10814,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-90a4150a-0373-43d0-967e-03dcb8b491dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-451ef498-58af-4ba2-89a9-9362cfa54ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-edf394d1-f3bd-4fb0-94bf-433f6d9637b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-f2492985-b6d7-4aed-a5bf-1ca5f02ef339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-958865625-172.17.0.7-1597214996050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46356,DS-4f8cf0ca-8d85-41a6-acec-23e838d7207b,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-043e25cd-09c7-4656-b8da-fd73f614a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-7d7a7455-e9ef-4703-8ac0-c64629d0403e,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-93060194-531b-4e2b-b7a3-39f9bcb10814,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-90a4150a-0373-43d0-967e-03dcb8b491dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-451ef498-58af-4ba2-89a9-9362cfa54ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-edf394d1-f3bd-4fb0-94bf-433f6d9637b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-f2492985-b6d7-4aed-a5bf-1ca5f02ef339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900032821-172.17.0.7-1597215040340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34581,DS-d8b883c2-cee0-4852-b6fc-d59862bdee02,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-6cbe0d03-f24f-4189-8032-a03df9dd7ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-3b06297b-526c-442a-9554-25b122c3c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-8aca8486-83ea-46bb-984a-1a180f58f47e,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-7bbee5de-6cfa-4005-a01a-a0e8efc135cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-c7aeefe4-ddfe-456e-a491-98a1bd035882,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-09a37114-1f3d-4fe4-a047-0a814ee5ac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-5f7b8246-50b7-42b7-9634-5867568477c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900032821-172.17.0.7-1597215040340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34581,DS-d8b883c2-cee0-4852-b6fc-d59862bdee02,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-6cbe0d03-f24f-4189-8032-a03df9dd7ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-3b06297b-526c-442a-9554-25b122c3c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-8aca8486-83ea-46bb-984a-1a180f58f47e,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-7bbee5de-6cfa-4005-a01a-a0e8efc135cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-c7aeefe4-ddfe-456e-a491-98a1bd035882,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-09a37114-1f3d-4fe4-a047-0a814ee5ac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-5f7b8246-50b7-42b7-9634-5867568477c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623983245-172.17.0.7-1597215537213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-68452f6a-99b9-431e-88f8-507d1c57b279,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-5ecbcc57-9f9d-4b61-b11f-436c6fdf8e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-92143404-83aa-43e7-99c5-4f12ae66dc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-92713ca2-b784-4873-98bd-b12be8389a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-0128a00a-d022-4c76-8f49-cbddb873bf03,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-665ab060-04d1-4121-a363-28d65886034e,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-81a7423d-2243-41f1-8f90-fff43a05321d,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-3f33740c-4101-4a0f-8fd6-4d52861f64df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623983245-172.17.0.7-1597215537213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36872,DS-68452f6a-99b9-431e-88f8-507d1c57b279,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-5ecbcc57-9f9d-4b61-b11f-436c6fdf8e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-92143404-83aa-43e7-99c5-4f12ae66dc39,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-92713ca2-b784-4873-98bd-b12be8389a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-0128a00a-d022-4c76-8f49-cbddb873bf03,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-665ab060-04d1-4121-a363-28d65886034e,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-81a7423d-2243-41f1-8f90-fff43a05321d,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-3f33740c-4101-4a0f-8fd6-4d52861f64df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061457716-172.17.0.7-1597215784713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-08163416-c096-4ecb-8368-9b61eb62cabb,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-a91bab86-3238-4dff-ac68-3c805cab0c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-332411fb-53d4-487d-8a00-692f66400787,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-62aeacdb-aa96-4a76-a279-31123cb1021a,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-b22e3ea2-ad7e-4bba-bd22-c84955058d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-67973943-e0b1-49ab-8456-9e0b0404bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-95ad9eff-dff7-4456-9f59-3d3c5e12d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-cb2a75a6-553e-4e57-8384-bee7f8d962a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061457716-172.17.0.7-1597215784713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-08163416-c096-4ecb-8368-9b61eb62cabb,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-a91bab86-3238-4dff-ac68-3c805cab0c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-332411fb-53d4-487d-8a00-692f66400787,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-62aeacdb-aa96-4a76-a279-31123cb1021a,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-b22e3ea2-ad7e-4bba-bd22-c84955058d85,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-67973943-e0b1-49ab-8456-9e0b0404bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-95ad9eff-dff7-4456-9f59-3d3c5e12d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-cb2a75a6-553e-4e57-8384-bee7f8d962a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 6550
