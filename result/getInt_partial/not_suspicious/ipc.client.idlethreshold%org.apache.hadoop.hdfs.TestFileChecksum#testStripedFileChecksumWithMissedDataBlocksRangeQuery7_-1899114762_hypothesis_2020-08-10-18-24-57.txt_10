reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875912589-172.17.0.12-1597083951125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36041,DS-ed4cdde4-ef02-496f-9b39-0a45a66514f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-4527b988-1bff-4502-a914-6cadf3853ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-17e32e76-72e3-455c-9fed-145f11391540,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-3a0aece9-8fdd-4fcf-8e8d-fb9c9caa61ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-718f4ad7-0b85-46fb-bc45-dd42c59749ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-e37f0a82-e794-404c-ae13-b09340d2dbef,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-0f1539d9-6e59-46b3-91c6-ae05dcdfe67c,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-d65f1929-02fc-4c4d-ba27-39077c6faa80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875912589-172.17.0.12-1597083951125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36041,DS-ed4cdde4-ef02-496f-9b39-0a45a66514f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-4527b988-1bff-4502-a914-6cadf3853ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-17e32e76-72e3-455c-9fed-145f11391540,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-3a0aece9-8fdd-4fcf-8e8d-fb9c9caa61ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-718f4ad7-0b85-46fb-bc45-dd42c59749ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-e37f0a82-e794-404c-ae13-b09340d2dbef,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-0f1539d9-6e59-46b3-91c6-ae05dcdfe67c,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-d65f1929-02fc-4c4d-ba27-39077c6faa80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363600704-172.17.0.12-1597084202416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32779,DS-7810cfd9-3606-471b-b25b-23b6e54c37d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-9a2e1684-d730-4dc3-96ce-93cbf96e32bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-f7295cda-7503-4b0c-88cd-850bdcfe325b,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-edc33d4a-8439-4994-88f5-68e2be17c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-502a0561-3541-4d94-bc9c-b3b31d7c41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-5c1605bb-1d5b-4d6c-abdd-52eb83372ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-e9d636cb-4db7-4588-8ef0-ffad031a506b,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-d23e8646-a3bf-40df-973b-81b253281ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363600704-172.17.0.12-1597084202416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32779,DS-7810cfd9-3606-471b-b25b-23b6e54c37d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37309,DS-9a2e1684-d730-4dc3-96ce-93cbf96e32bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-f7295cda-7503-4b0c-88cd-850bdcfe325b,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-edc33d4a-8439-4994-88f5-68e2be17c8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-502a0561-3541-4d94-bc9c-b3b31d7c41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-5c1605bb-1d5b-4d6c-abdd-52eb83372ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-e9d636cb-4db7-4588-8ef0-ffad031a506b,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-d23e8646-a3bf-40df-973b-81b253281ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157881225-172.17.0.12-1597084310951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-10994e79-171f-41eb-acb4-64673f5cb552,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-a08dc0c6-9d1a-4b05-bbab-8c67d99beafb,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-80106dbb-470d-4f7c-ac95-63225ca9b53b,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-06ad7a6c-5bf1-40ed-8cd0-612505ed7877,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-32f1bc2a-7542-417e-b72f-9451600f2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-6bd83b63-e14e-4cdd-a232-bd7d055e9826,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-5b293c35-e659-443a-981c-3d128ce63750,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-2735e392-528f-4858-b6a9-02edb78cca06,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157881225-172.17.0.12-1597084310951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-10994e79-171f-41eb-acb4-64673f5cb552,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-a08dc0c6-9d1a-4b05-bbab-8c67d99beafb,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-80106dbb-470d-4f7c-ac95-63225ca9b53b,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-06ad7a6c-5bf1-40ed-8cd0-612505ed7877,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-32f1bc2a-7542-417e-b72f-9451600f2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:37317,DS-6bd83b63-e14e-4cdd-a232-bd7d055e9826,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-5b293c35-e659-443a-981c-3d128ce63750,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-2735e392-528f-4858-b6a9-02edb78cca06,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308442016-172.17.0.12-1597084390529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38281,DS-eb637721-3afe-41b4-a8d2-ca50701e9c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-04dfa29c-426e-4c1c-b834-7611f5d12a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-88e68f07-81ed-4c74-b0f2-49384a8071f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-80ab8957-4c37-447b-8331-a757220bae0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-c2447726-1f33-4085-9015-14d3265358bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-6af5a753-b308-40b5-88c1-8a45dc2cc030,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-8be43d38-05df-4db8-9c4a-ccbe510961dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-c4559847-641a-4928-aba8-1c11c6ea55d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308442016-172.17.0.12-1597084390529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38281,DS-eb637721-3afe-41b4-a8d2-ca50701e9c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-04dfa29c-426e-4c1c-b834-7611f5d12a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-88e68f07-81ed-4c74-b0f2-49384a8071f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-80ab8957-4c37-447b-8331-a757220bae0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-c2447726-1f33-4085-9015-14d3265358bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-6af5a753-b308-40b5-88c1-8a45dc2cc030,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-8be43d38-05df-4db8-9c4a-ccbe510961dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-c4559847-641a-4928-aba8-1c11c6ea55d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707315085-172.17.0.12-1597084538778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43216,DS-ebfcba3b-8dfb-460e-b2cd-f2c03988e994,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-fe4cdc30-9624-40c6-b33b-0c122727623d,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-9528ca6c-063f-4341-8418-5407a3d6092d,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-6c27b08e-a61d-4de9-982f-bec8fcfb90ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-35c525ee-9ed1-49c5-89bd-a140394018f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-8331616c-6b45-424d-88e0-811cb2cfecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-1a58f395-196c-419e-9015-c67a60977a51,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-7a58e606-a6be-440e-a5b7-4397d211d86a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707315085-172.17.0.12-1597084538778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43216,DS-ebfcba3b-8dfb-460e-b2cd-f2c03988e994,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-fe4cdc30-9624-40c6-b33b-0c122727623d,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-9528ca6c-063f-4341-8418-5407a3d6092d,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-6c27b08e-a61d-4de9-982f-bec8fcfb90ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-35c525ee-9ed1-49c5-89bd-a140394018f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-8331616c-6b45-424d-88e0-811cb2cfecc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-1a58f395-196c-419e-9015-c67a60977a51,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-7a58e606-a6be-440e-a5b7-4397d211d86a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092597716-172.17.0.12-1597084573766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39852,DS-df373433-e83f-496f-a300-97e54de47d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-2764a018-7837-4928-8637-addbd29f72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-009de114-6a05-4d9d-b035-22ee360973b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-6cf5d0aa-178a-4365-9f02-1f17254a67e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-98fc9a75-499c-49a8-bbb5-b7bed2ce7e26,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-6b81ca7b-0b56-40c8-8afd-a6845233c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-1e6fa61a-112d-4c13-a266-a88463402d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-d8de1060-9a8b-4173-b4ad-0dec3747cf6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092597716-172.17.0.12-1597084573766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39852,DS-df373433-e83f-496f-a300-97e54de47d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-2764a018-7837-4928-8637-addbd29f72b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-009de114-6a05-4d9d-b035-22ee360973b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-6cf5d0aa-178a-4365-9f02-1f17254a67e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-98fc9a75-499c-49a8-bbb5-b7bed2ce7e26,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-6b81ca7b-0b56-40c8-8afd-a6845233c6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-1e6fa61a-112d-4c13-a266-a88463402d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-d8de1060-9a8b-4173-b4ad-0dec3747cf6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449818343-172.17.0.12-1597084932450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-6b19224b-c7d5-4382-9cf3-dbaec51cfc58,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-7ecd8796-5565-440d-908d-f67623604399,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-1e8152b2-1aec-491d-8336-ba430bd6e8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-5bbb1142-f681-4977-ba22-818cb5778913,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-f51b328d-0bd5-4c67-8d9a-7ece30ffb500,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-2574dfcc-7dd2-4951-b5f7-81936a5056e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-25ac4f19-4e33-47eb-9b80-f8c2933a8940,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-63ea0520-bada-4f66-8013-caa006de6068,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1449818343-172.17.0.12-1597084932450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37696,DS-6b19224b-c7d5-4382-9cf3-dbaec51cfc58,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-7ecd8796-5565-440d-908d-f67623604399,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-1e8152b2-1aec-491d-8336-ba430bd6e8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-5bbb1142-f681-4977-ba22-818cb5778913,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-f51b328d-0bd5-4c67-8d9a-7ece30ffb500,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-2574dfcc-7dd2-4951-b5f7-81936a5056e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-25ac4f19-4e33-47eb-9b80-f8c2933a8940,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-63ea0520-bada-4f66-8013-caa006de6068,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348708140-172.17.0.12-1597084969911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-f1643015-960c-43e7-8c5b-e53da63e30c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-b0478621-e132-418b-9873-8469abe85e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-05963b5e-69ef-4e69-98ed-8404803b4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f5e3097a-6534-4593-a2d6-ae171014d290,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-f0ed44e3-bffe-4632-9d9c-662b6071763c,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-38562f42-8e41-4a10-b8bb-98cd4a099cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-377fa47c-93bb-4134-a544-8abf04080672,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-8f437a2c-c86d-4974-a290-dce62914a08a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348708140-172.17.0.12-1597084969911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33811,DS-f1643015-960c-43e7-8c5b-e53da63e30c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-b0478621-e132-418b-9873-8469abe85e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-05963b5e-69ef-4e69-98ed-8404803b4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f5e3097a-6534-4593-a2d6-ae171014d290,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-f0ed44e3-bffe-4632-9d9c-662b6071763c,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-38562f42-8e41-4a10-b8bb-98cd4a099cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-377fa47c-93bb-4134-a544-8abf04080672,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-8f437a2c-c86d-4974-a290-dce62914a08a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442909894-172.17.0.12-1597085043409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45437,DS-3a9363c3-0e9a-482f-bd53-305f382caadb,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-2b724e32-2f1b-4c9f-840b-0c3352015814,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-39140823-feb8-4e51-849e-dfe9238477e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-5dea5737-0532-4588-8a07-8e840385e1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-3a70b3a7-c159-4f9c-abf6-625b28c67765,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-16442346-eb28-4272-88cf-2c3c490d293e,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-5a315159-612c-461b-a58e-fff5ca8418b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-9369bc58-390f-4860-a2c4-ac3230acbc29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-442909894-172.17.0.12-1597085043409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45437,DS-3a9363c3-0e9a-482f-bd53-305f382caadb,DISK], DatanodeInfoWithStorage[127.0.0.1:36020,DS-2b724e32-2f1b-4c9f-840b-0c3352015814,DISK], DatanodeInfoWithStorage[127.0.0.1:43842,DS-39140823-feb8-4e51-849e-dfe9238477e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-5dea5737-0532-4588-8a07-8e840385e1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-3a70b3a7-c159-4f9c-abf6-625b28c67765,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-16442346-eb28-4272-88cf-2c3c490d293e,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-5a315159-612c-461b-a58e-fff5ca8418b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-9369bc58-390f-4860-a2c4-ac3230acbc29,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107449424-172.17.0.12-1597085231403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35412,DS-eb095278-d35d-4509-967a-802df1d6b7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-9551887d-eecc-4fe1-b617-366325fd8ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8b15e08b-297d-402e-a217-e0dfce5031d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-43b0e170-8158-4269-80ec-f7df97c622bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-1b7469eb-f936-425c-a0b3-9952bcc39a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-5b39f099-752f-49d5-af3c-e514cf49a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-e249314c-8fde-4a90-ba35-66dd0b0cbe84,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-c32830b9-d1ef-46a8-a58d-aa8f902daace,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107449424-172.17.0.12-1597085231403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35412,DS-eb095278-d35d-4509-967a-802df1d6b7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-9551887d-eecc-4fe1-b617-366325fd8ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-8b15e08b-297d-402e-a217-e0dfce5031d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46686,DS-43b0e170-8158-4269-80ec-f7df97c622bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-1b7469eb-f936-425c-a0b3-9952bcc39a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-5b39f099-752f-49d5-af3c-e514cf49a5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-e249314c-8fde-4a90-ba35-66dd0b0cbe84,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-c32830b9-d1ef-46a8-a58d-aa8f902daace,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100886189-172.17.0.12-1597085298133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-6c662576-bc12-42a6-822a-2c597d814aac,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-dd7772fb-ba57-4419-b087-b267054a944f,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-35551bca-f30e-480d-8ee8-bb139f8177e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-44c9be8d-5717-498f-9c0e-c6a0cc3e386e,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-45e48f4c-835a-45ba-ae1c-c4129ccc6e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-433af020-c745-4baf-8b18-ac36f2362f77,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-d4b25dc1-e234-4264-aa49-b0428fd683a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-20d1ad37-7fb6-43c8-88ae-5c4160cb6481,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100886189-172.17.0.12-1597085298133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36043,DS-6c662576-bc12-42a6-822a-2c597d814aac,DISK], DatanodeInfoWithStorage[127.0.0.1:42774,DS-dd7772fb-ba57-4419-b087-b267054a944f,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-35551bca-f30e-480d-8ee8-bb139f8177e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45498,DS-44c9be8d-5717-498f-9c0e-c6a0cc3e386e,DISK], DatanodeInfoWithStorage[127.0.0.1:34017,DS-45e48f4c-835a-45ba-ae1c-c4129ccc6e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-433af020-c745-4baf-8b18-ac36f2362f77,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-d4b25dc1-e234-4264-aa49-b0428fd683a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-20d1ad37-7fb6-43c8-88ae-5c4160cb6481,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748963983-172.17.0.12-1597085488277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34019,DS-3dae5336-3c23-41e6-9f7e-554edc5f7828,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-4e4c0a4d-bf8f-40c3-bbf8-e18503f75144,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-56dd9eae-9a57-4510-8b27-3a118a5cd832,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-3c04855a-307c-4737-b1b2-f8e982bb71da,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7f0b1436-216e-4481-8c83-fe704474790b,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-22ed0afe-efc0-42e7-a9ac-aca9309ff913,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-0a9d0de8-08bc-403f-9fdc-17bd0fddfabf,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-9cbccf13-4a15-4a08-b0fc-33c11134408a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748963983-172.17.0.12-1597085488277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34019,DS-3dae5336-3c23-41e6-9f7e-554edc5f7828,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-4e4c0a4d-bf8f-40c3-bbf8-e18503f75144,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-56dd9eae-9a57-4510-8b27-3a118a5cd832,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-3c04855a-307c-4737-b1b2-f8e982bb71da,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7f0b1436-216e-4481-8c83-fe704474790b,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-22ed0afe-efc0-42e7-a9ac-aca9309ff913,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-0a9d0de8-08bc-403f-9fdc-17bd0fddfabf,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-9cbccf13-4a15-4a08-b0fc-33c11134408a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721361995-172.17.0.12-1597085590938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-7708f43b-11a0-4c49-9135-5d6dbc51dc86,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-4293aba7-2989-43d6-abaa-dd6fd4a04eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-0a833452-9f99-4ab0-a45c-954e9781857c,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-60cd9eba-93c9-4f7c-a879-53625a9c3ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-c4426338-00ea-46d0-bb19-6b7a652aed76,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-be014bef-8fc0-4803-bd62-0eb0d2d57c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f4fa3acb-e1a2-443e-9501-07e0a33ee424,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-1483e28e-39b6-40cf-bcf2-38eeb2c3dadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721361995-172.17.0.12-1597085590938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37714,DS-7708f43b-11a0-4c49-9135-5d6dbc51dc86,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-4293aba7-2989-43d6-abaa-dd6fd4a04eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-0a833452-9f99-4ab0-a45c-954e9781857c,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-60cd9eba-93c9-4f7c-a879-53625a9c3ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-c4426338-00ea-46d0-bb19-6b7a652aed76,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-be014bef-8fc0-4803-bd62-0eb0d2d57c22,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-f4fa3acb-e1a2-443e-9501-07e0a33ee424,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-1483e28e-39b6-40cf-bcf2-38eeb2c3dadc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864394549-172.17.0.12-1597085627992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-29d74145-a3d7-4bd6-b084-0a849c0b68e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-e4c50cf9-791d-45b8-8db0-26cdcea95522,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-9c532d4c-a85e-425f-b119-7b3b464542c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-f4e92bab-c5ab-4355-9382-1e4877ad9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-3041b08d-152d-4d28-a849-ed2b530dd488,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-f5760b7c-549f-45de-8e92-604803654b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-61b26031-7b19-4b85-8511-933a83e060b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-fd4f7405-201d-454a-bdde-d86ae287d7ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864394549-172.17.0.12-1597085627992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40856,DS-29d74145-a3d7-4bd6-b084-0a849c0b68e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-e4c50cf9-791d-45b8-8db0-26cdcea95522,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-9c532d4c-a85e-425f-b119-7b3b464542c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-f4e92bab-c5ab-4355-9382-1e4877ad9f94,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-3041b08d-152d-4d28-a849-ed2b530dd488,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-f5760b7c-549f-45de-8e92-604803654b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-61b26031-7b19-4b85-8511-933a83e060b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-fd4f7405-201d-454a-bdde-d86ae287d7ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845812399-172.17.0.12-1597086052560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38913,DS-d9316609-b02c-4840-aee4-a5abf130153a,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-4b992237-9817-4952-a902-3df3dbc001cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-7db92d4b-dc6b-41c2-9ac7-c0cf7589c3da,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-576f7c8b-cc31-4ff2-824f-10bb27f271de,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-322bd5cd-cd7b-439b-a57b-bf3ba6fcbcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-0c115541-ba13-4feb-8089-0aa3a387b0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-dc5bee32-49c5-49e3-baca-76962bf790b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-7f3fa16f-3b03-45ea-99fc-48b591e037ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845812399-172.17.0.12-1597086052560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38913,DS-d9316609-b02c-4840-aee4-a5abf130153a,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-4b992237-9817-4952-a902-3df3dbc001cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-7db92d4b-dc6b-41c2-9ac7-c0cf7589c3da,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-576f7c8b-cc31-4ff2-824f-10bb27f271de,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-322bd5cd-cd7b-439b-a57b-bf3ba6fcbcf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-0c115541-ba13-4feb-8089-0aa3a387b0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-dc5bee32-49c5-49e3-baca-76962bf790b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-7f3fa16f-3b03-45ea-99fc-48b591e037ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35916458-172.17.0.12-1597086093910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-59e91e16-f785-4a22-8b74-f22976e2f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-f8c3eba5-2a1e-49ca-bd2c-a6b1eac4adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-c3b5de10-0286-481d-9a96-033eac665ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-e26338b9-cab2-436c-9c11-d7802e54dc85,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-0e36f7b7-8c45-4350-8894-3ae930e74ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-450ed5ed-bbd2-4f3e-ab78-e8e47f787c89,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-1ad67d23-fd73-4909-b1cf-3046c78b482e,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-3d7872c1-b278-4d71-bfbe-2f0280b23c9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35916458-172.17.0.12-1597086093910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-59e91e16-f785-4a22-8b74-f22976e2f80c,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-f8c3eba5-2a1e-49ca-bd2c-a6b1eac4adf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-c3b5de10-0286-481d-9a96-033eac665ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-e26338b9-cab2-436c-9c11-d7802e54dc85,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-0e36f7b7-8c45-4350-8894-3ae930e74ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-450ed5ed-bbd2-4f3e-ab78-e8e47f787c89,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-1ad67d23-fd73-4909-b1cf-3046c78b482e,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-3d7872c1-b278-4d71-bfbe-2f0280b23c9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950408988-172.17.0.12-1597086201631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-08482921-bb55-48a9-9535-b6e9899d378a,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-f52a7d0e-e6e4-4246-a187-0b2c3de8b8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-cae04963-7654-496a-abe9-f94dd1365a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-1a7f7b5e-a3d7-45f3-9119-9cc7c0d64c16,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-4ec76781-db1d-41c5-b24c-9fd077ef1d14,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-94d84129-a7dd-4118-b4c4-7fd50b117535,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-fa9e72c6-3fa5-4f18-a3aa-28853a7f06f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-6d258c7f-bde0-4891-81c6-bcf06cd2ecfe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950408988-172.17.0.12-1597086201631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37056,DS-08482921-bb55-48a9-9535-b6e9899d378a,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-f52a7d0e-e6e4-4246-a187-0b2c3de8b8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-cae04963-7654-496a-abe9-f94dd1365a77,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-1a7f7b5e-a3d7-45f3-9119-9cc7c0d64c16,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-4ec76781-db1d-41c5-b24c-9fd077ef1d14,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-94d84129-a7dd-4118-b4c4-7fd50b117535,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-fa9e72c6-3fa5-4f18-a3aa-28853a7f06f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-6d258c7f-bde0-4891-81c6-bcf06cd2ecfe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881310535-172.17.0.12-1597086647948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34989,DS-64c1b315-1605-4d06-9051-3a55ab559c67,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-5a05ffb2-5b8b-4750-afa5-49db4681ad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-2411838f-7d4c-42bb-91bb-c37732ccc9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d89a1d8b-48f4-48b9-afb8-cd3ea405828d,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-b97f0a26-f6de-439f-b18a-ce54521ed8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-6bf6feb1-473f-472f-a0db-33f7c859bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-c3435edc-359e-43f8-a12d-975f828c83e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-b8ecac01-4241-43b6-83bb-d500a4c66f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881310535-172.17.0.12-1597086647948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34989,DS-64c1b315-1605-4d06-9051-3a55ab559c67,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-5a05ffb2-5b8b-4750-afa5-49db4681ad1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-2411838f-7d4c-42bb-91bb-c37732ccc9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d89a1d8b-48f4-48b9-afb8-cd3ea405828d,DISK], DatanodeInfoWithStorage[127.0.0.1:37630,DS-b97f0a26-f6de-439f-b18a-ce54521ed8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-6bf6feb1-473f-472f-a0db-33f7c859bfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-c3435edc-359e-43f8-a12d-975f828c83e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-b8ecac01-4241-43b6-83bb-d500a4c66f05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518183495-172.17.0.12-1597086879587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-9049cd06-2d93-417c-8fdd-de7a1b5097c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-810e9979-7a76-4ba9-80fc-631bedeaa246,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-1a1511ca-9c6a-4fde-8746-845ded4928bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-17df6bcb-4575-4b9e-a41e-4ab358524dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-8d7ce442-73e0-4b3c-b471-6647e32ddbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-c352eb0f-a09b-4595-98a0-2e70d8b3a11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-c6f28d55-0e96-43c6-a2d7-99243ec8267b,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-2a4d3af7-44ae-432a-8bce-b0d4473f1926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518183495-172.17.0.12-1597086879587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-9049cd06-2d93-417c-8fdd-de7a1b5097c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-810e9979-7a76-4ba9-80fc-631bedeaa246,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-1a1511ca-9c6a-4fde-8746-845ded4928bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-17df6bcb-4575-4b9e-a41e-4ab358524dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:46403,DS-8d7ce442-73e0-4b3c-b471-6647e32ddbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-c352eb0f-a09b-4595-98a0-2e70d8b3a11d,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-c6f28d55-0e96-43c6-a2d7-99243ec8267b,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-2a4d3af7-44ae-432a-8bce-b0d4473f1926,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710670316-172.17.0.12-1597087253637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35405,DS-03c19466-899c-4581-8427-7e150050dc95,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-c3f80ee9-3637-48fe-8059-a2992f575c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-086d2eea-5f49-4c85-b3b8-72d7728c2cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-457acea0-6a51-4eec-b556-29f3fcb6789b,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-155ac98b-431e-4ed5-9514-0526fef53373,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-1c20893c-d154-4a72-a3ee-b21c76691d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-020858a4-c53e-41d4-8428-318f373a2eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-fd1d9fbf-7669-432b-aecb-2336ca6794aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-710670316-172.17.0.12-1597087253637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35405,DS-03c19466-899c-4581-8427-7e150050dc95,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-c3f80ee9-3637-48fe-8059-a2992f575c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-086d2eea-5f49-4c85-b3b8-72d7728c2cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-457acea0-6a51-4eec-b556-29f3fcb6789b,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-155ac98b-431e-4ed5-9514-0526fef53373,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-1c20893c-d154-4a72-a3ee-b21c76691d92,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-020858a4-c53e-41d4-8428-318f373a2eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-fd1d9fbf-7669-432b-aecb-2336ca6794aa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922663540-172.17.0.12-1597087398992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45403,DS-7007e129-47f3-45e5-ad7c-ceb6af86d34b,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-db4ee958-8db2-41e2-9b53-0c7003dc4947,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-94359e75-9519-4614-a2e4-d31df3e43b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-9a03f538-efc6-40a7-a5e5-b823ca6769af,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-f9c27172-fe8e-4eec-a4ab-d8fec7e41018,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-e12910d6-1bcf-4a49-b199-bd46969f4537,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-054347a1-af37-468c-b121-9b75bdd10b69,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-dc7b6f18-9bdc-44d1-b297-a8b05dff84d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1922663540-172.17.0.12-1597087398992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45403,DS-7007e129-47f3-45e5-ad7c-ceb6af86d34b,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-db4ee958-8db2-41e2-9b53-0c7003dc4947,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-94359e75-9519-4614-a2e4-d31df3e43b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-9a03f538-efc6-40a7-a5e5-b823ca6769af,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-f9c27172-fe8e-4eec-a4ab-d8fec7e41018,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-e12910d6-1bcf-4a49-b199-bd46969f4537,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-054347a1-af37-468c-b121-9b75bdd10b69,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-dc7b6f18-9bdc-44d1-b297-a8b05dff84d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390818429-172.17.0.12-1597087542844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43220,DS-ae8519e9-552c-4a71-8ad8-82638213d3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-11d6ad7d-ba1c-4a5b-b777-8d5db01c8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-4215cc68-9b3c-4bae-b154-9acb14c4de69,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-96b34d8c-a8db-4932-9d75-3003162d44cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-99ecd446-2961-4a7d-9f42-f26271f1a864,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-0a6721a6-6299-4e70-94e5-97e8b5c2f901,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-3bcc0c21-7c8e-400e-88ad-ae719ae25908,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-e99ddc37-7568-4a87-9ef2-a7b93790af29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390818429-172.17.0.12-1597087542844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43220,DS-ae8519e9-552c-4a71-8ad8-82638213d3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-11d6ad7d-ba1c-4a5b-b777-8d5db01c8fec,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-4215cc68-9b3c-4bae-b154-9acb14c4de69,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-96b34d8c-a8db-4932-9d75-3003162d44cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-99ecd446-2961-4a7d-9f42-f26271f1a864,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-0a6721a6-6299-4e70-94e5-97e8b5c2f901,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-3bcc0c21-7c8e-400e-88ad-ae719ae25908,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-e99ddc37-7568-4a87-9ef2-a7b93790af29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407441998-172.17.0.12-1597087618173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-30c16914-492e-4344-b4bf-2f7d196e9e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-f003cf60-c3ec-4ff1-ba53-43d676c489eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-3140b072-7d75-49e6-a20e-f053bfd1e347,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-45558ce6-4703-4ac3-b64c-aa8dd1b1ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-b157bf95-20ac-443e-947c-6c4b804859b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-4daecd26-bc08-42f2-99e8-4fea794774d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-0c7b4952-c5e9-49e6-b892-33a679019103,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-799fff49-07cc-4dea-af79-f60855d51aed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407441998-172.17.0.12-1597087618173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33540,DS-30c16914-492e-4344-b4bf-2f7d196e9e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-f003cf60-c3ec-4ff1-ba53-43d676c489eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-3140b072-7d75-49e6-a20e-f053bfd1e347,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-45558ce6-4703-4ac3-b64c-aa8dd1b1ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-b157bf95-20ac-443e-947c-6c4b804859b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-4daecd26-bc08-42f2-99e8-4fea794774d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-0c7b4952-c5e9-49e6-b892-33a679019103,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-799fff49-07cc-4dea-af79-f60855d51aed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498621111-172.17.0.12-1597087922056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-d88aa242-93fd-4319-a72a-699b7f58a019,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-d464b980-2f20-4545-b10d-4c02b870a595,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-b5157e74-7f6f-44d6-b3eb-e944029d6db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-4c15d638-1c89-4f48-9018-1b19e807fbda,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-b07b08f7-e1c6-45f1-95cd-f5b32f6eba49,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-4ffb40a6-d6f8-4d3e-bce5-58a361a0dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-132e3fc3-9fdb-4319-80e1-23dbc2e1953e,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-83062276-8f77-4ff5-8127-93d3735c5968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498621111-172.17.0.12-1597087922056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-d88aa242-93fd-4319-a72a-699b7f58a019,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-d464b980-2f20-4545-b10d-4c02b870a595,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-b5157e74-7f6f-44d6-b3eb-e944029d6db5,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-4c15d638-1c89-4f48-9018-1b19e807fbda,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-b07b08f7-e1c6-45f1-95cd-f5b32f6eba49,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-4ffb40a6-d6f8-4d3e-bce5-58a361a0dbce,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-132e3fc3-9fdb-4319-80e1-23dbc2e1953e,DISK], DatanodeInfoWithStorage[127.0.0.1:38565,DS-83062276-8f77-4ff5-8127-93d3735c5968,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904671395-172.17.0.12-1597087958276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-c7e25fb0-4994-4f68-adb9-b20b808c5676,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-bc410d96-a517-4f0f-8d62-6e52281ad7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-dca397cd-4500-4a85-a9bd-df4c96bdd526,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-fbe285f2-aefd-4267-b763-f99372a5d15b,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9d4f138f-da83-4533-bc5d-0a45070d48a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-c3e54f2c-cc64-4296-bea8-fd3c86e6d64c,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-a276e720-5533-42ca-8342-89c989f3f4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-fee65591-ca85-42a3-94eb-0df92c7ec78c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904671395-172.17.0.12-1597087958276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-c7e25fb0-4994-4f68-adb9-b20b808c5676,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-bc410d96-a517-4f0f-8d62-6e52281ad7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-dca397cd-4500-4a85-a9bd-df4c96bdd526,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-fbe285f2-aefd-4267-b763-f99372a5d15b,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-9d4f138f-da83-4533-bc5d-0a45070d48a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-c3e54f2c-cc64-4296-bea8-fd3c86e6d64c,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-a276e720-5533-42ca-8342-89c989f3f4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-fee65591-ca85-42a3-94eb-0df92c7ec78c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620872026-172.17.0.12-1597088508715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44939,DS-486aa370-d399-4066-945c-a586f37af091,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-d0ba8f0d-5a30-436f-89de-fc7fac234023,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-0bf1f9bf-bf16-40f3-ad16-ba4153289e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-3b8feb03-fd65-4e84-8eb9-0686ca95eb11,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-14fdc4d0-eecf-4783-9059-e29fd48b5428,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-4c465bc0-2ab8-41ef-8279-8bf994dfe875,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-42907de6-0d47-452f-bb84-5ca23ba3879a,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-ec6895d4-ec22-4b2d-b9fa-70ffb361f6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620872026-172.17.0.12-1597088508715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44939,DS-486aa370-d399-4066-945c-a586f37af091,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-d0ba8f0d-5a30-436f-89de-fc7fac234023,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-0bf1f9bf-bf16-40f3-ad16-ba4153289e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-3b8feb03-fd65-4e84-8eb9-0686ca95eb11,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-14fdc4d0-eecf-4783-9059-e29fd48b5428,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-4c465bc0-2ab8-41ef-8279-8bf994dfe875,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-42907de6-0d47-452f-bb84-5ca23ba3879a,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-ec6895d4-ec22-4b2d-b9fa-70ffb361f6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936039371-172.17.0.12-1597088734349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36862,DS-dc62f91e-60f1-4958-a76e-191473990180,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-d4bf380b-10e5-449d-b11c-b7d4cc4a6189,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-198d68d0-9e16-4c56-a439-92d068c22eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-8740d40d-a785-4f4c-b7e9-3ca664bdd5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-27ae85a0-e005-4bdb-9f5c-0d5171b6ddde,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-9d19e2d2-c256-45be-b476-5e26ee688207,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-ad025841-6ad2-44be-b3d8-1b825bbdf1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-a670e13e-d062-4bf1-8e41-1862878a72bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1936039371-172.17.0.12-1597088734349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36862,DS-dc62f91e-60f1-4958-a76e-191473990180,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-d4bf380b-10e5-449d-b11c-b7d4cc4a6189,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-198d68d0-9e16-4c56-a439-92d068c22eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-8740d40d-a785-4f4c-b7e9-3ca664bdd5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-27ae85a0-e005-4bdb-9f5c-0d5171b6ddde,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-9d19e2d2-c256-45be-b476-5e26ee688207,DISK], DatanodeInfoWithStorage[127.0.0.1:33022,DS-ad025841-6ad2-44be-b3d8-1b825bbdf1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-a670e13e-d062-4bf1-8e41-1862878a72bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.idlethreshold
component: hdfs:DataNode
v1: 1
v2: 4000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445559662-172.17.0.12-1597089035706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40296,DS-80b8d697-5894-49ad-b40e-0d5e7e73de8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-1df10b11-628b-4184-a231-a18370a0b730,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-5fb03fcd-6b77-4f08-9ff9-dfc2ee283ade,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-84d3ff79-c6fd-4561-88f2-05876ca699b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-da13f638-09db-4a76-ad4f-87bfa2d27755,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-82781adb-408c-46e1-8958-a3c220634330,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-e45330af-76b1-4b03-a6a9-35027e1e689d,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-d4e37831-a023-4a94-92a3-9dfa1a62b011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445559662-172.17.0.12-1597089035706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40296,DS-80b8d697-5894-49ad-b40e-0d5e7e73de8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-1df10b11-628b-4184-a231-a18370a0b730,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-5fb03fcd-6b77-4f08-9ff9-dfc2ee283ade,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-84d3ff79-c6fd-4561-88f2-05876ca699b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-da13f638-09db-4a76-ad4f-87bfa2d27755,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-82781adb-408c-46e1-8958-a3c220634330,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-e45330af-76b1-4b03-a6a9-35027e1e689d,DISK], DatanodeInfoWithStorage[127.0.0.1:35840,DS-d4e37831-a023-4a94-92a3-9dfa1a62b011,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5621
