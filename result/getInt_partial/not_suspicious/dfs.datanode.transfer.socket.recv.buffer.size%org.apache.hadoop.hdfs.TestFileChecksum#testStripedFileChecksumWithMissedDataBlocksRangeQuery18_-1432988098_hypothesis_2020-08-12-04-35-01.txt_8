reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566859297-172.17.0.3-1597206952450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37113,DS-6256d9b1-66a6-47eb-bf0f-be861e1302dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-4ff732d5-0b8e-470f-9555-dd178ec43f62,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-450df33b-72cc-465f-92f3-99e83b4b433e,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-891ce9df-564a-49cf-9dc2-dda5143c1725,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-a7caeda1-a071-43a9-a407-5e020f0ec5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-35463e5f-42f0-45cf-9d23-bbc3b111bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-eac5d4c9-9551-4386-993c-77b0d4fa37be,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-1e9ec4ee-3372-41b6-a063-5742090d497a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1566859297-172.17.0.3-1597206952450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37113,DS-6256d9b1-66a6-47eb-bf0f-be861e1302dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-4ff732d5-0b8e-470f-9555-dd178ec43f62,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-450df33b-72cc-465f-92f3-99e83b4b433e,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-891ce9df-564a-49cf-9dc2-dda5143c1725,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-a7caeda1-a071-43a9-a407-5e020f0ec5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-35463e5f-42f0-45cf-9d23-bbc3b111bc50,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-eac5d4c9-9551-4386-993c-77b0d4fa37be,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-1e9ec4ee-3372-41b6-a063-5742090d497a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862586791-172.17.0.3-1597206987149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44062,DS-ae754bb2-b9c4-4366-9dc2-06c50bd836f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-9c6deb56-1cdd-4684-8d7a-6671866074bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-ed442f68-1c47-4145-a755-2054f867de62,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-81a939c1-932d-4d42-98c4-51e6acd34c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-79fbfc3f-c59b-4e78-9291-856b8dbf02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-db2c263c-f1bb-494b-84b4-1cae1eca7315,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-0d69fccf-2a29-43d7-8be6-3c647dbf6966,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-7c2f1bf6-7a9f-47bb-bfe1-e74e1d93311e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862586791-172.17.0.3-1597206987149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44062,DS-ae754bb2-b9c4-4366-9dc2-06c50bd836f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-9c6deb56-1cdd-4684-8d7a-6671866074bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46526,DS-ed442f68-1c47-4145-a755-2054f867de62,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-81a939c1-932d-4d42-98c4-51e6acd34c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-79fbfc3f-c59b-4e78-9291-856b8dbf02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-db2c263c-f1bb-494b-84b4-1cae1eca7315,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-0d69fccf-2a29-43d7-8be6-3c647dbf6966,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-7c2f1bf6-7a9f-47bb-bfe1-e74e1d93311e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707867698-172.17.0.3-1597207449553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-f06e92a2-9153-43d9-aafe-1bf7b05072c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-4bd4f8b5-6b95-40f5-a6b2-f13e3c5e8b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-d0f3565f-bac6-4baf-8d8d-3bcac48fd660,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-5c21bae3-545f-4707-8d4e-bff17327b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-9d855965-3d0e-4d67-83d8-970bf9ed23d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-fd6137af-f08e-4f89-8d22-1260712411df,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-4cc67770-410c-4b0d-b075-e64c8bd1f01a,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-7041e0ed-abeb-467b-ae60-c596ffcdbc09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707867698-172.17.0.3-1597207449553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-f06e92a2-9153-43d9-aafe-1bf7b05072c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-4bd4f8b5-6b95-40f5-a6b2-f13e3c5e8b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-d0f3565f-bac6-4baf-8d8d-3bcac48fd660,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-5c21bae3-545f-4707-8d4e-bff17327b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-9d855965-3d0e-4d67-83d8-970bf9ed23d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-fd6137af-f08e-4f89-8d22-1260712411df,DISK], DatanodeInfoWithStorage[127.0.0.1:34716,DS-4cc67770-410c-4b0d-b075-e64c8bd1f01a,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-7041e0ed-abeb-467b-ae60-c596ffcdbc09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-748864300-172.17.0.3-1597207640216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-0fe9f26f-db48-4929-b8b4-8e475d7bddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-b7c33c0c-dfbd-4d96-83d9-42a5413c858e,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-6024d227-d05f-482a-b5b8-cc0bfedad72c,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-56cbb6fb-8da2-4695-9965-b34c85999d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-9eac6be3-5ccc-450e-966b-bcf5cb0a05a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-87dddfd3-c73f-49af-8726-d78243174033,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-c4ad6967-c36f-4240-8ccc-116a0b912f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-605878a4-a1c4-4b84-a214-3c8139bb7bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-748864300-172.17.0.3-1597207640216:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38920,DS-0fe9f26f-db48-4929-b8b4-8e475d7bddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-b7c33c0c-dfbd-4d96-83d9-42a5413c858e,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-6024d227-d05f-482a-b5b8-cc0bfedad72c,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-56cbb6fb-8da2-4695-9965-b34c85999d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-9eac6be3-5ccc-450e-966b-bcf5cb0a05a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-87dddfd3-c73f-49af-8726-d78243174033,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-c4ad6967-c36f-4240-8ccc-116a0b912f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-605878a4-a1c4-4b84-a214-3c8139bb7bd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295309634-172.17.0.3-1597208330382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45600,DS-d5a2dbb2-3493-4bd4-86e5-c6b7263eb285,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-b2c7815b-633f-44eb-a036-241d01d15538,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b8e24436-701c-4fbd-8b5f-9067b5e35b35,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-54ce8212-c1e7-4cb3-bf93-820f99349bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-0828626e-e157-4bd9-b39c-95d8f4735bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-15756c6a-151b-43e9-9988-589a18479f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-61d2ae50-d4bb-4cd8-b582-b138a2f64269,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-c09d5b9a-5e46-47dd-9937-1029a76ef47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-295309634-172.17.0.3-1597208330382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45600,DS-d5a2dbb2-3493-4bd4-86e5-c6b7263eb285,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-b2c7815b-633f-44eb-a036-241d01d15538,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b8e24436-701c-4fbd-8b5f-9067b5e35b35,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-54ce8212-c1e7-4cb3-bf93-820f99349bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-0828626e-e157-4bd9-b39c-95d8f4735bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-15756c6a-151b-43e9-9988-589a18479f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-61d2ae50-d4bb-4cd8-b582-b138a2f64269,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-c09d5b9a-5e46-47dd-9937-1029a76ef47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783618487-172.17.0.3-1597208368937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43794,DS-b636bdd7-bd6d-4853-94a3-0c7b94baf034,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-15d0c432-044f-4484-b8d7-ab3b868bcf45,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-6eb193ed-9240-4365-8fdc-57fb4db0dc67,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-ad7537d8-7cb8-4111-a751-e4b6b14ffb16,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-35b7ec4e-da21-42a8-b6a9-9ca8e8006cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-6c41e9de-574f-4bd2-a9be-a7546487b821,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d974265c-5bfe-4fed-9453-c7a2cc5e10e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-d3f69ef4-842e-49bf-a2b3-9880fb30a7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-783618487-172.17.0.3-1597208368937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43794,DS-b636bdd7-bd6d-4853-94a3-0c7b94baf034,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-15d0c432-044f-4484-b8d7-ab3b868bcf45,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-6eb193ed-9240-4365-8fdc-57fb4db0dc67,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-ad7537d8-7cb8-4111-a751-e4b6b14ffb16,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-35b7ec4e-da21-42a8-b6a9-9ca8e8006cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38862,DS-6c41e9de-574f-4bd2-a9be-a7546487b821,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d974265c-5bfe-4fed-9453-c7a2cc5e10e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-d3f69ef4-842e-49bf-a2b3-9880fb30a7b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1920577708-172.17.0.3-1597208709833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34439,DS-3d6fe674-e8e8-4a0c-bdc7-5547cafcdaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-14bb44f7-aad6-462b-8511-db5689205893,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-2a13af29-b19e-43ff-9ce4-2b82827f3153,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-24eb61c6-c85c-43b7-a802-80c258f22ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-efa883c4-773a-4319-9d68-f467fd78a61a,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-61766ddb-b9af-4e0b-858c-054a27b60c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-a92bc5c4-29d7-4ad8-8678-e34b9fefa933,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-eeb50577-cff0-4921-8c3e-417cf122da1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1920577708-172.17.0.3-1597208709833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34439,DS-3d6fe674-e8e8-4a0c-bdc7-5547cafcdaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:46737,DS-14bb44f7-aad6-462b-8511-db5689205893,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-2a13af29-b19e-43ff-9ce4-2b82827f3153,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-24eb61c6-c85c-43b7-a802-80c258f22ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-efa883c4-773a-4319-9d68-f467fd78a61a,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-61766ddb-b9af-4e0b-858c-054a27b60c12,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-a92bc5c4-29d7-4ad8-8678-e34b9fefa933,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-eeb50577-cff0-4921-8c3e-417cf122da1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622190495-172.17.0.3-1597208769555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36596,DS-088630f6-10c5-4a84-9652-81965d33df3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-23292420-c1c3-4cae-8c40-d422112e8bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-94e59714-710c-41a6-8ae0-7c779c865750,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-48c44702-00ba-49a0-b080-1d789471a102,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-a79580f9-bbea-4529-bfd2-191d880a2c51,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-7b1a46ff-32a2-48ec-9101-273f72848c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-c6d898a3-43a3-45bd-8069-4f98670c8e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-3cca4f50-e643-4479-825a-0a5204ab9b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622190495-172.17.0.3-1597208769555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36596,DS-088630f6-10c5-4a84-9652-81965d33df3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-23292420-c1c3-4cae-8c40-d422112e8bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-94e59714-710c-41a6-8ae0-7c779c865750,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-48c44702-00ba-49a0-b080-1d789471a102,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-a79580f9-bbea-4529-bfd2-191d880a2c51,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-7b1a46ff-32a2-48ec-9101-273f72848c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-c6d898a3-43a3-45bd-8069-4f98670c8e93,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-3cca4f50-e643-4479-825a-0a5204ab9b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512798215-172.17.0.3-1597208803291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-e597c2aa-ac18-48c1-9e59-ada62c690cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-7a300b19-66fa-4bd3-87cf-8f68cc4ff1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-5d71630e-b973-4c89-ba7e-8d0a487b0d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-98e599f2-f46d-4f27-bd42-61c103bcb272,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-32911976-8600-4518-824f-fbc97a2cecba,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-6cde2398-f309-46e1-91ae-0e2e10ede56d,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-ae872d73-2d0b-467a-8495-12738b48ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-85e41308-e361-4b24-8926-e5481774f820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1512798215-172.17.0.3-1597208803291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-e597c2aa-ac18-48c1-9e59-ada62c690cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-7a300b19-66fa-4bd3-87cf-8f68cc4ff1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-5d71630e-b973-4c89-ba7e-8d0a487b0d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-98e599f2-f46d-4f27-bd42-61c103bcb272,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-32911976-8600-4518-824f-fbc97a2cecba,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-6cde2398-f309-46e1-91ae-0e2e10ede56d,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-ae872d73-2d0b-467a-8495-12738b48ac6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-85e41308-e361-4b24-8926-e5481774f820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990633937-172.17.0.3-1597209032481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-7c216845-3765-4443-8f78-ba1bcc337e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-aaa30a82-1285-430d-ab04-439bc25345c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-e7bab940-b02c-473b-81f6-999c28c01731,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-6d7a911a-f911-4a9b-9105-676d11961730,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-138c8a3f-1419-4bab-a81d-24242f1fc2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-adfc506d-604a-4f25-bbd8-be6eb8aeb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-a7567fc9-2cb0-4285-a49f-4fb4c5035ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-cee1c272-2043-4c30-8f7b-cfc13fd8ad19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-990633937-172.17.0.3-1597209032481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43538,DS-7c216845-3765-4443-8f78-ba1bcc337e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-aaa30a82-1285-430d-ab04-439bc25345c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-e7bab940-b02c-473b-81f6-999c28c01731,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-6d7a911a-f911-4a9b-9105-676d11961730,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-138c8a3f-1419-4bab-a81d-24242f1fc2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34670,DS-adfc506d-604a-4f25-bbd8-be6eb8aeb5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-a7567fc9-2cb0-4285-a49f-4fb4c5035ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:34243,DS-cee1c272-2043-4c30-8f7b-cfc13fd8ad19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505840777-172.17.0.3-1597209233320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33012,DS-eb16a96a-f59e-4b61-bbc7-6f5ebdb1256f,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-f5785823-02af-4a9f-8087-b7c1cec8c875,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-f4f63153-1345-4b26-bf20-0e1dc86b510a,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-a9435b26-3b17-4b51-a381-10aaaae8bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-21033a16-7948-405f-a6cd-b4ab938c85d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-cd04b2d3-22dc-41fe-9b58-2bf2032a6a90,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-467e51ac-7e59-41aa-8887-9e86a5c28621,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-15f8d5ec-d0b1-415a-bbff-c6543a3349fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-505840777-172.17.0.3-1597209233320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33012,DS-eb16a96a-f59e-4b61-bbc7-6f5ebdb1256f,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-f5785823-02af-4a9f-8087-b7c1cec8c875,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-f4f63153-1345-4b26-bf20-0e1dc86b510a,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-a9435b26-3b17-4b51-a381-10aaaae8bc47,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-21033a16-7948-405f-a6cd-b4ab938c85d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-cd04b2d3-22dc-41fe-9b58-2bf2032a6a90,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-467e51ac-7e59-41aa-8887-9e86a5c28621,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-15f8d5ec-d0b1-415a-bbff-c6543a3349fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073499208-172.17.0.3-1597210659398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38281,DS-95a4de13-64f8-46ff-bcee-83daae362709,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-5611b653-23fd-4f39-b6fa-764164919652,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-709519c9-d361-4949-9b8f-3eeef92d22a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6dd1abd9-0490-4306-b9f1-65f921a2a9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-c96e467a-697e-46b6-8c3b-e36a852ead70,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-9363af65-1b51-496f-9d96-ea6814d4671f,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-f1362e63-0699-404c-b89c-b6103ddbe243,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-4419e243-9278-4c7d-9db7-5c5d4e801c19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1073499208-172.17.0.3-1597210659398:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38281,DS-95a4de13-64f8-46ff-bcee-83daae362709,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-5611b653-23fd-4f39-b6fa-764164919652,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-709519c9-d361-4949-9b8f-3eeef92d22a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-6dd1abd9-0490-4306-b9f1-65f921a2a9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-c96e467a-697e-46b6-8c3b-e36a852ead70,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-9363af65-1b51-496f-9d96-ea6814d4671f,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-f1362e63-0699-404c-b89c-b6103ddbe243,DISK], DatanodeInfoWithStorage[127.0.0.1:43115,DS-4419e243-9278-4c7d-9db7-5c5d4e801c19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543824343-172.17.0.3-1597211070789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-fc95e86f-50cf-4dac-adc4-c23fa1c45c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-5d27abb1-c5b1-451a-8d77-cfe333274826,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-bae06574-9813-418a-af23-84338bff6e94,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-1b0ec9af-6bb7-45c4-83b0-853dc5754df0,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-9780a0c8-6d08-4382-9c2e-168fef289a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-0aa430ee-b686-484f-827b-a6e90a5397d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-fcf9f5e8-e4ed-42b6-b67c-7b78769ce56d,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-b6bc6e83-52cf-44fc-989f-e278eb2a6c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-543824343-172.17.0.3-1597211070789:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34127,DS-fc95e86f-50cf-4dac-adc4-c23fa1c45c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-5d27abb1-c5b1-451a-8d77-cfe333274826,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-bae06574-9813-418a-af23-84338bff6e94,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-1b0ec9af-6bb7-45c4-83b0-853dc5754df0,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-9780a0c8-6d08-4382-9c2e-168fef289a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-0aa430ee-b686-484f-827b-a6e90a5397d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-fcf9f5e8-e4ed-42b6-b67c-7b78769ce56d,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-b6bc6e83-52cf-44fc-989f-e278eb2a6c81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358223828-172.17.0.3-1597211293421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-8a20279f-2b51-4577-86a8-d93067ebb5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-948588bd-8f68-4b96-b0c7-7090d8a517ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-6c5941d1-90e4-4e82-9c44-e975d1c4faea,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-90cea683-bd08-4418-8ea5-1a4b88ff0b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-ef15c9f6-659c-4253-a117-98e519ca6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-55f434e5-c5fb-461e-9d2b-317fafa26421,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-1a39ad09-aaec-463b-8cae-8386b0288dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-7b132d23-a325-432c-aaf8-69c28a76d912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358223828-172.17.0.3-1597211293421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42137,DS-8a20279f-2b51-4577-86a8-d93067ebb5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-948588bd-8f68-4b96-b0c7-7090d8a517ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-6c5941d1-90e4-4e82-9c44-e975d1c4faea,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-90cea683-bd08-4418-8ea5-1a4b88ff0b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-ef15c9f6-659c-4253-a117-98e519ca6a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-55f434e5-c5fb-461e-9d2b-317fafa26421,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-1a39ad09-aaec-463b-8cae-8386b0288dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-7b132d23-a325-432c-aaf8-69c28a76d912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140515778-172.17.0.3-1597211404459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44109,DS-687cb4cc-d8b3-4293-96b9-9fc49fa49660,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-042eb310-d8d5-4a61-a5ec-26d44e2f2704,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-22cee536-e7e9-400a-91fd-797b5f7e37c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-74755f89-a098-40c9-abb4-8e972632eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-b7c481f3-4cc9-44e0-b1e7-381a2047dda4,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-747c763d-0437-403f-a3c4-f72b47efa993,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-fce28c98-1bb7-4238-aca4-4ccc89d92667,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-efba06b3-e33d-45d6-b2d8-daf7b12e3a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-140515778-172.17.0.3-1597211404459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44109,DS-687cb4cc-d8b3-4293-96b9-9fc49fa49660,DISK], DatanodeInfoWithStorage[127.0.0.1:41623,DS-042eb310-d8d5-4a61-a5ec-26d44e2f2704,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-22cee536-e7e9-400a-91fd-797b5f7e37c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-74755f89-a098-40c9-abb4-8e972632eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-b7c481f3-4cc9-44e0-b1e7-381a2047dda4,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-747c763d-0437-403f-a3c4-f72b47efa993,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-fce28c98-1bb7-4238-aca4-4ccc89d92667,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-efba06b3-e33d-45d6-b2d8-daf7b12e3a02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70537778-172.17.0.3-1597211479315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35872,DS-2115a436-69aa-47e9-9061-2170167311f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-d1cd32a7-c367-4b10-b107-21d3ed904969,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-695119b7-a1b1-46c8-af94-05a78987d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-95d02504-3695-4714-9d0e-cfca822a113f,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-86167f2e-772d-4b61-a6be-3f5df252068f,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-14a764b5-61d5-4259-81c6-c3e64342d5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-3206edc5-7f93-4179-af49-d6c0e2d4f526,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-c0a8354e-7cb2-4e80-ad9c-091b80abb47b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70537778-172.17.0.3-1597211479315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35872,DS-2115a436-69aa-47e9-9061-2170167311f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-d1cd32a7-c367-4b10-b107-21d3ed904969,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-695119b7-a1b1-46c8-af94-05a78987d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-95d02504-3695-4714-9d0e-cfca822a113f,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-86167f2e-772d-4b61-a6be-3f5df252068f,DISK], DatanodeInfoWithStorage[127.0.0.1:34643,DS-14a764b5-61d5-4259-81c6-c3e64342d5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-3206edc5-7f93-4179-af49-d6c0e2d4f526,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-c0a8354e-7cb2-4e80-ad9c-091b80abb47b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943008367-172.17.0.3-1597211513670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38943,DS-60a32b49-eea6-4cdb-b3f0-8f3cbb1eccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-2cdbb53b-657b-43bd-96f6-e1de57e5ac48,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-d1f26ea3-9865-4c7f-9118-8373c60932fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-33fafbdb-b2ca-444a-ba31-3bfe94326134,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-24840ad8-1d0b-4bd1-92e1-7e49a59eb313,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-961d9cfd-b002-4a27-99d8-de2fac58384e,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-dc7830a1-4d26-4845-8c94-bb9f0158708a,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-a24ef652-8de2-40e8-9ac1-f0f954edcc9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1943008367-172.17.0.3-1597211513670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38943,DS-60a32b49-eea6-4cdb-b3f0-8f3cbb1eccdf,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-2cdbb53b-657b-43bd-96f6-e1de57e5ac48,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-d1f26ea3-9865-4c7f-9118-8373c60932fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-33fafbdb-b2ca-444a-ba31-3bfe94326134,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-24840ad8-1d0b-4bd1-92e1-7e49a59eb313,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-961d9cfd-b002-4a27-99d8-de2fac58384e,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-dc7830a1-4d26-4845-8c94-bb9f0158708a,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-a24ef652-8de2-40e8-9ac1-f0f954edcc9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289549891-172.17.0.3-1597211757928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42966,DS-4330db8f-3813-4c32-bee9-88b653015607,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-a067749e-fbf6-45e3-a3dc-1711694b8466,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-1d4bd4d8-8978-456c-81ec-bdffa6dd1feb,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-9a5cd400-cd08-4d7d-87ab-a29ea8ae45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-8606c552-347c-458a-9dd9-d4c421877ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-71ba4936-f38d-4255-986e-05375f5a61a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-e3c58cc7-fce4-482c-9bff-b6bc71ee7e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-86fe6688-c3ec-43b3-8fb9-6a9338a9c5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-289549891-172.17.0.3-1597211757928:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42966,DS-4330db8f-3813-4c32-bee9-88b653015607,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-a067749e-fbf6-45e3-a3dc-1711694b8466,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-1d4bd4d8-8978-456c-81ec-bdffa6dd1feb,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-9a5cd400-cd08-4d7d-87ab-a29ea8ae45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-8606c552-347c-458a-9dd9-d4c421877ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-71ba4936-f38d-4255-986e-05375f5a61a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-e3c58cc7-fce4-482c-9bff-b6bc71ee7e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-86fe6688-c3ec-43b3-8fb9-6a9338a9c5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050166049-172.17.0.3-1597211932136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41359,DS-05954353-bae3-498d-8330-55715b5f6e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-6a1e8c24-52bc-444c-b71a-7f2bd3036d34,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-a4468c09-175e-46b3-a8c9-810e0c232f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-868c4393-24b2-4ade-a0f1-ec7b5180970f,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-7b2bbe4d-6cde-4d83-8349-1890a2ecee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-a981c32f-220b-43dd-9ab6-c00d1eeedbec,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-a6165518-7c0a-4d46-9748-971c7926c872,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-d6191d23-15ac-4053-b721-0d13a1e3b4c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050166049-172.17.0.3-1597211932136:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41359,DS-05954353-bae3-498d-8330-55715b5f6e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-6a1e8c24-52bc-444c-b71a-7f2bd3036d34,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-a4468c09-175e-46b3-a8c9-810e0c232f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-868c4393-24b2-4ade-a0f1-ec7b5180970f,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-7b2bbe4d-6cde-4d83-8349-1890a2ecee4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-a981c32f-220b-43dd-9ab6-c00d1eeedbec,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-a6165518-7c0a-4d46-9748-971c7926c872,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-d6191d23-15ac-4053-b721-0d13a1e3b4c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5084
