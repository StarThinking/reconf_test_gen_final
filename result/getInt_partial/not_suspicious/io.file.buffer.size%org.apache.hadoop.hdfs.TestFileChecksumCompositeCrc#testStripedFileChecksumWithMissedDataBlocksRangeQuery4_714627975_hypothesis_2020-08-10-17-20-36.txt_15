reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463645829-172.17.0.6-1597080237037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44296,DS-f0ee197e-e0dd-4b3d-91e1-63add6bad4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-fb50d3f8-82c5-4b69-9b2c-95bba41d0f31,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-36c20497-9c42-4260-846f-db319cbb60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-42d3e6db-f496-4dc8-a783-a52846896c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-7da2cc7b-7b4c-4048-90b6-133150ffab2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-746d3154-0317-4380-9730-9b79cb2e4208,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-2d6b0338-2e26-4d80-9f97-9a70d7640b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-0819d6d6-9d21-4494-98f6-4fc34c69927e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463645829-172.17.0.6-1597080237037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44296,DS-f0ee197e-e0dd-4b3d-91e1-63add6bad4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-fb50d3f8-82c5-4b69-9b2c-95bba41d0f31,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-36c20497-9c42-4260-846f-db319cbb60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-42d3e6db-f496-4dc8-a783-a52846896c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-7da2cc7b-7b4c-4048-90b6-133150ffab2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-746d3154-0317-4380-9730-9b79cb2e4208,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-2d6b0338-2e26-4d80-9f97-9a70d7640b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-0819d6d6-9d21-4494-98f6-4fc34c69927e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971311484-172.17.0.6-1597080415422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46125,DS-7b064ce2-814d-40ea-af99-40c34dd3cd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-cf29ca9b-4dfd-452f-a45d-5e4f1c9dcc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-a3faaca4-353e-4c10-8166-3ea3caeae372,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-24167fdc-8d40-43ba-8410-392e0e672df4,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-ee36957b-5a8f-45ad-9ae4-28a15fc190a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-f4e7fa01-8e3e-41bd-8c12-0a3c27337c35,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-f92ae970-4254-4e3a-8627-d45841692393,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-df1a4c62-0501-4bc3-97e8-eb5b841b148e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971311484-172.17.0.6-1597080415422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46125,DS-7b064ce2-814d-40ea-af99-40c34dd3cd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45658,DS-cf29ca9b-4dfd-452f-a45d-5e4f1c9dcc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-a3faaca4-353e-4c10-8166-3ea3caeae372,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-24167fdc-8d40-43ba-8410-392e0e672df4,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-ee36957b-5a8f-45ad-9ae4-28a15fc190a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-f4e7fa01-8e3e-41bd-8c12-0a3c27337c35,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-f92ae970-4254-4e3a-8627-d45841692393,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-df1a4c62-0501-4bc3-97e8-eb5b841b148e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033002057-172.17.0.6-1597080831312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-309b0a5b-d943-4196-8ed3-90b1227db45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-6d9c1a4a-e48e-4077-aaad-a2b50891c833,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-893b4d3e-289c-4280-8cd4-04c287865d72,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-6608e613-2740-48e0-9156-2f7dee025e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-a13fe669-8cc0-40d4-8f06-9f9e809c7695,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-bc950d93-4ced-4c96-84e3-a42a5637d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e75b54df-f12e-4cb5-8ef0-d96afd9afe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-d21c1d99-75d1-450c-a7c3-bf3fc1c8daad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033002057-172.17.0.6-1597080831312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39601,DS-309b0a5b-d943-4196-8ed3-90b1227db45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-6d9c1a4a-e48e-4077-aaad-a2b50891c833,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-893b4d3e-289c-4280-8cd4-04c287865d72,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-6608e613-2740-48e0-9156-2f7dee025e35,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-a13fe669-8cc0-40d4-8f06-9f9e809c7695,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-bc950d93-4ced-4c96-84e3-a42a5637d9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-e75b54df-f12e-4cb5-8ef0-d96afd9afe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-d21c1d99-75d1-450c-a7c3-bf3fc1c8daad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143497786-172.17.0.6-1597081213670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41793,DS-ad3fe9bc-a950-4091-bca9-4c597afc3a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-b2ca38ca-dc3f-4a59-bd92-97416ad46791,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-f450fdca-7231-4d20-98db-e3f52c00eec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-3e008cc1-9a6e-4143-b03f-e24c27893dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b074fdc2-0c45-43f0-bbcf-01fc1525116d,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-224bc651-3d03-41a0-a318-731c6ded5642,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-1bad5817-7849-4290-82a4-31fdb3069b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-1eb90e33-d48a-48d8-9526-a4882b49b568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143497786-172.17.0.6-1597081213670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41793,DS-ad3fe9bc-a950-4091-bca9-4c597afc3a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-b2ca38ca-dc3f-4a59-bd92-97416ad46791,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-f450fdca-7231-4d20-98db-e3f52c00eec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-3e008cc1-9a6e-4143-b03f-e24c27893dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-b074fdc2-0c45-43f0-bbcf-01fc1525116d,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-224bc651-3d03-41a0-a318-731c6ded5642,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-1bad5817-7849-4290-82a4-31fdb3069b53,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-1eb90e33-d48a-48d8-9526-a4882b49b568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744457441-172.17.0.6-1597082626057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-970b0ed1-f186-46d8-ac90-a7ce654dea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-c7bb229f-548d-4db5-8473-e6708ec715ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-8c26edda-f664-46b8-a8fb-0d0f56fa2fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-2873118d-f42d-477d-b28f-f3a8df8fa3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-da967654-f1aa-41d0-8c0a-3803e1b41955,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-91bf2762-5aea-471e-88ea-d9aeef00e24c,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-fedc9b21-20fc-49fb-b700-4d6dd7d12c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-6ac114e2-5287-47e1-b044-1997a1ce6fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-744457441-172.17.0.6-1597082626057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-970b0ed1-f186-46d8-ac90-a7ce654dea6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-c7bb229f-548d-4db5-8473-e6708ec715ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-8c26edda-f664-46b8-a8fb-0d0f56fa2fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-2873118d-f42d-477d-b28f-f3a8df8fa3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-da967654-f1aa-41d0-8c0a-3803e1b41955,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-91bf2762-5aea-471e-88ea-d9aeef00e24c,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-fedc9b21-20fc-49fb-b700-4d6dd7d12c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-6ac114e2-5287-47e1-b044-1997a1ce6fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746065081-172.17.0.6-1597082847874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-9c6adf18-9694-44fb-924e-c7997eed22be,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-d32617e1-ace8-4a0f-a223-11bd49a0e786,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-5c59df14-8ed9-4582-a5a0-8ab344c3bd26,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-fe6a6828-7078-49d1-bd09-9e3abe90a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-3de0a8e0-ef91-43fa-8846-a829779fa6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-b0db2058-7c56-4ae8-8d13-c7222f33f0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-7601387f-378d-44d0-89a0-12c5d5dfe8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-c9e498ca-97b9-4b61-9aa1-e7edcf71353d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-746065081-172.17.0.6-1597082847874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-9c6adf18-9694-44fb-924e-c7997eed22be,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-d32617e1-ace8-4a0f-a223-11bd49a0e786,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-5c59df14-8ed9-4582-a5a0-8ab344c3bd26,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-fe6a6828-7078-49d1-bd09-9e3abe90a1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-3de0a8e0-ef91-43fa-8846-a829779fa6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-b0db2058-7c56-4ae8-8d13-c7222f33f0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-7601387f-378d-44d0-89a0-12c5d5dfe8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-c9e498ca-97b9-4b61-9aa1-e7edcf71353d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403762466-172.17.0.6-1597083283139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-c80d9165-0fa9-48fc-8121-cfbd5c53b9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-f055d570-32c7-46e1-9e67-ea7deb62b7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-62036209-d4ac-4ade-a123-d33064267c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-34dadc24-9b99-4c41-a3c6-ec25bb93508a,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-9b8306ae-1d31-40d1-9e75-6effe8c9c302,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-fe18340c-e6be-43e7-bdd3-37758200969a,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-7e6e9b59-1282-4b73-9c34-03c1400fe58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-ac17453c-fbbe-4973-9ceb-6bae55c161ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403762466-172.17.0.6-1597083283139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-c80d9165-0fa9-48fc-8121-cfbd5c53b9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-f055d570-32c7-46e1-9e67-ea7deb62b7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-62036209-d4ac-4ade-a123-d33064267c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-34dadc24-9b99-4c41-a3c6-ec25bb93508a,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-9b8306ae-1d31-40d1-9e75-6effe8c9c302,DISK], DatanodeInfoWithStorage[127.0.0.1:35553,DS-fe18340c-e6be-43e7-bdd3-37758200969a,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-7e6e9b59-1282-4b73-9c34-03c1400fe58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-ac17453c-fbbe-4973-9ceb-6bae55c161ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614391673-172.17.0.6-1597083800104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39847,DS-af723d59-fe40-42cf-b761-fc2d03fca894,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-c1be1d86-6f33-4e8a-9237-776e2f303eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-d558a054-412d-42bb-ba77-09e117aae68a,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-ed35c459-f0e6-4f5a-94d2-c24aaa307700,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-9a5b6c74-15ca-406b-a3e6-301673793710,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-2a9f6f1c-ef45-4d66-a84a-e0996481f446,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-e726b62a-2b9e-4558-badf-f7a7ab52a464,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-7a622ec5-a7f7-41aa-b7a7-d68ab57cc916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614391673-172.17.0.6-1597083800104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39847,DS-af723d59-fe40-42cf-b761-fc2d03fca894,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-c1be1d86-6f33-4e8a-9237-776e2f303eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-d558a054-412d-42bb-ba77-09e117aae68a,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-ed35c459-f0e6-4f5a-94d2-c24aaa307700,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-9a5b6c74-15ca-406b-a3e6-301673793710,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-2a9f6f1c-ef45-4d66-a84a-e0996481f446,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-e726b62a-2b9e-4558-badf-f7a7ab52a464,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-7a622ec5-a7f7-41aa-b7a7-d68ab57cc916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108893345-172.17.0.6-1597083970563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38475,DS-77049a0d-0b97-4371-a163-2cb772646c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-21f10947-ff1d-48a0-9dd3-4add16654166,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-6cfd248f-1e6c-4cd8-a733-e394eca75368,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-5b9fe6d0-1e2b-4e1e-9a2b-09a67998d00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-3764d1b6-d1d7-4715-8a1a-509759b26d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-b5ad375d-b5d8-4dea-9d93-fa6c166ef747,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-8b33613c-4c83-477d-b1f3-ccc6c12304ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-c6155bcd-18e6-438c-ac71-d59271efd28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2108893345-172.17.0.6-1597083970563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38475,DS-77049a0d-0b97-4371-a163-2cb772646c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39232,DS-21f10947-ff1d-48a0-9dd3-4add16654166,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-6cfd248f-1e6c-4cd8-a733-e394eca75368,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-5b9fe6d0-1e2b-4e1e-9a2b-09a67998d00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-3764d1b6-d1d7-4715-8a1a-509759b26d74,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-b5ad375d-b5d8-4dea-9d93-fa6c166ef747,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-8b33613c-4c83-477d-b1f3-ccc6c12304ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-c6155bcd-18e6-438c-ac71-d59271efd28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131475278-172.17.0.6-1597084019322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-df00d0f1-d8bd-4fcb-b01a-a71af7dc318e,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-71fdb978-2a9d-4256-b1ea-378bcd39a430,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-50f20347-6c2e-465c-b489-78985d41b1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-0c070f49-f161-4869-9b3c-650145545022,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-8bef23ac-c060-4663-8113-5d52ac97197f,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-65a3182b-2b73-4509-bf01-910acedd7214,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-c4fd907c-dc04-4a0d-9c0e-d14a99a098f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-fbd13093-5183-4ebd-80d7-a38da9611b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131475278-172.17.0.6-1597084019322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42640,DS-df00d0f1-d8bd-4fcb-b01a-a71af7dc318e,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-71fdb978-2a9d-4256-b1ea-378bcd39a430,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-50f20347-6c2e-465c-b489-78985d41b1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-0c070f49-f161-4869-9b3c-650145545022,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-8bef23ac-c060-4663-8113-5d52ac97197f,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-65a3182b-2b73-4509-bf01-910acedd7214,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-c4fd907c-dc04-4a0d-9c0e-d14a99a098f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-fbd13093-5183-4ebd-80d7-a38da9611b02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684357036-172.17.0.6-1597084067903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34602,DS-2d3713a3-4fd7-475c-8fee-d2964568e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-83aecac6-5c85-4b09-ba7f-f9736f34841a,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-35168470-ec98-4f34-b777-6006e493b5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-e2a23f08-3c4c-4f89-94ce-0546e6d2a734,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-c7b8ef29-8e74-4b5d-adc2-cb811e11bf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-6b6babdb-b9f2-4a6d-9dd9-f76afdb5cbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-3faaeedd-a157-4c4a-85bb-343bfefa9d01,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-fa0b1fce-1007-4949-9361-0225cee157f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684357036-172.17.0.6-1597084067903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34602,DS-2d3713a3-4fd7-475c-8fee-d2964568e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-83aecac6-5c85-4b09-ba7f-f9736f34841a,DISK], DatanodeInfoWithStorage[127.0.0.1:38030,DS-35168470-ec98-4f34-b777-6006e493b5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-e2a23f08-3c4c-4f89-94ce-0546e6d2a734,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-c7b8ef29-8e74-4b5d-adc2-cb811e11bf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34742,DS-6b6babdb-b9f2-4a6d-9dd9-f76afdb5cbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-3faaeedd-a157-4c4a-85bb-343bfefa9d01,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-fa0b1fce-1007-4949-9361-0225cee157f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734213274-172.17.0.6-1597084244358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-771a26f4-da8d-45c7-8419-58b47747c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-7d093672-2e0d-47a0-8df8-96b16181e9de,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-83484cdb-e841-4a24-81a2-476f9d763192,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-caa22bee-1a58-4807-8022-20c2e27ddace,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-e88e56f7-3c81-4e92-b914-fdf5bffe9b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-36a96308-5a16-4d48-acb6-3234340725ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-1a0bdc1f-d087-4a65-ac8c-f16f136b4987,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-d58ba291-88a7-4400-b06d-321394a50427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734213274-172.17.0.6-1597084244358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-771a26f4-da8d-45c7-8419-58b47747c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-7d093672-2e0d-47a0-8df8-96b16181e9de,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-83484cdb-e841-4a24-81a2-476f9d763192,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-caa22bee-1a58-4807-8022-20c2e27ddace,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-e88e56f7-3c81-4e92-b914-fdf5bffe9b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-36a96308-5a16-4d48-acb6-3234340725ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-1a0bdc1f-d087-4a65-ac8c-f16f136b4987,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-d58ba291-88a7-4400-b06d-321394a50427,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595260738-172.17.0.6-1597084360904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34679,DS-0ef6b0ef-6f19-4973-afe9-da738610986d,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-b65f93cc-80b2-4f80-b3a5-d9fba4315e99,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-0ca69a26-153e-4367-ad9a-512552486358,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-47f56bcb-9060-4982-923d-b69ef3ca57a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-c100c55a-e37c-4ee1-858b-dc25ae51824a,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-39be4c48-1773-4407-a501-ce3bdbc0236c,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-cf11b999-b422-422b-9ecb-b81dc4a5ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-1e8a5974-eb88-4dfd-b0c0-593818be564b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595260738-172.17.0.6-1597084360904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34679,DS-0ef6b0ef-6f19-4973-afe9-da738610986d,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-b65f93cc-80b2-4f80-b3a5-d9fba4315e99,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-0ca69a26-153e-4367-ad9a-512552486358,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-47f56bcb-9060-4982-923d-b69ef3ca57a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-c100c55a-e37c-4ee1-858b-dc25ae51824a,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-39be4c48-1773-4407-a501-ce3bdbc0236c,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-cf11b999-b422-422b-9ecb-b81dc4a5ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-1e8a5974-eb88-4dfd-b0c0-593818be564b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114314409-172.17.0.6-1597084931765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-de29ad4c-6fb7-4d38-84a5-c27f63202a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-4062d299-6d8f-42a2-9a2b-6908651b56a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-953c3667-7f5e-4a58-8a7d-8c2a9aca19b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-0beb5019-18f4-4221-a9b5-94ea38345f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-1d881829-7a91-4f77-841d-defa80a20e02,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-81717fe5-b64e-4ddd-beae-09394c4f03a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-01f50bf7-5928-4770-93c8-80973a5063a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-ccdd8376-d00a-4c57-827c-7609e3dae969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114314409-172.17.0.6-1597084931765:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-de29ad4c-6fb7-4d38-84a5-c27f63202a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-4062d299-6d8f-42a2-9a2b-6908651b56a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-953c3667-7f5e-4a58-8a7d-8c2a9aca19b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-0beb5019-18f4-4221-a9b5-94ea38345f36,DISK], DatanodeInfoWithStorage[127.0.0.1:34723,DS-1d881829-7a91-4f77-841d-defa80a20e02,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-81717fe5-b64e-4ddd-beae-09394c4f03a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-01f50bf7-5928-4770-93c8-80973a5063a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-ccdd8376-d00a-4c57-827c-7609e3dae969,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215995153-172.17.0.6-1597084969186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45892,DS-4c658d91-3605-4afe-a30d-7d81d9797865,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-3cab5d5a-2d9e-4f5d-98f3-940b586f47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-22731ab7-b5fd-462d-8031-0ae7cf857bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-f7adb8d1-f19b-42fd-b022-598f6c0b4391,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-8022ad9c-a06b-47b9-9cca-ecdbc99a2f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-0a15107f-0d7a-4028-b6e1-dd6644b7d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-aa76b735-23e8-4a06-b6ad-04fb460a16c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-9b24fa9d-7bcc-4d96-b4b6-d7c3d2d90cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215995153-172.17.0.6-1597084969186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45892,DS-4c658d91-3605-4afe-a30d-7d81d9797865,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-3cab5d5a-2d9e-4f5d-98f3-940b586f47f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-22731ab7-b5fd-462d-8031-0ae7cf857bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-f7adb8d1-f19b-42fd-b022-598f6c0b4391,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-8022ad9c-a06b-47b9-9cca-ecdbc99a2f84,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-0a15107f-0d7a-4028-b6e1-dd6644b7d78c,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-aa76b735-23e8-4a06-b6ad-04fb460a16c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-9b24fa9d-7bcc-4d96-b4b6-d7c3d2d90cb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727948173-172.17.0.6-1597085357822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39615,DS-851566ef-991c-43c2-b67b-33f3dde0bfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-18ba2312-1da7-4ca7-874f-8437185b4306,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-56896274-cc99-44fe-ab8c-5db2874ee81a,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-d901b3c7-d218-4604-b011-1792ed52b13c,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-7ebe55ac-9c1d-49a3-95e0-3a58096f68ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-80e75828-0646-4a4c-be82-4061c96adf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-cacca78a-11a7-4432-ae12-31c1194b0859,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-e8b03750-ad11-4063-b4f4-5453abcdb40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727948173-172.17.0.6-1597085357822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39615,DS-851566ef-991c-43c2-b67b-33f3dde0bfe2,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-18ba2312-1da7-4ca7-874f-8437185b4306,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-56896274-cc99-44fe-ab8c-5db2874ee81a,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-d901b3c7-d218-4604-b011-1792ed52b13c,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-7ebe55ac-9c1d-49a3-95e0-3a58096f68ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42468,DS-80e75828-0646-4a4c-be82-4061c96adf8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-cacca78a-11a7-4432-ae12-31c1194b0859,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-e8b03750-ad11-4063-b4f4-5453abcdb40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647029600-172.17.0.6-1597085724154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35437,DS-6162ccc3-2b4b-4094-92c9-fc840c0a4282,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-32163e6e-aa1b-4a39-9029-0f911803e513,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-1f286347-91de-4908-b343-6e1ee187d394,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-c0a8fe39-881c-49d4-92c6-13b94f80de13,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-2f0a2958-5001-4257-8d8a-2aeb2684639e,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-20d5d658-da57-4155-9b96-93f5e059c1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-8b2ce43f-0268-4797-bc66-8cc333352b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-5f8721d9-f66f-46ee-b125-1356d47b6b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647029600-172.17.0.6-1597085724154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35437,DS-6162ccc3-2b4b-4094-92c9-fc840c0a4282,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-32163e6e-aa1b-4a39-9029-0f911803e513,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-1f286347-91de-4908-b343-6e1ee187d394,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-c0a8fe39-881c-49d4-92c6-13b94f80de13,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-2f0a2958-5001-4257-8d8a-2aeb2684639e,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-20d5d658-da57-4155-9b96-93f5e059c1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-8b2ce43f-0268-4797-bc66-8cc333352b39,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-5f8721d9-f66f-46ee-b125-1356d47b6b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217735734-172.17.0.6-1597085858951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45066,DS-f942e460-303b-4e9a-a81d-eababa94e840,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-c1181dac-0d3b-447e-ade9-71b915aa8b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-d105f794-9983-48dc-94ed-afa4ab833228,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-3a1df650-f57b-4f2c-849d-565fade239f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-88c62cb3-eda5-4d95-801d-1d71c5b029e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-4836ec05-d27d-4617-8db3-ed51ca62986a,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-344b9ead-dfe5-4e20-82b7-bbae0074d9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-a737b66f-d79f-4554-9b3f-7a5a8807f1de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217735734-172.17.0.6-1597085858951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45066,DS-f942e460-303b-4e9a-a81d-eababa94e840,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-c1181dac-0d3b-447e-ade9-71b915aa8b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-d105f794-9983-48dc-94ed-afa4ab833228,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-3a1df650-f57b-4f2c-849d-565fade239f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-88c62cb3-eda5-4d95-801d-1d71c5b029e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-4836ec05-d27d-4617-8db3-ed51ca62986a,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-344b9ead-dfe5-4e20-82b7-bbae0074d9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-a737b66f-d79f-4554-9b3f-7a5a8807f1de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 4096
v2: 8192
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106312627-172.17.0.6-1597086079696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37780,DS-1dd1c538-5ac7-4ccb-b236-a3d250952579,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-fee54d92-fee8-4f2d-9461-4188215f1a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-639d3d40-b1c8-4228-9441-000ff49524ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-b69ac794-0a00-4342-834c-6f0002c7fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-1c5ad550-57df-49dd-afa3-034d251d2657,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-0f764439-3251-4a0f-b636-e647aac553ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-ce08fc6c-fa27-4711-9e23-5519a5d8a669,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-53277599-7d16-41fb-9bba-c7c73eab4930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106312627-172.17.0.6-1597086079696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37780,DS-1dd1c538-5ac7-4ccb-b236-a3d250952579,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-fee54d92-fee8-4f2d-9461-4188215f1a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-639d3d40-b1c8-4228-9441-000ff49524ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-b69ac794-0a00-4342-834c-6f0002c7fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-1c5ad550-57df-49dd-afa3-034d251d2657,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-0f764439-3251-4a0f-b636-e647aac553ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-ce08fc6c-fa27-4711-9e23-5519a5d8a669,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-53277599-7d16-41fb-9bba-c7c73eab4930,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6738
