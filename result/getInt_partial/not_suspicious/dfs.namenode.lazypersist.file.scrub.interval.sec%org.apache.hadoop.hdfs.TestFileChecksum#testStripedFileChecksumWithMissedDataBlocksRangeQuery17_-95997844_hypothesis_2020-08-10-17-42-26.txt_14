reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097291649-172.17.0.13-1597081862932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33643,DS-0c6b0af4-b6bb-4665-b04b-60eda3871747,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-3e35ed18-db38-4686-a89c-59fe74154a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-a10fdf9f-3951-47a6-9214-b716944d4cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-d9f09cb7-44d9-4767-b8d9-a6ccfa662820,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-ccebabb8-8f34-40fd-ac10-04437e021cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-d05012ff-f725-46d3-9c51-cc95115dfadd,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-b7e3c7ff-9b9f-4bf4-8e78-5a9e033a6199,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-81b8d5a9-7887-43df-9cdd-f7534b8b23f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097291649-172.17.0.13-1597081862932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33643,DS-0c6b0af4-b6bb-4665-b04b-60eda3871747,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-3e35ed18-db38-4686-a89c-59fe74154a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-a10fdf9f-3951-47a6-9214-b716944d4cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-d9f09cb7-44d9-4767-b8d9-a6ccfa662820,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-ccebabb8-8f34-40fd-ac10-04437e021cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41046,DS-d05012ff-f725-46d3-9c51-cc95115dfadd,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-b7e3c7ff-9b9f-4bf4-8e78-5a9e033a6199,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-81b8d5a9-7887-43df-9cdd-f7534b8b23f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580686171-172.17.0.13-1597081998793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40752,DS-e074b4c9-9216-4dcb-9164-0a937fc3647a,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-eb29b383-ca11-4c94-94b1-1fcaa2a16da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-c3cfcfb3-0b81-48d2-8a77-b2902d2c9cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-6c343e0c-a16b-4497-ab61-ec3e0809602d,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-d4788171-761c-4f94-9c95-d9a22e77792b,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-a114a096-b268-46f8-b869-7dce4a297fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-cf36a180-8c13-4c30-b309-f0c0d0079769,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-8d64d8bd-2b5c-4386-8fbe-7d2bd801ff1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580686171-172.17.0.13-1597081998793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40752,DS-e074b4c9-9216-4dcb-9164-0a937fc3647a,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-eb29b383-ca11-4c94-94b1-1fcaa2a16da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-c3cfcfb3-0b81-48d2-8a77-b2902d2c9cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38920,DS-6c343e0c-a16b-4497-ab61-ec3e0809602d,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-d4788171-761c-4f94-9c95-d9a22e77792b,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-a114a096-b268-46f8-b869-7dce4a297fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-cf36a180-8c13-4c30-b309-f0c0d0079769,DISK], DatanodeInfoWithStorage[127.0.0.1:45956,DS-8d64d8bd-2b5c-4386-8fbe-7d2bd801ff1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91388357-172.17.0.13-1597082476516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-61b8ed5a-fcd4-42d6-8600-4521fcc8a9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-597fea9f-aca2-4a03-87dc-3f42615758b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-ecfd0d38-7ad4-4a64-88d8-b2eb3a41d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-fed182cf-be64-4ad5-91d1-36bcb116a57d,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-bbc53619-526f-490b-8857-32f77c013d03,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-40274096-71c1-4d6c-8f00-23bb9afe4b39,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-f0c98852-845f-42f0-a013-17425465ba00,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-41878000-3c02-4ac8-9777-680102995061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91388357-172.17.0.13-1597082476516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-61b8ed5a-fcd4-42d6-8600-4521fcc8a9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-597fea9f-aca2-4a03-87dc-3f42615758b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-ecfd0d38-7ad4-4a64-88d8-b2eb3a41d6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-fed182cf-be64-4ad5-91d1-36bcb116a57d,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-bbc53619-526f-490b-8857-32f77c013d03,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-40274096-71c1-4d6c-8f00-23bb9afe4b39,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-f0c98852-845f-42f0-a013-17425465ba00,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-41878000-3c02-4ac8-9777-680102995061,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063693739-172.17.0.13-1597083202470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-29d341ed-75c1-4389-bec6-fd540692bcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-adf7d3d8-e702-47b8-b3c7-37b89e02caed,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-366ddeec-c9b9-4bb7-8870-b0018e4649c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-1e262096-cdbf-4052-93ae-b875eceeab26,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-b48fb8fe-ebf4-4f71-863f-9455ec5b08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-f845e5c4-f7f2-448e-9582-dfb80175da97,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-223c4143-95ab-4fbc-9049-020d22fdfdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-5de490d2-2a11-406f-89c5-02f033f6b97f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063693739-172.17.0.13-1597083202470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-29d341ed-75c1-4389-bec6-fd540692bcae,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-adf7d3d8-e702-47b8-b3c7-37b89e02caed,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-366ddeec-c9b9-4bb7-8870-b0018e4649c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46470,DS-1e262096-cdbf-4052-93ae-b875eceeab26,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-b48fb8fe-ebf4-4f71-863f-9455ec5b08cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-f845e5c4-f7f2-448e-9582-dfb80175da97,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-223c4143-95ab-4fbc-9049-020d22fdfdd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-5de490d2-2a11-406f-89c5-02f033f6b97f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211078954-172.17.0.13-1597083234604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41890,DS-eace77e3-29d5-4573-8b98-8e6055d5c5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-fd385d91-4f78-40d5-8402-5bed328b4f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-dc4a7789-5ad6-4915-a66d-fa29712b0a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-4e491892-b5e8-4724-b08c-d53f16cd3f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-80d69ce1-65f5-4e27-817d-95ad80bc94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-bf41c298-a870-4093-a2ed-d3d223f8eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-4e08a93d-ba41-46fc-9363-19ebcbf5f375,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-a97c1c5b-eb5c-4d73-b74c-36aed10c5678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211078954-172.17.0.13-1597083234604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41890,DS-eace77e3-29d5-4573-8b98-8e6055d5c5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-fd385d91-4f78-40d5-8402-5bed328b4f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-dc4a7789-5ad6-4915-a66d-fa29712b0a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34118,DS-4e491892-b5e8-4724-b08c-d53f16cd3f06,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-80d69ce1-65f5-4e27-817d-95ad80bc94dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-bf41c298-a870-4093-a2ed-d3d223f8eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-4e08a93d-ba41-46fc-9363-19ebcbf5f375,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-a97c1c5b-eb5c-4d73-b74c-36aed10c5678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138314672-172.17.0.13-1597083447077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38214,DS-c3a88f95-cff4-44fa-bbcf-e183f7f7f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-7becceca-3b27-4707-9ce7-cc5a1bc08ada,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-1ee668d7-5e63-4860-87bc-462bf80f5ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-c45a270d-6853-44fc-8205-f129a055f70c,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-8441baef-8126-4636-bf30-af0fffefbd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-cd0ef749-1ebb-48c3-ac66-fc17490574e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-369d6cbe-7b33-49f0-b292-b179bde3b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-419d63a3-6488-4025-90c2-8e79d204fe8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138314672-172.17.0.13-1597083447077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38214,DS-c3a88f95-cff4-44fa-bbcf-e183f7f7f78c,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-7becceca-3b27-4707-9ce7-cc5a1bc08ada,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-1ee668d7-5e63-4860-87bc-462bf80f5ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-c45a270d-6853-44fc-8205-f129a055f70c,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-8441baef-8126-4636-bf30-af0fffefbd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-cd0ef749-1ebb-48c3-ac66-fc17490574e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-369d6cbe-7b33-49f0-b292-b179bde3b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-419d63a3-6488-4025-90c2-8e79d204fe8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757086872-172.17.0.13-1597083693059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45749,DS-1a4cf667-c3f7-4ee7-a4d0-e7975257a206,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-38ac1cbb-3424-4616-8498-393c3acc8616,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-bc635917-2343-4f08-ae29-da00a57aed57,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-7a087f5b-90ad-45a2-9b86-e83a652d65f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-5a4ead21-57b5-4f90-8224-f93d796f200c,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-0586b79d-5feb-4414-b24b-ccd4c1586030,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-c1dc7be5-a1f5-4ce8-a84a-3dabf264e3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-5094d05b-4896-467c-8ffb-fd8a29b8e971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-757086872-172.17.0.13-1597083693059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45749,DS-1a4cf667-c3f7-4ee7-a4d0-e7975257a206,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-38ac1cbb-3424-4616-8498-393c3acc8616,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-bc635917-2343-4f08-ae29-da00a57aed57,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-7a087f5b-90ad-45a2-9b86-e83a652d65f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-5a4ead21-57b5-4f90-8224-f93d796f200c,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-0586b79d-5feb-4414-b24b-ccd4c1586030,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-c1dc7be5-a1f5-4ce8-a84a-3dabf264e3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-5094d05b-4896-467c-8ffb-fd8a29b8e971,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521117312-172.17.0.13-1597083976195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-23e08531-72b9-46c6-a0ff-8e6daa4e827a,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-96dbf2be-04a0-42ad-a424-bdf5019c3c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-afe77367-c28f-4d3e-afc3-2520eaff6b56,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-1b07b64f-d9bc-4f2f-9bf6-df5237e22352,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-25f8eb17-3962-4c43-afc3-dba8f36459e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-237239f5-9b3f-4cb8-904e-bce027a1de37,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-5b9b86c5-aef4-49f4-ab81-b5e0352c82f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-1c643c6f-49b3-4b4c-b8aa-f330da62238b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521117312-172.17.0.13-1597083976195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38804,DS-23e08531-72b9-46c6-a0ff-8e6daa4e827a,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-96dbf2be-04a0-42ad-a424-bdf5019c3c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43127,DS-afe77367-c28f-4d3e-afc3-2520eaff6b56,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-1b07b64f-d9bc-4f2f-9bf6-df5237e22352,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-25f8eb17-3962-4c43-afc3-dba8f36459e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-237239f5-9b3f-4cb8-904e-bce027a1de37,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-5b9b86c5-aef4-49f4-ab81-b5e0352c82f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46137,DS-1c643c6f-49b3-4b4c-b8aa-f330da62238b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647365184-172.17.0.13-1597084467687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-ff9061e7-00e6-4f90-b91f-a3c725df2864,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-d31c1f23-4a39-4f53-9755-e9e4302eb227,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-f3bd16e0-a66a-41ce-a9b1-8af91ccb3a63,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-6d2d2165-8414-43f8-907b-29b6a2eed417,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-e7f57fe2-d2aa-436d-851b-48ff13d89a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-a2c1588f-4648-41f4-907c-d031775c0ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-65116eb2-b52b-4263-957c-ac484bd7a9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-a1c68b41-d2ff-4970-8566-d7f6402e1e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-647365184-172.17.0.13-1597084467687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36389,DS-ff9061e7-00e6-4f90-b91f-a3c725df2864,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-d31c1f23-4a39-4f53-9755-e9e4302eb227,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-f3bd16e0-a66a-41ce-a9b1-8af91ccb3a63,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-6d2d2165-8414-43f8-907b-29b6a2eed417,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-e7f57fe2-d2aa-436d-851b-48ff13d89a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-a2c1588f-4648-41f4-907c-d031775c0ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-65116eb2-b52b-4263-957c-ac484bd7a9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-a1c68b41-d2ff-4970-8566-d7f6402e1e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824978104-172.17.0.13-1597084882235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33494,DS-50e31aae-6359-4d05-8b04-afae23ce556c,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-10b30261-ecdc-4aa4-a3fa-1d668e7d6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-1205b047-b7b6-4e5d-9b8a-da6d681f2417,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-55f80fa2-8c02-4ac4-a229-1379f1d1e123,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-402b868c-590b-49fb-936e-3b6a57f47939,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-6b078088-725d-437c-a5c1-8eb4e7b0cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-71bed886-7768-4be9-bd85-fcf116982186,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-93ca5bf3-379e-4deb-af47-61b41ebe74d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824978104-172.17.0.13-1597084882235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33494,DS-50e31aae-6359-4d05-8b04-afae23ce556c,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-10b30261-ecdc-4aa4-a3fa-1d668e7d6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-1205b047-b7b6-4e5d-9b8a-da6d681f2417,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-55f80fa2-8c02-4ac4-a229-1379f1d1e123,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-402b868c-590b-49fb-936e-3b6a57f47939,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-6b078088-725d-437c-a5c1-8eb4e7b0cd95,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-71bed886-7768-4be9-bd85-fcf116982186,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-93ca5bf3-379e-4deb-af47-61b41ebe74d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054527508-172.17.0.13-1597085089167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-65583e88-7f5f-4230-9fc8-4fc29f5d7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-6a3f9af1-dd03-451f-85ec-deb123f88462,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-6c672f78-3c8a-4773-89c4-fbee0e5c0884,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-5356c280-022e-4edd-8eee-3bf35646db46,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-a9ccf4b7-0d6b-481c-b25c-f2547e6e468a,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-34f19ae0-c846-4651-ae8c-a4248929c01a,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-aadb36a7-9d02-4ac8-a713-a84677f8cdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-0102b5a1-d3c3-4523-a165-6ddc5cbc7d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1054527508-172.17.0.13-1597085089167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35774,DS-65583e88-7f5f-4230-9fc8-4fc29f5d7d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-6a3f9af1-dd03-451f-85ec-deb123f88462,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-6c672f78-3c8a-4773-89c4-fbee0e5c0884,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-5356c280-022e-4edd-8eee-3bf35646db46,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-a9ccf4b7-0d6b-481c-b25c-f2547e6e468a,DISK], DatanodeInfoWithStorage[127.0.0.1:43332,DS-34f19ae0-c846-4651-ae8c-a4248929c01a,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-aadb36a7-9d02-4ac8-a713-a84677f8cdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-0102b5a1-d3c3-4523-a165-6ddc5cbc7d4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972933361-172.17.0.13-1597085416944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41238,DS-9019026a-e910-4bf1-9c55-ddd56d3899d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-aee935d6-e520-4d76-946d-9afb8ac87cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-161a345f-ad13-4b59-bd01-53c76a47aec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-376672b0-1c1b-45e0-8abe-4886a6c30b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-b6a507be-12d2-4060-b092-cd253c9c0010,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-de8fd574-5d53-43a8-bfc3-9efaef45e561,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-2692faad-afa1-4eea-8ba1-35697d62a040,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-bb3e0f5f-61d2-4c95-8b83-6807aa1b0687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972933361-172.17.0.13-1597085416944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41238,DS-9019026a-e910-4bf1-9c55-ddd56d3899d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-aee935d6-e520-4d76-946d-9afb8ac87cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-161a345f-ad13-4b59-bd01-53c76a47aec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-376672b0-1c1b-45e0-8abe-4886a6c30b17,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-b6a507be-12d2-4060-b092-cd253c9c0010,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-de8fd574-5d53-43a8-bfc3-9efaef45e561,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-2692faad-afa1-4eea-8ba1-35697d62a040,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-bb3e0f5f-61d2-4c95-8b83-6807aa1b0687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68610213-172.17.0.13-1597085557413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42261,DS-55a36cfc-8399-48e8-bd04-6e92119dd2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-7ed509b9-788e-48b1-9cee-375198c8f71e,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-04f8fcba-f670-45bf-8ddf-2eca6f37998f,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-41140f01-1a8d-4336-9a3b-52ee6a50c258,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-5bd3214f-e84d-401e-a324-93284a2931df,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-ce6b0ad0-2196-49d0-920d-1d1b7896ba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-6a6f8df5-9cee-449b-b066-5e963040367e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-94426da7-f970-448b-8bf9-b46ea31cd786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68610213-172.17.0.13-1597085557413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42261,DS-55a36cfc-8399-48e8-bd04-6e92119dd2ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-7ed509b9-788e-48b1-9cee-375198c8f71e,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-04f8fcba-f670-45bf-8ddf-2eca6f37998f,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-41140f01-1a8d-4336-9a3b-52ee6a50c258,DISK], DatanodeInfoWithStorage[127.0.0.1:36038,DS-5bd3214f-e84d-401e-a324-93284a2931df,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-ce6b0ad0-2196-49d0-920d-1d1b7896ba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-6a6f8df5-9cee-449b-b066-5e963040367e,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-94426da7-f970-448b-8bf9-b46ea31cd786,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991571359-172.17.0.13-1597085616210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36232,DS-d5206039-f4e5-4084-8511-27bfba49e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-a993e365-b925-4a1f-ba45-9a5378436314,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-6cdffab7-8680-4f4c-9d28-4142058d33f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-bdb8d8c3-c7e3-4a87-bb8d-7d28b137a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-98d256ea-5187-4326-8e74-cde3f750c607,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-04e89214-c25a-40e3-92af-6f01a42754fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-309c35ae-c9e1-4c27-9d3c-230a96733e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-04d054de-d1fb-4c23-a4f7-d9fb5c965b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1991571359-172.17.0.13-1597085616210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36232,DS-d5206039-f4e5-4084-8511-27bfba49e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-a993e365-b925-4a1f-ba45-9a5378436314,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-6cdffab7-8680-4f4c-9d28-4142058d33f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-bdb8d8c3-c7e3-4a87-bb8d-7d28b137a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-98d256ea-5187-4326-8e74-cde3f750c607,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-04e89214-c25a-40e3-92af-6f01a42754fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-309c35ae-c9e1-4c27-9d3c-230a96733e42,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-04d054de-d1fb-4c23-a4f7-d9fb5c965b82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288481782-172.17.0.13-1597086156567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-f0198d12-ad27-4ba5-a63c-fb76bcf5fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-1165c9a6-8bf4-405d-8031-d625a4fe1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-6c1181ee-fc36-4c03-9b51-5be369c8fa36,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-54618097-0b95-4ff8-b414-1c4c086798c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-3db2de1c-e504-4d41-af34-c41ff526756f,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-dd56f06b-528d-467b-a8fb-9366bf10efc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-1e5df02c-95f8-4fa3-bd4c-a6d61cd88c83,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-b23a838d-5c84-49b1-acce-b329dbc2c737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288481782-172.17.0.13-1597086156567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39534,DS-f0198d12-ad27-4ba5-a63c-fb76bcf5fa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-1165c9a6-8bf4-405d-8031-d625a4fe1c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-6c1181ee-fc36-4c03-9b51-5be369c8fa36,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-54618097-0b95-4ff8-b414-1c4c086798c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-3db2de1c-e504-4d41-af34-c41ff526756f,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-dd56f06b-528d-467b-a8fb-9366bf10efc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-1e5df02c-95f8-4fa3-bd4c-a6d61cd88c83,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-b23a838d-5c84-49b1-acce-b329dbc2c737,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 5242
