reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560342114-172.17.0.16-1597123737167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-43a21977-cd67-4e62-90b9-fbec7c5c186a,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-6fba19fa-088a-42d9-9574-20dfcd1d72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-894e3e8c-d382-4710-aff6-a0e45644b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-e120feaf-039a-46e2-8c7b-59d12c10bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-0d81ff42-daf1-45ce-b4e7-f575f1c63988,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-3ba4f790-41a5-48b0-b905-44f943d52d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-93c19b69-a7cc-4f8b-a566-92208518ac70,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-1bdeff9f-9583-4979-96f6-2912f6c1f25c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1560342114-172.17.0.16-1597123737167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-43a21977-cd67-4e62-90b9-fbec7c5c186a,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-6fba19fa-088a-42d9-9574-20dfcd1d72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-894e3e8c-d382-4710-aff6-a0e45644b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-e120feaf-039a-46e2-8c7b-59d12c10bcff,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-0d81ff42-daf1-45ce-b4e7-f575f1c63988,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-3ba4f790-41a5-48b0-b905-44f943d52d02,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-93c19b69-a7cc-4f8b-a566-92208518ac70,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-1bdeff9f-9583-4979-96f6-2912f6c1f25c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209182353-172.17.0.16-1597123967852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-e227b01c-5ed7-4833-9aef-a4585770004a,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-f1c719fb-fcc8-45f2-a0bb-899344caa0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-bd75dbee-d1c3-4a55-9fd4-5add45b98fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-fae3902f-ac4c-4988-839d-e9ca5a8d4dac,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-ba66a339-93e1-4c7c-9052-0bd876224020,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-be452e7a-a4d7-47c6-ae4d-7e709344d583,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-860f60f5-d2ca-4ba0-92c4-9aed61ed633e,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-fc57308f-faa8-4447-ab33-acbb0cea8b45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209182353-172.17.0.16-1597123967852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34773,DS-e227b01c-5ed7-4833-9aef-a4585770004a,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-f1c719fb-fcc8-45f2-a0bb-899344caa0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-bd75dbee-d1c3-4a55-9fd4-5add45b98fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-fae3902f-ac4c-4988-839d-e9ca5a8d4dac,DISK], DatanodeInfoWithStorage[127.0.0.1:38610,DS-ba66a339-93e1-4c7c-9052-0bd876224020,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-be452e7a-a4d7-47c6-ae4d-7e709344d583,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-860f60f5-d2ca-4ba0-92c4-9aed61ed633e,DISK], DatanodeInfoWithStorage[127.0.0.1:33863,DS-fc57308f-faa8-4447-ab33-acbb0cea8b45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043141502-172.17.0.16-1597124004376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36517,DS-b4ede062-758e-4da6-9dd6-628392dcbe16,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-3c413284-7216-49e0-8913-5633bba459a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-f242b77a-d70b-4ee2-a7da-03624c5c1fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-1e7cbd10-81e0-4c6d-bc70-4589ac11f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-39b556e1-0c68-45a6-953a-ef12cf7dbb53,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-3524ce27-c1a7-4857-8cc5-a859927ae6de,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-deb93661-2a27-4618-bd2c-554efb8de165,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-3ba28fe6-ebbf-4f4d-a3be-1bf65abb8105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1043141502-172.17.0.16-1597124004376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36517,DS-b4ede062-758e-4da6-9dd6-628392dcbe16,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-3c413284-7216-49e0-8913-5633bba459a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-f242b77a-d70b-4ee2-a7da-03624c5c1fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-1e7cbd10-81e0-4c6d-bc70-4589ac11f56f,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-39b556e1-0c68-45a6-953a-ef12cf7dbb53,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-3524ce27-c1a7-4857-8cc5-a859927ae6de,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-deb93661-2a27-4618-bd2c-554efb8de165,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-3ba28fe6-ebbf-4f4d-a3be-1bf65abb8105,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107867449-172.17.0.16-1597124070815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42610,DS-9fcb7c42-3004-418b-974b-75c707a066e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-400ae17d-b0d8-4217-92d5-8c2601907e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-88934de6-5a74-4f33-b8a0-560a823ffa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-9bba3074-9c4a-4ebd-88c8-4d116c771db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-0baddd7f-5d47-4f9f-80bb-afdc2e623262,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-162ce2f1-56c2-4acd-b6eb-b5b8c32ddd16,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a3cfb50d-a791-4075-bf9a-64cb4f378023,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-083c1faa-3779-499c-90e2-afe9f60d2e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107867449-172.17.0.16-1597124070815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42610,DS-9fcb7c42-3004-418b-974b-75c707a066e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-400ae17d-b0d8-4217-92d5-8c2601907e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-88934de6-5a74-4f33-b8a0-560a823ffa1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-9bba3074-9c4a-4ebd-88c8-4d116c771db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-0baddd7f-5d47-4f9f-80bb-afdc2e623262,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-162ce2f1-56c2-4acd-b6eb-b5b8c32ddd16,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a3cfb50d-a791-4075-bf9a-64cb4f378023,DISK], DatanodeInfoWithStorage[127.0.0.1:38228,DS-083c1faa-3779-499c-90e2-afe9f60d2e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714359553-172.17.0.16-1597124141688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-6c43612a-ad8c-481c-9206-03f21a554f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-34f246d9-b552-4216-a6ed-141b705f7aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-305144b2-ec9c-404f-a713-7b12cceedc36,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-93aafe57-89fd-4470-82c7-c34b940fdee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-03e00bb4-0b02-46f3-898f-47c254cd0dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-da65ba4b-438b-441f-994c-6cc9da0e16f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-d28183ef-65bb-4dfb-8323-ff85a3a37a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-4b13fb8c-d1b5-4d8e-8ef3-6e3dc7bbb0a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-714359553-172.17.0.16-1597124141688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42488,DS-6c43612a-ad8c-481c-9206-03f21a554f73,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-34f246d9-b552-4216-a6ed-141b705f7aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-305144b2-ec9c-404f-a713-7b12cceedc36,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-93aafe57-89fd-4470-82c7-c34b940fdee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-03e00bb4-0b02-46f3-898f-47c254cd0dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-da65ba4b-438b-441f-994c-6cc9da0e16f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-d28183ef-65bb-4dfb-8323-ff85a3a37a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-4b13fb8c-d1b5-4d8e-8ef3-6e3dc7bbb0a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328912828-172.17.0.16-1597124487601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41961,DS-17868381-eb9f-4e82-9488-ed0a5c8b4a38,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-15df2db9-5d0e-4db8-8f80-25fef8535cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-8661ceec-932e-4dc4-a1d8-b054a46b5d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-a9b66806-a1e7-40dc-9e0c-5b132c7e4d40,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-7b464c29-5b9f-4d63-8af3-a93c75270fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-e13ac7ff-580f-45b4-ba92-a299c3aebbec,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-8d54a7dc-9f19-450b-a59e-7eef216e6d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-7c0aa82d-5f85-419d-95e2-9689b11aafe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1328912828-172.17.0.16-1597124487601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41961,DS-17868381-eb9f-4e82-9488-ed0a5c8b4a38,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-15df2db9-5d0e-4db8-8f80-25fef8535cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-8661ceec-932e-4dc4-a1d8-b054a46b5d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-a9b66806-a1e7-40dc-9e0c-5b132c7e4d40,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-7b464c29-5b9f-4d63-8af3-a93c75270fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-e13ac7ff-580f-45b4-ba92-a299c3aebbec,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-8d54a7dc-9f19-450b-a59e-7eef216e6d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:41782,DS-7c0aa82d-5f85-419d-95e2-9689b11aafe4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507574921-172.17.0.16-1597124767531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-5d4d46d9-2eef-43db-9e20-a23935027920,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-78e4b5cd-5f78-4bd8-9e83-2f2b66f829c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-4867827c-c1f2-4d36-aa88-7812718e87da,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-32f080a1-0e43-4a4c-a595-3c512c3a9161,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-6454b67b-1c6b-482c-b4a1-c060a4f1d7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-d329caa8-0137-4db9-8d38-6271e3a73190,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-35fd0af0-6278-4226-8885-962250bc5f75,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-61e24ef1-2b97-47b8-9131-056c3d062a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-507574921-172.17.0.16-1597124767531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-5d4d46d9-2eef-43db-9e20-a23935027920,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-78e4b5cd-5f78-4bd8-9e83-2f2b66f829c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-4867827c-c1f2-4d36-aa88-7812718e87da,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-32f080a1-0e43-4a4c-a595-3c512c3a9161,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-6454b67b-1c6b-482c-b4a1-c060a4f1d7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-d329caa8-0137-4db9-8d38-6271e3a73190,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-35fd0af0-6278-4226-8885-962250bc5f75,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-61e24ef1-2b97-47b8-9131-056c3d062a17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407974143-172.17.0.16-1597124903335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-164820b6-31aa-49d8-804d-f60821f32644,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-ad5d189b-cf0f-47bc-b536-2a0b65992c31,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-439c7284-889a-4074-861c-7f6519ed4c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-6477beeb-1296-46d3-b339-f2db60badcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-1010e59f-b22d-4c22-8e4a-6f91a34138b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-b2f67614-e958-406b-bfd1-1dc32f92bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-96fcc402-7908-41fb-8899-de00640f91fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-1e285451-48cb-4c57-a8d5-deb0b084d4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407974143-172.17.0.16-1597124903335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45954,DS-164820b6-31aa-49d8-804d-f60821f32644,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-ad5d189b-cf0f-47bc-b536-2a0b65992c31,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-439c7284-889a-4074-861c-7f6519ed4c57,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-6477beeb-1296-46d3-b339-f2db60badcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-1010e59f-b22d-4c22-8e4a-6f91a34138b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-b2f67614-e958-406b-bfd1-1dc32f92bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-96fcc402-7908-41fb-8899-de00640f91fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-1e285451-48cb-4c57-a8d5-deb0b084d4e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493704945-172.17.0.16-1597125571419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-fd165c47-a52b-471e-8daf-879aac2b8643,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-06930b1f-3969-4d4b-badb-7ff2c0de869a,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-d7999104-07aa-4ed0-b3bf-2b289a24c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-44fc733e-b8d5-4f82-a8bd-8ce7d4e0047b,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-65a4d8bf-8dc4-45db-8ed2-af03d716ec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-bfce86d6-0daa-4b78-90d4-0fd658c9418a,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-04cc4987-d317-446d-9709-302a99eea0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-b5474ecc-7b21-4428-a16b-e9050b59c16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493704945-172.17.0.16-1597125571419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38341,DS-fd165c47-a52b-471e-8daf-879aac2b8643,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-06930b1f-3969-4d4b-badb-7ff2c0de869a,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-d7999104-07aa-4ed0-b3bf-2b289a24c4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-44fc733e-b8d5-4f82-a8bd-8ce7d4e0047b,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-65a4d8bf-8dc4-45db-8ed2-af03d716ec0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-bfce86d6-0daa-4b78-90d4-0fd658c9418a,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-04cc4987-d317-446d-9709-302a99eea0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-b5474ecc-7b21-4428-a16b-e9050b59c16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793500554-172.17.0.16-1597126109090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-bb2a3685-29f2-497d-9087-1d17246c5137,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-381d94c7-e4f6-4265-b157-e3cf4ca99a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-8518eb75-c389-43ba-8488-0285eedb9fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-53e84501-b800-4c20-b6be-d8fcbcaed05d,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-ce0e8161-5d80-4e2c-a276-c48c49d50fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-ad6af520-94ec-45d9-ba3a-c2249e812f91,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-5fcffd77-ef18-46e5-aefc-0de4f64e22c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-5fd82efe-cae6-4579-88cd-39fe8e98306c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793500554-172.17.0.16-1597126109090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-bb2a3685-29f2-497d-9087-1d17246c5137,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-381d94c7-e4f6-4265-b157-e3cf4ca99a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-8518eb75-c389-43ba-8488-0285eedb9fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-53e84501-b800-4c20-b6be-d8fcbcaed05d,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-ce0e8161-5d80-4e2c-a276-c48c49d50fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-ad6af520-94ec-45d9-ba3a-c2249e812f91,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-5fcffd77-ef18-46e5-aefc-0de4f64e22c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-5fd82efe-cae6-4579-88cd-39fe8e98306c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119435652-172.17.0.16-1597126157911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40358,DS-62b57416-4c9f-49f9-acc8-fd7cd550003b,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-67b9ff07-5395-493f-9d89-d34690932104,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-9c17d867-15b9-455d-902c-ef7211caff7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-defda09a-5ac6-4edb-bca2-e57c5d63a5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-31b64005-751c-4bf0-9948-e30b5a31faa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-78d5a73b-17f5-4a3d-86d1-2711c293bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-12d19cba-df62-4b0d-89a7-8d153b79991a,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-d179c389-05b3-4702-86c6-168fd9724704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119435652-172.17.0.16-1597126157911:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40358,DS-62b57416-4c9f-49f9-acc8-fd7cd550003b,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-67b9ff07-5395-493f-9d89-d34690932104,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-9c17d867-15b9-455d-902c-ef7211caff7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-defda09a-5ac6-4edb-bca2-e57c5d63a5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43831,DS-31b64005-751c-4bf0-9948-e30b5a31faa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-78d5a73b-17f5-4a3d-86d1-2711c293bf4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42324,DS-12d19cba-df62-4b0d-89a7-8d153b79991a,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-d179c389-05b3-4702-86c6-168fd9724704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690845991-172.17.0.16-1597126499162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-c9add269-1b10-4858-85cb-8ca1460cf752,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-5e628e78-f23c-4e05-9b58-7093c7090c33,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-9bba0b4b-75c0-495d-affb-c479cc1cc3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-96f24519-66d0-44e9-a0b2-81eab62d3d81,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-41cefcfe-0295-4aab-adcf-34fc776d1425,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-29bc2a7f-5de2-4057-a456-a5a25b9e265a,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-e9847f2b-b2ae-4522-8840-b229c9505af4,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-fc914bba-4672-4536-8d19-55b1f79dcd9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-690845991-172.17.0.16-1597126499162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38693,DS-c9add269-1b10-4858-85cb-8ca1460cf752,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-5e628e78-f23c-4e05-9b58-7093c7090c33,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-9bba0b4b-75c0-495d-affb-c479cc1cc3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-96f24519-66d0-44e9-a0b2-81eab62d3d81,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-41cefcfe-0295-4aab-adcf-34fc776d1425,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-29bc2a7f-5de2-4057-a456-a5a25b9e265a,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-e9847f2b-b2ae-4522-8840-b229c9505af4,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-fc914bba-4672-4536-8d19-55b1f79dcd9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485372639-172.17.0.16-1597126728199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-d6346f93-53e3-4a63-9df5-233392f0d458,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-870fd38e-789a-4f6b-b425-b4d122fcebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-eeb866b0-d6bf-4ebf-af79-06cba7e0bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-5749c31e-de30-4c27-9bdb-61221861e5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-f3a324a9-e53f-41f0-a18a-950f5de27e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-b339b9a6-6f60-4424-b4b7-37854dce25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-568f918b-8a5f-4cfd-aa48-9510cbac87b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-871b91c8-3dfb-4b36-a915-72b041222f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485372639-172.17.0.16-1597126728199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45988,DS-d6346f93-53e3-4a63-9df5-233392f0d458,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-870fd38e-789a-4f6b-b425-b4d122fcebfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-eeb866b0-d6bf-4ebf-af79-06cba7e0bfad,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-5749c31e-de30-4c27-9bdb-61221861e5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-f3a324a9-e53f-41f0-a18a-950f5de27e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-b339b9a6-6f60-4424-b4b7-37854dce25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-568f918b-8a5f-4cfd-aa48-9510cbac87b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-871b91c8-3dfb-4b36-a915-72b041222f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lazypersist.file.scrub.interval.sec
component: hdfs:NameNode
v1: 0
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914148693-172.17.0.16-1597127004087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46216,DS-98bc5aee-7758-4a96-93c1-7f2764f1f298,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-b0f65610-fb5d-45d3-87cd-dc08a0a357bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-b66dbf0b-c977-40e4-87b0-487d61525f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-534724ec-b4a9-4ba2-9c9c-0c60a390e168,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-cefb467b-12cc-464b-9c16-c1ca2a272985,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-41a5f3d8-d8f6-449b-8ef9-90252614f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-a452bce8-04d2-4432-86c9-d84314d64d31,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e74aecf0-a51a-4f3c-9caa-fa44e62129ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914148693-172.17.0.16-1597127004087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46216,DS-98bc5aee-7758-4a96-93c1-7f2764f1f298,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-b0f65610-fb5d-45d3-87cd-dc08a0a357bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-b66dbf0b-c977-40e4-87b0-487d61525f19,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-534724ec-b4a9-4ba2-9c9c-0c60a390e168,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-cefb467b-12cc-464b-9c16-c1ca2a272985,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-41a5f3d8-d8f6-449b-8ef9-90252614f7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-a452bce8-04d2-4432-86c9-d84314d64d31,DISK], DatanodeInfoWithStorage[127.0.0.1:36429,DS-e74aecf0-a51a-4f3c-9caa-fa44e62129ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5097
