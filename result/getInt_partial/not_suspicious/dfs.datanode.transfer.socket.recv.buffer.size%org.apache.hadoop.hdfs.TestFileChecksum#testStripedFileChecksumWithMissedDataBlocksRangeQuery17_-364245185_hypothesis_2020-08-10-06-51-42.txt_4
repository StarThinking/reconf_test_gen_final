reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457849586-172.17.0.5-1597042659284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40315,DS-cfbf7e83-c894-4e60-890c-ca92d714e5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-e9162391-0a3a-4b5b-bc72-a7138c0c4475,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-eca41e14-0509-4de0-84a5-730c3cde220f,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-99e449ff-9e82-4a35-ab1e-9904bf2c8fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-6c811f67-bd48-48b8-bd22-82e4ed573ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-bce22113-8a2b-41d1-bccd-0276f9a8b30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-5aab1bd0-5651-429c-99f7-ac3c7b4070ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-8c76f868-44d9-43ce-83d1-27eb781e11f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457849586-172.17.0.5-1597042659284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40315,DS-cfbf7e83-c894-4e60-890c-ca92d714e5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-e9162391-0a3a-4b5b-bc72-a7138c0c4475,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-eca41e14-0509-4de0-84a5-730c3cde220f,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-99e449ff-9e82-4a35-ab1e-9904bf2c8fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-6c811f67-bd48-48b8-bd22-82e4ed573ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-bce22113-8a2b-41d1-bccd-0276f9a8b30c,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-5aab1bd0-5651-429c-99f7-ac3c7b4070ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-8c76f868-44d9-43ce-83d1-27eb781e11f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349386935-172.17.0.5-1597044499093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-2d9adc12-bd62-4048-aac2-2f6992219a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-5db23547-7e34-4180-9a6d-3daf5e79d372,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-96d1e23e-5869-4be0-9cb2-9f393a77fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-485dc6d3-4a4a-45b6-bb10-97a7af292ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-7108a416-b010-4440-89bc-38251919f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-c0e90c17-16fb-4903-8ffa-173dc800c458,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-28fac935-db1f-487f-8bef-3befba0ee760,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-53720524-3758-4a84-bac3-1fe6604021dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-349386935-172.17.0.5-1597044499093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-2d9adc12-bd62-4048-aac2-2f6992219a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-5db23547-7e34-4180-9a6d-3daf5e79d372,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-96d1e23e-5869-4be0-9cb2-9f393a77fcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-485dc6d3-4a4a-45b6-bb10-97a7af292ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-7108a416-b010-4440-89bc-38251919f1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-c0e90c17-16fb-4903-8ffa-173dc800c458,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-28fac935-db1f-487f-8bef-3befba0ee760,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-53720524-3758-4a84-bac3-1fe6604021dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680465321-172.17.0.5-1597044644981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36117,DS-d5c7272d-c973-4ccf-bf6d-2d0d4051e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-df2ff802-9e6c-426c-ac32-95e209d35422,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-c968f605-3fe3-4a72-a876-432b47d42e93,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-2ad874bb-67c0-40f6-a57b-e1d5257c142e,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-db6a82b1-1e62-44ee-b265-808484f8374b,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-8c70103a-2687-47f0-95e4-c51c0af6451c,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-bd37f425-bff8-4415-9be2-821782926075,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-1238cb7c-1eaf-4596-9257-3a825b3381f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680465321-172.17.0.5-1597044644981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36117,DS-d5c7272d-c973-4ccf-bf6d-2d0d4051e46c,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-df2ff802-9e6c-426c-ac32-95e209d35422,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-c968f605-3fe3-4a72-a876-432b47d42e93,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-2ad874bb-67c0-40f6-a57b-e1d5257c142e,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-db6a82b1-1e62-44ee-b265-808484f8374b,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-8c70103a-2687-47f0-95e4-c51c0af6451c,DISK], DatanodeInfoWithStorage[127.0.0.1:35705,DS-bd37f425-bff8-4415-9be2-821782926075,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-1238cb7c-1eaf-4596-9257-3a825b3381f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405884789-172.17.0.5-1597044789725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-da9edbe6-0804-4640-b549-bcbd550011e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-a8e2d0b0-c254-4bf2-a728-a6df2d8efc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-90992833-ac93-4e2a-b1fc-a6dd89c95441,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-c4a17362-d528-4e74-a61f-e5b4a4b26557,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-03126f1a-a7e1-4083-808e-460900095fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-388e985c-3d53-494d-ae48-426c0d89e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-de1a1aa3-effe-4707-8eb6-5704ad7250c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-3c7ec6c7-1be9-4459-8a82-42defece2f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405884789-172.17.0.5-1597044789725:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42066,DS-da9edbe6-0804-4640-b549-bcbd550011e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-a8e2d0b0-c254-4bf2-a728-a6df2d8efc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-90992833-ac93-4e2a-b1fc-a6dd89c95441,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-c4a17362-d528-4e74-a61f-e5b4a4b26557,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-03126f1a-a7e1-4083-808e-460900095fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-388e985c-3d53-494d-ae48-426c0d89e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-de1a1aa3-effe-4707-8eb6-5704ad7250c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-3c7ec6c7-1be9-4459-8a82-42defece2f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874838392-172.17.0.5-1597044963285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34914,DS-6efa56b5-e086-45b8-b1ec-4058d9c86ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-e4d20783-e358-4be6-a1ba-6a0844800463,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-832e7cab-50c1-468d-873d-308ddfd0f13b,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-3e6d5ba5-589c-4c89-a6d8-060d5ac432a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-9a4aa35c-e572-4f49-994e-81d08de36e64,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-69fbe49d-276c-44d3-9704-e5f287187d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-44563b74-3b01-42d2-b043-9f916bff0411,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-e18e8952-8977-43f5-bfe8-cdf3e3628e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874838392-172.17.0.5-1597044963285:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34914,DS-6efa56b5-e086-45b8-b1ec-4058d9c86ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-e4d20783-e358-4be6-a1ba-6a0844800463,DISK], DatanodeInfoWithStorage[127.0.0.1:44388,DS-832e7cab-50c1-468d-873d-308ddfd0f13b,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-3e6d5ba5-589c-4c89-a6d8-060d5ac432a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-9a4aa35c-e572-4f49-994e-81d08de36e64,DISK], DatanodeInfoWithStorage[127.0.0.1:39106,DS-69fbe49d-276c-44d3-9704-e5f287187d79,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-44563b74-3b01-42d2-b043-9f916bff0411,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-e18e8952-8977-43f5-bfe8-cdf3e3628e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384582373-172.17.0.5-1597045229060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-94f7e94d-ec72-4007-a525-550cbe4f44cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-8867d2ca-1828-443a-add9-e5ee0192848d,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-480bf1f6-6da5-4b7e-be47-9431be088d26,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-9e9dafbb-4e93-4f1e-8a27-3ffa2d8bad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-29deaa28-c672-4bab-8f95-949fe9485942,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-873bfc23-82e3-4959-a1e5-efb7fe47e9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-8aabeebc-ec8e-4b24-8028-63727c02b58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-80ea005f-9301-4d69-8e4a-a61a35c67c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384582373-172.17.0.5-1597045229060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36520,DS-94f7e94d-ec72-4007-a525-550cbe4f44cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-8867d2ca-1828-443a-add9-e5ee0192848d,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-480bf1f6-6da5-4b7e-be47-9431be088d26,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-9e9dafbb-4e93-4f1e-8a27-3ffa2d8bad8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-29deaa28-c672-4bab-8f95-949fe9485942,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-873bfc23-82e3-4959-a1e5-efb7fe47e9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-8aabeebc-ec8e-4b24-8028-63727c02b58a,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-80ea005f-9301-4d69-8e4a-a61a35c67c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201505300-172.17.0.5-1597045296868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-b69e8b19-c2ec-4f3c-80a2-ea131db9d3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-b6be191b-3339-436a-aaf9-3a4ad6f24c52,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-4165840d-32ff-4b11-a95f-a3e96942642d,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-853b987c-9615-4613-b2a2-a5ff7128d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-45fd5e55-b2a3-4997-8ac9-0122a9f1354d,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-bd8dcced-26a6-48d9-9b38-dd21a0c2d6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-a2ab333e-fe30-4cae-8a00-d700f28371c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-5afbd211-cee1-468e-89c8-c24f63611f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-201505300-172.17.0.5-1597045296868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-b69e8b19-c2ec-4f3c-80a2-ea131db9d3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-b6be191b-3339-436a-aaf9-3a4ad6f24c52,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-4165840d-32ff-4b11-a95f-a3e96942642d,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-853b987c-9615-4613-b2a2-a5ff7128d5c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-45fd5e55-b2a3-4997-8ac9-0122a9f1354d,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-bd8dcced-26a6-48d9-9b38-dd21a0c2d6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-a2ab333e-fe30-4cae-8a00-d700f28371c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-5afbd211-cee1-468e-89c8-c24f63611f17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177394359-172.17.0.5-1597045605850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40533,DS-af76a35c-46fc-4c82-8744-b3689410fa16,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-fecfb461-2206-496b-a5e9-458fa7a0bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-59b0e7d5-eaf4-4376-aa9a-70f163bc9721,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-47d98175-30d7-43e3-b342-2cc0528ae1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a336da53-50ed-4179-a871-9fe293b9ad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-e8c4d00b-3f2f-4dfb-b7bc-ac5bf26ac769,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-9a1f4e71-fba8-423a-a44a-f99506705ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-5add9648-dbdd-4270-bd71-375958d7980d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177394359-172.17.0.5-1597045605850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40533,DS-af76a35c-46fc-4c82-8744-b3689410fa16,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-fecfb461-2206-496b-a5e9-458fa7a0bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-59b0e7d5-eaf4-4376-aa9a-70f163bc9721,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-47d98175-30d7-43e3-b342-2cc0528ae1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a336da53-50ed-4179-a871-9fe293b9ad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-e8c4d00b-3f2f-4dfb-b7bc-ac5bf26ac769,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-9a1f4e71-fba8-423a-a44a-f99506705ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-5add9648-dbdd-4270-bd71-375958d7980d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822476109-172.17.0.5-1597046042577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-d5e0e8e9-ca46-4a7b-8f1c-ff897d2cf049,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-5567e5a7-ffdc-4a3f-b1c4-dd3c3ba95d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-5c1e0411-38cd-4703-9cfe-c290e3d853cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-275d59c3-1618-4f9a-b2eb-17028684ad50,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-3aa606f8-579e-44c6-8924-db3328083d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-c3283a0c-38e1-445d-8891-318ccb8ae8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-ef43e405-161a-4f4a-acd9-f2eece482a41,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-84a8a2e6-6f9c-41cd-9c55-1e1e246312a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822476109-172.17.0.5-1597046042577:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36100,DS-d5e0e8e9-ca46-4a7b-8f1c-ff897d2cf049,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-5567e5a7-ffdc-4a3f-b1c4-dd3c3ba95d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-5c1e0411-38cd-4703-9cfe-c290e3d853cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-275d59c3-1618-4f9a-b2eb-17028684ad50,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-3aa606f8-579e-44c6-8924-db3328083d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-c3283a0c-38e1-445d-8891-318ccb8ae8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-ef43e405-161a-4f4a-acd9-f2eece482a41,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-84a8a2e6-6f9c-41cd-9c55-1e1e246312a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745549851-172.17.0.5-1597046150162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41026,DS-92679aa4-561a-4f61-8e3c-d3a81c887009,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-a5461636-b075-4446-a2e4-350bc3908f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-b6b7a686-d116-4a15-89d0-8d59dba779f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-106e88d8-e0aa-42b3-8b14-34f5cbd67900,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-1f4e109f-615d-4e63-976f-c0d9b52b09ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-548aba93-cc4d-4965-801b-c80983f69cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-14c9ec30-84fd-4d1b-b8e5-2af7541f3c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-a2817844-1e71-4544-bbe3-cea2d3b9f968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1745549851-172.17.0.5-1597046150162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41026,DS-92679aa4-561a-4f61-8e3c-d3a81c887009,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-a5461636-b075-4446-a2e4-350bc3908f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-b6b7a686-d116-4a15-89d0-8d59dba779f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-106e88d8-e0aa-42b3-8b14-34f5cbd67900,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-1f4e109f-615d-4e63-976f-c0d9b52b09ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-548aba93-cc4d-4965-801b-c80983f69cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-14c9ec30-84fd-4d1b-b8e5-2af7541f3c93,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-a2817844-1e71-4544-bbe3-cea2d3b9f968,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546893328-172.17.0.5-1597046436011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40993,DS-a01503be-27d2-4c6c-95ec-435538ab5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-3369ee71-6fea-4dde-b900-f433bf1d41f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-661a4983-93da-4500-b9d8-6fd752ee045e,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-dced92c0-9eb8-4a72-8e97-d20e0d3d92c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-007b4eb9-6d53-4c06-9069-8e17fb454653,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-74efbe22-0270-4e0b-8010-d40c8c73c87b,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-0c170425-d721-4f19-8136-cd0428c5aeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-b04d00cd-4e6d-4467-b2ad-a0fffe657125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1546893328-172.17.0.5-1597046436011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40993,DS-a01503be-27d2-4c6c-95ec-435538ab5f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-3369ee71-6fea-4dde-b900-f433bf1d41f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-661a4983-93da-4500-b9d8-6fd752ee045e,DISK], DatanodeInfoWithStorage[127.0.0.1:36633,DS-dced92c0-9eb8-4a72-8e97-d20e0d3d92c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-007b4eb9-6d53-4c06-9069-8e17fb454653,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-74efbe22-0270-4e0b-8010-d40c8c73c87b,DISK], DatanodeInfoWithStorage[127.0.0.1:33191,DS-0c170425-d721-4f19-8136-cd0428c5aeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-b04d00cd-4e6d-4467-b2ad-a0fffe657125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415496575-172.17.0.5-1597046922412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36185,DS-e0317790-1f1f-4b08-a308-8b9efcc47a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-730d191d-29f1-4016-99d5-6823cede3f45,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-f0826cee-2bac-4c3f-984f-33efa70433df,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-c7dca360-9f7e-4fd1-bd2c-c5fcde47a61c,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-81f0c129-3a47-44e3-8055-d3d842eec3da,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-a14456de-3e5b-42d0-be61-398f1ef9fbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-9ce8a36e-f83a-4154-935b-8d127c8f8a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-b430c8e2-d022-4597-a5a7-ed3ccf426df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415496575-172.17.0.5-1597046922412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36185,DS-e0317790-1f1f-4b08-a308-8b9efcc47a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-730d191d-29f1-4016-99d5-6823cede3f45,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-f0826cee-2bac-4c3f-984f-33efa70433df,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-c7dca360-9f7e-4fd1-bd2c-c5fcde47a61c,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-81f0c129-3a47-44e3-8055-d3d842eec3da,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-a14456de-3e5b-42d0-be61-398f1ef9fbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-9ce8a36e-f83a-4154-935b-8d127c8f8a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-b430c8e2-d022-4597-a5a7-ed3ccf426df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712210235-172.17.0.5-1597046963225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43607,DS-32c0f341-b789-41e8-9436-33e45cf63dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-815035c3-a8be-4738-8f50-e3ed697e6fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-3306ed88-fe09-4574-a0c2-e82903093bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-7de65e28-61bb-4d45-b199-141651c2d0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-c46f7c77-9c1f-4b8a-9d1c-f4fefe04de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-12f0ec5c-1303-4ccb-a000-3a13b3897c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-746f423b-6c77-4715-94b5-8a72f659bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-2e4d20ec-f595-434c-84c8-ca8a2544f87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1712210235-172.17.0.5-1597046963225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43607,DS-32c0f341-b789-41e8-9436-33e45cf63dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-815035c3-a8be-4738-8f50-e3ed697e6fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-3306ed88-fe09-4574-a0c2-e82903093bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-7de65e28-61bb-4d45-b199-141651c2d0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-c46f7c77-9c1f-4b8a-9d1c-f4fefe04de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-12f0ec5c-1303-4ccb-a000-3a13b3897c06,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-746f423b-6c77-4715-94b5-8a72f659bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-2e4d20ec-f595-434c-84c8-ca8a2544f87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703329583-172.17.0.5-1597047032002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-cbcdfb3b-5fff-4d09-b609-278b78470d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-8ca5883b-3daa-4c54-aec6-0b8d93e9cf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-c0863585-5e2f-49b4-92f0-1cae99bd0974,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-253d3246-8878-4b39-851c-c0cd38e848e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-0cebdb9d-a8b2-4b18-b3ce-f18e0459b745,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-4abeae67-b3b0-43f6-8dfa-5e89745dfc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-d8e17eab-f2f6-4b6a-8578-ce5922dfd4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-f9d4c7fa-e7a3-453c-b430-dcbd32403d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703329583-172.17.0.5-1597047032002:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-cbcdfb3b-5fff-4d09-b609-278b78470d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-8ca5883b-3daa-4c54-aec6-0b8d93e9cf6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-c0863585-5e2f-49b4-92f0-1cae99bd0974,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-253d3246-8878-4b39-851c-c0cd38e848e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-0cebdb9d-a8b2-4b18-b3ce-f18e0459b745,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-4abeae67-b3b0-43f6-8dfa-5e89745dfc0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-d8e17eab-f2f6-4b6a-8578-ce5922dfd4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-f9d4c7fa-e7a3-453c-b430-dcbd32403d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.recv.buffer.size
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374122898-172.17.0.5-1597047176282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35385,DS-1ac75f46-e19f-4caf-af36-734e9b6cdd14,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-7e8dec85-abfe-422a-bc6e-4d5936220ace,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-9d18b247-93e8-4a94-99bc-300bde7e78d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-6062917a-77f4-4bfd-b605-2617fa80a507,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-eea555f9-ad92-4cbe-9241-4c2e7b84d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-5024070d-25cc-491e-bb4a-94ae38e59eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-1f0674de-877e-4380-aada-fafe28900fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-1af59781-bbb1-4aa7-b285-93445a047db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-374122898-172.17.0.5-1597047176282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35385,DS-1ac75f46-e19f-4caf-af36-734e9b6cdd14,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-7e8dec85-abfe-422a-bc6e-4d5936220ace,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-9d18b247-93e8-4a94-99bc-300bde7e78d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-6062917a-77f4-4bfd-b605-2617fa80a507,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-eea555f9-ad92-4cbe-9241-4c2e7b84d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-5024070d-25cc-491e-bb4a-94ae38e59eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-1f0674de-877e-4380-aada-fafe28900fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-1af59781-bbb1-4aa7-b285-93445a047db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5257
