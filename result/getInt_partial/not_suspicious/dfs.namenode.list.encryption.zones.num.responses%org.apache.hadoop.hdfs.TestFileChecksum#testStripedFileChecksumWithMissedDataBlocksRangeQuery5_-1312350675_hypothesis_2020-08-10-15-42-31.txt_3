reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443741899-172.17.0.16-1597074540155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43185,DS-01337ea7-f10d-47bb-8a24-777a38cc3295,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-fd134fd2-b02c-4828-bfef-b283fdc971be,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-6c3ed61e-c7cc-4fe9-98f1-7b6337d4f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-0ae17eee-7f7e-4564-b368-9dfb9be4ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-8677cc06-90eb-47e9-87dc-c913e0a58740,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-36fae29f-a7ae-4b4e-82c7-483ddc1f3381,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-0c8603a2-0393-49c0-90e9-d7bf4ff609de,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-f0152791-4a78-4ffa-adf2-e5ff643ec9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443741899-172.17.0.16-1597074540155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43185,DS-01337ea7-f10d-47bb-8a24-777a38cc3295,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-fd134fd2-b02c-4828-bfef-b283fdc971be,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-6c3ed61e-c7cc-4fe9-98f1-7b6337d4f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-0ae17eee-7f7e-4564-b368-9dfb9be4ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-8677cc06-90eb-47e9-87dc-c913e0a58740,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-36fae29f-a7ae-4b4e-82c7-483ddc1f3381,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-0c8603a2-0393-49c0-90e9-d7bf4ff609de,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-f0152791-4a78-4ffa-adf2-e5ff643ec9f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567737617-172.17.0.16-1597074614869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46496,DS-4356cc18-b748-49d0-b9c1-1f2fbb215d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-bd1300a2-9553-4e85-a311-537db06c3ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-bdcc3787-265d-48f2-8fda-1bc1c49a5be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-a8008d85-dde1-4432-b31a-fa202cdedd13,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-1f8fecea-e3ce-4e2b-a406-401bd4d3fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-8b733f70-96ca-46ed-9a15-47ad9c897e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-1d043265-68b4-429e-89c9-b8ba1aabf097,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-f9c2ca41-bc2d-426e-816f-0507ba56e9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567737617-172.17.0.16-1597074614869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46496,DS-4356cc18-b748-49d0-b9c1-1f2fbb215d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-bd1300a2-9553-4e85-a311-537db06c3ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-bdcc3787-265d-48f2-8fda-1bc1c49a5be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-a8008d85-dde1-4432-b31a-fa202cdedd13,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-1f8fecea-e3ce-4e2b-a406-401bd4d3fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-8b733f70-96ca-46ed-9a15-47ad9c897e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-1d043265-68b4-429e-89c9-b8ba1aabf097,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-f9c2ca41-bc2d-426e-816f-0507ba56e9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864186814-172.17.0.16-1597075090904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-61c381fe-904f-47e3-b009-e489d81a6811,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-664257f2-8341-417b-bf40-77f213beddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-875e8088-7571-4b3b-9ca5-82df96942cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-7b5f243e-486e-4818-a958-761a787315ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-b914a055-7e19-42d6-91cd-fcdc49815b80,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-2a997556-d239-45ae-8294-2cb2d0245be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-636823ee-c4c5-46db-acc5-84edc79e7364,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-b583036b-2b67-407f-9cf2-497135c8c3d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-864186814-172.17.0.16-1597075090904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-61c381fe-904f-47e3-b009-e489d81a6811,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-664257f2-8341-417b-bf40-77f213beddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-875e8088-7571-4b3b-9ca5-82df96942cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-7b5f243e-486e-4818-a958-761a787315ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-b914a055-7e19-42d6-91cd-fcdc49815b80,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-2a997556-d239-45ae-8294-2cb2d0245be2,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-636823ee-c4c5-46db-acc5-84edc79e7364,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-b583036b-2b67-407f-9cf2-497135c8c3d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857095064-172.17.0.16-1597075418142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42925,DS-5d5cadb1-4cbb-468e-aeca-fc3389a30a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-f13c0a48-291d-4ca3-a54a-d439736ac328,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-da8cd4f1-a4ca-47f6-8e54-14928ce7ec06,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-a7fda367-f75f-4ddf-947c-0ffd16ca803d,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-b0bf0433-63a2-4b71-875f-816c02e08b02,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-220b4511-fa71-4f7b-8f9f-08c3d5fee4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-11d73668-7723-46d7-bcfe-dfd2f1692618,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-e3b75d9f-76c2-442b-896f-9fc5acc28893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857095064-172.17.0.16-1597075418142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42925,DS-5d5cadb1-4cbb-468e-aeca-fc3389a30a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43425,DS-f13c0a48-291d-4ca3-a54a-d439736ac328,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-da8cd4f1-a4ca-47f6-8e54-14928ce7ec06,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-a7fda367-f75f-4ddf-947c-0ffd16ca803d,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-b0bf0433-63a2-4b71-875f-816c02e08b02,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-220b4511-fa71-4f7b-8f9f-08c3d5fee4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-11d73668-7723-46d7-bcfe-dfd2f1692618,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-e3b75d9f-76c2-442b-896f-9fc5acc28893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747526283-172.17.0.16-1597075476868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-167d08a4-03b3-42a3-9bcd-961dfb1b73a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-c68acad5-a6ce-400f-beb2-c64b47b6a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-c1d654e7-f9ac-484d-991a-295608f0ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-0da71899-2b26-4c53-944a-0b704ebd9b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-1a009ed5-8ed1-4521-bbf6-12daf62e30b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-5a481d2b-1b8e-48fb-b9b4-1df70c037bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-c84cfca7-d381-4036-ab9f-7e9729f23621,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-f84aeb7a-2195-47fd-a9fe-afb6a9bd5e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747526283-172.17.0.16-1597075476868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33073,DS-167d08a4-03b3-42a3-9bcd-961dfb1b73a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-c68acad5-a6ce-400f-beb2-c64b47b6a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:35828,DS-c1d654e7-f9ac-484d-991a-295608f0ac21,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-0da71899-2b26-4c53-944a-0b704ebd9b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-1a009ed5-8ed1-4521-bbf6-12daf62e30b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-5a481d2b-1b8e-48fb-b9b4-1df70c037bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-c84cfca7-d381-4036-ab9f-7e9729f23621,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-f84aeb7a-2195-47fd-a9fe-afb6a9bd5e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596867263-172.17.0.16-1597075816589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-1e2fe1cd-41a1-4a0e-93b8-51f34bd2a7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-0b344a70-16ba-436f-a954-6a66be27a695,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-16625d9c-33ab-4ced-9c00-042f6bd62f25,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-903293f4-40a9-44b0-b824-c7c19dc75b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-4a7f3bc9-bdcb-470c-91c8-0b82e376dff6,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-5b2776df-5cb2-47f0-a7f5-2da0dcb07c18,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-41ff476e-1fc3-49f6-82b8-13ffab7597cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-2cda8427-e8c1-4f4b-9c20-c96ed63cfe10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-596867263-172.17.0.16-1597075816589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-1e2fe1cd-41a1-4a0e-93b8-51f34bd2a7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-0b344a70-16ba-436f-a954-6a66be27a695,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-16625d9c-33ab-4ced-9c00-042f6bd62f25,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-903293f4-40a9-44b0-b824-c7c19dc75b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-4a7f3bc9-bdcb-470c-91c8-0b82e376dff6,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-5b2776df-5cb2-47f0-a7f5-2da0dcb07c18,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-41ff476e-1fc3-49f6-82b8-13ffab7597cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-2cda8427-e8c1-4f4b-9c20-c96ed63cfe10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681749696-172.17.0.16-1597077553820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-ae86763a-cd57-4403-8f9c-a87ed232dc47,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-62abe137-9ac6-4d19-bd0b-afabf9a484c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-650e5dea-d128-40c0-b868-e79271a39d33,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-fad7c5d7-4b7a-4d2d-82e8-e024750e27c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-928b7d2c-f1ce-4bf6-bda2-83a9c0161947,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-edf150ac-6e7b-4378-af80-e4221b27d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-c16b55cf-c4a2-4e34-9f7d-d9fdf68f4772,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-594e396b-9216-4349-88d2-de08143b0396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681749696-172.17.0.16-1597077553820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-ae86763a-cd57-4403-8f9c-a87ed232dc47,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-62abe137-9ac6-4d19-bd0b-afabf9a484c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-650e5dea-d128-40c0-b868-e79271a39d33,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-fad7c5d7-4b7a-4d2d-82e8-e024750e27c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-928b7d2c-f1ce-4bf6-bda2-83a9c0161947,DISK], DatanodeInfoWithStorage[127.0.0.1:44927,DS-edf150ac-6e7b-4378-af80-e4221b27d0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-c16b55cf-c4a2-4e34-9f7d-d9fdf68f4772,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-594e396b-9216-4349-88d2-de08143b0396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701153097-172.17.0.16-1597077773633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-ef663d17-e5b3-4b7e-ae47-3b0e5e60284a,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-c55039fd-736d-4478-b48d-0bebf789cefc,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-b138302d-bae2-4a7a-b236-18200255a562,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-6595f66a-00c0-4d04-a239-71ed9aa013ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-db4de517-bdf9-4c9d-b454-9a2874e22652,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-6d7d568d-12c4-4bde-8399-a92082eeff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-f222d856-b424-42e3-8fdc-1a33241d460e,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-60dae259-8307-458b-9325-2eb4934775e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1701153097-172.17.0.16-1597077773633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-ef663d17-e5b3-4b7e-ae47-3b0e5e60284a,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-c55039fd-736d-4478-b48d-0bebf789cefc,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-b138302d-bae2-4a7a-b236-18200255a562,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-6595f66a-00c0-4d04-a239-71ed9aa013ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46518,DS-db4de517-bdf9-4c9d-b454-9a2874e22652,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-6d7d568d-12c4-4bde-8399-a92082eeff9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34495,DS-f222d856-b424-42e3-8fdc-1a33241d460e,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-60dae259-8307-458b-9325-2eb4934775e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924603233-172.17.0.16-1597078143861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41728,DS-a47b3b9e-5804-4e37-a916-4e4150922347,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-da7518b5-1f96-4b2d-a842-c378c6269abc,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-cd3c7a0e-119e-4f45-a91c-9c4c7be512d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-97e70fc8-c107-4538-88d0-7bdfbf78201e,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-f0fcd9e2-60cf-4413-b554-946bb1ef7b98,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-ecd3266a-352f-4dc9-a7d5-7d6afa9ec42a,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-ef6634ea-69b3-4509-81fe-1ed22cd901cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-42fe811f-7f13-4752-810b-6012dacea574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924603233-172.17.0.16-1597078143861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41728,DS-a47b3b9e-5804-4e37-a916-4e4150922347,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-da7518b5-1f96-4b2d-a842-c378c6269abc,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-cd3c7a0e-119e-4f45-a91c-9c4c7be512d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-97e70fc8-c107-4538-88d0-7bdfbf78201e,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-f0fcd9e2-60cf-4413-b554-946bb1ef7b98,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-ecd3266a-352f-4dc9-a7d5-7d6afa9ec42a,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-ef6634ea-69b3-4509-81fe-1ed22cd901cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-42fe811f-7f13-4752-810b-6012dacea574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100550105-172.17.0.16-1597078518557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44189,DS-378998eb-f9aa-48a6-a38b-c33d74a9720c,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-29ab49c8-f544-4c8c-ad48-e5ca544f3f74,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-e798f8a2-a77d-4ae1-9ed1-457909de960f,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-9ac246e9-d05b-4d24-b389-e75a6d1efbad,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-40e4704e-b32a-41b7-9ba7-00894d749961,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-6a48ca52-3398-400f-8a9b-e3ba5aef0e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-c6d651e2-c8ab-4970-900f-ae32f640ac8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-0fa1ce43-c5b0-4649-9f37-df282996be25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100550105-172.17.0.16-1597078518557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44189,DS-378998eb-f9aa-48a6-a38b-c33d74a9720c,DISK], DatanodeInfoWithStorage[127.0.0.1:39235,DS-29ab49c8-f544-4c8c-ad48-e5ca544f3f74,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-e798f8a2-a77d-4ae1-9ed1-457909de960f,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-9ac246e9-d05b-4d24-b389-e75a6d1efbad,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-40e4704e-b32a-41b7-9ba7-00894d749961,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-6a48ca52-3398-400f-8a9b-e3ba5aef0e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-c6d651e2-c8ab-4970-900f-ae32f640ac8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-0fa1ce43-c5b0-4649-9f37-df282996be25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453328449-172.17.0.16-1597078554884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44335,DS-d02c2d08-f636-4fe1-9c4e-d4f998117e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-1f90c57f-1578-4ba2-8ea0-340dfdc29c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-b0b309ed-c7d7-428c-818d-8b193c52e424,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-163c6702-5864-4d4d-a3b6-5b07cd5a8853,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-a7a71493-2117-4425-a37d-c8d581504343,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-9705fc48-337b-46c1-80db-39f9d4ddb4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-d524cff3-5bb5-4613-ad4e-07f9e14ba3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-2d0250d9-b0eb-4115-b6a5-234ac373a65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453328449-172.17.0.16-1597078554884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44335,DS-d02c2d08-f636-4fe1-9c4e-d4f998117e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-1f90c57f-1578-4ba2-8ea0-340dfdc29c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39001,DS-b0b309ed-c7d7-428c-818d-8b193c52e424,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-163c6702-5864-4d4d-a3b6-5b07cd5a8853,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-a7a71493-2117-4425-a37d-c8d581504343,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-9705fc48-337b-46c1-80db-39f9d4ddb4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-d524cff3-5bb5-4613-ad4e-07f9e14ba3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-2d0250d9-b0eb-4115-b6a5-234ac373a65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257547629-172.17.0.16-1597079528999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46611,DS-c716b229-69b6-435b-be49-f97efd3259f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-73334f0c-6aba-45c3-9487-3eeb6a00b2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-eb231a04-22e1-458d-9293-c7c7f8066d52,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-651f6dca-49a1-4796-9273-584e80b3c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-541bdf3c-70f2-473a-a9f5-e79d8278a2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-cd8cc6c7-88a4-4fad-b044-59e8c9c5fe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-d137705a-0775-4cc0-a9b4-298a774673c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-9e8794c5-123f-40c6-8b77-44e57376c8f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257547629-172.17.0.16-1597079528999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46611,DS-c716b229-69b6-435b-be49-f97efd3259f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-73334f0c-6aba-45c3-9487-3eeb6a00b2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-eb231a04-22e1-458d-9293-c7c7f8066d52,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-651f6dca-49a1-4796-9273-584e80b3c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-541bdf3c-70f2-473a-a9f5-e79d8278a2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-cd8cc6c7-88a4-4fad-b044-59e8c9c5fe7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-d137705a-0775-4cc0-a9b4-298a774673c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-9e8794c5-123f-40c6-8b77-44e57376c8f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.encryption.zones.num.responses
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293221064-172.17.0.16-1597079565903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-ba347186-8b82-4abb-bd62-a191788293ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-237ac7c0-eb1f-4720-adc1-f06dbdbe3a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-b673693a-7282-4e70-8752-be21d9f1e5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-6da8bcb8-1d54-4d73-9e94-6483f09e6e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-42420722-0885-4ac8-bc72-af38292c459d,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-a72a8915-e4ac-457c-9ccc-4fe063b5d0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-91a9340d-920e-40cb-901f-2fa11a0cc956,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-c2a72018-22fe-4a63-b897-ab58c1e39f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293221064-172.17.0.16-1597079565903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40552,DS-ba347186-8b82-4abb-bd62-a191788293ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-237ac7c0-eb1f-4720-adc1-f06dbdbe3a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-b673693a-7282-4e70-8752-be21d9f1e5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-6da8bcb8-1d54-4d73-9e94-6483f09e6e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-42420722-0885-4ac8-bc72-af38292c459d,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-a72a8915-e4ac-457c-9ccc-4fe063b5d0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-91a9340d-920e-40cb-901f-2fa11a0cc956,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-c2a72018-22fe-4a63-b897-ab58c1e39f63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5432
