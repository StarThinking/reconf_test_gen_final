reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875794459-172.17.0.9-1597108724358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-4ea96fca-a9fd-44aa-a9eb-112e540a1313,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-fd10811a-a749-447a-8bcb-50a202f7693c,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-b3555b24-d6dc-4226-9b28-6acaa84ef1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-43fdb9a4-78e9-4a9d-8ae5-a665cefa2653,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-5602b652-2629-43b7-8fa6-71f9f74e40c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-87899b97-30cb-4087-a8f8-c9a95c242c55,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-5c57050c-2104-4024-822f-c55afbc9bb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-63de91ea-e53a-4f98-ad76-4a580d41b69a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875794459-172.17.0.9-1597108724358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43776,DS-4ea96fca-a9fd-44aa-a9eb-112e540a1313,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-fd10811a-a749-447a-8bcb-50a202f7693c,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-b3555b24-d6dc-4226-9b28-6acaa84ef1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-43fdb9a4-78e9-4a9d-8ae5-a665cefa2653,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-5602b652-2629-43b7-8fa6-71f9f74e40c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-87899b97-30cb-4087-a8f8-c9a95c242c55,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-5c57050c-2104-4024-822f-c55afbc9bb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-63de91ea-e53a-4f98-ad76-4a580d41b69a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193520349-172.17.0.9-1597108784162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-138fd571-57de-4462-8762-cf224d2316ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-124b61f7-3aa5-40f4-b53e-fcf7d71cfa11,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-2c55f179-54f5-4d1c-8661-21ac09342000,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-90afae19-548e-4126-b242-1a33911c0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-c5b97959-2ca7-4999-a6d0-4d1a3a1835d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-115bde6e-d026-4e4d-8fcb-7fb4e8336aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-9c21d576-b422-4035-aad0-ff698ea7af74,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-455263ac-e142-464a-9c03-e011f5ba7ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-193520349-172.17.0.9-1597108784162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-138fd571-57de-4462-8762-cf224d2316ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-124b61f7-3aa5-40f4-b53e-fcf7d71cfa11,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-2c55f179-54f5-4d1c-8661-21ac09342000,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-90afae19-548e-4126-b242-1a33911c0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-c5b97959-2ca7-4999-a6d0-4d1a3a1835d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-115bde6e-d026-4e4d-8fcb-7fb4e8336aae,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-9c21d576-b422-4035-aad0-ff698ea7af74,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-455263ac-e142-464a-9c03-e011f5ba7ffb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046810945-172.17.0.9-1597109252544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-6e19aae0-002c-42d6-a35e-249987268811,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-2dce1782-3d04-4fe7-81dd-2bb5245f263c,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-61d39a8b-2071-4859-aa76-3bf77bf12669,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-9b41e6dc-9b7f-4104-8a2c-a2a9b0e25181,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-5bbadda4-6447-4aa1-8f92-7e217a49888d,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-2a03050f-0e72-42e1-a962-93e902040c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-2e416bbb-9b81-46e9-a8fe-94906e3995eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-4c8e59c8-6a2c-4904-9e69-262334e4ae8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2046810945-172.17.0.9-1597109252544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-6e19aae0-002c-42d6-a35e-249987268811,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-2dce1782-3d04-4fe7-81dd-2bb5245f263c,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-61d39a8b-2071-4859-aa76-3bf77bf12669,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-9b41e6dc-9b7f-4104-8a2c-a2a9b0e25181,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-5bbadda4-6447-4aa1-8f92-7e217a49888d,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-2a03050f-0e72-42e1-a962-93e902040c21,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-2e416bbb-9b81-46e9-a8fe-94906e3995eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-4c8e59c8-6a2c-4904-9e69-262334e4ae8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590835118-172.17.0.9-1597109354523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-d8b06127-1e29-42e7-9c07-ca2e9be4bccb,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-de3d69f8-c517-4d85-a9aa-869edf010797,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-5d1e1594-dea2-4f24-bfd8-354facb6be9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-df12b372-7241-4ecf-b269-794bf53d769c,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-807ac91d-3fdd-48c0-a1de-9316c3b6d7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-49af9323-3af7-4a3a-8466-c925f7ee89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-3c49c574-ca45-4a08-a3b2-3fa46b6be215,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-ef975b4a-d545-4266-90f2-8396ea209ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590835118-172.17.0.9-1597109354523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42371,DS-d8b06127-1e29-42e7-9c07-ca2e9be4bccb,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-de3d69f8-c517-4d85-a9aa-869edf010797,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-5d1e1594-dea2-4f24-bfd8-354facb6be9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-df12b372-7241-4ecf-b269-794bf53d769c,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-807ac91d-3fdd-48c0-a1de-9316c3b6d7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-49af9323-3af7-4a3a-8466-c925f7ee89c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-3c49c574-ca45-4a08-a3b2-3fa46b6be215,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-ef975b4a-d545-4266-90f2-8396ea209ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266340828-172.17.0.9-1597109444661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43727,DS-253ff09e-2e0b-4323-9002-2604534a4bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-f1d2d6a5-b6d7-43b8-863c-3c4c185d52a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-ea50e86f-3e09-471b-9008-98db63bacc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-cfcd4e85-c355-4dc0-ab95-a5ad7fe2665b,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-d17c23cd-0788-4da3-b341-78b63a8ca1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0a266f15-e734-44b5-9998-3e0b9b10f454,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-99affad3-6a99-442b-8d50-6210bbfe84d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-8db1eab9-3056-4709-8649-9608b0b7cd71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266340828-172.17.0.9-1597109444661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43727,DS-253ff09e-2e0b-4323-9002-2604534a4bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-f1d2d6a5-b6d7-43b8-863c-3c4c185d52a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-ea50e86f-3e09-471b-9008-98db63bacc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-cfcd4e85-c355-4dc0-ab95-a5ad7fe2665b,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-d17c23cd-0788-4da3-b341-78b63a8ca1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-0a266f15-e734-44b5-9998-3e0b9b10f454,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-99affad3-6a99-442b-8d50-6210bbfe84d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-8db1eab9-3056-4709-8649-9608b0b7cd71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663977163-172.17.0.9-1597109537831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-1d5caccd-78a6-42c1-99ad-9bb8fc9857c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-d240f36e-022c-4271-8616-eedcd885f038,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-c9b31472-4011-4958-b234-18064eff1c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-06010aeb-c6f8-458f-863e-f5ff69fb6b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-ee4aecc2-5736-40d1-8dc1-63451c361934,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-5ae1150f-8a70-496b-9c4d-9f30c8511c67,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-9bb2e7cd-1f13-4eb3-b8a2-7c45467ada01,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-e4693d3a-2dc8-4d14-baf0-12e4deee2daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663977163-172.17.0.9-1597109537831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39770,DS-1d5caccd-78a6-42c1-99ad-9bb8fc9857c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33148,DS-d240f36e-022c-4271-8616-eedcd885f038,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-c9b31472-4011-4958-b234-18064eff1c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-06010aeb-c6f8-458f-863e-f5ff69fb6b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-ee4aecc2-5736-40d1-8dc1-63451c361934,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-5ae1150f-8a70-496b-9c4d-9f30c8511c67,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-9bb2e7cd-1f13-4eb3-b8a2-7c45467ada01,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-e4693d3a-2dc8-4d14-baf0-12e4deee2daf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097971092-172.17.0.9-1597109587035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35195,DS-7328dbc4-7679-433e-a898-0bcec4992743,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-394502e7-a800-46d7-8861-19f27b40c197,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-5845b661-86fc-4d0a-82ab-344a13d6f485,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-d4f74bd4-a058-4324-aec3-66411b247124,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-5352a67e-c432-45da-9fbd-7bcb622498ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-304a9037-f48a-482b-8952-dfc111469dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-444e4aa3-b8cb-4a0b-a655-696c7e5c9200,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-1e2f200b-6d53-4649-ba63-34165c8b9f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2097971092-172.17.0.9-1597109587035:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35195,DS-7328dbc4-7679-433e-a898-0bcec4992743,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-394502e7-a800-46d7-8861-19f27b40c197,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-5845b661-86fc-4d0a-82ab-344a13d6f485,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-d4f74bd4-a058-4324-aec3-66411b247124,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-5352a67e-c432-45da-9fbd-7bcb622498ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-304a9037-f48a-482b-8952-dfc111469dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-444e4aa3-b8cb-4a0b-a655-696c7e5c9200,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-1e2f200b-6d53-4649-ba63-34165c8b9f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317557037-172.17.0.9-1597109888946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36030,DS-fe8d01c6-6330-4bc6-aacf-ca10481c761d,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-d8b4f6f6-5631-490f-b6d4-415ab383f84d,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-d5023563-6781-41cf-9e63-3f37509d0b60,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-4099088e-0133-4dc9-927c-c61526c9101a,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-4fb00c87-781f-4441-aeac-61d7a96ce28a,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-c716208e-239a-412d-80b6-36372fec06f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-501c082a-7adb-4f2d-a288-3a730504f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-aa5256c8-7895-436a-9507-9a7bbc502c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1317557037-172.17.0.9-1597109888946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36030,DS-fe8d01c6-6330-4bc6-aacf-ca10481c761d,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-d8b4f6f6-5631-490f-b6d4-415ab383f84d,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-d5023563-6781-41cf-9e63-3f37509d0b60,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-4099088e-0133-4dc9-927c-c61526c9101a,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-4fb00c87-781f-4441-aeac-61d7a96ce28a,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-c716208e-239a-412d-80b6-36372fec06f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-501c082a-7adb-4f2d-a288-3a730504f98a,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-aa5256c8-7895-436a-9507-9a7bbc502c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202890320-172.17.0.9-1597110819670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38408,DS-2b746947-bd1e-4430-b1ec-f41c50a37edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-27451882-b381-4486-9cd8-570b383c9769,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-572250d9-4abe-46c1-bec3-c286e741d2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-61662553-a1dd-4b94-a5c5-71219567a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-7f7a38f1-690d-4713-9f8f-cc49fcd9b401,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-5393e6d0-70bd-447c-90da-0be8aaa7a379,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-f67b3ba5-534b-45ba-a00e-e32d2277ced5,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-9577490c-e5ca-4525-b6e0-af6dfde50eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1202890320-172.17.0.9-1597110819670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38408,DS-2b746947-bd1e-4430-b1ec-f41c50a37edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-27451882-b381-4486-9cd8-570b383c9769,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-572250d9-4abe-46c1-bec3-c286e741d2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-61662553-a1dd-4b94-a5c5-71219567a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-7f7a38f1-690d-4713-9f8f-cc49fcd9b401,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-5393e6d0-70bd-447c-90da-0be8aaa7a379,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-f67b3ba5-534b-45ba-a00e-e32d2277ced5,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-9577490c-e5ca-4525-b6e0-af6dfde50eca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-399227957-172.17.0.9-1597111573456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-52e1b859-0e70-4636-86ac-4b2a35c9357d,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-955d19ac-b8ee-4467-b4d8-165bc5242ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-7477a068-829c-4fb9-b8b4-992c31b78335,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-b99ffbcd-d5c4-44dc-bbe6-663ab51fdf88,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-24c33691-63de-4ff7-93dd-2841fa9d43f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-2ca13aa4-5961-4dac-973c-83ab7bfd7def,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-2cf0f391-ed0c-4cfa-a49b-8c9f80b62bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-c9cfc08b-f62f-45e1-af6a-c015df66b09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-399227957-172.17.0.9-1597111573456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-52e1b859-0e70-4636-86ac-4b2a35c9357d,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-955d19ac-b8ee-4467-b4d8-165bc5242ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-7477a068-829c-4fb9-b8b4-992c31b78335,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-b99ffbcd-d5c4-44dc-bbe6-663ab51fdf88,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-24c33691-63de-4ff7-93dd-2841fa9d43f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-2ca13aa4-5961-4dac-973c-83ab7bfd7def,DISK], DatanodeInfoWithStorage[127.0.0.1:45523,DS-2cf0f391-ed0c-4cfa-a49b-8c9f80b62bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-c9cfc08b-f62f-45e1-af6a-c015df66b09f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473210033-172.17.0.9-1597111624948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-0a80fe30-aad9-49c9-ac8a-70b3617c99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-70a89b0d-1d24-4f60-b15e-a9bc662e6927,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-32dd90a2-058d-4487-bc83-bb1170d175cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-8bce6560-8281-40cd-934e-19f90f2cc179,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-2aa01ce5-6082-4b2a-b1f3-7d9633e9f499,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-d5c27a8f-fdd1-4e07-b970-eda9d701d371,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-1ec7b2ba-947f-4ef8-a7ba-b76e4ecc9fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-271bf875-a554-4ea9-83c1-a01aff384a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473210033-172.17.0.9-1597111624948:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36608,DS-0a80fe30-aad9-49c9-ac8a-70b3617c99c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-70a89b0d-1d24-4f60-b15e-a9bc662e6927,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-32dd90a2-058d-4487-bc83-bb1170d175cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-8bce6560-8281-40cd-934e-19f90f2cc179,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-2aa01ce5-6082-4b2a-b1f3-7d9633e9f499,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-d5c27a8f-fdd1-4e07-b970-eda9d701d371,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-1ec7b2ba-947f-4ef8-a7ba-b76e4ecc9fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36649,DS-271bf875-a554-4ea9-83c1-a01aff384a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857404820-172.17.0.9-1597111723891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37652,DS-0cc97c9a-606e-420f-9447-84faa801ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-eeaf1b13-701a-4e4c-a2ae-9949b6b2b7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-68af546e-94f3-49d2-b797-9767bed86c90,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-87bb1e78-00cc-41a1-acb1-09f7b2efb3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-9a16c21e-2519-4928-aeee-3f14745ba60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-3152d7be-b730-4ca6-99b5-471e1fee0b12,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-9984ae7b-3a7c-4017-8b38-d9df4b868eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-93856363-7723-4162-bb3a-e6bd7e42f6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-857404820-172.17.0.9-1597111723891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37652,DS-0cc97c9a-606e-420f-9447-84faa801ead9,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-eeaf1b13-701a-4e4c-a2ae-9949b6b2b7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-68af546e-94f3-49d2-b797-9767bed86c90,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-87bb1e78-00cc-41a1-acb1-09f7b2efb3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37930,DS-9a16c21e-2519-4928-aeee-3f14745ba60d,DISK], DatanodeInfoWithStorage[127.0.0.1:46618,DS-3152d7be-b730-4ca6-99b5-471e1fee0b12,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-9984ae7b-3a7c-4017-8b38-d9df4b868eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-93856363-7723-4162-bb3a-e6bd7e42f6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840780441-172.17.0.9-1597111868934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-57212cc0-cc3e-417e-8e48-775877398230,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-d425d5b7-a284-4dcb-ac91-995bea52563e,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-2965f7cd-9e75-4a5e-ac6d-55305945c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-266d2392-2df1-4a29-ac64-efac156074a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-c00c5675-0de1-4399-91be-706f53450515,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-d6cdcbbb-20da-4afa-bd48-648f7f0ce9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-1d05c2f7-4ed6-4356-b011-06cfa7210696,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-beec5ebf-8a7d-4b4a-9de1-80d15b1463f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840780441-172.17.0.9-1597111868934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35745,DS-57212cc0-cc3e-417e-8e48-775877398230,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-d425d5b7-a284-4dcb-ac91-995bea52563e,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-2965f7cd-9e75-4a5e-ac6d-55305945c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-266d2392-2df1-4a29-ac64-efac156074a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33303,DS-c00c5675-0de1-4399-91be-706f53450515,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-d6cdcbbb-20da-4afa-bd48-648f7f0ce9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-1d05c2f7-4ed6-4356-b011-06cfa7210696,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-beec5ebf-8a7d-4b4a-9de1-80d15b1463f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915000746-172.17.0.9-1597112220097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-4d845792-b881-4b15-80bd-ecf632eb5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-c7458cba-ce37-4ede-9c04-a4fff76c7639,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-224daf34-e15b-4409-aaa7-023d1f3a184e,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-39ab3c9f-f3d6-44f8-ad8f-e49f160e717e,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-2efeeae3-12d0-445e-9ea4-573b8f7640c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-3da264f1-0fc5-404d-9684-1d9e2c357007,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-eafe2cf8-c118-469c-963a-54c72cbdda83,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-118b63b2-41d4-4261-b441-37c183067741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915000746-172.17.0.9-1597112220097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34360,DS-4d845792-b881-4b15-80bd-ecf632eb5e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34273,DS-c7458cba-ce37-4ede-9c04-a4fff76c7639,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-224daf34-e15b-4409-aaa7-023d1f3a184e,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-39ab3c9f-f3d6-44f8-ad8f-e49f160e717e,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-2efeeae3-12d0-445e-9ea4-573b8f7640c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-3da264f1-0fc5-404d-9684-1d9e2c357007,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-eafe2cf8-c118-469c-963a-54c72cbdda83,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-118b63b2-41d4-4261-b441-37c183067741,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598979808-172.17.0.9-1597112656505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33552,DS-624ec337-f1e8-4ec1-9f24-750b1ac4f0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-f03cefc7-baee-4fab-b139-503b9e7c3aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-371b8719-b3c9-47a0-91dc-54ca67428314,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-af10c007-570f-41d6-83a1-1d8dc1464b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-7e94a13f-f013-481e-8e9c-e08730a6793f,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-c8196180-91a7-4a35-9cb9-56a68c3eae00,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-f2859a69-e687-4762-aec2-f8fc0b2f2558,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-8cdefdeb-5836-424d-acb6-b6871e77790c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-598979808-172.17.0.9-1597112656505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33552,DS-624ec337-f1e8-4ec1-9f24-750b1ac4f0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-f03cefc7-baee-4fab-b139-503b9e7c3aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-371b8719-b3c9-47a0-91dc-54ca67428314,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-af10c007-570f-41d6-83a1-1d8dc1464b48,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-7e94a13f-f013-481e-8e9c-e08730a6793f,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-c8196180-91a7-4a35-9cb9-56a68c3eae00,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-f2859a69-e687-4762-aec2-f8fc0b2f2558,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-8cdefdeb-5836-424d-acb6-b6871e77790c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676108506-172.17.0.9-1597112750235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44152,DS-95d73090-4503-4407-9f5c-cf3d9d6813a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-8e421dbf-316d-464e-a01d-93b1ca729f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-83d0cc08-50da-4a39-ba2f-51ba33997566,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-976e3822-1c19-46f8-b309-3765212e74b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-b8fbf48a-a18c-4f9e-8704-666942990568,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-fc03d1a8-cc4e-400a-a5dc-e871cc0bae39,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-93180c27-c3f4-40ca-b32d-ffff82c4b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-cc116a83-5f97-49e9-b029-de97ce162ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676108506-172.17.0.9-1597112750235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44152,DS-95d73090-4503-4407-9f5c-cf3d9d6813a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-8e421dbf-316d-464e-a01d-93b1ca729f20,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-83d0cc08-50da-4a39-ba2f-51ba33997566,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-976e3822-1c19-46f8-b309-3765212e74b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45440,DS-b8fbf48a-a18c-4f9e-8704-666942990568,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-fc03d1a8-cc4e-400a-a5dc-e871cc0bae39,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-93180c27-c3f4-40ca-b32d-ffff82c4b7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-cc116a83-5f97-49e9-b029-de97ce162ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044722986-172.17.0.9-1597113077824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-d3c04155-6837-4dd8-a361-2068d3924c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-5509e142-e5d5-49fa-a76e-287a8493241a,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-3fd1d26b-910d-4fa5-a248-31b6235ff7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-d3e992ad-c1ec-41a5-a10a-57420e8eb39d,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-e0686c6d-9dca-4df4-97da-f5d70c7048df,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-9692c4ab-6ba5-459c-ac7c-ba0c5b19d3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-6fc6ad4b-8a06-4833-aa69-186cc505617a,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-b2c7d261-a69d-46e8-aecf-35c53bb58ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044722986-172.17.0.9-1597113077824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-d3c04155-6837-4dd8-a361-2068d3924c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-5509e142-e5d5-49fa-a76e-287a8493241a,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-3fd1d26b-910d-4fa5-a248-31b6235ff7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41139,DS-d3e992ad-c1ec-41a5-a10a-57420e8eb39d,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-e0686c6d-9dca-4df4-97da-f5d70c7048df,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-9692c4ab-6ba5-459c-ac7c-ba0c5b19d3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34943,DS-6fc6ad4b-8a06-4833-aa69-186cc505617a,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-b2c7d261-a69d-46e8-aecf-35c53bb58ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223774370-172.17.0.9-1597113493939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-5e7a28ac-3713-4559-8b93-f2755d6e90e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-be4c2ac0-9f24-4a66-a643-6ab71e5f400a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-a1d08a7a-51b8-4d17-b12e-fa94466f8b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-2dcbd082-740a-465c-babc-652b3aa8f3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-0c3ae7be-96f2-4931-8ddd-0f802f4ab759,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-956ef6e1-0725-43e8-9855-cfc0af35e4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-8caab89b-e8e7-4000-8b24-9bf86f408653,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-ec1699d1-26b2-43f1-98b1-b41bff7107d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223774370-172.17.0.9-1597113493939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46231,DS-5e7a28ac-3713-4559-8b93-f2755d6e90e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-be4c2ac0-9f24-4a66-a643-6ab71e5f400a,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-a1d08a7a-51b8-4d17-b12e-fa94466f8b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-2dcbd082-740a-465c-babc-652b3aa8f3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-0c3ae7be-96f2-4931-8ddd-0f802f4ab759,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-956ef6e1-0725-43e8-9855-cfc0af35e4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-8caab89b-e8e7-4000-8b24-9bf86f408653,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-ec1699d1-26b2-43f1-98b1-b41bff7107d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310066850-172.17.0.9-1597113546404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-97ddd66d-7136-4655-9804-2c886764fe41,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-96b650d6-7341-4e55-a46d-e5e43111b51d,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-d8d2030a-89b8-4fcb-90f2-b3aa0043bb11,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-2c65a7e8-ea45-4b25-b92e-f91e2e944dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-4e986fe2-bb86-4c78-a45a-7ab6038562a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-43ab1933-fb95-4a6d-a126-2ebe98bf6a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-799a05a8-224d-4816-b378-8370154be01d,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-830e3eac-36a2-4880-a494-d3f951779c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1310066850-172.17.0.9-1597113546404:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-97ddd66d-7136-4655-9804-2c886764fe41,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-96b650d6-7341-4e55-a46d-e5e43111b51d,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-d8d2030a-89b8-4fcb-90f2-b3aa0043bb11,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-2c65a7e8-ea45-4b25-b92e-f91e2e944dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-4e986fe2-bb86-4c78-a45a-7ab6038562a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-43ab1933-fb95-4a6d-a126-2ebe98bf6a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-799a05a8-224d-4816-b378-8370154be01d,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-830e3eac-36a2-4880-a494-d3f951779c7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030149089-172.17.0.9-1597113865364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46210,DS-1d8b6eaf-0640-41c6-80b2-69c8c679d272,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-31d9e755-8052-4c63-bf25-73b6337c02ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-8987cf68-48c4-4b63-8a94-0687316a71ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-fb15daba-3184-4621-95e3-e94ba9b3e9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-589247f9-b0b5-4049-816c-a71a63f4da26,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-f964a984-9da5-4398-a1a8-73df860ddafd,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-cc7151e0-a92a-49bc-8270-6fe23c0ef753,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-5b312479-1bcc-4d4d-a05a-731aa6fd644b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1030149089-172.17.0.9-1597113865364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46210,DS-1d8b6eaf-0640-41c6-80b2-69c8c679d272,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-31d9e755-8052-4c63-bf25-73b6337c02ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-8987cf68-48c4-4b63-8a94-0687316a71ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-fb15daba-3184-4621-95e3-e94ba9b3e9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-589247f9-b0b5-4049-816c-a71a63f4da26,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-f964a984-9da5-4398-a1a8-73df860ddafd,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-cc7151e0-a92a-49bc-8270-6fe23c0ef753,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-5b312479-1bcc-4d4d-a05a-731aa6fd644b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057090075-172.17.0.9-1597114100575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33046,DS-1ad743e9-7b55-4afb-9aef-3b35dd73faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-06024ded-8246-4df6-bb91-dfa159be02b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-9463f9e0-7930-4da2-a3b2-93a19c8a7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-dd0e592a-6385-490a-8818-194620c03aef,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-72c7074c-7f2a-427c-921f-53f240c604dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-53796174-d202-4581-ae9e-59e433db8b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-961eac78-4e5e-497b-a5d1-d577578b6829,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-26ff1817-5dab-430b-90d2-0a9a4012e0dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2057090075-172.17.0.9-1597114100575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33046,DS-1ad743e9-7b55-4afb-9aef-3b35dd73faf6,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-06024ded-8246-4df6-bb91-dfa159be02b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-9463f9e0-7930-4da2-a3b2-93a19c8a7b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-dd0e592a-6385-490a-8818-194620c03aef,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-72c7074c-7f2a-427c-921f-53f240c604dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-53796174-d202-4581-ae9e-59e433db8b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-961eac78-4e5e-497b-a5d1-d577578b6829,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-26ff1817-5dab-430b-90d2-0a9a4012e0dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696074613-172.17.0.9-1597114283437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33231,DS-bd349182-e1ce-4d01-8f2a-114b4ae53da0,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-4616f9a0-c749-4de3-b0bb-fc6b63936edd,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-30306231-4939-48d4-bfa6-e2b1634d7927,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-5c7b0162-6f41-40f0-8505-21476500bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-8c55314f-6df1-4c76-92d7-0f4afbd3601b,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-b1450640-a3f5-4195-9a3a-6fec8edc3be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-fc83cbbf-8031-4764-88f8-3a0f86ea342e,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-7addbe82-276e-4c0a-9fbf-b811d9cc0091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696074613-172.17.0.9-1597114283437:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33231,DS-bd349182-e1ce-4d01-8f2a-114b4ae53da0,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-4616f9a0-c749-4de3-b0bb-fc6b63936edd,DISK], DatanodeInfoWithStorage[127.0.0.1:38978,DS-30306231-4939-48d4-bfa6-e2b1634d7927,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-5c7b0162-6f41-40f0-8505-21476500bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46725,DS-8c55314f-6df1-4c76-92d7-0f4afbd3601b,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-b1450640-a3f5-4195-9a3a-6fec8edc3be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-fc83cbbf-8031-4764-88f8-3a0f86ea342e,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-7addbe82-276e-4c0a-9fbf-b811d9cc0091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022929179-172.17.0.9-1597114568910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-1e9f776b-c736-4f2b-89c2-db9036da471c,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-85c2bb9d-9659-43a6-bf86-24bd1a65feb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-98dada41-db5b-4dec-9d55-042ba266c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-53989425-691c-49da-bf2b-5cf75f355810,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-6e086059-20cb-4963-9062-f0920049a577,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c8fde9bd-cc06-423f-9864-6b2343a260b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-43ddce45-3f60-4b57-8d30-b3a8dcbc9adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-cec95497-29eb-44b7-95a8-ec874aa40058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1022929179-172.17.0.9-1597114568910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39322,DS-1e9f776b-c736-4f2b-89c2-db9036da471c,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-85c2bb9d-9659-43a6-bf86-24bd1a65feb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-98dada41-db5b-4dec-9d55-042ba266c1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-53989425-691c-49da-bf2b-5cf75f355810,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-6e086059-20cb-4963-9062-f0920049a577,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c8fde9bd-cc06-423f-9864-6b2343a260b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-43ddce45-3f60-4b57-8d30-b3a8dcbc9adc,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-cec95497-29eb-44b7-95a8-ec874aa40058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787477510-172.17.0.9-1597114707499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34870,DS-afca6827-27ea-4a4b-852d-d618036ceab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-afca6333-adcf-4386-9d59-8389155a6673,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-38a0e7c7-08d5-41cc-ab15-4257a6391ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-a3c2c9e4-6061-48e5-9679-27c9739016f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-9d50e1c2-f802-447d-8893-59c712cfe609,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-87b99538-90d9-4b9d-8f2b-9432664b0126,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-5981e094-6dcc-43c6-9920-5be09cf7de4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-3d6c4431-e240-4e74-9faa-266511b3c578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787477510-172.17.0.9-1597114707499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34870,DS-afca6827-27ea-4a4b-852d-d618036ceab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-afca6333-adcf-4386-9d59-8389155a6673,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-38a0e7c7-08d5-41cc-ab15-4257a6391ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:37263,DS-a3c2c9e4-6061-48e5-9679-27c9739016f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-9d50e1c2-f802-447d-8893-59c712cfe609,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-87b99538-90d9-4b9d-8f2b-9432664b0126,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-5981e094-6dcc-43c6-9920-5be09cf7de4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-3d6c4431-e240-4e74-9faa-266511b3c578,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.fileio.profiling.sampling.percentage
component: hdfs:DataNode
v1: 1
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722250582-172.17.0.9-1597115766894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-15ce0756-174c-42fc-b6c3-be31f8cbc87a,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-c5ef46ff-345c-4807-b7f0-1a88d3aff51d,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-a85fb602-76c5-4b43-9c29-f790ee5f0812,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-b6a40d02-ca94-4d67-99fe-0eeec380b225,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-1c3402d5-1f68-44af-a1db-ff4463036ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-6a3396ee-1ffc-4fef-859e-6d6c0a7f00d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-463a2759-39b6-4a5b-99b1-d2a3b687fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-48f87ec8-03e5-40ed-a659-4d68a56a4477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722250582-172.17.0.9-1597115766894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-15ce0756-174c-42fc-b6c3-be31f8cbc87a,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-c5ef46ff-345c-4807-b7f0-1a88d3aff51d,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-a85fb602-76c5-4b43-9c29-f790ee5f0812,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-b6a40d02-ca94-4d67-99fe-0eeec380b225,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-1c3402d5-1f68-44af-a1db-ff4463036ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-6a3396ee-1ffc-4fef-859e-6d6c0a7f00d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-463a2759-39b6-4a5b-99b1-d2a3b687fb36,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-48f87ec8-03e5-40ed-a659-4d68a56a4477,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 7088
