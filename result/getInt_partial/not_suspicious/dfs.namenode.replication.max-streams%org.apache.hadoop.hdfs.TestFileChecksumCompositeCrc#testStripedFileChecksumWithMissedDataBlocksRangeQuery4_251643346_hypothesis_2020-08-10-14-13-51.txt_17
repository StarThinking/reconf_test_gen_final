reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926629973-172.17.0.9-1597069174047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-b090b3c3-748d-4c20-95f8-cbaf3d65cc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-817be046-b8d5-42c4-87f2-460b3982a7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-6774eeb1-0e4a-4991-8ce7-2aaed2019f45,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-c12be17a-8c09-447e-8930-0de680801c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-99bce58d-d39f-41ee-9402-78f99e4ce5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-54c5e163-3a9f-403b-ba8e-1965ac25a45f,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-5d2fdd36-419e-4337-9bc7-7678e418df55,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-328f93fa-6413-471b-be1f-2417445d1957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1926629973-172.17.0.9-1597069174047:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43265,DS-b090b3c3-748d-4c20-95f8-cbaf3d65cc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-817be046-b8d5-42c4-87f2-460b3982a7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-6774eeb1-0e4a-4991-8ce7-2aaed2019f45,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-c12be17a-8c09-447e-8930-0de680801c69,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-99bce58d-d39f-41ee-9402-78f99e4ce5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-54c5e163-3a9f-403b-ba8e-1965ac25a45f,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-5d2fdd36-419e-4337-9bc7-7678e418df55,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-328f93fa-6413-471b-be1f-2417445d1957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257642806-172.17.0.9-1597069275793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36569,DS-0fe83fea-cf3d-4b78-bf56-d3c3120f71b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-e427686c-8818-4e12-a051-828848dd7d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-8f1f165b-3dcf-4eb0-b353-eabd1981da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-9bc57596-bc85-4c43-974e-d3dde007f740,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-4108ee85-2201-4778-9553-b191a304b07a,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-404de672-9601-49b7-88e7-3d677484c013,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-80d2ae7a-8b18-452a-9df7-e01a2b9d9ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-c595222f-a20e-40df-8863-0595ac0369c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257642806-172.17.0.9-1597069275793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36569,DS-0fe83fea-cf3d-4b78-bf56-d3c3120f71b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-e427686c-8818-4e12-a051-828848dd7d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-8f1f165b-3dcf-4eb0-b353-eabd1981da1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-9bc57596-bc85-4c43-974e-d3dde007f740,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-4108ee85-2201-4778-9553-b191a304b07a,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-404de672-9601-49b7-88e7-3d677484c013,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-80d2ae7a-8b18-452a-9df7-e01a2b9d9ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-c595222f-a20e-40df-8863-0595ac0369c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975382966-172.17.0.9-1597069715834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-3198f812-86fe-4dc4-88c1-180afa3d660a,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-cf4cf592-e5be-4488-9369-a1aa42892886,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-2fcd6a99-b09d-4b3a-8e12-0f801b38a08f,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-419d7774-4a7b-4eaf-824d-8ee48bc421cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-9ce5f39a-7963-448e-8a84-0a34e5b02a80,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-a9dac83f-9ec2-4495-8aea-09ecee8337e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-0325d4ac-0559-43c3-87d6-a3fcf21ef650,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-d21f1a8a-750b-4221-ae24-db6b8ddff3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975382966-172.17.0.9-1597069715834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42730,DS-3198f812-86fe-4dc4-88c1-180afa3d660a,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-cf4cf592-e5be-4488-9369-a1aa42892886,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-2fcd6a99-b09d-4b3a-8e12-0f801b38a08f,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-419d7774-4a7b-4eaf-824d-8ee48bc421cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-9ce5f39a-7963-448e-8a84-0a34e5b02a80,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-a9dac83f-9ec2-4495-8aea-09ecee8337e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-0325d4ac-0559-43c3-87d6-a3fcf21ef650,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-d21f1a8a-750b-4221-ae24-db6b8ddff3e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678785923-172.17.0.9-1597070072814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-ed3ed3a4-314d-40a9-9b77-3256936159d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-66b2c25d-c00f-4ba8-97b3-234cb652b4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-94cc5d3d-6d3d-4cb4-b3d9-41ee15e028e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-8ac176f6-4155-4d8a-b5b7-e7136d827189,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-dbf17a43-12ec-4ae1-817d-496050db4fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-8c767cb6-211e-42a8-b676-656962338935,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-eee17d1a-8686-49d4-b416-c243f53f69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-950b600e-f319-4d2e-9904-7be990beddca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1678785923-172.17.0.9-1597070072814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-ed3ed3a4-314d-40a9-9b77-3256936159d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-66b2c25d-c00f-4ba8-97b3-234cb652b4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-94cc5d3d-6d3d-4cb4-b3d9-41ee15e028e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-8ac176f6-4155-4d8a-b5b7-e7136d827189,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-dbf17a43-12ec-4ae1-817d-496050db4fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-8c767cb6-211e-42a8-b676-656962338935,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-eee17d1a-8686-49d4-b416-c243f53f69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-950b600e-f319-4d2e-9904-7be990beddca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310504892-172.17.0.9-1597071309209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-355be72b-f9c3-43d4-bad6-e3c9760264f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-79587aec-bd37-4aeb-8b6b-7b39468bc4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-01e2d70e-948d-48f7-80a6-91cee6897499,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-e9be6876-804e-4f55-9757-1a4cda5a6be5,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-6fe20fdc-1b1a-4c24-a735-de4776e1eb30,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-739681fc-2abd-448c-9cba-d8e7b5496756,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-0dbc91a5-ec90-4c58-806e-d958894422a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-1b9090cb-8de2-4199-9df4-d626004791e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310504892-172.17.0.9-1597071309209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-355be72b-f9c3-43d4-bad6-e3c9760264f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-79587aec-bd37-4aeb-8b6b-7b39468bc4bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-01e2d70e-948d-48f7-80a6-91cee6897499,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-e9be6876-804e-4f55-9757-1a4cda5a6be5,DISK], DatanodeInfoWithStorage[127.0.0.1:43675,DS-6fe20fdc-1b1a-4c24-a735-de4776e1eb30,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-739681fc-2abd-448c-9cba-d8e7b5496756,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-0dbc91a5-ec90-4c58-806e-d958894422a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-1b9090cb-8de2-4199-9df4-d626004791e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526388095-172.17.0.9-1597072054440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40949,DS-1266f850-e5cb-4cf7-a345-9e3979b74959,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-57824141-4c1c-4ace-b16d-e1ab0afe75f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-15daac25-9b84-4ded-b230-8b157f155e60,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-738b395f-e606-436d-9517-02915c600181,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-5142f0c2-9667-417f-8093-0654ecbeef39,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-16516c38-2082-41da-a9bb-b29fda7da4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-231b0065-bf3f-4a18-aace-634c7e3c081c,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-a2a80ed8-1aec-415b-8f8c-b4051c5be72d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-526388095-172.17.0.9-1597072054440:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40949,DS-1266f850-e5cb-4cf7-a345-9e3979b74959,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-57824141-4c1c-4ace-b16d-e1ab0afe75f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-15daac25-9b84-4ded-b230-8b157f155e60,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-738b395f-e606-436d-9517-02915c600181,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-5142f0c2-9667-417f-8093-0654ecbeef39,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-16516c38-2082-41da-a9bb-b29fda7da4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-231b0065-bf3f-4a18-aace-634c7e3c081c,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-a2a80ed8-1aec-415b-8f8c-b4051c5be72d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570729791-172.17.0.9-1597072255031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35246,DS-66d2452f-a0d1-42a1-ae0b-f4db45b18777,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-58277dec-bf95-4e99-980d-f95103b18355,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-b0aa70a2-d86e-49d7-9b7b-f1e7ab8abe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-1f601181-f839-46d1-b72e-5dc8ed8ee29e,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-a228b66f-4c89-43ec-8fbf-cc570f209ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-029b1538-967f-46fa-8710-07e4e0ecd30c,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-34841c78-dc82-43f0-9bd4-b20bd9140d11,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-c58ab247-bd1a-49fa-97c4-d30af7ae262f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570729791-172.17.0.9-1597072255031:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35246,DS-66d2452f-a0d1-42a1-ae0b-f4db45b18777,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-58277dec-bf95-4e99-980d-f95103b18355,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-b0aa70a2-d86e-49d7-9b7b-f1e7ab8abe3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-1f601181-f839-46d1-b72e-5dc8ed8ee29e,DISK], DatanodeInfoWithStorage[127.0.0.1:34586,DS-a228b66f-4c89-43ec-8fbf-cc570f209ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-029b1538-967f-46fa-8710-07e4e0ecd30c,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-34841c78-dc82-43f0-9bd4-b20bd9140d11,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-c58ab247-bd1a-49fa-97c4-d30af7ae262f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332359404-172.17.0.9-1597073229577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39915,DS-cb9bfabe-9dac-4176-9b25-270c9d7da7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-66aa44b8-15ea-4e31-a567-0f8a7a52d00b,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-6c5f7cd5-844e-490a-a556-9acd5d39e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-00543d97-865e-4a0d-aea2-39d6920cf50a,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-ee1d0304-c5b5-4180-920e-eb0bc285293b,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-69f51394-25c8-4c30-80b5-faa5d8e69d36,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-e6ecc6de-ed71-417f-bf91-eb6351e07125,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-7dc920f6-968e-4727-8e82-b0bf71e9d485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332359404-172.17.0.9-1597073229577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39915,DS-cb9bfabe-9dac-4176-9b25-270c9d7da7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-66aa44b8-15ea-4e31-a567-0f8a7a52d00b,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-6c5f7cd5-844e-490a-a556-9acd5d39e8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-00543d97-865e-4a0d-aea2-39d6920cf50a,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-ee1d0304-c5b5-4180-920e-eb0bc285293b,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-69f51394-25c8-4c30-80b5-faa5d8e69d36,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-e6ecc6de-ed71-417f-bf91-eb6351e07125,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-7dc920f6-968e-4727-8e82-b0bf71e9d485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.max-streams
component: hdfs:NameNode
v1: 0
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999316250-172.17.0.9-1597074168308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44111,DS-fc507cb5-060c-48d6-b782-aaab54491f77,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-afa2e306-a4fa-41de-9966-58ca54147dae,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-c35110e9-47b6-46e8-b289-700b619b1c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-025986b1-faee-4b4a-93c7-fb9625bc34b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-4c39b8d1-bbf8-4d14-bceb-063e7564dd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-961948fd-7e56-4650-a4f3-ed31d5e11c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-b0ebec12-7238-45bd-bafc-fc1c095e8f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-61abf7f2-4747-4113-bada-9101e71065db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999316250-172.17.0.9-1597074168308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44111,DS-fc507cb5-060c-48d6-b782-aaab54491f77,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-afa2e306-a4fa-41de-9966-58ca54147dae,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-c35110e9-47b6-46e8-b289-700b619b1c49,DISK], DatanodeInfoWithStorage[127.0.0.1:41188,DS-025986b1-faee-4b4a-93c7-fb9625bc34b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-4c39b8d1-bbf8-4d14-bceb-063e7564dd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-961948fd-7e56-4650-a4f3-ed31d5e11c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45356,DS-b0ebec12-7238-45bd-bafc-fc1c095e8f54,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-61abf7f2-4747-4113-bada-9101e71065db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 5823
