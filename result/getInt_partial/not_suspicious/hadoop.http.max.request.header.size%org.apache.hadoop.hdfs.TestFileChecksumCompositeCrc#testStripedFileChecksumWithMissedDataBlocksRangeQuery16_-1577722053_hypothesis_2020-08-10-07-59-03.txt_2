reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026211869-172.17.0.5-1597046728790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-dce35362-0ce2-4500-9009-af64a0fa5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-28b97a97-cce3-4e3c-ba2a-f80a1a54fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-f7125bba-e86f-480a-9d69-2b41975c80b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-cb33a7a1-85af-47db-984a-229d243cf9da,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-134d5d4f-6e0c-495c-ab6e-38278feb632a,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-86293578-232b-49a1-b6ec-aa357c599e67,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-001a93a2-3a45-4fe0-9437-628f88e5681b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-9ddaa881-b97b-4def-97d5-45d72c59199d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026211869-172.17.0.5-1597046728790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35656,DS-dce35362-0ce2-4500-9009-af64a0fa5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-28b97a97-cce3-4e3c-ba2a-f80a1a54fc09,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-f7125bba-e86f-480a-9d69-2b41975c80b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-cb33a7a1-85af-47db-984a-229d243cf9da,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-134d5d4f-6e0c-495c-ab6e-38278feb632a,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-86293578-232b-49a1-b6ec-aa357c599e67,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-001a93a2-3a45-4fe0-9437-628f88e5681b,DISK], DatanodeInfoWithStorage[127.0.0.1:41321,DS-9ddaa881-b97b-4def-97d5-45d72c59199d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539683897-172.17.0.5-1597047014744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-c05ad125-f432-4e2d-b951-233a77bff55d,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-0cb4e9ee-934d-480a-9f8d-71946ed2cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-b4aca68a-85a4-494a-ab97-836af88f607b,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-bc08a45c-73fe-4b42-99df-c0a6ede8bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-2ca03497-986e-4586-ba0b-04878b2c9af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-40724659-b0e6-4c6c-a841-c1b9dcad8cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-5dfebed8-840d-4b14-800a-12ff9ddac4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-7e1fd757-9dda-4682-8d0c-ac3fbf07014b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539683897-172.17.0.5-1597047014744:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-c05ad125-f432-4e2d-b951-233a77bff55d,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-0cb4e9ee-934d-480a-9f8d-71946ed2cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-b4aca68a-85a4-494a-ab97-836af88f607b,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-bc08a45c-73fe-4b42-99df-c0a6ede8bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-2ca03497-986e-4586-ba0b-04878b2c9af4,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-40724659-b0e6-4c6c-a841-c1b9dcad8cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-5dfebed8-840d-4b14-800a-12ff9ddac4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-7e1fd757-9dda-4682-8d0c-ac3fbf07014b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506429985-172.17.0.5-1597047435555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45156,DS-1518b395-2250-4922-96f0-aa1f46242229,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-ac1cdffc-58a4-4898-9f3b-f68b22f9703a,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-aeb5342d-3b97-4aaf-98c7-092a693aeda3,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-393eaf76-b45f-4c79-95bb-621a767b8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-9230d32e-d933-442b-bdef-39b8432a1381,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-8164d02f-8995-4617-9111-c084eeac7054,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-6503e2f6-8c69-49a1-be82-836e4795820b,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-fec6b5c1-f6ac-4295-8c9f-08fadd00fe3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1506429985-172.17.0.5-1597047435555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45156,DS-1518b395-2250-4922-96f0-aa1f46242229,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-ac1cdffc-58a4-4898-9f3b-f68b22f9703a,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-aeb5342d-3b97-4aaf-98c7-092a693aeda3,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-393eaf76-b45f-4c79-95bb-621a767b8bf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-9230d32e-d933-442b-bdef-39b8432a1381,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-8164d02f-8995-4617-9111-c084eeac7054,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-6503e2f6-8c69-49a1-be82-836e4795820b,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-fec6b5c1-f6ac-4295-8c9f-08fadd00fe3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842729506-172.17.0.5-1597047474106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45424,DS-130d4802-b5da-468f-9c8f-02fcc7ab6a46,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-17cdcd96-c8f8-4aeb-9a8c-1b2e5e0bfb85,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-601734ca-1651-4aba-a108-43a175a044ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-80e009cf-0b5d-4748-8f72-77a9ff0ba05e,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-add7a2e5-bbe5-43d5-9349-711aabade5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-5a0d1ac4-a7a2-4a79-ac59-1a0a9eb27f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-27a98897-a577-4cda-bbbc-90b0b126fde3,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-579e7118-d318-41ca-9e89-775f9ccdfcd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1842729506-172.17.0.5-1597047474106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45424,DS-130d4802-b5da-468f-9c8f-02fcc7ab6a46,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-17cdcd96-c8f8-4aeb-9a8c-1b2e5e0bfb85,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-601734ca-1651-4aba-a108-43a175a044ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-80e009cf-0b5d-4748-8f72-77a9ff0ba05e,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-add7a2e5-bbe5-43d5-9349-711aabade5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-5a0d1ac4-a7a2-4a79-ac59-1a0a9eb27f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44855,DS-27a98897-a577-4cda-bbbc-90b0b126fde3,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-579e7118-d318-41ca-9e89-775f9ccdfcd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387387851-172.17.0.5-1597047510164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33292,DS-a0201a5f-813d-4bb3-b9ec-08803a7a6045,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-1ec49d93-96e8-44fa-93e9-9b18b04e836a,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-0a8db67f-270e-4e06-901d-08bb7ad4c93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-af4a0fa2-3d00-423c-82d7-311d0ec2dbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-84c2504c-4ef0-43a1-a6d8-a2c4fe3bb1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-7fe0328c-cdc1-4b1e-8331-ddf60381c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-3856cc8b-fb3b-4632-a4d0-c6b1bfe7fce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-b92e5434-ff5e-4157-9321-4dc4c65ff6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387387851-172.17.0.5-1597047510164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33292,DS-a0201a5f-813d-4bb3-b9ec-08803a7a6045,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-1ec49d93-96e8-44fa-93e9-9b18b04e836a,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-0a8db67f-270e-4e06-901d-08bb7ad4c93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-af4a0fa2-3d00-423c-82d7-311d0ec2dbc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-84c2504c-4ef0-43a1-a6d8-a2c4fe3bb1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-7fe0328c-cdc1-4b1e-8331-ddf60381c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-3856cc8b-fb3b-4632-a4d0-c6b1bfe7fce9,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-b92e5434-ff5e-4157-9321-4dc4c65ff6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227030626-172.17.0.5-1597047615935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41290,DS-77a83bd9-b774-45bc-a5cd-ff268d086797,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-d94b551e-251e-415d-b70d-24866425ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-03df1490-9cd2-43eb-b99e-7199399db509,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-a0d6fb08-c3b6-4a47-ae75-a0b6b1aba80c,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-34f8c580-825c-4c89-894a-02c28541b1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-3ee0d40a-b97f-4a2e-8cd7-b878bf1ae6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-f74c9a07-4c91-429b-b8a3-cdc5eb69bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-8576dbb5-b453-458d-bdd1-5d5ac8ea8c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227030626-172.17.0.5-1597047615935:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41290,DS-77a83bd9-b774-45bc-a5cd-ff268d086797,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-d94b551e-251e-415d-b70d-24866425ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-03df1490-9cd2-43eb-b99e-7199399db509,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-a0d6fb08-c3b6-4a47-ae75-a0b6b1aba80c,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-34f8c580-825c-4c89-894a-02c28541b1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-3ee0d40a-b97f-4a2e-8cd7-b878bf1ae6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-f74c9a07-4c91-429b-b8a3-cdc5eb69bfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-8576dbb5-b453-458d-bdd1-5d5ac8ea8c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91066235-172.17.0.5-1597047794399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-271abde3-b862-4131-834c-d36cbcf338fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-7bc5b560-1396-4d45-ac4d-d709a664cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-c75a995d-84f6-4e01-809c-c7d94fdc769b,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-18a70f86-5d6d-4678-8241-62930e0bbfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-779ba44a-8c60-40d8-91f9-ca7729f96fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-98b6acf2-aa90-442c-a827-78a7157b522e,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-9229650f-5ea1-4ec4-b1d5-18f80eac771a,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-59a24994-915f-48ea-a954-e35c7bde216d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-91066235-172.17.0.5-1597047794399:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39343,DS-271abde3-b862-4131-834c-d36cbcf338fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-7bc5b560-1396-4d45-ac4d-d709a664cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45068,DS-c75a995d-84f6-4e01-809c-c7d94fdc769b,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-18a70f86-5d6d-4678-8241-62930e0bbfc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-779ba44a-8c60-40d8-91f9-ca7729f96fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-98b6acf2-aa90-442c-a827-78a7157b522e,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-9229650f-5ea1-4ec4-b1d5-18f80eac771a,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-59a24994-915f-48ea-a954-e35c7bde216d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612097287-172.17.0.5-1597048235143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34544,DS-90edad74-24a9-4b85-9222-118a02709127,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-71e3a927-7a8c-4555-883b-65566018c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-7beddfc5-3634-404c-8b1a-fa5b5a041fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-a096acfa-76b9-4f18-880b-ff91efb3451e,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-5d5862bd-811c-46aa-8bc2-6e5c1819dba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-ad044d19-69bf-4485-b771-2b1c20b4b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-e74744d1-6aed-4151-9bf0-fcc8bc518d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-3a3c2652-fc5f-4ca0-be74-31fd553735d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612097287-172.17.0.5-1597048235143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34544,DS-90edad74-24a9-4b85-9222-118a02709127,DISK], DatanodeInfoWithStorage[127.0.0.1:34244,DS-71e3a927-7a8c-4555-883b-65566018c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-7beddfc5-3634-404c-8b1a-fa5b5a041fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-a096acfa-76b9-4f18-880b-ff91efb3451e,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-5d5862bd-811c-46aa-8bc2-6e5c1819dba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-ad044d19-69bf-4485-b771-2b1c20b4b56c,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-e74744d1-6aed-4151-9bf0-fcc8bc518d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-3a3c2652-fc5f-4ca0-be74-31fd553735d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709299897-172.17.0.5-1597048316448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39633,DS-d1d98406-87c1-4e2d-9f19-3cdd73603349,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-2535b91b-48db-4a4b-baef-ecbec0bb4689,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-980ef2a8-8e80-4fb7-a87e-02b0789b3ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-1e330922-1e2d-4e09-bbcb-b19233d6b420,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-e480df45-7d85-43f3-ac9c-6882c04d53fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-6828fc4f-fd62-44db-b3a6-ce03c6232a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-66dc0905-502b-4d9d-bc07-b543e45deda8,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-4d156ede-915c-4867-b904-77e33dd1d04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709299897-172.17.0.5-1597048316448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39633,DS-d1d98406-87c1-4e2d-9f19-3cdd73603349,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-2535b91b-48db-4a4b-baef-ecbec0bb4689,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-980ef2a8-8e80-4fb7-a87e-02b0789b3ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-1e330922-1e2d-4e09-bbcb-b19233d6b420,DISK], DatanodeInfoWithStorage[127.0.0.1:41428,DS-e480df45-7d85-43f3-ac9c-6882c04d53fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-6828fc4f-fd62-44db-b3a6-ce03c6232a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-66dc0905-502b-4d9d-bc07-b543e45deda8,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-4d156ede-915c-4867-b904-77e33dd1d04f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831911815-172.17.0.5-1597048673130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-403c4629-e8ae-45b0-8f71-4714a2ec1655,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-840a8533-034a-4cd8-a965-88d4220d4132,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-4c56825d-e699-44ae-8a91-9a5eab36d21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-258cf5d6-06f8-4351-8423-94a92bc62d55,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-3c6362c3-ecb3-4d59-87b6-22064af27bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-7132e336-57b8-41ef-8b9d-edfc4e35187d,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-a9f8ec70-ddc1-428d-b554-d18a6b824668,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-28afc068-d541-4f42-929b-9ebdaf5e1f04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831911815-172.17.0.5-1597048673130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-403c4629-e8ae-45b0-8f71-4714a2ec1655,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-840a8533-034a-4cd8-a965-88d4220d4132,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-4c56825d-e699-44ae-8a91-9a5eab36d21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-258cf5d6-06f8-4351-8423-94a92bc62d55,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-3c6362c3-ecb3-4d59-87b6-22064af27bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-7132e336-57b8-41ef-8b9d-edfc4e35187d,DISK], DatanodeInfoWithStorage[127.0.0.1:42724,DS-a9f8ec70-ddc1-428d-b554-d18a6b824668,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-28afc068-d541-4f42-929b-9ebdaf5e1f04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356401860-172.17.0.5-1597049611565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-a9bedb95-48f8-4887-a25e-f64b0245c138,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-72bbd3fd-2233-4c6d-be03-a85055f06ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-4923f886-03ff-4bb1-9798-4cfd216bf688,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-7afbcf75-93b2-4ffe-b578-19c7dfd434d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-b5303a3f-ffc2-4f5f-97f4-964da9cb649b,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-1c6fc5bc-dc3b-4273-8205-77368710aacf,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-555ea44e-2eb2-4ef0-981b-3d0581becc33,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-b18bcc45-0d39-4d3f-b762-8c8be82dc83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356401860-172.17.0.5-1597049611565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42636,DS-a9bedb95-48f8-4887-a25e-f64b0245c138,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-72bbd3fd-2233-4c6d-be03-a85055f06ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-4923f886-03ff-4bb1-9798-4cfd216bf688,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-7afbcf75-93b2-4ffe-b578-19c7dfd434d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41071,DS-b5303a3f-ffc2-4f5f-97f4-964da9cb649b,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-1c6fc5bc-dc3b-4273-8205-77368710aacf,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-555ea44e-2eb2-4ef0-981b-3d0581becc33,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-b18bcc45-0d39-4d3f-b762-8c8be82dc83f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641862695-172.17.0.5-1597049756631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33584,DS-054eebcc-33cc-48d9-bc03-104fdd499761,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-60a6bac1-9bd0-4d9c-bc2c-6e669efe6303,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-061409f7-aa30-4f30-93e7-05df38f16fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-d4129883-57e7-49aa-9e69-ca516b49d46c,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-059ee6b5-7f2f-4c2e-ac95-01f3790cd7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-592986e6-5a69-4a31-8c8f-9042e77ba98d,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-edd262f4-4608-466f-ab2d-9671ef987a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-54f336dd-b0cd-4650-ac0a-dcbfa3f8138a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641862695-172.17.0.5-1597049756631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33584,DS-054eebcc-33cc-48d9-bc03-104fdd499761,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-60a6bac1-9bd0-4d9c-bc2c-6e669efe6303,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-061409f7-aa30-4f30-93e7-05df38f16fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-d4129883-57e7-49aa-9e69-ca516b49d46c,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-059ee6b5-7f2f-4c2e-ac95-01f3790cd7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-592986e6-5a69-4a31-8c8f-9042e77ba98d,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-edd262f4-4608-466f-ab2d-9671ef987a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-54f336dd-b0cd-4650-ac0a-dcbfa3f8138a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376792873-172.17.0.5-1597049859669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35907,DS-d67126ba-3050-4d48-8b4d-64bf4bca940f,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-d50aabfb-825e-4b77-b50c-e9a88fd6957c,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-a4acddaf-c9b1-4910-936e-d695995ace78,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-5e89715c-0c3f-43ee-afb9-677185253a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-645b3f02-2527-4293-b214-5b6ba7c528e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-9adf664a-687a-477f-b114-2a8c0ebde9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-36eff29a-3f95-4fc4-b2be-19e3fe68a536,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-e621590c-4bce-4001-a1c6-177c06089c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-376792873-172.17.0.5-1597049859669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35907,DS-d67126ba-3050-4d48-8b4d-64bf4bca940f,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-d50aabfb-825e-4b77-b50c-e9a88fd6957c,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-a4acddaf-c9b1-4910-936e-d695995ace78,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-5e89715c-0c3f-43ee-afb9-677185253a83,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-645b3f02-2527-4293-b214-5b6ba7c528e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-9adf664a-687a-477f-b114-2a8c0ebde9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44455,DS-36eff29a-3f95-4fc4-b2be-19e3fe68a536,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-e621590c-4bce-4001-a1c6-177c06089c21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167472528-172.17.0.5-1597049995749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41130,DS-3d164882-d40a-441e-8485-65e352fbc5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-2278a0df-91e0-49f1-b48d-1323b6238d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-c23d1947-9c4b-44f1-a09a-60e8356d6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-70587312-903f-41ea-861a-52a52b828be2,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-4dc870c2-58be-4efc-998e-de3876e8f652,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-03be6b95-dd85-4f36-8d44-c368ba4be3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-c988bac7-e248-4a92-b27b-d6f8080d8da1,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-91574bec-9804-45b1-b871-32d5f61a8ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1167472528-172.17.0.5-1597049995749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41130,DS-3d164882-d40a-441e-8485-65e352fbc5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-2278a0df-91e0-49f1-b48d-1323b6238d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-c23d1947-9c4b-44f1-a09a-60e8356d6c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-70587312-903f-41ea-861a-52a52b828be2,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-4dc870c2-58be-4efc-998e-de3876e8f652,DISK], DatanodeInfoWithStorage[127.0.0.1:45546,DS-03be6b95-dd85-4f36-8d44-c368ba4be3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41356,DS-c988bac7-e248-4a92-b27b-d6f8080d8da1,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-91574bec-9804-45b1-b871-32d5f61a8ea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249038033-172.17.0.5-1597050204078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38335,DS-39645387-e06c-4ec3-9876-d46e28a5526b,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-67858e12-60a9-45ce-b7f9-0290deb76a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-dc3637f5-752f-4119-98dd-af0a17b1903b,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-90204397-4ee5-4820-a459-5a064cdcca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f1b35165-a531-4de7-b3bc-0d79c798f9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-7855fee4-e264-4a70-8c64-659f069ce495,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-51f915c7-048e-43df-bc02-1c2a37a48369,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-a10a9374-53ed-4118-95e2-7565ea83f7f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249038033-172.17.0.5-1597050204078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38335,DS-39645387-e06c-4ec3-9876-d46e28a5526b,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-67858e12-60a9-45ce-b7f9-0290deb76a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-dc3637f5-752f-4119-98dd-af0a17b1903b,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-90204397-4ee5-4820-a459-5a064cdcca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f1b35165-a531-4de7-b3bc-0d79c798f9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-7855fee4-e264-4a70-8c64-659f069ce495,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-51f915c7-048e-43df-bc02-1c2a37a48369,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-a10a9374-53ed-4118-95e2-7565ea83f7f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523277961-172.17.0.5-1597050302696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45605,DS-a240fcc2-e39b-4910-bea0-ac6414ae3d35,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-36e69ea4-a3d0-4fa6-8785-139ec05aff99,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-4b3e00a1-ae0c-4312-8c30-ec0dcf330245,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-11511fcb-95fe-45bb-9f6e-a4ed47817162,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-bae217a8-58f0-46db-925f-36007417ed70,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-a0413e80-445a-4888-9c63-62deea7aafaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-c9c8d47d-5834-44eb-afb5-f061d80372f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-ad548e7f-4c93-4694-a2e4-247f3f2dd735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1523277961-172.17.0.5-1597050302696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45605,DS-a240fcc2-e39b-4910-bea0-ac6414ae3d35,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-36e69ea4-a3d0-4fa6-8785-139ec05aff99,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-4b3e00a1-ae0c-4312-8c30-ec0dcf330245,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-11511fcb-95fe-45bb-9f6e-a4ed47817162,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-bae217a8-58f0-46db-925f-36007417ed70,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-a0413e80-445a-4888-9c63-62deea7aafaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33781,DS-c9c8d47d-5834-44eb-afb5-f061d80372f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-ad548e7f-4c93-4694-a2e4-247f3f2dd735,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812885281-172.17.0.5-1597050923213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38710,DS-e112f0c6-e413-437e-ad60-7f14aa53c84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-5c52bc0c-7793-4e98-be5f-84d2e2aab563,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-d5a93253-b3ee-408d-b35f-32ae6490c100,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a472ac28-cfea-4bf1-8ac2-ef582512c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-0d87f7ef-722c-4f69-b57b-bac579a2ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-cd78d1f9-9057-40e8-ba0b-41341dd9b9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-40b2c878-a5b0-4951-a995-b811ee8427f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-623a0168-98b6-4f94-8545-8dde5551b8db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-812885281-172.17.0.5-1597050923213:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38710,DS-e112f0c6-e413-437e-ad60-7f14aa53c84c,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-5c52bc0c-7793-4e98-be5f-84d2e2aab563,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-d5a93253-b3ee-408d-b35f-32ae6490c100,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a472ac28-cfea-4bf1-8ac2-ef582512c94b,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-0d87f7ef-722c-4f69-b57b-bac579a2ad2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-cd78d1f9-9057-40e8-ba0b-41341dd9b9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-40b2c878-a5b0-4951-a995-b811ee8427f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-623a0168-98b6-4f94-8545-8dde5551b8db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587131089-172.17.0.5-1597051104505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37740,DS-4aab1618-519b-444a-b9e4-a66470716618,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-24fd2d6f-2b4d-49c4-9e79-50a95945c8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-2fc1e95e-4763-49a9-93fc-3b04b9edc597,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-02497487-7c8a-47ca-a57d-727dee63ddaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-501ee5d3-83db-4777-af19-65479c6cb61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-5962661d-fab7-426d-9e15-80f258b9c155,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-7eeed201-f38a-4967-8469-c7d839dd90b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-e6449853-b8b8-45bb-af2f-e9fa10324fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587131089-172.17.0.5-1597051104505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37740,DS-4aab1618-519b-444a-b9e4-a66470716618,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-24fd2d6f-2b4d-49c4-9e79-50a95945c8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-2fc1e95e-4763-49a9-93fc-3b04b9edc597,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-02497487-7c8a-47ca-a57d-727dee63ddaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-501ee5d3-83db-4777-af19-65479c6cb61d,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-5962661d-fab7-426d-9e15-80f258b9c155,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-7eeed201-f38a-4967-8469-c7d839dd90b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-e6449853-b8b8-45bb-af2f-e9fa10324fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391664815-172.17.0.5-1597051164266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35733,DS-f17a343c-26f7-4261-a2b8-cf6cd5c9fe28,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-cb7b1b0d-782d-4653-a12b-18d1fc601498,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-eba177a3-bb5d-484c-94c1-b6cd3b113cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-a2e9630e-3a0d-4d0f-9706-68a93ba9e368,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-42eb2a09-7f60-4b4c-9299-eaf7792e6447,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-69bd1351-508c-432c-8399-06f38e99fd15,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-85e13e5e-9def-4d07-8f5b-509e616a7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-dea28d40-7f30-4758-8231-546e57abe3e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391664815-172.17.0.5-1597051164266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35733,DS-f17a343c-26f7-4261-a2b8-cf6cd5c9fe28,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-cb7b1b0d-782d-4653-a12b-18d1fc601498,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-eba177a3-bb5d-484c-94c1-b6cd3b113cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-a2e9630e-3a0d-4d0f-9706-68a93ba9e368,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-42eb2a09-7f60-4b4c-9299-eaf7792e6447,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-69bd1351-508c-432c-8399-06f38e99fd15,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-85e13e5e-9def-4d07-8f5b-509e616a7a27,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-dea28d40-7f30-4758-8231-546e57abe3e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658839481-172.17.0.5-1597051197644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37546,DS-436906fd-cc81-48ef-8da5-a0b279f38f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-96454882-abdc-4981-a649-c486d323749f,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-b02ab0e4-4d0e-44f4-bec1-d89db07dfc07,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-56357247-dcbc-471d-93b9-a0b617b1261b,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-60752403-c5da-4a64-ab88-5ccb8145e679,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-c617568f-bc48-4931-ba60-738bee17aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-6c4d96e6-ab01-490e-80b7-fb860c99123c,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-9a53d679-30bf-48c0-82eb-f168dddb701f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658839481-172.17.0.5-1597051197644:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37546,DS-436906fd-cc81-48ef-8da5-a0b279f38f95,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-96454882-abdc-4981-a649-c486d323749f,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-b02ab0e4-4d0e-44f4-bec1-d89db07dfc07,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-56357247-dcbc-471d-93b9-a0b617b1261b,DISK], DatanodeInfoWithStorage[127.0.0.1:43213,DS-60752403-c5da-4a64-ab88-5ccb8145e679,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-c617568f-bc48-4931-ba60-738bee17aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-6c4d96e6-ab01-490e-80b7-fb860c99123c,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-9a53d679-30bf-48c0-82eb-f168dddb701f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 131072
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595158892-172.17.0.5-1597051234026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42503,DS-2a9513a0-c6c3-4350-a331-a9ab383b2bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-a836ed97-c86f-49d1-8816-5614e258ffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-f187f749-2f07-4aa6-afd0-d1fca4b9944e,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-27196204-1998-40b1-8ba0-7e5dc364a3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-356d19a2-db24-4ded-89d8-0c187de43fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-cb7c5df7-8854-453a-92f7-8fb8e339de21,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-0dfdeca5-13be-4e4e-88eb-4b2b654b9abb,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-d8afbd7e-26b5-4e3c-acf4-dd58a50165e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595158892-172.17.0.5-1597051234026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42503,DS-2a9513a0-c6c3-4350-a331-a9ab383b2bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-a836ed97-c86f-49d1-8816-5614e258ffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-f187f749-2f07-4aa6-afd0-d1fca4b9944e,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-27196204-1998-40b1-8ba0-7e5dc364a3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-356d19a2-db24-4ded-89d8-0c187de43fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-cb7c5df7-8854-453a-92f7-8fb8e339de21,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-0dfdeca5-13be-4e4e-88eb-4b2b654b9abb,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-d8afbd7e-26b5-4e3c-acf4-dd58a50165e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5370
