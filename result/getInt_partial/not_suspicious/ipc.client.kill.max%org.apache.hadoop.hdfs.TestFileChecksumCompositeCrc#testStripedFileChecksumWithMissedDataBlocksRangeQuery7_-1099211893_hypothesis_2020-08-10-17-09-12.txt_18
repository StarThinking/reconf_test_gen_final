reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868518707-172.17.0.2-1597079420194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43536,DS-2f3b15f6-63ed-46ce-a7ca-165c450198a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-a8a21937-4faf-472b-a257-01a0742858f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-21a2225c-1498-44f8-b928-8690d4a26ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-e4169c37-d8e7-4c77-b839-c31bb2f6d401,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-eab33976-1a87-4652-84ae-10586ccc8cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-b6c5f277-f967-426d-9ddf-532d4bb8dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-94929b9e-77af-4def-a786-66e2759b00b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-13e56e00-4085-42a1-88bc-c616b8c36330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868518707-172.17.0.2-1597079420194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43536,DS-2f3b15f6-63ed-46ce-a7ca-165c450198a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-a8a21937-4faf-472b-a257-01a0742858f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-21a2225c-1498-44f8-b928-8690d4a26ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-e4169c37-d8e7-4c77-b839-c31bb2f6d401,DISK], DatanodeInfoWithStorage[127.0.0.1:36069,DS-eab33976-1a87-4652-84ae-10586ccc8cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-b6c5f277-f967-426d-9ddf-532d4bb8dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-94929b9e-77af-4def-a786-66e2759b00b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-13e56e00-4085-42a1-88bc-c616b8c36330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178343911-172.17.0.2-1597080197453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35792,DS-43c6f15c-6a56-4e77-a980-59222a81a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-9a3f37f0-39fb-4e04-9bab-3c7cb21f287d,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-04fc75cb-f9f8-4990-9404-960107b3daf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-b4a93751-2544-465b-8f75-309db3bdb05e,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-a4ee76a0-c8b2-4646-8fe2-15d1ed211874,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-f6948e21-8bc9-48ab-9b07-02128e90062b,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-c72506fc-420b-4870-a31e-e5f88d7a6a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-37f80633-77b5-41e8-be82-875b831deaf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178343911-172.17.0.2-1597080197453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35792,DS-43c6f15c-6a56-4e77-a980-59222a81a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-9a3f37f0-39fb-4e04-9bab-3c7cb21f287d,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-04fc75cb-f9f8-4990-9404-960107b3daf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-b4a93751-2544-465b-8f75-309db3bdb05e,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-a4ee76a0-c8b2-4646-8fe2-15d1ed211874,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-f6948e21-8bc9-48ab-9b07-02128e90062b,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-c72506fc-420b-4870-a31e-e5f88d7a6a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-37f80633-77b5-41e8-be82-875b831deaf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345671193-172.17.0.2-1597080378379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45190,DS-930efc79-0fbf-45a2-86a5-fd3213ba46da,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-e5b25d80-2e3e-4169-acab-021cabb0cc96,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-e9cb7140-ed6e-4263-b38f-dff30d31ae84,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-30504793-c61c-4457-b25b-1c306f13282b,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-be8c4680-c5d9-450d-b572-71a8da6158d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-73cc6ca6-28a9-4e91-a2fd-57c64606e7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-c1d8249d-664e-4056-b04c-dc49d1e17153,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-37a6bed4-a274-4a01-9a0d-fbc11d388f9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345671193-172.17.0.2-1597080378379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45190,DS-930efc79-0fbf-45a2-86a5-fd3213ba46da,DISK], DatanodeInfoWithStorage[127.0.0.1:41261,DS-e5b25d80-2e3e-4169-acab-021cabb0cc96,DISK], DatanodeInfoWithStorage[127.0.0.1:46303,DS-e9cb7140-ed6e-4263-b38f-dff30d31ae84,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-30504793-c61c-4457-b25b-1c306f13282b,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-be8c4680-c5d9-450d-b572-71a8da6158d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-73cc6ca6-28a9-4e91-a2fd-57c64606e7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-c1d8249d-664e-4056-b04c-dc49d1e17153,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-37a6bed4-a274-4a01-9a0d-fbc11d388f9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469275067-172.17.0.2-1597080424921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-ea8eeb89-863f-4475-ba12-ece4ee2d95d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-8c1274f9-63be-4583-9f6c-0077429dcef8,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-20adfea9-368e-4b8c-8dc5-f2075a39c709,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-5c004383-bb84-46ca-82e4-77cbdec17f90,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-59bac86d-82c4-4cb3-93c3-7dc2b0845bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-56526e42-dc48-41df-bd52-8ba39ea3f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-9f3f4c9a-49c0-4049-847d-4459d677fd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-d0a4c8c1-361a-4b4a-8427-f73bff4494ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469275067-172.17.0.2-1597080424921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-ea8eeb89-863f-4475-ba12-ece4ee2d95d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-8c1274f9-63be-4583-9f6c-0077429dcef8,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-20adfea9-368e-4b8c-8dc5-f2075a39c709,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-5c004383-bb84-46ca-82e4-77cbdec17f90,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-59bac86d-82c4-4cb3-93c3-7dc2b0845bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-56526e42-dc48-41df-bd52-8ba39ea3f3af,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-9f3f4c9a-49c0-4049-847d-4459d677fd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-d0a4c8c1-361a-4b4a-8427-f73bff4494ad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324825950-172.17.0.2-1597080554083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38227,DS-88fd458a-3eaa-49e3-a038-8c1e21f3b0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-40aeccbd-8e83-41ae-8356-be7d51e56865,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-2aa3776a-298c-45ef-a002-ac4b8cb564fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-7f13804a-b7cd-4aa4-af57-d4d1462854b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-530b4144-e877-42fd-a7dd-7f0549d0aa64,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-e12558f9-1929-427e-a7e9-7b78c0b4148e,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-26ac9efe-3aac-464a-98c1-03015121c740,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-5e8d4498-d6c0-4708-81da-432fd9202b3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324825950-172.17.0.2-1597080554083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38227,DS-88fd458a-3eaa-49e3-a038-8c1e21f3b0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33405,DS-40aeccbd-8e83-41ae-8356-be7d51e56865,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-2aa3776a-298c-45ef-a002-ac4b8cb564fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-7f13804a-b7cd-4aa4-af57-d4d1462854b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-530b4144-e877-42fd-a7dd-7f0549d0aa64,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-e12558f9-1929-427e-a7e9-7b78c0b4148e,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-26ac9efe-3aac-464a-98c1-03015121c740,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-5e8d4498-d6c0-4708-81da-432fd9202b3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353861127-172.17.0.2-1597081183774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35362,DS-4db5ad9d-4bf5-4cf2-bc9f-f6e57ea6594a,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-db5cb877-7a5e-4151-b0a7-e5335bf79c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-2e4283f0-5f3f-4e6e-8712-489359dcf22a,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-aeb82353-613b-4664-b506-45591e710e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-cb4a754b-2f60-4738-9818-4c0843e7c7de,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-a6d0255d-e937-4e62-8081-f2b0d62b21cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-e7857b65-92a8-45af-9e5b-edc59fd35d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-5d6d970d-fb72-48d0-adbf-64acf97b4261,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353861127-172.17.0.2-1597081183774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35362,DS-4db5ad9d-4bf5-4cf2-bc9f-f6e57ea6594a,DISK], DatanodeInfoWithStorage[127.0.0.1:36184,DS-db5cb877-7a5e-4151-b0a7-e5335bf79c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-2e4283f0-5f3f-4e6e-8712-489359dcf22a,DISK], DatanodeInfoWithStorage[127.0.0.1:35128,DS-aeb82353-613b-4664-b506-45591e710e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-cb4a754b-2f60-4738-9818-4c0843e7c7de,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-a6d0255d-e937-4e62-8081-f2b0d62b21cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-e7857b65-92a8-45af-9e5b-edc59fd35d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-5d6d970d-fb72-48d0-adbf-64acf97b4261,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595765846-172.17.0.2-1597081229781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-7710ffe3-785b-40f3-8d05-4ebfa1014bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-5bd6964e-f390-4965-9eb8-baca9d2d45b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-6de9f338-dc6d-4dea-96e9-09939e99d038,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-fb6b1047-6279-4ab1-bb21-743957fb34e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-1c0dde80-4813-4796-9693-fd0aa06dafee,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-a6e12341-e626-4ddf-9e74-89a83d324e14,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-7d863b8a-9f75-46ec-ac25-8d545e827ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-e5c23c55-4d21-4299-99ba-539a238c33c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595765846-172.17.0.2-1597081229781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46882,DS-7710ffe3-785b-40f3-8d05-4ebfa1014bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-5bd6964e-f390-4965-9eb8-baca9d2d45b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-6de9f338-dc6d-4dea-96e9-09939e99d038,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-fb6b1047-6279-4ab1-bb21-743957fb34e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-1c0dde80-4813-4796-9693-fd0aa06dafee,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-a6e12341-e626-4ddf-9e74-89a83d324e14,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-7d863b8a-9f75-46ec-ac25-8d545e827ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-e5c23c55-4d21-4299-99ba-539a238c33c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599370827-172.17.0.2-1597081427048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37961,DS-cba07a71-224f-4448-b2dd-435062e62eec,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-84f580b7-3f4a-43b2-b7f7-f6e0ce0ebcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-6776fef2-7d10-433c-8eb5-4e6bebdcac93,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-2da36da2-9dab-41d4-a038-aff170936989,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-300c9d33-5f82-4e93-af34-99a58093e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-3d1ced56-22bc-4f7e-93a4-bdb20fa8ce57,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-1192361c-6770-45e0-9c06-443e284de391,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-26b3e944-9fc0-45d9-962b-13e2d55bbbfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599370827-172.17.0.2-1597081427048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37961,DS-cba07a71-224f-4448-b2dd-435062e62eec,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-84f580b7-3f4a-43b2-b7f7-f6e0ce0ebcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-6776fef2-7d10-433c-8eb5-4e6bebdcac93,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-2da36da2-9dab-41d4-a038-aff170936989,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-300c9d33-5f82-4e93-af34-99a58093e35a,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-3d1ced56-22bc-4f7e-93a4-bdb20fa8ce57,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-1192361c-6770-45e0-9c06-443e284de391,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-26b3e944-9fc0-45d9-962b-13e2d55bbbfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040551973-172.17.0.2-1597081643188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42039,DS-a5ca39e2-910e-4fc3-b1b4-7152367ff13e,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-f30ea4b1-b740-435b-822c-d57e3481e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-d58c337b-59a5-4d39-bafc-469698daabbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-4d5aa083-7054-482b-9b81-84e42b00724e,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-368d76a3-fe21-4e36-a17e-821a9baf11f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-19b42b1b-b454-44de-b9aa-cba942b2d7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-6d4be984-1a4c-488e-ab83-4ff8f8a50b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-c984dc1a-b0b8-44a9-b488-8918642b8586,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040551973-172.17.0.2-1597081643188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42039,DS-a5ca39e2-910e-4fc3-b1b4-7152367ff13e,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-f30ea4b1-b740-435b-822c-d57e3481e61b,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-d58c337b-59a5-4d39-bafc-469698daabbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36008,DS-4d5aa083-7054-482b-9b81-84e42b00724e,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-368d76a3-fe21-4e36-a17e-821a9baf11f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-19b42b1b-b454-44de-b9aa-cba942b2d7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-6d4be984-1a4c-488e-ab83-4ff8f8a50b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39489,DS-c984dc1a-b0b8-44a9-b488-8918642b8586,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459243052-172.17.0.2-1597081685493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-966f7d02-70f1-4726-9322-a14184c98fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f416f798-af60-48cc-b145-22beaf71fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-39d962b3-7ad5-45df-8534-ca4826f7d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-3db05f0c-db79-4122-ac54-deceead19755,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-59bfce51-e67f-4ad7-9fdb-655bdd59a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-a47d1ff5-1153-433f-b581-949928cac7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-d1566226-6c4e-4b15-8b3c-0524d87fac67,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-dd14eca1-6d86-42b0-8b45-431f2f4675a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459243052-172.17.0.2-1597081685493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-966f7d02-70f1-4726-9322-a14184c98fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34682,DS-f416f798-af60-48cc-b145-22beaf71fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-39d962b3-7ad5-45df-8534-ca4826f7d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-3db05f0c-db79-4122-ac54-deceead19755,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-59bfce51-e67f-4ad7-9fdb-655bdd59a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43758,DS-a47d1ff5-1153-433f-b581-949928cac7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-d1566226-6c4e-4b15-8b3c-0524d87fac67,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-dd14eca1-6d86-42b0-8b45-431f2f4675a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984316765-172.17.0.2-1597081791115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45136,DS-0e93df54-a9c9-40e0-b0f6-ad93ad6d7274,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-d86593b2-5941-454d-95a1-f15744604c58,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-852ba22a-356a-4f63-9f8d-baf7ac2ced12,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-2b80c50a-8118-4ce3-92c5-8b659a32e7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-45e31c03-9816-4bcd-b937-c3e2f828abff,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-678f5e8a-d8f2-4882-8408-a98a8bbb2b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-0f9bff5e-fedf-4006-b121-642613a156e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-ad15c822-6ff6-4e54-b1af-2927a59e96ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984316765-172.17.0.2-1597081791115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45136,DS-0e93df54-a9c9-40e0-b0f6-ad93ad6d7274,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-d86593b2-5941-454d-95a1-f15744604c58,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-852ba22a-356a-4f63-9f8d-baf7ac2ced12,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-2b80c50a-8118-4ce3-92c5-8b659a32e7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-45e31c03-9816-4bcd-b937-c3e2f828abff,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-678f5e8a-d8f2-4882-8408-a98a8bbb2b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-0f9bff5e-fedf-4006-b121-642613a156e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-ad15c822-6ff6-4e54-b1af-2927a59e96ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774588709-172.17.0.2-1597081926012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37727,DS-a4d2ceff-b53e-41cb-a1ad-70adf8f1dbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-a3813e10-8450-4ed6-b4a0-a8e008eea7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-4ccb8fe7-8002-419a-b920-80fb97e90e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-2b61c381-25ce-4aa8-9f5e-e34e73ae34a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-1a837d71-754b-4fbc-bae6-eae248ce44bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-426978be-49a9-4d3d-a499-c85128dc3005,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-12e3c205-4315-4a05-a056-ef0de47ad8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-612947e1-bc9e-4b75-afe6-291037b735a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-774588709-172.17.0.2-1597081926012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37727,DS-a4d2ceff-b53e-41cb-a1ad-70adf8f1dbb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45819,DS-a3813e10-8450-4ed6-b4a0-a8e008eea7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-4ccb8fe7-8002-419a-b920-80fb97e90e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-2b61c381-25ce-4aa8-9f5e-e34e73ae34a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-1a837d71-754b-4fbc-bae6-eae248ce44bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-426978be-49a9-4d3d-a499-c85128dc3005,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-12e3c205-4315-4a05-a056-ef0de47ad8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-612947e1-bc9e-4b75-afe6-291037b735a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015920146-172.17.0.2-1597082148978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44135,DS-84c6c104-37c3-474f-8e7d-361a74175abb,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-081a962c-76bb-4760-b8ab-7d299852ccba,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-5202bafd-f6db-4f6c-a813-63e1bfbe2299,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-6495a1be-0c38-49c1-a92a-ab0864293f44,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-658595d1-67c9-48b0-b30e-5434cceff3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-cdb9b0de-71ba-4e0e-a26b-58bfed6ceaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-85ac4543-0d28-4c0c-908c-9381449d9b26,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-d17b2c7c-8cfe-4f6a-ad4e-0cee8bb06e59,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1015920146-172.17.0.2-1597082148978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44135,DS-84c6c104-37c3-474f-8e7d-361a74175abb,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-081a962c-76bb-4760-b8ab-7d299852ccba,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-5202bafd-f6db-4f6c-a813-63e1bfbe2299,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-6495a1be-0c38-49c1-a92a-ab0864293f44,DISK], DatanodeInfoWithStorage[127.0.0.1:35932,DS-658595d1-67c9-48b0-b30e-5434cceff3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-cdb9b0de-71ba-4e0e-a26b-58bfed6ceaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-85ac4543-0d28-4c0c-908c-9381449d9b26,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-d17b2c7c-8cfe-4f6a-ad4e-0cee8bb06e59,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605569469-172.17.0.2-1597082273049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-a26dcd8e-3910-4a2d-9d4c-ecdd6abb5b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-babf2d2e-0745-48e0-9b53-9d3606051399,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-424fe452-d010-468a-835b-5bc47d6b5645,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-637e169d-2991-4a52-975e-508a58f6a02c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-ca8ce430-d92a-4985-87c7-de9f47a3daa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-8b17bd73-d008-4e6a-819f-e5263a1243ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-cd138800-68a0-4307-8613-6b9970733cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-31261f0e-ec24-4115-b9a7-435469815a3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605569469-172.17.0.2-1597082273049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40277,DS-a26dcd8e-3910-4a2d-9d4c-ecdd6abb5b01,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-babf2d2e-0745-48e0-9b53-9d3606051399,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-424fe452-d010-468a-835b-5bc47d6b5645,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-637e169d-2991-4a52-975e-508a58f6a02c,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-ca8ce430-d92a-4985-87c7-de9f47a3daa6,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-8b17bd73-d008-4e6a-819f-e5263a1243ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-cd138800-68a0-4307-8613-6b9970733cda,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-31261f0e-ec24-4115-b9a7-435469815a3b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097352661-172.17.0.2-1597082324357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-a4498997-26ea-4a83-adcc-81cf3cd61c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-3d25fdb9-08ce-459e-9884-fc07b0347290,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-4e62643f-61a9-41c1-b1c0-b9128077b375,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-8729e262-cd7c-47cd-9a0c-f0bee43819d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-1b26e83b-d6d7-4b71-b4a5-5317da45936a,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-01ad85a7-b159-4afb-b992-a98b2ce39cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-d15d5db9-bf38-49cc-bb7b-d26cab4239ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-d9f10f01-4df4-4b4f-9818-bbddfcb35611,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1097352661-172.17.0.2-1597082324357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42481,DS-a4498997-26ea-4a83-adcc-81cf3cd61c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-3d25fdb9-08ce-459e-9884-fc07b0347290,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-4e62643f-61a9-41c1-b1c0-b9128077b375,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-8729e262-cd7c-47cd-9a0c-f0bee43819d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-1b26e83b-d6d7-4b71-b4a5-5317da45936a,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-01ad85a7-b159-4afb-b992-a98b2ce39cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46374,DS-d15d5db9-bf38-49cc-bb7b-d26cab4239ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-d9f10f01-4df4-4b4f-9818-bbddfcb35611,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053982233-172.17.0.2-1597082364574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35858,DS-4b17a374-4508-4a16-986b-df4ac222ae82,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-ac3f1833-d5e8-4180-9eb6-063d40d5f197,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-4fb8b168-3a70-4240-976b-67f9d9f44a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-5902e558-6e91-47b7-8d0b-691fb9edd652,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-6bf424bf-5313-43d4-9c56-aedf37674760,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-dc4dc07d-2afe-4f3e-ac6b-2f3272d70f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-845d5ca2-db81-4ca4-a790-791a85b450b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-3e7816c6-9b54-47f0-b297-af605792dbaf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053982233-172.17.0.2-1597082364574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35858,DS-4b17a374-4508-4a16-986b-df4ac222ae82,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-ac3f1833-d5e8-4180-9eb6-063d40d5f197,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-4fb8b168-3a70-4240-976b-67f9d9f44a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-5902e558-6e91-47b7-8d0b-691fb9edd652,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-6bf424bf-5313-43d4-9c56-aedf37674760,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-dc4dc07d-2afe-4f3e-ac6b-2f3272d70f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-845d5ca2-db81-4ca4-a790-791a85b450b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-3e7816c6-9b54-47f0-b297-af605792dbaf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52188178-172.17.0.2-1597082455804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-1802b9a4-82f4-485c-9171-39adcae21eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-3a553adc-ebc2-4064-a505-5603ea491d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-643f9b05-eab8-4a2b-979d-9138d44be722,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-7da8156a-5ddb-40c8-9457-84fffaf7b251,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-b6c74658-a269-4399-96c7-afaed16b5ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-25e2f776-4354-4359-9f12-5ea1f12c420a,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-dd271307-38f0-470e-a313-903862b6933e,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-0e4f2463-1580-4130-9dd8-d293038f3f79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52188178-172.17.0.2-1597082455804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39507,DS-1802b9a4-82f4-485c-9171-39adcae21eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-3a553adc-ebc2-4064-a505-5603ea491d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-643f9b05-eab8-4a2b-979d-9138d44be722,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-7da8156a-5ddb-40c8-9457-84fffaf7b251,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-b6c74658-a269-4399-96c7-afaed16b5ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-25e2f776-4354-4359-9f12-5ea1f12c420a,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-dd271307-38f0-470e-a313-903862b6933e,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-0e4f2463-1580-4130-9dd8-d293038f3f79,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330890509-172.17.0.2-1597082548368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-bd5676f4-d67d-490c-bdaf-622cc24db1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-7f7d4d39-2cf1-4337-915a-9e5237f71153,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-0d9480d3-4388-4db4-968d-860d477bb53a,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-5cdc808f-c2e3-40e7-9202-f7fcb43445ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-f584b902-2fc1-43ab-8d11-a411e4844747,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-db76df57-70c8-48fa-b72b-487ece213598,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-b281f4bf-54fa-437d-81c4-633d058f7877,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-3d6b0894-2c03-480d-b265-2496b6988192,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330890509-172.17.0.2-1597082548368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-bd5676f4-d67d-490c-bdaf-622cc24db1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-7f7d4d39-2cf1-4337-915a-9e5237f71153,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-0d9480d3-4388-4db4-968d-860d477bb53a,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-5cdc808f-c2e3-40e7-9202-f7fcb43445ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-f584b902-2fc1-43ab-8d11-a411e4844747,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-db76df57-70c8-48fa-b72b-487ece213598,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-b281f4bf-54fa-437d-81c4-633d058f7877,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-3d6b0894-2c03-480d-b265-2496b6988192,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759607531-172.17.0.2-1597082774426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33538,DS-70c72831-9ef7-4fe6-8d85-19cef5534deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-6017d05f-0c73-4ed7-b578-251825dcafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-480909a4-5487-4a83-bde7-d4e36a102436,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-08e4b81f-8cfe-4fad-94ba-0c31b57223db,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-7b3154d3-3435-4bc7-a0bc-47b87a1f6331,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-9f75fee9-acef-4d35-9658-583fb73debf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-1adf113b-f86d-4628-aabd-4651b0c255e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-787c54cc-be83-4281-b696-a1c234aad10f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-759607531-172.17.0.2-1597082774426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33538,DS-70c72831-9ef7-4fe6-8d85-19cef5534deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-6017d05f-0c73-4ed7-b578-251825dcafd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-480909a4-5487-4a83-bde7-d4e36a102436,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-08e4b81f-8cfe-4fad-94ba-0c31b57223db,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-7b3154d3-3435-4bc7-a0bc-47b87a1f6331,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-9f75fee9-acef-4d35-9658-583fb73debf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-1adf113b-f86d-4628-aabd-4651b0c255e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-787c54cc-be83-4281-b696-a1c234aad10f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044668680-172.17.0.2-1597082864697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42140,DS-a085b507-afc6-4e65-836f-9069561877eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-50b7a5af-cefd-475b-88d7-90df8ce44c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-2cfae4fc-7ccf-49ac-9403-9e0265e2f8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-a1da7c19-32b3-4ffb-aa23-8fcd592cf589,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-b7b7d088-13bf-4315-a4e1-eb886b7e8652,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-e980e641-2cb0-49a5-a13a-687c8223f4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-9702eb91-6083-4d77-a610-85cc59877752,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-45bebe93-474e-4a7e-b29f-d77a5e0298f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2044668680-172.17.0.2-1597082864697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42140,DS-a085b507-afc6-4e65-836f-9069561877eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-50b7a5af-cefd-475b-88d7-90df8ce44c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39182,DS-2cfae4fc-7ccf-49ac-9403-9e0265e2f8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-a1da7c19-32b3-4ffb-aa23-8fcd592cf589,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-b7b7d088-13bf-4315-a4e1-eb886b7e8652,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-e980e641-2cb0-49a5-a13a-687c8223f4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-9702eb91-6083-4d77-a610-85cc59877752,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-45bebe93-474e-4a7e-b29f-d77a5e0298f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957715311-172.17.0.2-1597083093937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46851,DS-650e7e11-4fc6-4923-8444-cce66a0bec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-f15ccf40-3128-4125-80d9-264158e44f74,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-97a8eaba-6b70-4ff9-844f-a5ab3af46fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-39fbd7fa-93ff-42fe-b91e-0a16f7a6890e,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-d9bfaf49-4202-4d89-88c8-b245e4d12de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-edfd7f15-f860-4937-b6a6-3bddbdf839d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-006d109a-24ca-41b4-a443-760d796e54c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-3fb72e9c-5e32-4372-b151-575944322ed6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957715311-172.17.0.2-1597083093937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46851,DS-650e7e11-4fc6-4923-8444-cce66a0bec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-f15ccf40-3128-4125-80d9-264158e44f74,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-97a8eaba-6b70-4ff9-844f-a5ab3af46fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-39fbd7fa-93ff-42fe-b91e-0a16f7a6890e,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-d9bfaf49-4202-4d89-88c8-b245e4d12de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-edfd7f15-f860-4937-b6a6-3bddbdf839d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-006d109a-24ca-41b4-a443-760d796e54c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-3fb72e9c-5e32-4372-b151-575944322ed6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421637981-172.17.0.2-1597083142012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42030,DS-a3842bfc-eacf-478d-a7fa-b013d86ce71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-61450970-8a70-48a8-829d-4eed06670f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-e2f132e2-f629-4a49-839d-f3a5500b75a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-ebf8f4d5-62e1-43f7-a8e9-33de61b0d541,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-ae0f7c9e-b202-4151-927a-bfee0c53199f,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-ba6290e5-df12-442e-8fd9-1b4aa19168f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-3f170120-5c63-40c8-9b74-d2e80c26e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-76604bc8-786b-4375-a934-78c133be16b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421637981-172.17.0.2-1597083142012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42030,DS-a3842bfc-eacf-478d-a7fa-b013d86ce71f,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-61450970-8a70-48a8-829d-4eed06670f99,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-e2f132e2-f629-4a49-839d-f3a5500b75a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-ebf8f4d5-62e1-43f7-a8e9-33de61b0d541,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-ae0f7c9e-b202-4151-927a-bfee0c53199f,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-ba6290e5-df12-442e-8fd9-1b4aa19168f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-3f170120-5c63-40c8-9b74-d2e80c26e1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-76604bc8-786b-4375-a934-78c133be16b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926946059-172.17.0.2-1597083309889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34754,DS-22db6ec0-682b-45ca-8d7d-25603e81781a,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-2aa29777-035c-4c3a-b3b9-9a8da2d6fd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-2dc959e9-64f6-415d-aee3-76537145e004,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-998bd178-bc31-4fd3-bef0-a4011e84984a,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-aa6f0e68-bc5d-41cd-8aae-d0b53d0ef2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-6daa8319-af29-4979-8a9f-441c832d55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-2a7ee736-794c-4878-bd95-41171f96e30d,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-5fbab21d-3393-4d7e-89b5-1c724209a778,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926946059-172.17.0.2-1597083309889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34754,DS-22db6ec0-682b-45ca-8d7d-25603e81781a,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-2aa29777-035c-4c3a-b3b9-9a8da2d6fd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-2dc959e9-64f6-415d-aee3-76537145e004,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-998bd178-bc31-4fd3-bef0-a4011e84984a,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-aa6f0e68-bc5d-41cd-8aae-d0b53d0ef2eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-6daa8319-af29-4979-8a9f-441c832d55ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-2a7ee736-794c-4878-bd95-41171f96e30d,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-5fbab21d-3393-4d7e-89b5-1c724209a778,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619769172-172.17.0.2-1597083881228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42729,DS-6c9a8921-23e2-4e4a-9114-e940953d1d67,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-2621fbbe-df64-4f78-8225-57c5877c4d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-df301e7b-0e84-4705-bea7-a46fbbe3d604,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-041ba27c-5ea9-44e3-9a68-d32948d5f088,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-90f8bec6-3b2b-4b6a-bb37-fe00b68fbcce,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-a78e5289-f5f6-4855-aef2-213215e543e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-55f91180-3270-4894-a911-3d0d69a91c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-b23675f1-57c3-41c8-813e-185589a8ead0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619769172-172.17.0.2-1597083881228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42729,DS-6c9a8921-23e2-4e4a-9114-e940953d1d67,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-2621fbbe-df64-4f78-8225-57c5877c4d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-df301e7b-0e84-4705-bea7-a46fbbe3d604,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-041ba27c-5ea9-44e3-9a68-d32948d5f088,DISK], DatanodeInfoWithStorage[127.0.0.1:34329,DS-90f8bec6-3b2b-4b6a-bb37-fe00b68fbcce,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-a78e5289-f5f6-4855-aef2-213215e543e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-55f91180-3270-4894-a911-3d0d69a91c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-b23675f1-57c3-41c8-813e-185589a8ead0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153310919-172.17.0.2-1597083928114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45046,DS-819d0f9a-d446-4928-a4b1-b72fd6aa71ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-b781c6d7-20cc-48a6-95e1-b583f4e8f942,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-1dc4b500-b571-432d-b9be-3a3b294bf45c,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-7a33975b-ee47-49fc-b2ca-26079b6f9619,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-68224e9e-7bcc-4452-867d-e4939785b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-b2b94227-577a-45d5-8c11-bd5ea9da202b,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-bacedcc9-6b21-4820-b9e8-6d343397f1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-aeb0e4db-500c-4662-971c-44012b15b6db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-153310919-172.17.0.2-1597083928114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45046,DS-819d0f9a-d446-4928-a4b1-b72fd6aa71ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-b781c6d7-20cc-48a6-95e1-b583f4e8f942,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-1dc4b500-b571-432d-b9be-3a3b294bf45c,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-7a33975b-ee47-49fc-b2ca-26079b6f9619,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-68224e9e-7bcc-4452-867d-e4939785b8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-b2b94227-577a-45d5-8c11-bd5ea9da202b,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-bacedcc9-6b21-4820-b9e8-6d343397f1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-aeb0e4db-500c-4662-971c-44012b15b6db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854853226-172.17.0.2-1597083966282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43112,DS-03475245-edfb-4574-93d3-be8e436b5e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-0950f4f7-aeb6-47bf-8a92-ec4c372dd166,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-8be95212-2a11-4e9c-9422-c4bf7cc2ca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-0c8ab3f1-e6bf-437d-a28c-66f46f2a1529,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-d77b965a-5622-47db-8b52-25f6d9e70120,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-9456813f-4551-47e1-82bc-16257387e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-b37c635e-69c4-4011-86c2-d677fb2995cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-3c39dbf4-2665-4a84-a4ed-f2efc9a04b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854853226-172.17.0.2-1597083966282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43112,DS-03475245-edfb-4574-93d3-be8e436b5e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-0950f4f7-aeb6-47bf-8a92-ec4c372dd166,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-8be95212-2a11-4e9c-9422-c4bf7cc2ca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33173,DS-0c8ab3f1-e6bf-437d-a28c-66f46f2a1529,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-d77b965a-5622-47db-8b52-25f6d9e70120,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-9456813f-4551-47e1-82bc-16257387e52e,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-b37c635e-69c4-4011-86c2-d677fb2995cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-3c39dbf4-2665-4a84-a4ed-f2efc9a04b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546279888-172.17.0.2-1597084153422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-d477e9f1-b6c9-4ab0-ad82-4ca6bd7a106c,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-2c3f6943-df54-4792-aac6-7f632dd8f703,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-d6199f33-0202-4985-af66-e3ff2d4a049a,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-7eb27aab-0097-4e36-9f52-348a67abca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-66d0ce4b-9bf2-4c9a-9efa-c85d649e60b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-42461e7c-4cf5-4e0f-836c-720a86fcb6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-89a36416-1c56-4681-a781-c0199a1aa37f,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-4f3f3783-4a97-439e-9d3d-f250c43b3691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546279888-172.17.0.2-1597084153422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34973,DS-d477e9f1-b6c9-4ab0-ad82-4ca6bd7a106c,DISK], DatanodeInfoWithStorage[127.0.0.1:45531,DS-2c3f6943-df54-4792-aac6-7f632dd8f703,DISK], DatanodeInfoWithStorage[127.0.0.1:32772,DS-d6199f33-0202-4985-af66-e3ff2d4a049a,DISK], DatanodeInfoWithStorage[127.0.0.1:43145,DS-7eb27aab-0097-4e36-9f52-348a67abca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-66d0ce4b-9bf2-4c9a-9efa-c85d649e60b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-42461e7c-4cf5-4e0f-836c-720a86fcb6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-89a36416-1c56-4681-a781-c0199a1aa37f,DISK], DatanodeInfoWithStorage[127.0.0.1:39485,DS-4f3f3783-4a97-439e-9d3d-f250c43b3691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57846639-172.17.0.2-1597084515507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43210,DS-9df4c3ae-ed3c-4cb8-94ad-8ed4bb3219fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-e79a4c6e-f210-4484-b02b-804a9e44ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-3d3d4008-5c63-4669-8add-b800defd7903,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-c1bcb4ff-2e72-4bb4-9a0b-ee97dc4707b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-7a07bdd3-4f94-4efc-96f3-70a9ece89186,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-783c911f-8b72-4955-9e82-2f140b752b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-1fe1fe67-2b2f-4d5d-a04a-c2037688982b,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-40fe6a0b-30cb-49ca-9a8e-2c3af63db757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57846639-172.17.0.2-1597084515507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43210,DS-9df4c3ae-ed3c-4cb8-94ad-8ed4bb3219fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-e79a4c6e-f210-4484-b02b-804a9e44ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-3d3d4008-5c63-4669-8add-b800defd7903,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-c1bcb4ff-2e72-4bb4-9a0b-ee97dc4707b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-7a07bdd3-4f94-4efc-96f3-70a9ece89186,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-783c911f-8b72-4955-9e82-2f140b752b73,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-1fe1fe67-2b2f-4d5d-a04a-c2037688982b,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-40fe6a0b-30cb-49ca-9a8e-2c3af63db757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799789568-172.17.0.2-1597084644600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45069,DS-d2a489d1-4bc8-4d4d-b735-56d2c150218a,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-43c3c6b0-89b3-48a2-baf3-e0cacac08735,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-5fe7af78-6627-4e28-beda-b0a22e8a30ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-8454d4c4-2a36-4a91-bda9-1825ac44e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-c0ac9f75-cc4e-4707-948b-974a7860c785,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-c56b9a6c-1595-43a1-9449-d52b23263cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-b4803d59-07d7-4ab0-aa55-55bcfa936d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-7fb522ef-84ff-4b73-9399-0fc6d585a3d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799789568-172.17.0.2-1597084644600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45069,DS-d2a489d1-4bc8-4d4d-b735-56d2c150218a,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-43c3c6b0-89b3-48a2-baf3-e0cacac08735,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-5fe7af78-6627-4e28-beda-b0a22e8a30ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46477,DS-8454d4c4-2a36-4a91-bda9-1825ac44e93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45745,DS-c0ac9f75-cc4e-4707-948b-974a7860c785,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-c56b9a6c-1595-43a1-9449-d52b23263cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-b4803d59-07d7-4ab0-aa55-55bcfa936d51,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-7fb522ef-84ff-4b73-9399-0fc6d585a3d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231795910-172.17.0.2-1597084819414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-03c120fa-f89a-4b62-9206-2bb1328c2389,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-bc77cccf-94f4-4ee8-a8d5-471517e25d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-d85bd17b-5363-4ad1-a00c-507bd4b9bf64,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-f9a1188e-a90e-4f4d-871b-2ec16c58c02e,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-bbb1489b-2020-4636-8b72-dd4ff894c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-bf62b1be-d974-4d02-b859-3ebd76410369,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-fdff8c15-5fb4-4cf5-931d-1853771277a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-175fde80-0a51-4642-a87f-7d7a15ed4096,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-231795910-172.17.0.2-1597084819414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-03c120fa-f89a-4b62-9206-2bb1328c2389,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-bc77cccf-94f4-4ee8-a8d5-471517e25d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-d85bd17b-5363-4ad1-a00c-507bd4b9bf64,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-f9a1188e-a90e-4f4d-871b-2ec16c58c02e,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-bbb1489b-2020-4636-8b72-dd4ff894c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-bf62b1be-d974-4d02-b859-3ebd76410369,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-fdff8c15-5fb4-4cf5-931d-1853771277a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-175fde80-0a51-4642-a87f-7d7a15ed4096,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164490817-172.17.0.2-1597084914761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42720,DS-336012eb-76bb-4730-b26a-badb6923db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-267aa1ea-070d-4926-ac7f-6bf9ade63042,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-c95f4690-78be-4457-b5a5-d60e48da075a,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-ba2c9373-997d-4ef4-8e5e-254068154957,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-6a249786-7fbe-4de6-af33-47d5fdd89bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-af14a7d3-095f-4315-a5f7-07ce6d5b6276,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-04d90f7c-0f69-4964-8078-876d85b9385d,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-7b4d07c7-21f1-4a49-8131-7b03bb67dc98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164490817-172.17.0.2-1597084914761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42720,DS-336012eb-76bb-4730-b26a-badb6923db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38422,DS-267aa1ea-070d-4926-ac7f-6bf9ade63042,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-c95f4690-78be-4457-b5a5-d60e48da075a,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-ba2c9373-997d-4ef4-8e5e-254068154957,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-6a249786-7fbe-4de6-af33-47d5fdd89bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-af14a7d3-095f-4315-a5f7-07ce6d5b6276,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-04d90f7c-0f69-4964-8078-876d85b9385d,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-7b4d07c7-21f1-4a49-8131-7b03bb67dc98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236166738-172.17.0.2-1597085038359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37988,DS-1fdc84de-7600-4dca-8ba3-b524e28c15c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-a71f3948-2b72-4380-8ce6-81f20a6cfd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-875c98c4-c4ba-4ff0-a03c-53b1a69ffe33,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-7a92571b-80dc-48ad-afe4-4ec824e992bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-680c5ec6-1066-42a9-b41f-a2cc7beeeede,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-211f6e1d-2988-4008-b000-562ab9597bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-16a06a9e-a911-4b6c-9286-e32e79c043ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-007abc76-9806-4164-8696-2f4652a5e9f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1236166738-172.17.0.2-1597085038359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37988,DS-1fdc84de-7600-4dca-8ba3-b524e28c15c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-a71f3948-2b72-4380-8ce6-81f20a6cfd6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-875c98c4-c4ba-4ff0-a03c-53b1a69ffe33,DISK], DatanodeInfoWithStorage[127.0.0.1:32830,DS-7a92571b-80dc-48ad-afe4-4ec824e992bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-680c5ec6-1066-42a9-b41f-a2cc7beeeede,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-211f6e1d-2988-4008-b000-562ab9597bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-16a06a9e-a911-4b6c-9286-e32e79c043ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-007abc76-9806-4164-8696-2f4652a5e9f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152312623-172.17.0.2-1597085072796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-d75d6683-6e30-4efc-a3f0-592526f210cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-9ac27d76-7e84-4ae3-8f81-487b2fa7d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-2b30a1a9-71f3-4789-9ba2-5e98e5ae5573,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-1eac2b60-30ec-446d-84b7-19eb0bef5122,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-f9c09683-0798-4deb-adb2-8112acf2bb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-e4e29283-835e-4f11-a9e4-b7ccb8b946ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-6ee17383-b09e-4896-8dc9-50b30782383b,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-afbce49e-8bec-45f3-9581-6e8308163c54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152312623-172.17.0.2-1597085072796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-d75d6683-6e30-4efc-a3f0-592526f210cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-9ac27d76-7e84-4ae3-8f81-487b2fa7d83b,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-2b30a1a9-71f3-4789-9ba2-5e98e5ae5573,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-1eac2b60-30ec-446d-84b7-19eb0bef5122,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-f9c09683-0798-4deb-adb2-8112acf2bb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-e4e29283-835e-4f11-a9e4-b7ccb8b946ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-6ee17383-b09e-4896-8dc9-50b30782383b,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-afbce49e-8bec-45f3-9581-6e8308163c54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529197859-172.17.0.2-1597085118443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42227,DS-c848775c-9221-4237-a3ab-4c93ddbf5257,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-cfac3d30-b983-48ec-8143-fd65740381ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-c3ab429c-381c-4d8f-bdaa-f7c08554b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-415fa460-8c10-4c7b-9adc-5157035dc4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-4ca811e3-2db3-445e-884c-64695663ae22,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-b920df1e-d00f-4740-9f62-d5aa9e52edd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-2c3e2654-dbc5-4d85-8418-4b1d13f7ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-ad431f55-8a9d-4a11-a089-72fedecf74d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529197859-172.17.0.2-1597085118443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42227,DS-c848775c-9221-4237-a3ab-4c93ddbf5257,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-cfac3d30-b983-48ec-8143-fd65740381ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-c3ab429c-381c-4d8f-bdaa-f7c08554b25a,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-415fa460-8c10-4c7b-9adc-5157035dc4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-4ca811e3-2db3-445e-884c-64695663ae22,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-b920df1e-d00f-4740-9f62-d5aa9e52edd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-2c3e2654-dbc5-4d85-8418-4b1d13f7ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-ad431f55-8a9d-4a11-a089-72fedecf74d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301413745-172.17.0.2-1597085459117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-6d2b622d-0e86-4396-b368-85886762858d,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-109f2246-893d-420f-ac0d-0dcbc1122c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-852c94b5-4fed-4b6f-aaa0-58da3f0eb009,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-f3eb0300-beeb-4bf3-a872-5ebbd605b3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-2df0023f-3ab8-4c76-9bf7-af10b6e544ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-33fd17fe-01ec-430e-a6ae-fb4b258248dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-6e9b2c3a-cca4-4e7c-b970-9d1a7334453c,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-b538321c-23c1-4887-9715-d5d899157be3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301413745-172.17.0.2-1597085459117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35038,DS-6d2b622d-0e86-4396-b368-85886762858d,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-109f2246-893d-420f-ac0d-0dcbc1122c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-852c94b5-4fed-4b6f-aaa0-58da3f0eb009,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-f3eb0300-beeb-4bf3-a872-5ebbd605b3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-2df0023f-3ab8-4c76-9bf7-af10b6e544ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-33fd17fe-01ec-430e-a6ae-fb4b258248dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-6e9b2c3a-cca4-4e7c-b970-9d1a7334453c,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-b538321c-23c1-4887-9715-d5d899157be3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.kill.max
component: hdfs:DataNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249026804-172.17.0.2-1597085723994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-77211d1c-a0a5-41f2-8a56-e7f0dfa88c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-ec718ff1-dd12-446d-9d4e-574467635a02,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-6da9b319-2892-4186-81f8-5210c86861d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-5ae1b6e3-8c42-4e91-9a17-aaa40896c047,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-70b13e78-d6e1-46f4-b052-765d6d1a81cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-7dd43d62-f10c-4f1f-bce4-9cb5e20374ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-fd05d971-204b-487b-add7-5256ba9ff3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-6b88f7ec-a74f-45c8-9e31-bdb1b8ada4cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249026804-172.17.0.2-1597085723994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-77211d1c-a0a5-41f2-8a56-e7f0dfa88c53,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-ec718ff1-dd12-446d-9d4e-574467635a02,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-6da9b319-2892-4186-81f8-5210c86861d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-5ae1b6e3-8c42-4e91-9a17-aaa40896c047,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-70b13e78-d6e1-46f4-b052-765d6d1a81cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-7dd43d62-f10c-4f1f-bce4-9cb5e20374ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-fd05d971-204b-487b-add7-5256ba9ff3f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-6b88f7ec-a74f-45c8-9e31-bdb1b8ada4cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 6694
