reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842396029-172.17.0.9-1597085584609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41831,DS-ed1e4d05-15b2-4a23-9ed2-75d48fb896e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-36911876-2d1b-42da-bc1d-ba0b7ae30501,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-9ae600e5-a551-4c1a-b652-f74f98c51dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-f9c7338f-03d1-4d46-8eb0-c6458d384280,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-654cec93-9349-4e1f-973e-9a69722a46d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-cdb7e761-d743-4476-bb34-cdf867e18838,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-38c035bb-51e0-439b-8a2a-92a76cd2eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-a4ba8b6f-d531-4b70-b876-136557bd5ed7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-842396029-172.17.0.9-1597085584609:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41831,DS-ed1e4d05-15b2-4a23-9ed2-75d48fb896e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-36911876-2d1b-42da-bc1d-ba0b7ae30501,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-9ae600e5-a551-4c1a-b652-f74f98c51dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-f9c7338f-03d1-4d46-8eb0-c6458d384280,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-654cec93-9349-4e1f-973e-9a69722a46d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-cdb7e761-d743-4476-bb34-cdf867e18838,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-38c035bb-51e0-439b-8a2a-92a76cd2eaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-a4ba8b6f-d531-4b70-b876-136557bd5ed7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169909317-172.17.0.9-1597086085061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-634ae2bb-a54f-4893-a72a-76f248f0598d,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-ce81cb7f-b564-43c0-8a3e-7647b4480df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-93e20d5f-5fbf-4406-8a80-f6325a966767,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-6cb42ed3-bb52-4a21-82bf-d30f3bffa831,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-da6f67dc-c2bd-401e-a0e6-9876b659f4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-ca6939eb-b8af-4aa6-99db-2e08bcda31be,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-8fc67836-323f-4cbb-8e02-521caf4650a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-21500660-0423-4887-b435-caec17fdee41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1169909317-172.17.0.9-1597086085061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-634ae2bb-a54f-4893-a72a-76f248f0598d,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-ce81cb7f-b564-43c0-8a3e-7647b4480df1,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-93e20d5f-5fbf-4406-8a80-f6325a966767,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-6cb42ed3-bb52-4a21-82bf-d30f3bffa831,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-da6f67dc-c2bd-401e-a0e6-9876b659f4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-ca6939eb-b8af-4aa6-99db-2e08bcda31be,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-8fc67836-323f-4cbb-8e02-521caf4650a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-21500660-0423-4887-b435-caec17fdee41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54529708-172.17.0.9-1597086216159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39807,DS-9598c915-c1c0-4cc1-8026-05e26cbef63a,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-e5bdff12-c0a6-43b4-90a8-6ad73b8c9db0,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-12560c62-74ce-40b1-a076-6411fedb3033,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-fa9a9c20-3130-4ea2-bf6e-3a3655dc8b56,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-21d0fdf1-b5c5-4bcf-9656-89a6ff00274a,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-c4296a9a-2260-41f9-a363-a98a14599ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-f36782d4-e8fc-457c-a186-e5574da23389,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-51f008b7-0fac-4840-a7bc-7b3fb33bed36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54529708-172.17.0.9-1597086216159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39807,DS-9598c915-c1c0-4cc1-8026-05e26cbef63a,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-e5bdff12-c0a6-43b4-90a8-6ad73b8c9db0,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-12560c62-74ce-40b1-a076-6411fedb3033,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-fa9a9c20-3130-4ea2-bf6e-3a3655dc8b56,DISK], DatanodeInfoWithStorage[127.0.0.1:41828,DS-21d0fdf1-b5c5-4bcf-9656-89a6ff00274a,DISK], DatanodeInfoWithStorage[127.0.0.1:42877,DS-c4296a9a-2260-41f9-a363-a98a14599ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-f36782d4-e8fc-457c-a186-e5574da23389,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-51f008b7-0fac-4840-a7bc-7b3fb33bed36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319019041-172.17.0.9-1597086260837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-ee1d1d48-f6a5-4762-b536-66942e1d42e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-3b8de142-39e1-4820-9283-26c9342854e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-529d6135-eda5-47eb-8cb7-d20e19bb83f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-8a4dc388-6372-4a29-a37c-368af7cc2327,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-be6af064-196c-4b90-aebd-ec3926c4d674,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-891f17be-874c-407e-a13e-cda797f1fa52,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-a01839d9-0928-417b-a773-070f97c61dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-67c6248f-c5ac-462b-9ce1-7db88731fb70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319019041-172.17.0.9-1597086260837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38638,DS-ee1d1d48-f6a5-4762-b536-66942e1d42e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-3b8de142-39e1-4820-9283-26c9342854e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-529d6135-eda5-47eb-8cb7-d20e19bb83f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-8a4dc388-6372-4a29-a37c-368af7cc2327,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-be6af064-196c-4b90-aebd-ec3926c4d674,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-891f17be-874c-407e-a13e-cda797f1fa52,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-a01839d9-0928-417b-a773-070f97c61dba,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-67c6248f-c5ac-462b-9ce1-7db88731fb70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094684831-172.17.0.9-1597086488578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41240,DS-d8178293-2d4f-4c1f-9dda-d7c09ae9f18d,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-ccec026a-51a3-42b2-a5c6-543b22a51c38,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-860b7f74-c4cb-4b9a-bf7b-ace71692d69d,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-5f2bb648-027d-4fb3-82ff-701f683c6396,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-af7b675c-cd77-4be0-9df4-e615cc3d0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-f0ed5b6c-821a-43bb-b3f7-a89afcd71946,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-627b3bec-6de7-4e98-88a6-94f2db87b489,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-31de3636-26ec-400c-8924-6664b18e3aed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094684831-172.17.0.9-1597086488578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41240,DS-d8178293-2d4f-4c1f-9dda-d7c09ae9f18d,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-ccec026a-51a3-42b2-a5c6-543b22a51c38,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-860b7f74-c4cb-4b9a-bf7b-ace71692d69d,DISK], DatanodeInfoWithStorage[127.0.0.1:38438,DS-5f2bb648-027d-4fb3-82ff-701f683c6396,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-af7b675c-cd77-4be0-9df4-e615cc3d0fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-f0ed5b6c-821a-43bb-b3f7-a89afcd71946,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-627b3bec-6de7-4e98-88a6-94f2db87b489,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-31de3636-26ec-400c-8924-6664b18e3aed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525505516-172.17.0.9-1597086572821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-ac491005-6b9a-4760-a612-04fd319a8039,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-8384d2a0-a299-4fbb-b13c-1861ea66dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-86eb085f-cfd0-4b0f-95dc-c53c107787ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-3f9ac5a5-5d11-4118-9590-07859a2b874d,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-a41dd26f-155a-496d-b100-85af2a3471db,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-5dfa0945-cf8e-4268-874f-e54d8b121249,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-1c4d9437-f325-4bbf-bdf7-cf14191981d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-0f1be9d1-0773-4777-acb2-ecee06e8a10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525505516-172.17.0.9-1597086572821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37301,DS-ac491005-6b9a-4760-a612-04fd319a8039,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-8384d2a0-a299-4fbb-b13c-1861ea66dfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-86eb085f-cfd0-4b0f-95dc-c53c107787ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-3f9ac5a5-5d11-4118-9590-07859a2b874d,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-a41dd26f-155a-496d-b100-85af2a3471db,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-5dfa0945-cf8e-4268-874f-e54d8b121249,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-1c4d9437-f325-4bbf-bdf7-cf14191981d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-0f1be9d1-0773-4777-acb2-ecee06e8a10e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361355525-172.17.0.9-1597086621795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38271,DS-e98051f2-43b0-4262-a1c3-e6781310f2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-c44dfb31-16dc-40e5-acda-4bcdf2fc305c,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-5c7cc2a7-12c2-4645-b968-b645eb507447,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-12ea86e1-e9e3-4fe8-86dc-de7b1c01b0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-afa8fd86-7110-4aec-9c3f-80199e140c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-ef5465e6-79f0-44ab-bdf1-99d517c6fdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-f434c2a0-46e0-422e-881d-20571d1afc58,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-98ab4b8a-db88-4be4-9d9f-3d6cc30a160b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361355525-172.17.0.9-1597086621795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38271,DS-e98051f2-43b0-4262-a1c3-e6781310f2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-c44dfb31-16dc-40e5-acda-4bcdf2fc305c,DISK], DatanodeInfoWithStorage[127.0.0.1:35510,DS-5c7cc2a7-12c2-4645-b968-b645eb507447,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-12ea86e1-e9e3-4fe8-86dc-de7b1c01b0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-afa8fd86-7110-4aec-9c3f-80199e140c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-ef5465e6-79f0-44ab-bdf1-99d517c6fdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-f434c2a0-46e0-422e-881d-20571d1afc58,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-98ab4b8a-db88-4be4-9d9f-3d6cc30a160b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474943855-172.17.0.9-1597087579865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-6160e3f4-477f-4a11-8dd9-7bccfbca012b,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-1a4da6cd-a96e-4851-901a-1158ce5f42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-91afb041-f167-4876-9f3c-be4b2e305f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-6f174019-dc35-4a06-af7e-673f5d00cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-7ff787bf-3831-46a7-bb5b-1916491479b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-17f025d8-aedd-4c00-9fb5-bf50d6d50ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-067e681f-f0c3-4c7b-b285-4b0a57635d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-c4bdf1a8-09e1-4472-bae0-8f735d21f2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1474943855-172.17.0.9-1597087579865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38521,DS-6160e3f4-477f-4a11-8dd9-7bccfbca012b,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-1a4da6cd-a96e-4851-901a-1158ce5f42d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-91afb041-f167-4876-9f3c-be4b2e305f86,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-6f174019-dc35-4a06-af7e-673f5d00cb64,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-7ff787bf-3831-46a7-bb5b-1916491479b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-17f025d8-aedd-4c00-9fb5-bf50d6d50ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-067e681f-f0c3-4c7b-b285-4b0a57635d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-c4bdf1a8-09e1-4472-bae0-8f735d21f2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115291204-172.17.0.9-1597087849499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43908,DS-94cb87c9-3be0-4cf8-9f59-e4eb7d65453c,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-a0349ceb-c026-4b60-8553-b82c1afc8daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-c95c8f58-2d11-417d-aade-0034d6cb4f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-7283e488-5ab2-4af5-9260-8e9c42cc16e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-e4425c56-ead4-4266-a0a8-0a5705be92a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-c0a6faa1-22fc-484b-98eb-18288dc5a229,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-54279496-8bbd-4dda-88be-ebe78dff6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-42602562-31ac-4540-860a-ab3ee4b3a2b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115291204-172.17.0.9-1597087849499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43908,DS-94cb87c9-3be0-4cf8-9f59-e4eb7d65453c,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-a0349ceb-c026-4b60-8553-b82c1afc8daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35135,DS-c95c8f58-2d11-417d-aade-0034d6cb4f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-7283e488-5ab2-4af5-9260-8e9c42cc16e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-e4425c56-ead4-4266-a0a8-0a5705be92a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-c0a6faa1-22fc-484b-98eb-18288dc5a229,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-54279496-8bbd-4dda-88be-ebe78dff6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-42602562-31ac-4540-860a-ab3ee4b3a2b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250757190-172.17.0.9-1597088387602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40648,DS-de5cada8-846b-4fd8-8b64-cbf555e8dc49,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-d9c031b8-e403-4c4e-a351-607d83ee1e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-db598f66-d0ec-44e4-9fa2-55968f8e75cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-89f3bad0-d5e5-4814-a671-80515fee399c,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-078ebc41-f182-48b9-8e31-f3923b1a5333,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-a31ceb85-93b9-4cdd-8d21-5a84c6fc1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-6bf64a37-44ba-4ee7-9033-20df89bd7ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-ba58fd92-cf11-4624-9506-5f505a48edeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250757190-172.17.0.9-1597088387602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40648,DS-de5cada8-846b-4fd8-8b64-cbf555e8dc49,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-d9c031b8-e403-4c4e-a351-607d83ee1e61,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-db598f66-d0ec-44e4-9fa2-55968f8e75cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-89f3bad0-d5e5-4814-a671-80515fee399c,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-078ebc41-f182-48b9-8e31-f3923b1a5333,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-a31ceb85-93b9-4cdd-8d21-5a84c6fc1eff,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-6bf64a37-44ba-4ee7-9033-20df89bd7ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-ba58fd92-cf11-4624-9506-5f505a48edeb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773764564-172.17.0.9-1597088478497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-86f7afe3-225f-4332-b0f3-f45df5a1d360,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-f0821679-3f8d-4161-9e84-95dfdd5d1514,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-f904806a-11e7-4c0d-8dd2-d14c5ea9cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-5d95bf86-ea4b-47f9-88fd-d87a51cc0507,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-d2a7e0fc-b951-4bdb-82d6-fa2a4ce5dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-584511a5-0bbe-4d93-b1e3-f6a85c3a0eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-2da29650-8059-4a39-a9ca-481266e96ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-afc8056a-64b9-4357-adab-8a02a44f44f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1773764564-172.17.0.9-1597088478497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33064,DS-86f7afe3-225f-4332-b0f3-f45df5a1d360,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-f0821679-3f8d-4161-9e84-95dfdd5d1514,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-f904806a-11e7-4c0d-8dd2-d14c5ea9cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-5d95bf86-ea4b-47f9-88fd-d87a51cc0507,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-d2a7e0fc-b951-4bdb-82d6-fa2a4ce5dbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-584511a5-0bbe-4d93-b1e3-f6a85c3a0eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-2da29650-8059-4a39-a9ca-481266e96ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-afc8056a-64b9-4357-adab-8a02a44f44f1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454932527-172.17.0.9-1597088613500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40877,DS-d71b338c-3279-4c72-8119-2091306939ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-781ecbb5-4ff6-473c-83af-c30de15ebe78,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-42f1c398-27ed-4075-8274-9f53f8799e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-7defa3d7-b0f5-4372-926e-81e6e801fa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-5eb3c14b-bed0-4090-b9b6-f288e6e6b9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-bc517439-a615-4053-9549-cf42c4b90827,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-35fec3ae-5c58-4750-82aa-61dde7338570,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-69a15602-7f6e-4778-96ed-1e7c6a6ac845,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454932527-172.17.0.9-1597088613500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40877,DS-d71b338c-3279-4c72-8119-2091306939ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-781ecbb5-4ff6-473c-83af-c30de15ebe78,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-42f1c398-27ed-4075-8274-9f53f8799e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46690,DS-7defa3d7-b0f5-4372-926e-81e6e801fa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-5eb3c14b-bed0-4090-b9b6-f288e6e6b9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46191,DS-bc517439-a615-4053-9549-cf42c4b90827,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-35fec3ae-5c58-4750-82aa-61dde7338570,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-69a15602-7f6e-4778-96ed-1e7c6a6ac845,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688314944-172.17.0.9-1597088717349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41030,DS-322f8049-90c7-468d-822c-d1496db0505d,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-a12ed5ad-e886-41bd-9259-a01b067fe7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-fae6342d-f5a4-4bda-89b5-2f5998747703,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-ad1beff6-9eb4-415d-9203-90b9eeb3a39e,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-7a470db5-733c-4a46-81cc-82c7e27b7a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-c7d751ea-bb6c-4dcd-b62d-755605cc2b97,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-dad15caa-948f-4a14-9731-79550bec039b,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-08109642-a322-40c3-a887-5ce130b08e56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688314944-172.17.0.9-1597088717349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41030,DS-322f8049-90c7-468d-822c-d1496db0505d,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-a12ed5ad-e886-41bd-9259-a01b067fe7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-fae6342d-f5a4-4bda-89b5-2f5998747703,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-ad1beff6-9eb4-415d-9203-90b9eeb3a39e,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-7a470db5-733c-4a46-81cc-82c7e27b7a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-c7d751ea-bb6c-4dcd-b62d-755605cc2b97,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-dad15caa-948f-4a14-9731-79550bec039b,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-08109642-a322-40c3-a887-5ce130b08e56,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801923476-172.17.0.9-1597088809199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-45a690c6-0c17-41fc-8326-0ff2b80c345f,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-4be8a71d-8147-480e-8aa6-1c0439002542,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-f7bb84d3-6ad0-4b4b-92b5-4a7cfea6c473,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-b9e03840-aed7-462e-820a-af5b7647541d,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-f4fb470e-9a9b-45bc-884d-0d71eb7f0ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-924f37ac-5abd-4921-80ad-20166faff361,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-859d67ba-efd0-4ac6-97b5-e04981311d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-339a51a5-dc0a-4a4d-a614-4ae92af88ed5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801923476-172.17.0.9-1597088809199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43321,DS-45a690c6-0c17-41fc-8326-0ff2b80c345f,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-4be8a71d-8147-480e-8aa6-1c0439002542,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-f7bb84d3-6ad0-4b4b-92b5-4a7cfea6c473,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-b9e03840-aed7-462e-820a-af5b7647541d,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-f4fb470e-9a9b-45bc-884d-0d71eb7f0ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-924f37ac-5abd-4921-80ad-20166faff361,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-859d67ba-efd0-4ac6-97b5-e04981311d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-339a51a5-dc0a-4a4d-a614-4ae92af88ed5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664365357-172.17.0.9-1597089477529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-ea35307f-80b8-4a10-86c1-b6ee99dab992,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-cb6885e8-0f55-458f-b0a2-f867b08630b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-c535cb13-181e-42a6-89e3-ad2892eab498,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-d9374179-c3f8-4614-955e-a84eb30e9237,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-e9228a8f-6a0a-4775-bfdf-bbaacaf76370,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-dbe86c24-0b4b-4685-9eb0-4dcdfc728b10,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-93f78c35-d647-4c56-bd52-c75e059378c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-badfba43-0353-4815-b6a2-5b82a95bd8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664365357-172.17.0.9-1597089477529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-ea35307f-80b8-4a10-86c1-b6ee99dab992,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-cb6885e8-0f55-458f-b0a2-f867b08630b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-c535cb13-181e-42a6-89e3-ad2892eab498,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-d9374179-c3f8-4614-955e-a84eb30e9237,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-e9228a8f-6a0a-4775-bfdf-bbaacaf76370,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-dbe86c24-0b4b-4685-9eb0-4dcdfc728b10,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-93f78c35-d647-4c56-bd52-c75e059378c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34985,DS-badfba43-0353-4815-b6a2-5b82a95bd8a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363483582-172.17.0.9-1597089923894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33318,DS-7b6157ef-674f-4595-a3d5-093c482ddec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-fe399baa-7b2f-45c9-93fe-f37ea313cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-490f500d-26fd-4112-a904-135c12021c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-d921a5b5-32d4-4a0b-a1ef-cde2d81ab088,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-6dce4c84-a393-422d-814d-6e2037995705,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-315dd641-2e74-45bb-9232-89c5c00db3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-d98ecc8c-b069-43e9-9bae-f2ecddc4f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-d3c1cf83-82f9-4a54-947c-581ae5c15198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1363483582-172.17.0.9-1597089923894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33318,DS-7b6157ef-674f-4595-a3d5-093c482ddec0,DISK], DatanodeInfoWithStorage[127.0.0.1:34986,DS-fe399baa-7b2f-45c9-93fe-f37ea313cdb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-490f500d-26fd-4112-a904-135c12021c85,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-d921a5b5-32d4-4a0b-a1ef-cde2d81ab088,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-6dce4c84-a393-422d-814d-6e2037995705,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-315dd641-2e74-45bb-9232-89c5c00db3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-d98ecc8c-b069-43e9-9bae-f2ecddc4f8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-d3c1cf83-82f9-4a54-947c-581ae5c15198,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029493662-172.17.0.9-1597090054269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-66a1dcad-f47c-4bbf-bee4-dd215417cdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-ad6b01db-21a4-4e86-9db3-447d450b3d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-23c75b9f-ed48-4ab2-b60f-7d43b79cd29e,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-9a3227bf-a324-4d72-b8cb-cfc7e6e501ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-9dde0910-5b72-4c8a-9e9a-59396415f501,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-6585dbd2-5d84-4fa0-bb99-037f8282175c,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-0b7a5119-61f8-4440-b536-1f118719faf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-0f1b8c45-90d7-40bf-a20d-840bd9303bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029493662-172.17.0.9-1597090054269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44383,DS-66a1dcad-f47c-4bbf-bee4-dd215417cdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-ad6b01db-21a4-4e86-9db3-447d450b3d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-23c75b9f-ed48-4ab2-b60f-7d43b79cd29e,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-9a3227bf-a324-4d72-b8cb-cfc7e6e501ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-9dde0910-5b72-4c8a-9e9a-59396415f501,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-6585dbd2-5d84-4fa0-bb99-037f8282175c,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-0b7a5119-61f8-4440-b536-1f118719faf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-0f1b8c45-90d7-40bf-a20d-840bd9303bb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680656194-172.17.0.9-1597090225192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-1b3952b9-10e5-4553-9b89-d6d86b0fc764,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-037ca418-b2df-405d-9ebc-7535db943b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-efe7bb05-c3a9-48d5-806a-8a3c3fae3097,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-c78c586e-55ef-4143-b3e7-6c9ada2a7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-00fd743d-3fe2-4d57-9545-7f20aaaf8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-aef399bd-924f-4a47-a8f0-e748bac82a05,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-f87fe825-ad20-40b7-a955-7dc5683ffb07,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-4264408e-68de-40c9-8c3c-7463e47d5211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680656194-172.17.0.9-1597090225192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-1b3952b9-10e5-4553-9b89-d6d86b0fc764,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-037ca418-b2df-405d-9ebc-7535db943b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-efe7bb05-c3a9-48d5-806a-8a3c3fae3097,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-c78c586e-55ef-4143-b3e7-6c9ada2a7fee,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-00fd743d-3fe2-4d57-9545-7f20aaaf8e00,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-aef399bd-924f-4a47-a8f0-e748bac82a05,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-f87fe825-ad20-40b7-a955-7dc5683ffb07,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-4264408e-68de-40c9-8c3c-7463e47d5211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779036260-172.17.0.9-1597090617928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38586,DS-2d85d7f1-a803-4692-bd37-4121a7d9a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-ae8e58c2-77c3-4e23-905a-c0dde4a0364c,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-9c2d9008-5a97-4d33-941f-a448c37e346b,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-08ffc95a-bc1b-4a5c-ad53-5f1c195b8c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-3bdcf5fc-9cad-4708-a427-26215ddd27a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-b675a4e3-ef88-428d-b71a-702e95d00ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-50843cfb-8c45-4379-b78a-fb4b4cef1bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-8bf2c907-d031-43f0-94ca-5e9d21fc69f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779036260-172.17.0.9-1597090617928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38586,DS-2d85d7f1-a803-4692-bd37-4121a7d9a9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-ae8e58c2-77c3-4e23-905a-c0dde4a0364c,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-9c2d9008-5a97-4d33-941f-a448c37e346b,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-08ffc95a-bc1b-4a5c-ad53-5f1c195b8c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-3bdcf5fc-9cad-4708-a427-26215ddd27a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-b675a4e3-ef88-428d-b71a-702e95d00ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-50843cfb-8c45-4379-b78a-fb4b4cef1bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-8bf2c907-d031-43f0-94ca-5e9d21fc69f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724509875-172.17.0.9-1597090661214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33127,DS-8e054063-8cc6-4804-8995-1227b1e64d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-a8570d9c-6469-4268-abb4-4437804a79fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-ef901e6d-4d86-4ad8-abd0-3d1fa0a6806d,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-1bfdbd13-d8e4-42e1-a09e-15f20b4a35d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-28538f67-c8ab-4cc5-a3b8-21aa37b6e073,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-845efbdd-0cf1-4e3a-8ea0-049c2ec14e33,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-ac0bf22b-0edd-4f99-b576-32692a00f8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-ef37fe30-b9af-4848-a0dc-a24e912793c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724509875-172.17.0.9-1597090661214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33127,DS-8e054063-8cc6-4804-8995-1227b1e64d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-a8570d9c-6469-4268-abb4-4437804a79fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-ef901e6d-4d86-4ad8-abd0-3d1fa0a6806d,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-1bfdbd13-d8e4-42e1-a09e-15f20b4a35d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-28538f67-c8ab-4cc5-a3b8-21aa37b6e073,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-845efbdd-0cf1-4e3a-8ea0-049c2ec14e33,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-ac0bf22b-0edd-4f99-b576-32692a00f8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-ef37fe30-b9af-4848-a0dc-a24e912793c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331084119-172.17.0.9-1597090784602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-73a7c283-f013-464b-8e75-a90874e2867b,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-b1770d84-aa15-49b1-ae7c-a92eb855253b,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-5c4f9264-c8d6-48f5-959a-05226c14ccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-6a7b15cb-2223-4315-b64d-6aafafe05d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-1699364b-e845-4f4d-bcad-93b7374e6f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-b668b9fb-bb74-445d-b942-cb1105a4003a,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-1c686dbc-55a6-4229-b688-cc410c2622f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-8cdbe093-437a-4814-9b10-e9b653f0972b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331084119-172.17.0.9-1597090784602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-73a7c283-f013-464b-8e75-a90874e2867b,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-b1770d84-aa15-49b1-ae7c-a92eb855253b,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-5c4f9264-c8d6-48f5-959a-05226c14ccfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-6a7b15cb-2223-4315-b64d-6aafafe05d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-1699364b-e845-4f4d-bcad-93b7374e6f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43871,DS-b668b9fb-bb74-445d-b942-cb1105a4003a,DISK], DatanodeInfoWithStorage[127.0.0.1:35144,DS-1c686dbc-55a6-4229-b688-cc410c2622f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-8cdbe093-437a-4814-9b10-e9b653f0972b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743305021-172.17.0.9-1597091071388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-3e8fd5a5-002e-46e8-94e5-94e566514f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-5f705b85-fe0a-4e00-ae23-f40ea2136a36,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-bf4bff60-c9b2-4f48-8d34-3c591cb9b7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-6b7a397c-7517-48cd-a8cb-205c15d8702f,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-2612d3ce-05cc-4e28-97bb-a5fa94fb0eac,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-80c4730b-4375-4e62-a7ab-abc9d03ef387,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-200bdc43-7acd-41ec-acdd-dc92d0345e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-6fd97256-222d-4e14-905a-405a5b3a11c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743305021-172.17.0.9-1597091071388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40093,DS-3e8fd5a5-002e-46e8-94e5-94e566514f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-5f705b85-fe0a-4e00-ae23-f40ea2136a36,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-bf4bff60-c9b2-4f48-8d34-3c591cb9b7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-6b7a397c-7517-48cd-a8cb-205c15d8702f,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-2612d3ce-05cc-4e28-97bb-a5fa94fb0eac,DISK], DatanodeInfoWithStorage[127.0.0.1:35846,DS-80c4730b-4375-4e62-a7ab-abc9d03ef387,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-200bdc43-7acd-41ec-acdd-dc92d0345e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-6fd97256-222d-4e14-905a-405a5b3a11c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964524947-172.17.0.9-1597091363645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36098,DS-8033819b-63c0-488f-ab5f-772906cbaec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-ff1ab55e-3b5f-4641-98bc-4858f7431cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-2d8e0ab8-bb40-4cc6-911a-fa3d93e6058b,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-ad708e4a-6bb6-4b23-a421-a21732ae700f,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-8eb8709a-bc10-4be9-bcef-becf65ca52d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-6d6de1a1-4a41-48d9-9098-305ef139b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-543475d1-e06c-4dd8-bf87-a895937c20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d45b635e-a36e-46a8-bbd0-6cca9650c425,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964524947-172.17.0.9-1597091363645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36098,DS-8033819b-63c0-488f-ab5f-772906cbaec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42947,DS-ff1ab55e-3b5f-4641-98bc-4858f7431cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-2d8e0ab8-bb40-4cc6-911a-fa3d93e6058b,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-ad708e4a-6bb6-4b23-a421-a21732ae700f,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-8eb8709a-bc10-4be9-bcef-becf65ca52d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-6d6de1a1-4a41-48d9-9098-305ef139b70d,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-543475d1-e06c-4dd8-bf87-a895937c20f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-d45b635e-a36e-46a8-bbd0-6cca9650c425,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630211739-172.17.0.9-1597091608263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-22ffca11-47c1-4e4e-844e-7ba8d073ea40,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-49e0bf64-2a34-47ea-89dd-d3d49f3587e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-40353556-50ec-4bd7-8ff6-349a57cf5a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-0854ed13-50d3-48e0-8cae-be7807ffbd67,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-bf28ba99-1361-4918-aadf-fed01657813e,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-31e59842-5611-48c1-9c9f-866370cab0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-9f6820ec-227e-4f94-ba5c-3824794a6a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-43d45a44-0e7f-47bb-a15f-959bb233f837,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630211739-172.17.0.9-1597091608263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45844,DS-22ffca11-47c1-4e4e-844e-7ba8d073ea40,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-49e0bf64-2a34-47ea-89dd-d3d49f3587e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-40353556-50ec-4bd7-8ff6-349a57cf5a94,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-0854ed13-50d3-48e0-8cae-be7807ffbd67,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-bf28ba99-1361-4918-aadf-fed01657813e,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-31e59842-5611-48c1-9c9f-866370cab0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-9f6820ec-227e-4f94-ba5c-3824794a6a96,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-43d45a44-0e7f-47bb-a15f-959bb233f837,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48030621-172.17.0.9-1597091787829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42945,DS-a31298c5-4a5b-4b9b-96cb-4125841f968e,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-526aab18-1086-43fa-92e9-4a537b0d23a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-3382d7e1-4f38-4c08-841d-30ee20c82a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-455c82ea-966a-400a-933f-a6d671eb63ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-a056ba70-c4bb-4b28-b5ea-0cb93b82701c,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-4caf345c-3817-47dc-9a75-d93ecb203d78,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-387ee3af-3f10-42ed-9f78-c6ab65ec4815,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-163988bc-361c-4adb-b7e6-8e2fd9aea656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48030621-172.17.0.9-1597091787829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42945,DS-a31298c5-4a5b-4b9b-96cb-4125841f968e,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-526aab18-1086-43fa-92e9-4a537b0d23a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-3382d7e1-4f38-4c08-841d-30ee20c82a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-455c82ea-966a-400a-933f-a6d671eb63ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-a056ba70-c4bb-4b28-b5ea-0cb93b82701c,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-4caf345c-3817-47dc-9a75-d93ecb203d78,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-387ee3af-3f10-42ed-9f78-c6ab65ec4815,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-163988bc-361c-4adb-b7e6-8e2fd9aea656,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883910305-172.17.0.9-1597091975150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39377,DS-4ff1575a-2e70-4612-bfd8-56ed7a198daf,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-ae3afd54-a46b-4fdc-9d2e-3f949214dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-327d4f94-8baf-49a7-9f57-430f090aebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-22c1cb03-921f-4ef6-9445-bff59c237ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-740738c3-f409-4c6e-9f28-c8b9f98cb759,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-8bf97c2d-3bce-46f5-9c9d-b6f6b204562f,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-4f556a6c-9434-47c3-8876-6c49ea8d914c,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-27e4ffb9-425e-41c6-b6b4-3a30126e3d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-883910305-172.17.0.9-1597091975150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39377,DS-4ff1575a-2e70-4612-bfd8-56ed7a198daf,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-ae3afd54-a46b-4fdc-9d2e-3f949214dfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-327d4f94-8baf-49a7-9f57-430f090aebf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41892,DS-22c1cb03-921f-4ef6-9445-bff59c237ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-740738c3-f409-4c6e-9f28-c8b9f98cb759,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-8bf97c2d-3bce-46f5-9c9d-b6f6b204562f,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-4f556a6c-9434-47c3-8876-6c49ea8d914c,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-27e4ffb9-425e-41c6-b6b4-3a30126e3d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10000
v2: 2000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376968933-172.17.0.9-1597092066880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43772,DS-292aeeaa-ec2a-44bd-a604-9ed728adf665,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-63110864-92f2-4f07-bf00-9362eee5b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-4158efc6-a425-4e68-9a24-22dd8ceaee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-34b28462-6f52-488d-bbfd-cfb959ad6891,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-822281f6-12cf-4ad6-a129-83d1d47d8eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-b0cec74b-1377-4613-9594-e09b98560247,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-c3fd70c9-eaff-43c8-8129-10fd4dd1c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-5136a6c3-cff6-4224-a268-209edd70ff78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376968933-172.17.0.9-1597092066880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43772,DS-292aeeaa-ec2a-44bd-a604-9ed728adf665,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-63110864-92f2-4f07-bf00-9362eee5b7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-4158efc6-a425-4e68-9a24-22dd8ceaee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:44959,DS-34b28462-6f52-488d-bbfd-cfb959ad6891,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-822281f6-12cf-4ad6-a129-83d1d47d8eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-b0cec74b-1377-4613-9594-e09b98560247,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-c3fd70c9-eaff-43c8-8129-10fd4dd1c87c,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-5136a6c3-cff6-4224-a268-209edd70ff78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6634
