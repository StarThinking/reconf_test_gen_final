reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037660095-172.17.0.15-1597129547252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-a50fc7b4-0255-4836-99b8-b2d5c1bf2bce,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-16f6eecb-df41-47e0-8fbb-8927fa6b09e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-103c5db1-7dd5-4fc5-947a-24b1566e75fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-b7a82195-a691-4420-a49c-df6542ad0328,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-a1f05961-1eed-4e81-90de-ae880b404ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-ccc416ae-d2ab-4235-b8bf-a252bef91e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-10dccc70-044d-4ddb-87d4-ae8183fdc672,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-d186b8bb-70fd-4790-88bf-b7e64edd2e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2037660095-172.17.0.15-1597129547252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35637,DS-a50fc7b4-0255-4836-99b8-b2d5c1bf2bce,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-16f6eecb-df41-47e0-8fbb-8927fa6b09e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-103c5db1-7dd5-4fc5-947a-24b1566e75fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-b7a82195-a691-4420-a49c-df6542ad0328,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-a1f05961-1eed-4e81-90de-ae880b404ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-ccc416ae-d2ab-4235-b8bf-a252bef91e74,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-10dccc70-044d-4ddb-87d4-ae8183fdc672,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-d186b8bb-70fd-4790-88bf-b7e64edd2e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676144264-172.17.0.15-1597129770198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-ec1d3af8-4159-44c4-9a55-4772558e72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-69aa177f-074e-4d49-9668-b4a7134244f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-dcd68594-0f4e-40c7-88b2-c051b9b03a84,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-fdf63dc3-5778-4c7e-bd10-4a7657f0f9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-3ba856dc-2b22-4705-95b4-b8d39b841091,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-03e7942b-b9c0-4103-877e-e83bf0ab1c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-9483aad7-930c-4cb2-8c28-89328b37c618,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-08dff38a-7785-4b4c-9a7f-7545d15b661c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676144264-172.17.0.15-1597129770198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-ec1d3af8-4159-44c4-9a55-4772558e72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-69aa177f-074e-4d49-9668-b4a7134244f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-dcd68594-0f4e-40c7-88b2-c051b9b03a84,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-fdf63dc3-5778-4c7e-bd10-4a7657f0f9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-3ba856dc-2b22-4705-95b4-b8d39b841091,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-03e7942b-b9c0-4103-877e-e83bf0ab1c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-9483aad7-930c-4cb2-8c28-89328b37c618,DISK], DatanodeInfoWithStorage[127.0.0.1:45237,DS-08dff38a-7785-4b4c-9a7f-7545d15b661c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730514553-172.17.0.15-1597130005391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37402,DS-06b3236c-0d5e-4cad-a885-7fc8d8525ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-10aa88dd-24b2-48c0-a77c-246835573244,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-8a0b81c5-1871-4383-960f-5733fa7e3300,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-fd10a741-812d-45ad-b2c2-5bccf45330a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-6036c3dc-9b84-42e8-bc56-df7f9f3e7dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-c2f3ef54-b691-4248-9880-5fda9894dbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-2d8faa6b-7ab5-4374-8570-e5a49e059c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-b5e202fa-8e35-49f3-83f2-bc390dca07ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730514553-172.17.0.15-1597130005391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37402,DS-06b3236c-0d5e-4cad-a885-7fc8d8525ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-10aa88dd-24b2-48c0-a77c-246835573244,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-8a0b81c5-1871-4383-960f-5733fa7e3300,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-fd10a741-812d-45ad-b2c2-5bccf45330a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-6036c3dc-9b84-42e8-bc56-df7f9f3e7dab,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-c2f3ef54-b691-4248-9880-5fda9894dbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-2d8faa6b-7ab5-4374-8570-e5a49e059c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-b5e202fa-8e35-49f3-83f2-bc390dca07ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460383843-172.17.0.15-1597130328892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-55df06b8-7c71-4e84-918a-e302cb7d9a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-a4d4b95e-2862-48c0-bcb3-bd0910462350,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-0cc7de64-95f5-4b37-a4f1-5b22f92ca89e,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-f1255886-3df1-45f3-b8eb-2f50a4f15c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-b1d966df-81f3-469a-8399-b6d097597b86,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-af2fa1ff-ce73-49a3-842f-10f439a86ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-cec9567f-cec9-4d6e-8d3c-5009eb9a0447,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-a0449ff2-8bd3-445a-8beb-c0b0e0070f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460383843-172.17.0.15-1597130328892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37527,DS-55df06b8-7c71-4e84-918a-e302cb7d9a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-a4d4b95e-2862-48c0-bcb3-bd0910462350,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-0cc7de64-95f5-4b37-a4f1-5b22f92ca89e,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-f1255886-3df1-45f3-b8eb-2f50a4f15c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-b1d966df-81f3-469a-8399-b6d097597b86,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-af2fa1ff-ce73-49a3-842f-10f439a86ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-cec9567f-cec9-4d6e-8d3c-5009eb9a0447,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-a0449ff2-8bd3-445a-8beb-c0b0e0070f53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102257068-172.17.0.15-1597130410995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-de554574-5087-4f6d-bf72-2bf1ccb78588,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-5afa3b3e-c8c7-41d8-bc44-ffc7e96e836d,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-19d065f9-aaa0-4a00-aa7a-92f9618b0e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-a2d4d7d5-33b9-4bfe-948e-ffb12b67d381,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-1f22c7c8-f467-4c35-bcd9-da51a34eafa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-97463cbd-740e-491e-a7dc-2f018f44b701,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-0a03779d-1e3c-4585-be6b-8b7fef8e3b75,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-401ddb83-cb42-4ee0-bde5-2ece4d9b6dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102257068-172.17.0.15-1597130410995:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33354,DS-de554574-5087-4f6d-bf72-2bf1ccb78588,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-5afa3b3e-c8c7-41d8-bc44-ffc7e96e836d,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-19d065f9-aaa0-4a00-aa7a-92f9618b0e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-a2d4d7d5-33b9-4bfe-948e-ffb12b67d381,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-1f22c7c8-f467-4c35-bcd9-da51a34eafa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-97463cbd-740e-491e-a7dc-2f018f44b701,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-0a03779d-1e3c-4585-be6b-8b7fef8e3b75,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-401ddb83-cb42-4ee0-bde5-2ece4d9b6dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269659360-172.17.0.15-1597130553571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-99e1661e-b785-4884-96d7-b67a3c3e9f43,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-b8cf2a70-3004-4ff9-a8ec-40460ae694bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-a244db77-4ff3-4b09-a2cf-2dd301129e82,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-3e730ab9-a895-4bcb-8499-f5b2ded1c89d,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-68155f02-0fd6-4b73-83f8-04bd2a0932e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-352421fa-d457-411f-86c5-fe838257e616,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-8ad846d6-0fe6-49e6-a46a-8e66cf7e207b,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-9495dd72-6877-4714-9d7d-b057f19a9f33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269659360-172.17.0.15-1597130553571:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-99e1661e-b785-4884-96d7-b67a3c3e9f43,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-b8cf2a70-3004-4ff9-a8ec-40460ae694bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-a244db77-4ff3-4b09-a2cf-2dd301129e82,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-3e730ab9-a895-4bcb-8499-f5b2ded1c89d,DISK], DatanodeInfoWithStorage[127.0.0.1:46628,DS-68155f02-0fd6-4b73-83f8-04bd2a0932e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-352421fa-d457-411f-86c5-fe838257e616,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-8ad846d6-0fe6-49e6-a46a-8e66cf7e207b,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-9495dd72-6877-4714-9d7d-b057f19a9f33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173802050-172.17.0.15-1597130601417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-90142894-1ee7-4ca4-96ef-9989ff999124,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-b0538544-80cc-4286-977b-baebda26020f,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-52a5a7c3-b1d7-4805-941d-3482d2f2f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-5c60e6ac-c68c-4491-8602-5ed222c015b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-ab26edb0-0ccc-4998-9d90-0e5547b1a6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-07702d68-2a72-469b-9532-d5e70b13ed2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-59db7d0c-26e7-43fd-967f-343626be7060,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-4ec96f8c-7f09-4340-9471-5cfe8bf27469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173802050-172.17.0.15-1597130601417:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-90142894-1ee7-4ca4-96ef-9989ff999124,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-b0538544-80cc-4286-977b-baebda26020f,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-52a5a7c3-b1d7-4805-941d-3482d2f2f93c,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-5c60e6ac-c68c-4491-8602-5ed222c015b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-ab26edb0-0ccc-4998-9d90-0e5547b1a6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-07702d68-2a72-469b-9532-d5e70b13ed2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-59db7d0c-26e7-43fd-967f-343626be7060,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-4ec96f8c-7f09-4340-9471-5cfe8bf27469,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525091125-172.17.0.15-1597130641479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34225,DS-547213b3-7e01-4047-8db8-6a7b95bb6a75,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-cd21b3d2-defd-4cb3-9f61-98d16b017de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-0229e51c-887c-48e9-89e5-f1b308609db5,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-d479e47f-cfa3-44a0-80a9-268426a12f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1b1f2916-edb6-488f-bee7-a28f7c26d090,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-0c5a9c4f-95b5-48a8-ba88-3f4ea4d8ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-4e1813cb-8ec9-4d12-b5f5-c8777f2942e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-1c84c8fd-a9bf-4cf7-823e-c7fdcfec3d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-525091125-172.17.0.15-1597130641479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34225,DS-547213b3-7e01-4047-8db8-6a7b95bb6a75,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-cd21b3d2-defd-4cb3-9f61-98d16b017de9,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-0229e51c-887c-48e9-89e5-f1b308609db5,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-d479e47f-cfa3-44a0-80a9-268426a12f38,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-1b1f2916-edb6-488f-bee7-a28f7c26d090,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-0c5a9c4f-95b5-48a8-ba88-3f4ea4d8ca7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-4e1813cb-8ec9-4d12-b5f5-c8777f2942e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34602,DS-1c84c8fd-a9bf-4cf7-823e-c7fdcfec3d55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059097250-172.17.0.15-1597130732012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46502,DS-89583bea-2774-430d-9d60-9231e0fb2a07,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-93783ce0-0e58-416f-86ba-6efa5e73e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-c8579f65-3c4f-4e88-86b8-fa7227f99110,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-d1653a79-c81f-447b-bc04-4aabdcc76dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-ce391c87-306d-4a6e-9494-024494009067,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-0a5e1b38-726d-46fc-b874-746427b2a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-54d87d17-b176-4901-a326-0b421b397e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-d3da7eba-893a-4efa-ba6c-72692f00e2dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059097250-172.17.0.15-1597130732012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46502,DS-89583bea-2774-430d-9d60-9231e0fb2a07,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-93783ce0-0e58-416f-86ba-6efa5e73e4e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-c8579f65-3c4f-4e88-86b8-fa7227f99110,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-d1653a79-c81f-447b-bc04-4aabdcc76dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-ce391c87-306d-4a6e-9494-024494009067,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-0a5e1b38-726d-46fc-b874-746427b2a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-54d87d17-b176-4901-a326-0b421b397e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-d3da7eba-893a-4efa-ba6c-72692f00e2dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252456016-172.17.0.15-1597130780104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-4c7e967c-91ce-4582-bd60-fe3212fd7291,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-008a2f3f-d9fa-485d-89ac-eee488254081,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-ac696501-153e-44bd-bc97-40e3e5125316,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-0c29c23c-7206-4806-929c-fdfe4f9c275b,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-f5f244d9-9370-4b37-98e6-c7ef6991de37,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-5e2fab44-55fc-4d29-b1ae-c54fc57ed64d,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-7a8f1eba-db88-4e4e-af39-d63ddc1b3695,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-ce9e992a-09c3-4bc6-8efc-861e922cd281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252456016-172.17.0.15-1597130780104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-4c7e967c-91ce-4582-bd60-fe3212fd7291,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-008a2f3f-d9fa-485d-89ac-eee488254081,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-ac696501-153e-44bd-bc97-40e3e5125316,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-0c29c23c-7206-4806-929c-fdfe4f9c275b,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-f5f244d9-9370-4b37-98e6-c7ef6991de37,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-5e2fab44-55fc-4d29-b1ae-c54fc57ed64d,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-7a8f1eba-db88-4e4e-af39-d63ddc1b3695,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-ce9e992a-09c3-4bc6-8efc-861e922cd281,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438445058-172.17.0.15-1597130937033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36498,DS-9b78a7f0-e426-4036-8fca-fdef19cc4e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-e2d5dae9-73ea-47af-bf59-3395935f113b,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-effd7406-204f-4e90-a534-6aa8c29a802e,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-b6e4a45b-6dc2-4b51-84af-16d2b32e801f,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-233ff400-1003-4a2b-9b10-9addd94db4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-a7ab80eb-d753-4259-98bc-589de31fd669,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-24d01979-3de5-475a-9d05-1cc18ab54836,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-85fc0a27-9a59-44de-b120-ebd61efe4941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1438445058-172.17.0.15-1597130937033:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36498,DS-9b78a7f0-e426-4036-8fca-fdef19cc4e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-e2d5dae9-73ea-47af-bf59-3395935f113b,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-effd7406-204f-4e90-a534-6aa8c29a802e,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-b6e4a45b-6dc2-4b51-84af-16d2b32e801f,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-233ff400-1003-4a2b-9b10-9addd94db4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41610,DS-a7ab80eb-d753-4259-98bc-589de31fd669,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-24d01979-3de5-475a-9d05-1cc18ab54836,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-85fc0a27-9a59-44de-b120-ebd61efe4941,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564494720-172.17.0.15-1597132799524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39839,DS-300579c4-566f-4f56-a12e-c36aab75343c,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-78a913af-897d-4d08-a031-57d50452df35,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-624423b4-1d7a-4248-b36b-15e8bc4514ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-b9329bf8-9294-4553-a8f0-1ed5a68802f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-8b023ae6-caf6-4671-a844-04d8261811ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-fe1f5a22-0211-4da7-b9d4-130eeefdcaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-7178983f-c163-4cf5-826d-7988621e8d97,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-6fcb0ae5-191e-43a8-b201-58b566a93494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1564494720-172.17.0.15-1597132799524:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39839,DS-300579c4-566f-4f56-a12e-c36aab75343c,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-78a913af-897d-4d08-a031-57d50452df35,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-624423b4-1d7a-4248-b36b-15e8bc4514ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-b9329bf8-9294-4553-a8f0-1ed5a68802f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-8b023ae6-caf6-4671-a844-04d8261811ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-fe1f5a22-0211-4da7-b9d4-130eeefdcaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-7178983f-c163-4cf5-826d-7988621e8d97,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-6fcb0ae5-191e-43a8-b201-58b566a93494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816047088-172.17.0.15-1597133302481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-f087d036-f012-4045-930e-11c166dff83a,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-e187a887-d682-4372-875f-2d16b14a3f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-4cf602a5-6c8b-4537-81d4-7bdd125e4140,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-7cdc73ee-4685-4123-9e6a-4940bb81211f,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-2147c5df-cd58-43db-8b87-1e94ed1b6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-7ad0cb6b-930c-4cfd-8379-8ed77a334eee,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-022d30a9-86e8-40f7-9763-2c8e7a7f7448,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-766ffebe-8f8b-4461-b09c-ff8e4f2be64c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816047088-172.17.0.15-1597133302481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38328,DS-f087d036-f012-4045-930e-11c166dff83a,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-e187a887-d682-4372-875f-2d16b14a3f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-4cf602a5-6c8b-4537-81d4-7bdd125e4140,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-7cdc73ee-4685-4123-9e6a-4940bb81211f,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-2147c5df-cd58-43db-8b87-1e94ed1b6c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-7ad0cb6b-930c-4cfd-8379-8ed77a334eee,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-022d30a9-86e8-40f7-9763-2c8e7a7f7448,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-766ffebe-8f8b-4461-b09c-ff8e4f2be64c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627224205-172.17.0.15-1597133618956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-312118cd-12eb-41d6-9fd6-17d92944b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-833c4f67-167b-464d-89bb-9dcd75235889,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-bd6fa331-9637-428e-9329-ff35bc8886ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-5c2e711e-6ea0-4482-a785-e88015b39863,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-699cfd98-f382-4cf4-be2a-facb91becdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-6184a3bf-d5ed-491d-ba6b-b53e38803dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-9609e0a6-2271-45f9-93cf-4a88bcfe7b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-a4e818c8-5b57-4ef5-bb5d-a164cbc9b9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627224205-172.17.0.15-1597133618956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44841,DS-312118cd-12eb-41d6-9fd6-17d92944b05e,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-833c4f67-167b-464d-89bb-9dcd75235889,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-bd6fa331-9637-428e-9329-ff35bc8886ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-5c2e711e-6ea0-4482-a785-e88015b39863,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-699cfd98-f382-4cf4-be2a-facb91becdcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-6184a3bf-d5ed-491d-ba6b-b53e38803dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-9609e0a6-2271-45f9-93cf-4a88bcfe7b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-a4e818c8-5b57-4ef5-bb5d-a164cbc9b9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513846319-172.17.0.15-1597134239245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45290,DS-10bdc5f9-d74b-446b-8f8e-664e5f502f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-194aed87-aa90-40a7-b10a-bed632cecedd,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-87e9e1bf-e2d7-4389-8a4c-78bfb42c7beb,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-820a88f0-cdd4-46a0-b9c0-0f4a4eeefb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-be5e276a-2030-4b4b-8b56-e81f86f49a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-8ad099f6-edce-47b6-b6ff-b72d90583335,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-ca044c07-337a-498d-ba5c-6117a58a3a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-d4888b36-0075-4bf1-a119-3226fd7da8d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513846319-172.17.0.15-1597134239245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45290,DS-10bdc5f9-d74b-446b-8f8e-664e5f502f31,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-194aed87-aa90-40a7-b10a-bed632cecedd,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-87e9e1bf-e2d7-4389-8a4c-78bfb42c7beb,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-820a88f0-cdd4-46a0-b9c0-0f4a4eeefb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-be5e276a-2030-4b4b-8b56-e81f86f49a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-8ad099f6-edce-47b6-b6ff-b72d90583335,DISK], DatanodeInfoWithStorage[127.0.0.1:39187,DS-ca044c07-337a-498d-ba5c-6117a58a3a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-d4888b36-0075-4bf1-a119-3226fd7da8d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808463065-172.17.0.15-1597134429420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-fc001cd3-d2f4-4e1d-96f2-8d5a5a06575a,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-b4c17013-115e-4488-a35d-1598b179393e,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-ff91a2ad-c188-4f1d-85fc-de9f3cda911f,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-f9f8eef6-5155-4bcd-921b-9876341c22fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-d65ccd2c-21da-4de5-8ec0-6aa29f339cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-97b4da26-a2ff-4127-aa1d-5ba974bed913,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-ae4f1726-3f22-4c70-b272-95db0169d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-7e79e00c-d719-4af3-9662-2180b8c002fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808463065-172.17.0.15-1597134429420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42240,DS-fc001cd3-d2f4-4e1d-96f2-8d5a5a06575a,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-b4c17013-115e-4488-a35d-1598b179393e,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-ff91a2ad-c188-4f1d-85fc-de9f3cda911f,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-f9f8eef6-5155-4bcd-921b-9876341c22fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-d65ccd2c-21da-4de5-8ec0-6aa29f339cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-97b4da26-a2ff-4127-aa1d-5ba974bed913,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-ae4f1726-3f22-4c70-b272-95db0169d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45000,DS-7e79e00c-d719-4af3-9662-2180b8c002fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519942387-172.17.0.15-1597134628543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33327,DS-c2a2b789-8c06-4c05-8f33-d84e30ee5af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-0a5a666c-8a53-48b9-aa22-14d2f9c11c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-86716e21-620a-41ea-ba02-eaec9038e120,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-90318466-501c-413b-a916-0c136b2c6407,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-6a81f4d5-fd10-4c76-87e1-59b2053b9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-19b40cf8-8605-4536-a0fa-f564a63b26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-f5b661ca-fc98-4e63-bff0-993257b02987,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-7c9c25f8-c7b7-4721-abab-3bdb9db27f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-519942387-172.17.0.15-1597134628543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33327,DS-c2a2b789-8c06-4c05-8f33-d84e30ee5af1,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-0a5a666c-8a53-48b9-aa22-14d2f9c11c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-86716e21-620a-41ea-ba02-eaec9038e120,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-90318466-501c-413b-a916-0c136b2c6407,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-6a81f4d5-fd10-4c76-87e1-59b2053b9e90,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-19b40cf8-8605-4536-a0fa-f564a63b26b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-f5b661ca-fc98-4e63-bff0-993257b02987,DISK], DatanodeInfoWithStorage[127.0.0.1:34161,DS-7c9c25f8-c7b7-4721-abab-3bdb9db27f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231659228-172.17.0.15-1597134900319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-209a43d3-ec36-4961-bf2f-b0bd86f38b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-21853506-ce1e-41e3-8973-24c1846897e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-98d8098a-a584-4944-9c7f-0f02107622c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-9cc09ea3-53db-46f2-ba4d-2aa4d72c0da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-a3fde29b-0c48-421a-832b-3789c29944a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-03bf8654-1edb-4369-a6f7-d75f35be42fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-aaeec346-c24d-4ade-898b-01150e5eaafb,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-22b3dbc8-466e-4d3b-8d4f-c73eb2f8edc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1231659228-172.17.0.15-1597134900319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-209a43d3-ec36-4961-bf2f-b0bd86f38b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-21853506-ce1e-41e3-8973-24c1846897e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-98d8098a-a584-4944-9c7f-0f02107622c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-9cc09ea3-53db-46f2-ba4d-2aa4d72c0da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-a3fde29b-0c48-421a-832b-3789c29944a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-03bf8654-1edb-4369-a6f7-d75f35be42fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-aaeec346-c24d-4ade-898b-01150e5eaafb,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-22b3dbc8-466e-4d3b-8d4f-c73eb2f8edc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654150348-172.17.0.15-1597135158219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-a3d2f4f8-c17d-4af3-af95-c0246227ebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-42c3632d-9dce-4b41-9eea-984715749800,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-b7ffd86f-0b74-4735-b9b4-5afe962cd700,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-3c71e2ac-9c2b-406a-a172-ff370e06178c,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-b3bc76d0-7ad9-4b4d-830b-fe10052685e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-3e66a139-55d4-4664-b456-ed1cca3a9d55,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-13b82827-74a3-42be-8f75-4f8708c16487,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-1218742e-baf3-4383-8407-1a4b7c5348c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654150348-172.17.0.15-1597135158219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-a3d2f4f8-c17d-4af3-af95-c0246227ebc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-42c3632d-9dce-4b41-9eea-984715749800,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-b7ffd86f-0b74-4735-b9b4-5afe962cd700,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-3c71e2ac-9c2b-406a-a172-ff370e06178c,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-b3bc76d0-7ad9-4b4d-830b-fe10052685e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-3e66a139-55d4-4664-b456-ed1cca3a9d55,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-13b82827-74a3-42be-8f75-4f8708c16487,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-1218742e-baf3-4383-8407-1a4b7c5348c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855759003-172.17.0.15-1597135247797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-e302cd4e-1ba8-4fcd-bc1a-fe7d3c671b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-0aba942e-f35e-49ef-ae64-6a9f2ca3cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-3308e571-5b8d-443b-ac34-358abecde917,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-5182c55d-6f6c-4e86-82d7-1604fc8ce3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-c2725733-2eb3-4d5c-a4bd-8813d6a6c20e,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-b5bc82d4-9e45-4537-b51b-744d082b4678,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-21db2279-5bf7-4f67-b859-146ea039652d,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-af7adbda-2aa9-463b-863d-91797451d85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855759003-172.17.0.15-1597135247797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35060,DS-e302cd4e-1ba8-4fcd-bc1a-fe7d3c671b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-0aba942e-f35e-49ef-ae64-6a9f2ca3cac4,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-3308e571-5b8d-443b-ac34-358abecde917,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-5182c55d-6f6c-4e86-82d7-1604fc8ce3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-c2725733-2eb3-4d5c-a4bd-8813d6a6c20e,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-b5bc82d4-9e45-4537-b51b-744d082b4678,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-21db2279-5bf7-4f67-b859-146ea039652d,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-af7adbda-2aa9-463b-863d-91797451d85f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010014888-172.17.0.15-1597135328342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44012,DS-9761fa0e-54b9-4dfc-8a83-abbfe3491a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-131de663-1ce6-4cd0-bf23-4cb53c95e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-b47a0480-1b8c-4fa0-b1ff-6d4f2ab6bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-fc1edd65-9660-4170-a451-2d91f243da25,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-06b7b2a8-5994-420c-97a3-af3fb7de8a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a2bd3c03-a022-468d-9d8d-866b6d9a1c34,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-95853bbc-ca69-4fd1-a574-765af730d700,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-ebcdfc26-38a7-4755-8f89-8e16c6f9f6fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010014888-172.17.0.15-1597135328342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44012,DS-9761fa0e-54b9-4dfc-8a83-abbfe3491a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-131de663-1ce6-4cd0-bf23-4cb53c95e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-b47a0480-1b8c-4fa0-b1ff-6d4f2ab6bc68,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-fc1edd65-9660-4170-a451-2d91f243da25,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-06b7b2a8-5994-420c-97a3-af3fb7de8a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-a2bd3c03-a022-468d-9d8d-866b6d9a1c34,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-95853bbc-ca69-4fd1-a574-765af730d700,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-ebcdfc26-38a7-4755-8f89-8e16c6f9f6fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582813449-172.17.0.15-1597135808043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-36e7e3aa-4841-4329-b8c0-4e1673198252,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-80ad61b5-a3fd-4443-b6ee-fe9af4b7a757,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-27520bb0-e0b8-4062-a05b-c596e6d4359a,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-714eccdd-2030-47d0-acf7-7cafeb6d0902,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-142704c3-17d9-4451-a1e3-52186abd4a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-f2c172d8-a19c-42b0-a204-1559c0f75daa,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-c527d4cb-b62d-4f0e-8601-a7d05610a08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-7e41aa26-c754-443d-97b9-ac5d12917bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582813449-172.17.0.15-1597135808043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-36e7e3aa-4841-4329-b8c0-4e1673198252,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-80ad61b5-a3fd-4443-b6ee-fe9af4b7a757,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-27520bb0-e0b8-4062-a05b-c596e6d4359a,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-714eccdd-2030-47d0-acf7-7cafeb6d0902,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-142704c3-17d9-4451-a1e3-52186abd4a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-f2c172d8-a19c-42b0-a204-1559c0f75daa,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-c527d4cb-b62d-4f0e-8601-a7d05610a08c,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-7e41aa26-c754-443d-97b9-ac5d12917bcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6436
