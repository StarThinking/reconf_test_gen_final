reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550755679-172.17.0.2-1597102038139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-cdf0dcfa-b450-4bf7-b5ed-f81c7229db1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-f0bd16b7-0e36-4644-9278-88b44b6da240,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-689df959-f391-49e5-a8c8-b15176f8bb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-a0f15e17-630d-4623-8acf-6a106f7b7291,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-09c9f6d4-b4d7-44f8-bf51-0b7a5237fb79,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-7a51d995-746e-4d1e-8c1a-42fcb2615b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-8d96d3a4-1bea-4f89-819a-c00284790c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-badfd2be-c97a-4741-81b0-e1d198be4ab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-550755679-172.17.0.2-1597102038139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35343,DS-cdf0dcfa-b450-4bf7-b5ed-f81c7229db1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-f0bd16b7-0e36-4644-9278-88b44b6da240,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-689df959-f391-49e5-a8c8-b15176f8bb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-a0f15e17-630d-4623-8acf-6a106f7b7291,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-09c9f6d4-b4d7-44f8-bf51-0b7a5237fb79,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-7a51d995-746e-4d1e-8c1a-42fcb2615b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-8d96d3a4-1bea-4f89-819a-c00284790c59,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-badfd2be-c97a-4741-81b0-e1d198be4ab8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734957623-172.17.0.2-1597102176032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-7d7c5320-362c-42a3-9808-c7aec9b7df02,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-929c3cbf-b696-43af-9b8e-d35d77b9b679,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-ce3ec1e4-ca2a-4009-8a16-d248ddf5e328,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-91d4cb5f-d5ab-482e-a164-1c4920b4eb72,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-b160bec6-5bc0-4bfc-9f0e-caaafd3a3058,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-2ff12f2a-c69b-4723-834b-4045e06c72e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-b8e877a3-15ac-4339-89f4-4e1a4d2bf3df,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-5e1e2a16-af65-41d5-8f4c-a9e8e9ce30bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1734957623-172.17.0.2-1597102176032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44658,DS-7d7c5320-362c-42a3-9808-c7aec9b7df02,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-929c3cbf-b696-43af-9b8e-d35d77b9b679,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-ce3ec1e4-ca2a-4009-8a16-d248ddf5e328,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-91d4cb5f-d5ab-482e-a164-1c4920b4eb72,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-b160bec6-5bc0-4bfc-9f0e-caaafd3a3058,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-2ff12f2a-c69b-4723-834b-4045e06c72e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-b8e877a3-15ac-4339-89f4-4e1a4d2bf3df,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-5e1e2a16-af65-41d5-8f4c-a9e8e9ce30bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124883098-172.17.0.2-1597102214647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-1945d42e-41fb-4470-a53c-547409c13def,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-a0899130-533a-47d1-92ef-9dcf07e3a459,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-51c26008-df56-4e49-8f1b-a0a9b1533f16,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-a2c71dd5-fcc0-496a-bf58-3377aaa959c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-844cafac-cd3c-442d-a22c-afd4e130f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-e067e157-3546-4a67-85b7-1c290698f614,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-138694c5-b24e-4f5f-80a7-e11ad3df628d,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-cb66d2ab-225f-4e4f-8adf-91034ce24b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124883098-172.17.0.2-1597102214647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40424,DS-1945d42e-41fb-4470-a53c-547409c13def,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-a0899130-533a-47d1-92ef-9dcf07e3a459,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-51c26008-df56-4e49-8f1b-a0a9b1533f16,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-a2c71dd5-fcc0-496a-bf58-3377aaa959c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-844cafac-cd3c-442d-a22c-afd4e130f2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-e067e157-3546-4a67-85b7-1c290698f614,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-138694c5-b24e-4f5f-80a7-e11ad3df628d,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-cb66d2ab-225f-4e4f-8adf-91034ce24b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960059696-172.17.0.2-1597102248192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40176,DS-2e5f3e0b-03fe-4df6-ac12-dae9c267b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-5df41832-80ed-4474-a12c-3d1eb2353c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-9b3c2886-1b9c-47af-8ec9-da3919ad8e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-be21ccfa-482d-463d-97d6-82350433df86,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-33058725-4402-47eb-bceb-2b0433e17bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-404c3681-074f-4ff2-9c76-8e1fd42336bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-1c780572-4bb6-4b18-a832-6c81be345737,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-720f4f66-2c94-47a4-bd9d-2ce17eeb81a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1960059696-172.17.0.2-1597102248192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40176,DS-2e5f3e0b-03fe-4df6-ac12-dae9c267b4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-5df41832-80ed-4474-a12c-3d1eb2353c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-9b3c2886-1b9c-47af-8ec9-da3919ad8e84,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-be21ccfa-482d-463d-97d6-82350433df86,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-33058725-4402-47eb-bceb-2b0433e17bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-404c3681-074f-4ff2-9c76-8e1fd42336bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-1c780572-4bb6-4b18-a832-6c81be345737,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-720f4f66-2c94-47a4-bd9d-2ce17eeb81a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903237847-172.17.0.2-1597102557587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-5b807132-d6d1-4cae-91f0-7a99f7846bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-2e5139ff-b0a1-4203-8d57-83ad8ec91fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-96d43a12-50c6-4b05-8b06-2128e1690a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-2554fa53-bf1f-4e7b-b581-53e46a856700,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-f95baf76-e6a2-48ef-a562-6e855bf3ef50,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-fe2af2dc-ed26-4149-8ae4-e7f1883014fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-223ae243-8857-403c-bfa0-3e4e19c74e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-2704a421-3f87-4930-90f3-4c66e53488f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903237847-172.17.0.2-1597102557587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43354,DS-5b807132-d6d1-4cae-91f0-7a99f7846bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35726,DS-2e5139ff-b0a1-4203-8d57-83ad8ec91fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-96d43a12-50c6-4b05-8b06-2128e1690a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-2554fa53-bf1f-4e7b-b581-53e46a856700,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-f95baf76-e6a2-48ef-a562-6e855bf3ef50,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-fe2af2dc-ed26-4149-8ae4-e7f1883014fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-223ae243-8857-403c-bfa0-3e4e19c74e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-2704a421-3f87-4930-90f3-4c66e53488f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575495771-172.17.0.2-1597102587955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35692,DS-8d807f4a-26f8-4c54-8f65-f1988ece86e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-1f80292f-ca33-485b-af4e-d44b1ca29470,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-f4c52c4c-8cd2-4509-8bc9-5e3c67197057,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-fd4e93c1-c401-4e08-a7b3-61ee4cd0150b,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-935aed0b-738e-4310-96c5-a22ce2f324f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-43e76bd2-51c7-47e3-88b1-597f3c2a7b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-f0500125-93af-4042-8b7e-90014e7d64a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-c2a7adc8-8947-4d7a-afed-af2629e9ff48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575495771-172.17.0.2-1597102587955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35692,DS-8d807f4a-26f8-4c54-8f65-f1988ece86e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-1f80292f-ca33-485b-af4e-d44b1ca29470,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-f4c52c4c-8cd2-4509-8bc9-5e3c67197057,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-fd4e93c1-c401-4e08-a7b3-61ee4cd0150b,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-935aed0b-738e-4310-96c5-a22ce2f324f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-43e76bd2-51c7-47e3-88b1-597f3c2a7b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-f0500125-93af-4042-8b7e-90014e7d64a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-c2a7adc8-8947-4d7a-afed-af2629e9ff48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419718668-172.17.0.2-1597102868111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36747,DS-afc1a6d3-845e-4531-9834-f85cac09334f,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-4a1bb287-940d-404d-9b4b-ddf44f60ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-924e53f3-eb75-40fe-a383-c7010f95a704,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-e459a64c-f9b6-49d0-a469-5044c66793ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-9d5f7494-e978-4033-b9fb-8e92b5277157,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-cd2b7dd7-1861-4fd1-9c21-c09bf5f7742f,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-7a7d132b-8e9a-42f7-8b1b-3b917c2409ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-3c8d6ef6-258d-4b35-8310-fcfcf3ce90e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419718668-172.17.0.2-1597102868111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36747,DS-afc1a6d3-845e-4531-9834-f85cac09334f,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-4a1bb287-940d-404d-9b4b-ddf44f60ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-924e53f3-eb75-40fe-a383-c7010f95a704,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-e459a64c-f9b6-49d0-a469-5044c66793ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-9d5f7494-e978-4033-b9fb-8e92b5277157,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-cd2b7dd7-1861-4fd1-9c21-c09bf5f7742f,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-7a7d132b-8e9a-42f7-8b1b-3b917c2409ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-3c8d6ef6-258d-4b35-8310-fcfcf3ce90e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818318166-172.17.0.2-1597102902525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-9ea7acbe-9eee-4d67-90a3-8d728ee749b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-2449c873-0c34-4e4e-a6bf-574f4478f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-fa7558b8-1057-4a71-83de-d335f7f2deff,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-709b5ff7-7e59-43e6-a12f-0c75f8694953,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-c8e13c4a-4822-4513-bc14-a1800ea8723a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-f1d3f719-c1b7-4681-a6b7-7726eaf26d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-0cef0166-46e7-4b68-81cf-a16b0aad3713,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-15cb1494-5350-4920-8ddd-a3c958154112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818318166-172.17.0.2-1597102902525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35095,DS-9ea7acbe-9eee-4d67-90a3-8d728ee749b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-2449c873-0c34-4e4e-a6bf-574f4478f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-fa7558b8-1057-4a71-83de-d335f7f2deff,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-709b5ff7-7e59-43e6-a12f-0c75f8694953,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-c8e13c4a-4822-4513-bc14-a1800ea8723a,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-f1d3f719-c1b7-4681-a6b7-7726eaf26d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-0cef0166-46e7-4b68-81cf-a16b0aad3713,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-15cb1494-5350-4920-8ddd-a3c958154112,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310079716-172.17.0.2-1597102937965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-2291f5bd-0cb8-4667-82da-8c8955d9d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-a8beb193-46a5-453d-9c39-4c47f45f9082,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-e21b6b0d-5736-4f33-a4a1-e48b1100eda6,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-ccc8c480-8ae8-42b4-b1d4-3719b8211aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-e7526c94-8109-40b4-aecd-adb3208b34ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-e94f5393-cbab-4291-a540-0d867115e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-b0e161cb-a9df-4eee-8014-943f33b545b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-73e39667-6a7d-4cd7-8763-3832724e7c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310079716-172.17.0.2-1597102937965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-2291f5bd-0cb8-4667-82da-8c8955d9d25c,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-a8beb193-46a5-453d-9c39-4c47f45f9082,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-e21b6b0d-5736-4f33-a4a1-e48b1100eda6,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-ccc8c480-8ae8-42b4-b1d4-3719b8211aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-e7526c94-8109-40b4-aecd-adb3208b34ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-e94f5393-cbab-4291-a540-0d867115e5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-b0e161cb-a9df-4eee-8014-943f33b545b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38781,DS-73e39667-6a7d-4cd7-8763-3832724e7c00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968931452-172.17.0.2-1597104235423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37207,DS-a1eecf87-25e3-444e-b692-7868a2c591d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-8571322e-c668-42e5-b38e-9dd93a2386f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-48a4c319-c2b8-4ef3-af5d-8de932fe426b,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-61222d86-2463-4667-b0f5-80a1f28fd82a,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-aba44a08-f35b-4f57-af49-0e02c984eb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-9e4b761f-66d8-40b8-af64-99d20fcf1866,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-c5e53b8e-94f7-4327-b1d8-59661c7cfd14,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-5d514f6c-b15d-4acf-a260-25c9ab953826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968931452-172.17.0.2-1597104235423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37207,DS-a1eecf87-25e3-444e-b692-7868a2c591d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-8571322e-c668-42e5-b38e-9dd93a2386f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-48a4c319-c2b8-4ef3-af5d-8de932fe426b,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-61222d86-2463-4667-b0f5-80a1f28fd82a,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-aba44a08-f35b-4f57-af49-0e02c984eb5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-9e4b761f-66d8-40b8-af64-99d20fcf1866,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-c5e53b8e-94f7-4327-b1d8-59661c7cfd14,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-5d514f6c-b15d-4acf-a260-25c9ab953826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375814959-172.17.0.2-1597104949071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35372,DS-1940ee2b-9554-4207-99b1-120f9b62c726,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-089c577f-de37-46ef-ab93-6608fbb98e29,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-7d3c30e0-24f1-41eb-b29d-6154229f74ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-3752e5ff-5203-4ef7-8e66-08bd7345ed05,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-c02787a7-0042-46d5-bd2e-84950acef594,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-b7e675bb-5fd4-404c-8837-929412e1b764,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-6805fa26-18d9-4033-a9b6-12b312258c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-f75e6f1a-54a7-4bff-9ec7-c4898bcbd522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375814959-172.17.0.2-1597104949071:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35372,DS-1940ee2b-9554-4207-99b1-120f9b62c726,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-089c577f-de37-46ef-ab93-6608fbb98e29,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-7d3c30e0-24f1-41eb-b29d-6154229f74ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-3752e5ff-5203-4ef7-8e66-08bd7345ed05,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-c02787a7-0042-46d5-bd2e-84950acef594,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-b7e675bb-5fd4-404c-8837-929412e1b764,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-6805fa26-18d9-4033-a9b6-12b312258c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-f75e6f1a-54a7-4bff-9ec7-c4898bcbd522,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372859634-172.17.0.2-1597104984774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44974,DS-abb7dec5-6b7d-4684-9204-6dec19b3c526,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-edb7e8f4-5562-4d25-941b-db49c4fd7d40,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-a9b82cc2-b57b-4692-9436-804f56bbc81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-6ca41011-a30c-4868-af1d-6f4fe118b452,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-c6d6c656-dc19-46c6-a9c6-6466631f85bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-80859cc9-042a-40df-9660-53da147ee56e,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-fc95c5df-1fdc-474b-8adf-0175b4e2a778,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-90482fec-3dc4-441a-a369-7d3459256b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-372859634-172.17.0.2-1597104984774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44974,DS-abb7dec5-6b7d-4684-9204-6dec19b3c526,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-edb7e8f4-5562-4d25-941b-db49c4fd7d40,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-a9b82cc2-b57b-4692-9436-804f56bbc81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-6ca41011-a30c-4868-af1d-6f4fe118b452,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-c6d6c656-dc19-46c6-a9c6-6466631f85bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-80859cc9-042a-40df-9660-53da147ee56e,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-fc95c5df-1fdc-474b-8adf-0175b4e2a778,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-90482fec-3dc4-441a-a369-7d3459256b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544015417-172.17.0.2-1597105171921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-0bf1c155-367d-4acf-af3e-c98156f60dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-e5f673d4-8fc0-4be0-888a-95617de66144,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-1f2ed23e-f01e-48eb-9301-47762983ae1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-57ff6b85-8386-4fcf-ac37-529bcac2fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-3ec6eaf2-56eb-434e-b9d6-820aff74b046,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-07e4a5a8-1a3a-4d94-8ba0-d87e8bcc282d,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-d5688963-cec6-46b8-8558-f6a6e5ca471e,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-db4c50a2-71aa-4845-b4bf-d26b095c55c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544015417-172.17.0.2-1597105171921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37342,DS-0bf1c155-367d-4acf-af3e-c98156f60dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-e5f673d4-8fc0-4be0-888a-95617de66144,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-1f2ed23e-f01e-48eb-9301-47762983ae1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37141,DS-57ff6b85-8386-4fcf-ac37-529bcac2fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41842,DS-3ec6eaf2-56eb-434e-b9d6-820aff74b046,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-07e4a5a8-1a3a-4d94-8ba0-d87e8bcc282d,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-d5688963-cec6-46b8-8558-f6a6e5ca471e,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-db4c50a2-71aa-4845-b4bf-d26b095c55c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609655076-172.17.0.2-1597106141312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-8db44a3c-0605-47c9-8077-ea12887a051d,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-4d48daf2-e632-4bb0-a551-fb3474cc0bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-259d7348-813b-43ea-84c4-52c4a5205f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-8e1a12f4-9944-4f7f-9e84-94369311d4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-b2cc878b-cb03-45d8-998f-16e6c161ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-e960eb5b-8a1d-4ba8-ba94-fd8fb067447c,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-62aafee1-3d11-4233-883c-ec762458b4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-17e10c74-b26e-40dc-8824-8f2a38397278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609655076-172.17.0.2-1597106141312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40086,DS-8db44a3c-0605-47c9-8077-ea12887a051d,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-4d48daf2-e632-4bb0-a551-fb3474cc0bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35903,DS-259d7348-813b-43ea-84c4-52c4a5205f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-8e1a12f4-9944-4f7f-9e84-94369311d4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-b2cc878b-cb03-45d8-998f-16e6c161ad45,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-e960eb5b-8a1d-4ba8-ba94-fd8fb067447c,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-62aafee1-3d11-4233-883c-ec762458b4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-17e10c74-b26e-40dc-8824-8f2a38397278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604241090-172.17.0.2-1597106175109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-bee5b515-a75c-499f-a3da-88b1f22dbced,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-cfb60298-575a-470e-adeb-d24c4acbd090,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-17748477-2197-464b-9726-d706354e9155,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-d35af3f9-f933-45a7-8821-66ff09977984,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-a39afaaa-6552-4868-9702-a4f2a805fbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-95c1199a-048f-48e4-a8bc-eb1f31466e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-03392b2b-d9cc-4e9f-8e9a-ec37326783bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-b641750c-7ea6-4d8e-a3dc-4d2f2f0af45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604241090-172.17.0.2-1597106175109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34528,DS-bee5b515-a75c-499f-a3da-88b1f22dbced,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-cfb60298-575a-470e-adeb-d24c4acbd090,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-17748477-2197-464b-9726-d706354e9155,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-d35af3f9-f933-45a7-8821-66ff09977984,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-a39afaaa-6552-4868-9702-a4f2a805fbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-95c1199a-048f-48e4-a8bc-eb1f31466e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-03392b2b-d9cc-4e9f-8e9a-ec37326783bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-b641750c-7ea6-4d8e-a3dc-4d2f2f0af45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60205245-172.17.0.2-1597106627811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39584,DS-4d73307a-028f-4b5a-85fa-4d96aa5b4de7,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-a6d805ee-58bd-44af-82d5-ef720c19c1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-ae983df8-d69f-4ee6-919b-131d8bb0a592,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-88df938a-6386-4e4a-acd4-c3a4cacd3410,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-b9430aa0-5044-4f4d-b8af-5a681affe5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-143daf6b-7f1b-45c9-af31-000650c477c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-e2f41596-7892-4926-b1dd-97fddc4c4a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-7ea41e9d-0f1b-4a8d-9388-e6a481ce6714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60205245-172.17.0.2-1597106627811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39584,DS-4d73307a-028f-4b5a-85fa-4d96aa5b4de7,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-a6d805ee-58bd-44af-82d5-ef720c19c1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-ae983df8-d69f-4ee6-919b-131d8bb0a592,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-88df938a-6386-4e4a-acd4-c3a4cacd3410,DISK], DatanodeInfoWithStorage[127.0.0.1:36544,DS-b9430aa0-5044-4f4d-b8af-5a681affe5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-143daf6b-7f1b-45c9-af31-000650c477c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-e2f41596-7892-4926-b1dd-97fddc4c4a03,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-7ea41e9d-0f1b-4a8d-9388-e6a481ce6714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.limit
component: hdfs:NameNode
v1: 10000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055581068-172.17.0.2-1597106929508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42108,DS-cd238bc8-b5e5-4a75-b5c4-1e44b9c56b78,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-6b345cd0-924a-4931-b2da-f5d8efde7e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-9dce7001-8038-498b-b053-633f05004616,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-c08a21ca-6071-4ee7-b1de-4ed839624c76,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-356f82ba-1881-4992-9b44-2602e054f83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-dcf3361d-91d0-4a76-974e-5cd9f8c63969,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-cc006d05-cfde-43c6-a5e3-b720855e4a55,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-7d573ddd-43d4-4f1e-8c0e-62e27b7f13e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1055581068-172.17.0.2-1597106929508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42108,DS-cd238bc8-b5e5-4a75-b5c4-1e44b9c56b78,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-6b345cd0-924a-4931-b2da-f5d8efde7e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-9dce7001-8038-498b-b053-633f05004616,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-c08a21ca-6071-4ee7-b1de-4ed839624c76,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-356f82ba-1881-4992-9b44-2602e054f83a,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-dcf3361d-91d0-4a76-974e-5cd9f8c63969,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-cc006d05-cfde-43c6-a5e3-b720855e4a55,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-7d573ddd-43d4-4f1e-8c0e-62e27b7f13e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5233
