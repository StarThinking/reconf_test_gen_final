reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44427430-172.17.0.8-1597142296730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-67951df2-8012-45a2-bf2f-ecd4fdd6b87d,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-73541aaf-c610-48f0-9633-43040070405b,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-af7b2d69-0823-49ec-b17c-749b48876886,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-625bfbbf-8c5a-454e-aea3-5038a4d99fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-d7d9adca-a139-45ec-90dd-817d961c0c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-26caa7b3-7a1e-4d1f-b756-5e1202a8132a,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-cd0c7a92-7cf1-4e82-8043-33f16c0c07ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-23ef4281-6826-4be7-8e19-b3a680df5e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44427430-172.17.0.8-1597142296730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-67951df2-8012-45a2-bf2f-ecd4fdd6b87d,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-73541aaf-c610-48f0-9633-43040070405b,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-af7b2d69-0823-49ec-b17c-749b48876886,DISK], DatanodeInfoWithStorage[127.0.0.1:43074,DS-625bfbbf-8c5a-454e-aea3-5038a4d99fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-d7d9adca-a139-45ec-90dd-817d961c0c45,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-26caa7b3-7a1e-4d1f-b756-5e1202a8132a,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-cd0c7a92-7cf1-4e82-8043-33f16c0c07ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-23ef4281-6826-4be7-8e19-b3a680df5e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691913909-172.17.0.8-1597142595359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-74cd8beb-8d43-40c1-b6af-469a6aae56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-1a8243c5-41ab-44f7-b26d-2d9f0e639b06,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-9a93e6b8-99ba-4988-ae18-0a0400985b60,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-850cc448-5610-481d-bb12-0be35b4ee096,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-96089e21-1802-4846-b45e-0d4588c3988e,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-5d9f8fa1-81e2-4707-b1bf-8fa034eb3ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-06a5cd46-3281-419f-8a7c-cd92fbbcacb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-5f3255f8-137b-4da0-8541-4dfeb20ec7fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691913909-172.17.0.8-1597142595359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40457,DS-74cd8beb-8d43-40c1-b6af-469a6aae56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-1a8243c5-41ab-44f7-b26d-2d9f0e639b06,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-9a93e6b8-99ba-4988-ae18-0a0400985b60,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-850cc448-5610-481d-bb12-0be35b4ee096,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-96089e21-1802-4846-b45e-0d4588c3988e,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-5d9f8fa1-81e2-4707-b1bf-8fa034eb3ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-06a5cd46-3281-419f-8a7c-cd92fbbcacb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-5f3255f8-137b-4da0-8541-4dfeb20ec7fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244050886-172.17.0.8-1597143585494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-5abfed53-6ede-4340-9de6-3e4a494bcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-886a04fe-5858-4c3a-a735-62a75c0f46ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-ec1a7763-119f-4973-afb2-ec8c7c42e3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-96fb3b11-b2d3-492c-a08e-f701f8edc57b,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-531ca57a-128a-459f-8afc-1c3ead168626,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-f0cbaeb1-5f1b-4b11-b882-5973721aa79c,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-01cc11a0-b44c-40bc-8fa8-e84567826ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-2d87557f-de7d-45bc-9cdc-c5b0908ab90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1244050886-172.17.0.8-1597143585494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-5abfed53-6ede-4340-9de6-3e4a494bcc37,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-886a04fe-5858-4c3a-a735-62a75c0f46ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-ec1a7763-119f-4973-afb2-ec8c7c42e3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-96fb3b11-b2d3-492c-a08e-f701f8edc57b,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-531ca57a-128a-459f-8afc-1c3ead168626,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-f0cbaeb1-5f1b-4b11-b882-5973721aa79c,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-01cc11a0-b44c-40bc-8fa8-e84567826ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-2d87557f-de7d-45bc-9cdc-c5b0908ab90c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119480198-172.17.0.8-1597143889680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-ad49c8cd-673f-4f67-a05e-3e8d326e530e,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-fede6e73-2167-4a37-995e-036091b9de5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-84964c84-8f4e-4b86-aeef-5b6faf293164,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-ddd1dc66-1828-473c-aaa7-48ac1b19fa42,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-4495d26f-b5b3-44bf-b472-caf718fb2238,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-36740268-fc86-4264-9e8d-bf0aab4e70d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-9af9b0e5-d9aa-4fa5-a7a8-5eb054e4ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-1ca7082d-fbc9-4a7e-8538-756955ce1631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119480198-172.17.0.8-1597143889680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-ad49c8cd-673f-4f67-a05e-3e8d326e530e,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-fede6e73-2167-4a37-995e-036091b9de5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-84964c84-8f4e-4b86-aeef-5b6faf293164,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-ddd1dc66-1828-473c-aaa7-48ac1b19fa42,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-4495d26f-b5b3-44bf-b472-caf718fb2238,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-36740268-fc86-4264-9e8d-bf0aab4e70d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-9af9b0e5-d9aa-4fa5-a7a8-5eb054e4ab12,DISK], DatanodeInfoWithStorage[127.0.0.1:36297,DS-1ca7082d-fbc9-4a7e-8538-756955ce1631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531388306-172.17.0.8-1597144801228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38508,DS-27396ff7-dbce-471e-baf1-43eb4241395a,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-3da068a8-d693-4862-be75-cfaa1f838b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-a8c71ea2-cb22-42fb-8919-ebbea0fb4687,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-6c0615f4-fb09-46b7-8a0d-507deef05ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-0736f78f-b235-4c20-871b-6012ef9b0dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-ff0c6140-5c0b-4333-927b-b296de34cd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-aec1e5eb-ea42-4f4e-a26f-4685acbfd577,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-c04eda0d-ab46-4b32-96fe-b97f49a2c9c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531388306-172.17.0.8-1597144801228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38508,DS-27396ff7-dbce-471e-baf1-43eb4241395a,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-3da068a8-d693-4862-be75-cfaa1f838b33,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-a8c71ea2-cb22-42fb-8919-ebbea0fb4687,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-6c0615f4-fb09-46b7-8a0d-507deef05ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-0736f78f-b235-4c20-871b-6012ef9b0dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-ff0c6140-5c0b-4333-927b-b296de34cd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-aec1e5eb-ea42-4f4e-a26f-4685acbfd577,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-c04eda0d-ab46-4b32-96fe-b97f49a2c9c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760867370-172.17.0.8-1597146089672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-a7a859a3-9b81-4744-894d-1210ea310342,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-22e48b4b-060a-470b-8db7-440cb0bdcbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-872d2c57-df24-4c2c-9f2b-adeeef65c98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-05e2aa3d-d9c0-40ef-b429-c75fa66ae04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-39d91bdf-aa63-4113-9047-e366b2db8ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-c0b69b79-6b08-4f19-8ad3-0295afe5b2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-44e1dbda-0575-435d-a0d2-9cacf4341f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-eae930f2-e210-406b-91d7-87242ea64ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760867370-172.17.0.8-1597146089672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-a7a859a3-9b81-4744-894d-1210ea310342,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-22e48b4b-060a-470b-8db7-440cb0bdcbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-872d2c57-df24-4c2c-9f2b-adeeef65c98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41922,DS-05e2aa3d-d9c0-40ef-b429-c75fa66ae04b,DISK], DatanodeInfoWithStorage[127.0.0.1:38855,DS-39d91bdf-aa63-4113-9047-e366b2db8ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-c0b69b79-6b08-4f19-8ad3-0295afe5b2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-44e1dbda-0575-435d-a0d2-9cacf4341f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42048,DS-eae930f2-e210-406b-91d7-87242ea64ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537139405-172.17.0.8-1597146339608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-7d042c09-511b-4aa8-8242-c11fa26389c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-7e8c78fd-d788-4d66-9a8b-58d4aa9cd1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-73f64d10-7229-45ef-bb24-72b49d1d4ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-55c20784-8134-41dd-ae3d-652bc1bcf7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-475a1fc7-ae21-478f-90f8-644c66934c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-c0dfe75e-2725-4d2b-81e8-93e38f98747c,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-88338c60-5ecb-4734-9342-ef1cca09c7af,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-f5db2f5f-aec4-41c7-938f-8310a0a5fd76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537139405-172.17.0.8-1597146339608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-7d042c09-511b-4aa8-8242-c11fa26389c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-7e8c78fd-d788-4d66-9a8b-58d4aa9cd1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-73f64d10-7229-45ef-bb24-72b49d1d4ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-55c20784-8134-41dd-ae3d-652bc1bcf7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-475a1fc7-ae21-478f-90f8-644c66934c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41036,DS-c0dfe75e-2725-4d2b-81e8-93e38f98747c,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-88338c60-5ecb-4734-9342-ef1cca09c7af,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-f5db2f5f-aec4-41c7-938f-8310a0a5fd76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192021308-172.17.0.8-1597146792958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35665,DS-9c1f052c-3897-4be0-b2ae-8d91c2893107,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-38dde661-5f26-4ea7-bef1-d59d8003d7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-43d66850-dc3e-4563-88c4-4b6f70298ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-fe5c1080-5f47-4482-a75d-1febd28ffd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-0879c5af-3fe5-4bac-8b78-3954b92913df,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-dbaa3ff2-50cb-4763-b0df-50fea0622f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-988a21f4-ff19-4e5b-8497-cb7041c8092d,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-856489a5-0251-4849-b1fe-681e77df2b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1192021308-172.17.0.8-1597146792958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35665,DS-9c1f052c-3897-4be0-b2ae-8d91c2893107,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-38dde661-5f26-4ea7-bef1-d59d8003d7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-43d66850-dc3e-4563-88c4-4b6f70298ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-fe5c1080-5f47-4482-a75d-1febd28ffd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41932,DS-0879c5af-3fe5-4bac-8b78-3954b92913df,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-dbaa3ff2-50cb-4763-b0df-50fea0622f76,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-988a21f4-ff19-4e5b-8497-cb7041c8092d,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-856489a5-0251-4849-b1fe-681e77df2b62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464381390-172.17.0.8-1597147068753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40102,DS-d9647d12-ed0a-4f22-8fe8-6d72cea86d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-b0d51c41-3abf-400c-a4b0-2d18ed179c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-0fcbf1db-1df0-4f2a-8a9f-0f0a057a64c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-6ddb97e8-6ec1-4e5e-8bf1-572f5896360d,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-cbdcddf7-8271-49b2-b47f-94dd704182bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-920f7b8b-5258-4dee-b805-8feaba9dacbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-385b6c7a-d18c-49a5-94ee-a7ed21e6fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-d498b2b7-3ec5-40bf-8fee-a8b128a87098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1464381390-172.17.0.8-1597147068753:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40102,DS-d9647d12-ed0a-4f22-8fe8-6d72cea86d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-b0d51c41-3abf-400c-a4b0-2d18ed179c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-0fcbf1db-1df0-4f2a-8a9f-0f0a057a64c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-6ddb97e8-6ec1-4e5e-8bf1-572f5896360d,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-cbdcddf7-8271-49b2-b47f-94dd704182bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-920f7b8b-5258-4dee-b805-8feaba9dacbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-385b6c7a-d18c-49a5-94ee-a7ed21e6fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-d498b2b7-3ec5-40bf-8fee-a8b128a87098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471771856-172.17.0.8-1597147750043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-af337a3b-e8bc-4d5b-8186-c826dd13e1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-3fda465b-1a81-42ba-ba64-069b45c1751c,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-2a2b936e-3311-49a3-a6ad-e6c709f5a8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-63ee659b-a1ba-4d9e-867b-b0760506b248,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-44e6c6da-fd97-4617-b10c-1a2fc1d83d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-b255f3b9-d28c-4a6c-b9b4-f8feec62453e,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-ac56e97b-4a9c-47fc-ad3c-6416d4220f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-f7fbdcb4-35dd-43e8-a8ae-676d2e9a2719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471771856-172.17.0.8-1597147750043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38470,DS-af337a3b-e8bc-4d5b-8186-c826dd13e1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40404,DS-3fda465b-1a81-42ba-ba64-069b45c1751c,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-2a2b936e-3311-49a3-a6ad-e6c709f5a8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-63ee659b-a1ba-4d9e-867b-b0760506b248,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-44e6c6da-fd97-4617-b10c-1a2fc1d83d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-b255f3b9-d28c-4a6c-b9b4-f8feec62453e,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-ac56e97b-4a9c-47fc-ad3c-6416d4220f05,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-f7fbdcb4-35dd-43e8-a8ae-676d2e9a2719,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528567400-172.17.0.8-1597148146729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38665,DS-c2866793-22e8-4a54-82d0-6921d334d328,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-6dd04fc5-9b7e-4ad6-9d8b-d4f4733153bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-98d6fb2a-e0a7-4836-a1c4-94574c78e69a,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-9803ad1a-70eb-4ddc-a832-6130785fbbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-56dec34c-8092-4dce-a2b7-3115b87e71bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-7880dac0-0158-4ae9-82c1-d7dd08669c50,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-757a2127-6099-4ee8-92e0-c452def5e115,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-f31777c9-c868-45af-a6ed-2277a62b7d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-528567400-172.17.0.8-1597148146729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38665,DS-c2866793-22e8-4a54-82d0-6921d334d328,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-6dd04fc5-9b7e-4ad6-9d8b-d4f4733153bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-98d6fb2a-e0a7-4836-a1c4-94574c78e69a,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-9803ad1a-70eb-4ddc-a832-6130785fbbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-56dec34c-8092-4dce-a2b7-3115b87e71bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-7880dac0-0158-4ae9-82c1-d7dd08669c50,DISK], DatanodeInfoWithStorage[127.0.0.1:33842,DS-757a2127-6099-4ee8-92e0-c452def5e115,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-f31777c9-c868-45af-a6ed-2277a62b7d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292299536-172.17.0.8-1597148372319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37190,DS-32ac0528-f017-424d-bdfb-10b282b8c975,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-bc5941cf-a5c3-4079-be08-01d3e319f389,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-af9d1703-74b4-4de1-b9bc-7798f4d998f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-df99676b-c6d1-412e-aac7-bf957bcd7568,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-49f41fae-2db4-4b1c-b6c0-d0f480f4cd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-713b6b3d-cc55-443b-8894-ae68e0b679db,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-507ecaad-bc2c-426f-9908-2b7a4287d1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-72a8a68a-1424-4ed3-a5c2-1528d4c13859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292299536-172.17.0.8-1597148372319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37190,DS-32ac0528-f017-424d-bdfb-10b282b8c975,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-bc5941cf-a5c3-4079-be08-01d3e319f389,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-af9d1703-74b4-4de1-b9bc-7798f4d998f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45361,DS-df99676b-c6d1-412e-aac7-bf957bcd7568,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-49f41fae-2db4-4b1c-b6c0-d0f480f4cd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-713b6b3d-cc55-443b-8894-ae68e0b679db,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-507ecaad-bc2c-426f-9908-2b7a4287d1a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-72a8a68a-1424-4ed3-a5c2-1528d4c13859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982416293-172.17.0.8-1597148534583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-2c489904-f3d0-4414-ba59-1e13a3f1b488,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-0588b55f-694d-490f-bc98-2a1a55dbeed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-1a1640cf-fb68-475a-92db-4efbe0b5954e,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-e4ca257f-414a-464b-98b8-ed8aacbfacd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-a9febc8a-8eb2-4b24-a3fa-e01550ad6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-a7aceb31-f12c-4cfa-a7a3-69fd6a84c749,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-78c30d86-2c71-4e92-aa8e-fad9bdb0a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-9f99cb93-6b74-4a05-87a2-c700f9102cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982416293-172.17.0.8-1597148534583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41879,DS-2c489904-f3d0-4414-ba59-1e13a3f1b488,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-0588b55f-694d-490f-bc98-2a1a55dbeed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-1a1640cf-fb68-475a-92db-4efbe0b5954e,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-e4ca257f-414a-464b-98b8-ed8aacbfacd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-a9febc8a-8eb2-4b24-a3fa-e01550ad6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-a7aceb31-f12c-4cfa-a7a3-69fd6a84c749,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-78c30d86-2c71-4e92-aa8e-fad9bdb0a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-9f99cb93-6b74-4a05-87a2-c700f9102cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105599521-172.17.0.8-1597148900218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38386,DS-ca8f5e92-c8d0-47e3-80d2-426799979248,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-a20cbd77-cf1f-4c7a-b517-27c888b03d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-e818f620-9aff-4760-ad53-f896b447c6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-2d8711e1-7c67-445f-a8ca-049da1824950,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-accc9b32-347b-4688-a8fc-78f1e3aca7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-9acb37b4-639b-48f4-becd-6ca7074afe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-c993ef87-08fc-4f4b-87e0-6e7a21639066,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-d7169ef8-59ec-4171-885a-fc67f34a9c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105599521-172.17.0.8-1597148900218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38386,DS-ca8f5e92-c8d0-47e3-80d2-426799979248,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-a20cbd77-cf1f-4c7a-b517-27c888b03d38,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-e818f620-9aff-4760-ad53-f896b447c6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-2d8711e1-7c67-445f-a8ca-049da1824950,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-accc9b32-347b-4688-a8fc-78f1e3aca7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41930,DS-9acb37b4-639b-48f4-becd-6ca7074afe5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-c993ef87-08fc-4f4b-87e0-6e7a21639066,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-d7169ef8-59ec-4171-885a-fc67f34a9c94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224553009-172.17.0.8-1597149095020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-d0e7ffd5-8d24-4752-ac12-72a4f054b148,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-fb6b1d70-c374-4fa1-b60c-c4d56ef18278,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-b6459cc4-6f9a-494f-a4cb-27ee92ab2ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-b3bdabd8-305b-4da8-9d7d-c10c3cc2eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-b0469c11-ac4a-4de6-9a5e-c388b39ab66e,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-34a171ac-aabc-4e07-ba4e-2cbbf19ed481,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-bfdb9a3b-a500-46d4-90e7-7e96dd3ba9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-c0dd55d9-d189-4db8-9aef-65cf1df34a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224553009-172.17.0.8-1597149095020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-d0e7ffd5-8d24-4752-ac12-72a4f054b148,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-fb6b1d70-c374-4fa1-b60c-c4d56ef18278,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-b6459cc4-6f9a-494f-a4cb-27ee92ab2ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-b3bdabd8-305b-4da8-9d7d-c10c3cc2eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-b0469c11-ac4a-4de6-9a5e-c388b39ab66e,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-34a171ac-aabc-4e07-ba4e-2cbbf19ed481,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-bfdb9a3b-a500-46d4-90e7-7e96dd3ba9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-c0dd55d9-d189-4db8-9aef-65cf1df34a0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.handler.count
component: hdfs:DataNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409032674-172.17.0.8-1597149152853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43917,DS-60862e86-30ed-4fb9-8c04-1944151c2790,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-d9321624-72b2-4887-9fff-d659193a938d,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-fc295328-55ad-4594-91c3-da7c68456e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-d4f017bd-f884-4bda-8aeb-67db08673281,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-962ffd9f-35a9-4a70-b6f5-aedf5c3be4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-73de8c5f-d615-4283-96c6-d9984f0a925a,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-f221067c-38e3-4f91-ae4c-f982165a5047,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-693f8ad7-a649-4d37-9498-020ae61192fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409032674-172.17.0.8-1597149152853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43917,DS-60862e86-30ed-4fb9-8c04-1944151c2790,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-d9321624-72b2-4887-9fff-d659193a938d,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-fc295328-55ad-4594-91c3-da7c68456e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-d4f017bd-f884-4bda-8aeb-67db08673281,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-962ffd9f-35a9-4a70-b6f5-aedf5c3be4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-73de8c5f-d615-4283-96c6-d9984f0a925a,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-f221067c-38e3-4f91-ae4c-f982165a5047,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-693f8ad7-a649-4d37-9498-020ae61192fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7652
