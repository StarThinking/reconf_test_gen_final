reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100201422-172.17.0.17-1597137268751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33875,DS-8e6aeda9-ec29-4e22-b77a-508df7007eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-3f9b0d1e-9a7a-46dc-b7df-7b30281775c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-e75dd1e3-606f-409a-89b1-9ce914bf0abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-6b95d93e-1aac-4c4e-b52c-353e1f3413f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-a2b60670-0661-4f39-8188-02ad07e39cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-15ee6251-5932-4733-afbb-bd97cedf6b71,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-0668f7a9-31cd-4072-8c29-48b2c1025cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-a45cec19-38a4-424b-8f17-dae5be6191fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100201422-172.17.0.17-1597137268751:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33875,DS-8e6aeda9-ec29-4e22-b77a-508df7007eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-3f9b0d1e-9a7a-46dc-b7df-7b30281775c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-e75dd1e3-606f-409a-89b1-9ce914bf0abe,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-6b95d93e-1aac-4c4e-b52c-353e1f3413f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-a2b60670-0661-4f39-8188-02ad07e39cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-15ee6251-5932-4733-afbb-bd97cedf6b71,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-0668f7a9-31cd-4072-8c29-48b2c1025cab,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-a45cec19-38a4-424b-8f17-dae5be6191fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344761894-172.17.0.17-1597137637476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46434,DS-57ef52a0-95b9-41b6-84f7-5ded9d653c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-88dfc2b5-82a6-4a64-86d9-1c97b62e82f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-c314a4ce-bb57-47b2-a844-16fcd1262426,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-800ce043-e523-401f-b7ea-0aba65a1e565,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-e08647f2-db3e-4842-905b-6332d2562d87,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-45d811f1-c77d-45e7-be2d-f81e3e47b000,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-1b18b57c-c367-4398-a880-4f5e4d453b69,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-9945d0ce-7faa-452f-97c4-43aeb380c11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344761894-172.17.0.17-1597137637476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46434,DS-57ef52a0-95b9-41b6-84f7-5ded9d653c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-88dfc2b5-82a6-4a64-86d9-1c97b62e82f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-c314a4ce-bb57-47b2-a844-16fcd1262426,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-800ce043-e523-401f-b7ea-0aba65a1e565,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-e08647f2-db3e-4842-905b-6332d2562d87,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-45d811f1-c77d-45e7-be2d-f81e3e47b000,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-1b18b57c-c367-4398-a880-4f5e4d453b69,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-9945d0ce-7faa-452f-97c4-43aeb380c11c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158474674-172.17.0.17-1597137875080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43145,DS-c16db05d-db2e-40bf-8cf6-ec3fddae2fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-0c998ff9-33fd-495d-9458-96dec1d4e7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-3504f682-31e5-4e7b-ba54-900d639bad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-e5f3e223-4919-4bd8-b546-649c808597e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-139e8d83-ebe4-4d9a-90de-cc382cf7ec34,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-17b215e6-f6f8-4777-ab24-1ca08765d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-f1104c9f-e7bf-4db1-b066-5deb49aea2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-79164a8d-29ec-4237-9a46-e9334af2653e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158474674-172.17.0.17-1597137875080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43145,DS-c16db05d-db2e-40bf-8cf6-ec3fddae2fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-0c998ff9-33fd-495d-9458-96dec1d4e7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-3504f682-31e5-4e7b-ba54-900d639bad2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-e5f3e223-4919-4bd8-b546-649c808597e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-139e8d83-ebe4-4d9a-90de-cc382cf7ec34,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-17b215e6-f6f8-4777-ab24-1ca08765d07c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-f1104c9f-e7bf-4db1-b066-5deb49aea2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-79164a8d-29ec-4237-9a46-e9334af2653e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761533201-172.17.0.17-1597138157208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-0558d5df-6f78-4ee2-b05f-6bfb1a7ea116,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-d7fa214e-9cfa-4a4d-b806-6696c169ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-e6143ebf-6cd1-49a7-832a-f2210accf121,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-f01d33f2-d409-4a83-a814-b8c2793bc985,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-62717daa-32ac-47da-a96c-a96bceddac11,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-0b0e08e7-7c37-4877-af13-f08581b8558a,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-3789286f-2aab-41f2-8142-11fdcaf766a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-90fd495a-2bdd-4638-8e37-bf90c034b3ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761533201-172.17.0.17-1597138157208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-0558d5df-6f78-4ee2-b05f-6bfb1a7ea116,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-d7fa214e-9cfa-4a4d-b806-6696c169ba24,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-e6143ebf-6cd1-49a7-832a-f2210accf121,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-f01d33f2-d409-4a83-a814-b8c2793bc985,DISK], DatanodeInfoWithStorage[127.0.0.1:41131,DS-62717daa-32ac-47da-a96c-a96bceddac11,DISK], DatanodeInfoWithStorage[127.0.0.1:39396,DS-0b0e08e7-7c37-4877-af13-f08581b8558a,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-3789286f-2aab-41f2-8142-11fdcaf766a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-90fd495a-2bdd-4638-8e37-bf90c034b3ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370435858-172.17.0.17-1597138194210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41770,DS-4999517e-c32e-41fd-9a40-65b94c08af26,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-0c4d10d6-0a10-4ef9-bbe5-66a911e45c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-44108b64-ad0d-4340-89d3-4afab4b23630,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-9dc0ec5c-01dd-41c4-8c6a-a6adc959e27b,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-73847461-3f92-4f75-8c5d-6889256719c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-0e305e53-6f86-43d4-b508-d5bb01861137,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-e1daa9da-efb3-4c7a-8c9c-a5a81c531f38,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-577c2786-d515-4503-90d6-7ead5577af1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1370435858-172.17.0.17-1597138194210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41770,DS-4999517e-c32e-41fd-9a40-65b94c08af26,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-0c4d10d6-0a10-4ef9-bbe5-66a911e45c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-44108b64-ad0d-4340-89d3-4afab4b23630,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-9dc0ec5c-01dd-41c4-8c6a-a6adc959e27b,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-73847461-3f92-4f75-8c5d-6889256719c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-0e305e53-6f86-43d4-b508-d5bb01861137,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-e1daa9da-efb3-4c7a-8c9c-a5a81c531f38,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-577c2786-d515-4503-90d6-7ead5577af1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612992739-172.17.0.17-1597138423282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-871684c5-fa1a-44d8-bc75-e72079122d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-0677dbb1-60bd-4481-8537-de4d02d22e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-4aa3c6a9-eeca-44b6-a274-50be069a9286,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-26c2764a-370c-4dcd-a16f-caf0430c7b55,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-fa10e516-3b08-472d-a5bd-c177e78717b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-9a94618c-6288-4637-9579-85b5bddb491a,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-164d7477-dbb5-4f3a-af96-1f17f7e35298,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-c922ddb5-1de6-4269-99aa-fc9614c51dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-612992739-172.17.0.17-1597138423282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-871684c5-fa1a-44d8-bc75-e72079122d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-0677dbb1-60bd-4481-8537-de4d02d22e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-4aa3c6a9-eeca-44b6-a274-50be069a9286,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-26c2764a-370c-4dcd-a16f-caf0430c7b55,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-fa10e516-3b08-472d-a5bd-c177e78717b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-9a94618c-6288-4637-9579-85b5bddb491a,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-164d7477-dbb5-4f3a-af96-1f17f7e35298,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-c922ddb5-1de6-4269-99aa-fc9614c51dc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483457102-172.17.0.17-1597138461500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-fa6d54f7-bce9-4c72-b36e-015ef6b3fdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-47ffc8be-8c80-4ae4-a8b0-f3cebdee8aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-05e94eef-ca4f-4b23-89bb-85a5fe7e85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-46c04e8b-ea09-494b-88fa-d134f9289e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-cda4c1f2-00bd-43c3-8e19-255e90cf2f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-3946edeb-2ea8-4d8e-ad26-4c40dcf11f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-51df3ae5-3110-4553-b9b3-8a830745eff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-4f8adfcb-d97f-4b83-a0df-fa762737bdaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-483457102-172.17.0.17-1597138461500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43710,DS-fa6d54f7-bce9-4c72-b36e-015ef6b3fdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-47ffc8be-8c80-4ae4-a8b0-f3cebdee8aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-05e94eef-ca4f-4b23-89bb-85a5fe7e85b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-46c04e8b-ea09-494b-88fa-d134f9289e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-cda4c1f2-00bd-43c3-8e19-255e90cf2f99,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-3946edeb-2ea8-4d8e-ad26-4c40dcf11f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-51df3ae5-3110-4553-b9b3-8a830745eff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-4f8adfcb-d97f-4b83-a0df-fa762737bdaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719591835-172.17.0.17-1597138501747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-00112938-3a5b-4508-a56b-390784502271,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-30dc8ef3-736a-4c80-a4f7-533eb2802007,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-aa44f79f-a91c-4ebd-896e-de1569cf02e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-b4f1b6a7-baf1-41df-970f-1738c756f956,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-6a0a8f5a-03d1-4afd-94aa-f4754bb4e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-31a8ef87-b9ce-4aea-8651-893b8bc2c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-2980ded5-107c-45fb-b1a1-71a413461c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-936b6157-b02d-46a5-bf6b-075adbfa983f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-719591835-172.17.0.17-1597138501747:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39005,DS-00112938-3a5b-4508-a56b-390784502271,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-30dc8ef3-736a-4c80-a4f7-533eb2802007,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-aa44f79f-a91c-4ebd-896e-de1569cf02e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-b4f1b6a7-baf1-41df-970f-1738c756f956,DISK], DatanodeInfoWithStorage[127.0.0.1:44102,DS-6a0a8f5a-03d1-4afd-94aa-f4754bb4e35c,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-31a8ef87-b9ce-4aea-8651-893b8bc2c90a,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-2980ded5-107c-45fb-b1a1-71a413461c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-936b6157-b02d-46a5-bf6b-075adbfa983f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428196972-172.17.0.17-1597138604123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-503c17ef-50b4-4cb6-bf10-5081062d6bac,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-ef52f264-1af5-45e0-b1d8-3240a13348a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-827ca5d1-ff3d-4c8b-a559-d6b96919adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-e4d54267-c0b3-4ac0-a9b6-f67046dfb52e,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-5d3ce193-c023-40d6-a635-d7ec9e33422a,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-3708c110-f12f-407c-b04d-ae54acf6c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-f0153849-ff98-40fa-bc2e-f7ad5417f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-2ea85f9d-fa50-4f2b-9209-afea9b256187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428196972-172.17.0.17-1597138604123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-503c17ef-50b4-4cb6-bf10-5081062d6bac,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-ef52f264-1af5-45e0-b1d8-3240a13348a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-827ca5d1-ff3d-4c8b-a559-d6b96919adcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-e4d54267-c0b3-4ac0-a9b6-f67046dfb52e,DISK], DatanodeInfoWithStorage[127.0.0.1:46376,DS-5d3ce193-c023-40d6-a635-d7ec9e33422a,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-3708c110-f12f-407c-b04d-ae54acf6c0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-f0153849-ff98-40fa-bc2e-f7ad5417f2f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-2ea85f9d-fa50-4f2b-9209-afea9b256187,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513355453-172.17.0.17-1597139118689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35689,DS-f7d302c2-0d9c-43a9-9bdb-8a57d139ee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-06a20582-e5b7-40c8-8523-a2410ec5b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-dff1021e-582a-4dd8-b50a-b3df4c1a1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-71b5f5b5-6917-4c89-b778-7137412071bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-adbfcf27-0e7d-4980-9c95-ff60bfed18df,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-a3b856ad-5817-4a4e-aeee-a1a8030ba108,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-e0685a16-512a-47c8-90ce-67b17a326275,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-4e03c2b5-b977-43ab-9f1e-5daf2165bc17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513355453-172.17.0.17-1597139118689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35689,DS-f7d302c2-0d9c-43a9-9bdb-8a57d139ee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-06a20582-e5b7-40c8-8523-a2410ec5b8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-dff1021e-582a-4dd8-b50a-b3df4c1a1ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-71b5f5b5-6917-4c89-b778-7137412071bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-adbfcf27-0e7d-4980-9c95-ff60bfed18df,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-a3b856ad-5817-4a4e-aeee-a1a8030ba108,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-e0685a16-512a-47c8-90ce-67b17a326275,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-4e03c2b5-b977-43ab-9f1e-5daf2165bc17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74975045-172.17.0.17-1597139620298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42122,DS-91f3cc7b-2013-4fee-8c45-942fce931720,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-2a03e019-2f93-4151-b18c-1cf79bb40545,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-00e67970-5458-4140-ae6a-e18fd025fdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-5429951f-0f96-4ccf-a30c-c280de117c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-8f1f7721-7f9a-48a9-a42e-3b676ba10bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-3ae0188c-57ee-484e-9e2e-c1d44dfc3abe,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-206fa302-f45f-409d-8589-4d3f6ea569cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-1cc2dd57-39ff-4183-9af2-582cabbd33ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74975045-172.17.0.17-1597139620298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42122,DS-91f3cc7b-2013-4fee-8c45-942fce931720,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-2a03e019-2f93-4151-b18c-1cf79bb40545,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-00e67970-5458-4140-ae6a-e18fd025fdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-5429951f-0f96-4ccf-a30c-c280de117c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-8f1f7721-7f9a-48a9-a42e-3b676ba10bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34129,DS-3ae0188c-57ee-484e-9e2e-c1d44dfc3abe,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-206fa302-f45f-409d-8589-4d3f6ea569cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-1cc2dd57-39ff-4183-9af2-582cabbd33ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19749358-172.17.0.17-1597140218740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36078,DS-92daa878-2c29-450a-bee2-47dd024b5ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-995a3091-8e2c-44bb-9f46-c673c9132b60,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-22a91450-1615-471f-ad83-42c0103b5822,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-7de09863-66c2-4b51-b192-10acd6ebb112,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-60dda7fd-17ac-4da6-8bbd-3a86fba9d258,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-4b960fae-086d-424c-a1c6-f74cc639dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-6915ff0f-ce53-4192-8e59-a55a39b2be05,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-d68ab0b1-e0ba-4a6a-a70c-05109b95cb43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19749358-172.17.0.17-1597140218740:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36078,DS-92daa878-2c29-450a-bee2-47dd024b5ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-995a3091-8e2c-44bb-9f46-c673c9132b60,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-22a91450-1615-471f-ad83-42c0103b5822,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-7de09863-66c2-4b51-b192-10acd6ebb112,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-60dda7fd-17ac-4da6-8bbd-3a86fba9d258,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-4b960fae-086d-424c-a1c6-f74cc639dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-6915ff0f-ce53-4192-8e59-a55a39b2be05,DISK], DatanodeInfoWithStorage[127.0.0.1:41305,DS-d68ab0b1-e0ba-4a6a-a70c-05109b95cb43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261230671-172.17.0.17-1597140465707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46784,DS-951e71ed-1e03-4076-b62a-8981d4c5854e,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-9f0807cd-3ff0-4125-abf2-9392a00e42f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-3287cdf3-9fee-452a-9d27-e6f9288d7d88,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-81950133-987f-4f6d-8ca4-83fc9a6607af,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-5b329dc2-5609-453f-953f-3c78649ef8af,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-60b2a6a7-45bf-4c04-8532-1f4e57457b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-23d33812-2280-470d-8eb0-269ddf2395c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-8e1cea23-27c0-46b3-810c-ed92d33fd5c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-261230671-172.17.0.17-1597140465707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46784,DS-951e71ed-1e03-4076-b62a-8981d4c5854e,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-9f0807cd-3ff0-4125-abf2-9392a00e42f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-3287cdf3-9fee-452a-9d27-e6f9288d7d88,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-81950133-987f-4f6d-8ca4-83fc9a6607af,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-5b329dc2-5609-453f-953f-3c78649ef8af,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-60b2a6a7-45bf-4c04-8532-1f4e57457b55,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-23d33812-2280-470d-8eb0-269ddf2395c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-8e1cea23-27c0-46b3-810c-ed92d33fd5c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726995362-172.17.0.17-1597140878297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37241,DS-77bb3922-7339-480c-bc91-f0ff38dd4de2,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-ce7f79bc-6671-4394-8b53-2301ff96d3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-4bb76bde-23c5-4934-b711-d7e0c8fa1bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c85d9a17-9b8c-49e7-ad8d-51176804459a,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-7b9e111b-867f-4d39-86c1-d4e950800f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-a3054959-1429-4f38-9658-3974eb50aa41,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-6cbf297e-e311-4a14-80e6-0f2d0efa6d80,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-ffd253a7-f351-4f58-b9a3-0a27214b6eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726995362-172.17.0.17-1597140878297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37241,DS-77bb3922-7339-480c-bc91-f0ff38dd4de2,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-ce7f79bc-6671-4394-8b53-2301ff96d3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-4bb76bde-23c5-4934-b711-d7e0c8fa1bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-c85d9a17-9b8c-49e7-ad8d-51176804459a,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-7b9e111b-867f-4d39-86c1-d4e950800f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-a3054959-1429-4f38-9658-3974eb50aa41,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-6cbf297e-e311-4a14-80e6-0f2d0efa6d80,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-ffd253a7-f351-4f58-b9a3-0a27214b6eb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.streams.cache.size
component: hdfs:NameNode
v1: 256
v2: 8
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429002616-172.17.0.17-1597141806711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-95799981-eb8a-4e0a-bd07-b698d9334c02,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-075fea1a-1e82-42fe-a923-a3d0dbbcde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-2c8583b1-1747-465b-b702-e08cffbd6153,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-8a21ce5d-434e-41e2-bec1-e4503a9c1bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-614d92ae-bf8b-49ab-9572-b56b8d9b45d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-9401a6fc-54d8-49b0-b706-9759b389d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-043c7acb-84d0-46b3-9235-c96e5dfcd286,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-8fa3c7e5-d8a7-4dd6-bb4a-dcefe83a3ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429002616-172.17.0.17-1597141806711:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-95799981-eb8a-4e0a-bd07-b698d9334c02,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-075fea1a-1e82-42fe-a923-a3d0dbbcde8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-2c8583b1-1747-465b-b702-e08cffbd6153,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-8a21ce5d-434e-41e2-bec1-e4503a9c1bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-614d92ae-bf8b-49ab-9572-b56b8d9b45d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-9401a6fc-54d8-49b0-b706-9759b389d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-043c7acb-84d0-46b3-9235-c96e5dfcd286,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-8fa3c7e5-d8a7-4dd6-bb4a-dcefe83a3ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4859
