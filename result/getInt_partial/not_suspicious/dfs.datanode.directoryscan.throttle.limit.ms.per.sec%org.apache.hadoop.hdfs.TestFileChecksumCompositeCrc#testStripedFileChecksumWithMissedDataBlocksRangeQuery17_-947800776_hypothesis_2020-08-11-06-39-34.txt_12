reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811835723-172.17.0.5-1597128263568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-a1b38f9a-5ad1-41a8-a781-365729ee5beb,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-f1252746-91d7-402d-88d1-8727f1ddeb07,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-f41f891b-c5e1-4d4a-83f7-923dd0d3823c,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-3f49c086-db09-4078-a21a-337e9590a64d,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-b98d1f42-c3b9-4050-a99a-cbf46fe0749e,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-9b753798-5390-49c2-a1d7-d72e1c2adbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-0ea4e60b-33e2-417c-baf3-0492643d095f,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-fc532976-9873-4d80-ad77-bc9e5df59fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811835723-172.17.0.5-1597128263568:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-a1b38f9a-5ad1-41a8-a781-365729ee5beb,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-f1252746-91d7-402d-88d1-8727f1ddeb07,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-f41f891b-c5e1-4d4a-83f7-923dd0d3823c,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-3f49c086-db09-4078-a21a-337e9590a64d,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-b98d1f42-c3b9-4050-a99a-cbf46fe0749e,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-9b753798-5390-49c2-a1d7-d72e1c2adbf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-0ea4e60b-33e2-417c-baf3-0492643d095f,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-fc532976-9873-4d80-ad77-bc9e5df59fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428448876-172.17.0.5-1597128649226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42269,DS-a26e10cd-caeb-4f46-bfbb-f9678fb201b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-7de252d7-5254-4f46-aeab-9b8dbe55e3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-a817b270-285c-4762-9f5e-6edd2ff838dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-b3ed0fa2-0afd-42cd-9c59-211c2254929a,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-f0669e9c-b7cf-4e21-8af7-c099cbbf9049,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-38764a08-a2ea-4208-a509-cdf1641c563a,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-9996a303-0af5-4bb6-baeb-12a547fe9d24,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-55be9828-577e-49ad-ad78-469fabcdb534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428448876-172.17.0.5-1597128649226:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42269,DS-a26e10cd-caeb-4f46-bfbb-f9678fb201b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-7de252d7-5254-4f46-aeab-9b8dbe55e3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-a817b270-285c-4762-9f5e-6edd2ff838dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-b3ed0fa2-0afd-42cd-9c59-211c2254929a,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-f0669e9c-b7cf-4e21-8af7-c099cbbf9049,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-38764a08-a2ea-4208-a509-cdf1641c563a,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-9996a303-0af5-4bb6-baeb-12a547fe9d24,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-55be9828-577e-49ad-ad78-469fabcdb534,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873873405-172.17.0.5-1597128694554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-b6b72d24-db9b-48f5-982a-8b1d5ff72a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-1e6a8bfe-c63e-44ca-947a-ffac883c7870,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-599c7470-f39d-47ef-aa86-c24fc653f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-f8e9ae74-7e77-42d2-b1ec-d4580f2f11f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-dcdc2ef0-0459-4d35-8dad-faf52c9470bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-de154671-095e-4ea7-8f04-1851f6ffa7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-b5f6c9b6-6d22-4b4d-8946-2ca644492206,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-de3890a7-6def-4f1a-8a62-d39adcf8c36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1873873405-172.17.0.5-1597128694554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-b6b72d24-db9b-48f5-982a-8b1d5ff72a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-1e6a8bfe-c63e-44ca-947a-ffac883c7870,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-599c7470-f39d-47ef-aa86-c24fc653f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-f8e9ae74-7e77-42d2-b1ec-d4580f2f11f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-dcdc2ef0-0459-4d35-8dad-faf52c9470bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-de154671-095e-4ea7-8f04-1851f6ffa7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-b5f6c9b6-6d22-4b4d-8946-2ca644492206,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-de3890a7-6def-4f1a-8a62-d39adcf8c36a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657700333-172.17.0.5-1597129668313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42575,DS-f97cbc73-8b2e-4cf3-b7f7-c20512e24876,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-67842412-3fa8-4459-a5a5-71b06c39ab35,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-4aed1328-5618-4f9e-aa61-013c59fafc63,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-7d701a12-2d09-4251-a0df-1ef818025c12,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-23d982bc-6c3d-4830-82e3-88b7df3f35cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-3f83ef5d-9b29-47f9-92ca-08e557a95ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-6ae9aa91-07a1-40f6-9373-dc4393b74218,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-c90fa9b8-bffa-47f8-914d-6c4ca2de9bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-657700333-172.17.0.5-1597129668313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42575,DS-f97cbc73-8b2e-4cf3-b7f7-c20512e24876,DISK], DatanodeInfoWithStorage[127.0.0.1:45362,DS-67842412-3fa8-4459-a5a5-71b06c39ab35,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-4aed1328-5618-4f9e-aa61-013c59fafc63,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-7d701a12-2d09-4251-a0df-1ef818025c12,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-23d982bc-6c3d-4830-82e3-88b7df3f35cc,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-3f83ef5d-9b29-47f9-92ca-08e557a95ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-6ae9aa91-07a1-40f6-9373-dc4393b74218,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-c90fa9b8-bffa-47f8-914d-6c4ca2de9bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708382914-172.17.0.5-1597130118548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-068e0f98-6c64-4e9d-8b1c-d9651e05258c,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-e68960fa-2738-47d0-ba87-b7ee457ceb75,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-d980fdd5-d950-4e14-82ba-859b9c9de8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-6d8b9b38-b1da-494d-8628-d4bd7e9843be,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-274d7848-3960-4723-a191-47262bf7c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-0884a0f0-b273-4869-bcdf-ecff72afd928,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-967a6279-dc47-4287-9e47-4215724a3a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-60d15ced-27c4-4a8f-bfea-982f76535f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708382914-172.17.0.5-1597130118548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36893,DS-068e0f98-6c64-4e9d-8b1c-d9651e05258c,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-e68960fa-2738-47d0-ba87-b7ee457ceb75,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-d980fdd5-d950-4e14-82ba-859b9c9de8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-6d8b9b38-b1da-494d-8628-d4bd7e9843be,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-274d7848-3960-4723-a191-47262bf7c55e,DISK], DatanodeInfoWithStorage[127.0.0.1:38330,DS-0884a0f0-b273-4869-bcdf-ecff72afd928,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-967a6279-dc47-4287-9e47-4215724a3a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-60d15ced-27c4-4a8f-bfea-982f76535f61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970459349-172.17.0.5-1597130206210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39241,DS-1598f838-78c3-47bb-b6e6-53356ec4fac9,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-99093a2d-45b5-4910-a974-7a166c836dec,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-d14f0bef-feda-457d-bd00-8da6b0824362,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-cabd9ccd-ec75-4030-a600-30ff4ed0335a,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-8890471b-9830-41be-b2c7-e3844d2f8176,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-ef2aa637-2512-4654-a32f-b0531eeca850,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-c6a77358-d758-45ce-b2c7-e29c19a8ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-6be587a8-016e-4ebb-82e3-7df2634f7268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970459349-172.17.0.5-1597130206210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39241,DS-1598f838-78c3-47bb-b6e6-53356ec4fac9,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-99093a2d-45b5-4910-a974-7a166c836dec,DISK], DatanodeInfoWithStorage[127.0.0.1:38890,DS-d14f0bef-feda-457d-bd00-8da6b0824362,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-cabd9ccd-ec75-4030-a600-30ff4ed0335a,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-8890471b-9830-41be-b2c7-e3844d2f8176,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-ef2aa637-2512-4654-a32f-b0531eeca850,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-c6a77358-d758-45ce-b2c7-e29c19a8ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-6be587a8-016e-4ebb-82e3-7df2634f7268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069648221-172.17.0.5-1597130479222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-8a67e8f2-4259-4a18-bc3e-4ed648249e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-2567fc16-ceba-415b-bdf0-2bcc02a205ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-9d258a16-94ed-4ff5-a3b4-394eafe0c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-fdcc4521-485b-414a-af71-93e29ef26c14,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-97e2dce7-e518-4197-ac19-150e008f76a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-29c5bf46-f329-454f-aa19-b0c63cfcde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-c0bf5000-6c27-426e-ab15-70fbc70cbec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-49a79afc-99a9-4979-8e86-b48dc1231b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1069648221-172.17.0.5-1597130479222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-8a67e8f2-4259-4a18-bc3e-4ed648249e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-2567fc16-ceba-415b-bdf0-2bcc02a205ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-9d258a16-94ed-4ff5-a3b4-394eafe0c3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-fdcc4521-485b-414a-af71-93e29ef26c14,DISK], DatanodeInfoWithStorage[127.0.0.1:46768,DS-97e2dce7-e518-4197-ac19-150e008f76a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-29c5bf46-f329-454f-aa19-b0c63cfcde1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-c0bf5000-6c27-426e-ab15-70fbc70cbec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-49a79afc-99a9-4979-8e86-b48dc1231b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001961027-172.17.0.5-1597130570059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-a0987980-7f52-4544-9cae-70d863a4a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-fac57fa5-20f0-4278-85a7-4ae68d815c44,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-6e52c779-1d1c-4b5d-b3d1-abd0c86f13f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-4f16e80d-e2e4-4e78-8b23-94cfbdb52f81,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-7c6a2869-9a5b-4efd-9422-3262758575ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-df743047-e574-4527-8ac9-22c2fbdbb4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-bdb0f873-4083-4fb4-a620-f37d410f0a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ac58594b-6fa1-4492-a834-2ddac215ba95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1001961027-172.17.0.5-1597130570059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38014,DS-a0987980-7f52-4544-9cae-70d863a4a2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-fac57fa5-20f0-4278-85a7-4ae68d815c44,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-6e52c779-1d1c-4b5d-b3d1-abd0c86f13f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-4f16e80d-e2e4-4e78-8b23-94cfbdb52f81,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-7c6a2869-9a5b-4efd-9422-3262758575ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-df743047-e574-4527-8ac9-22c2fbdbb4a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-bdb0f873-4083-4fb4-a620-f37d410f0a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ac58594b-6fa1-4492-a834-2ddac215ba95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626824644-172.17.0.5-1597130937798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40346,DS-6c3387ae-acbb-46f2-b54e-9f6a01ad6e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-744c6214-f832-4f03-8f1f-6ae531e4afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-1a8d8c5c-a8b5-40a6-a24c-15d3cdf3aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-dfef2469-13c0-48b7-959f-3f6efcd957af,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-e23b4731-09c9-4e0f-ab09-87e733a03eca,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-7e36986f-81ee-458d-89d2-82cc64922d00,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-8b0a4754-9784-4331-b913-a61a81267af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-f3ee1321-ac11-4011-b439-7d1cf07d2077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626824644-172.17.0.5-1597130937798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40346,DS-6c3387ae-acbb-46f2-b54e-9f6a01ad6e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-744c6214-f832-4f03-8f1f-6ae531e4afdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-1a8d8c5c-a8b5-40a6-a24c-15d3cdf3aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-dfef2469-13c0-48b7-959f-3f6efcd957af,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-e23b4731-09c9-4e0f-ab09-87e733a03eca,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-7e36986f-81ee-458d-89d2-82cc64922d00,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-8b0a4754-9784-4331-b913-a61a81267af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-f3ee1321-ac11-4011-b439-7d1cf07d2077,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539144126-172.17.0.5-1597131774640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36398,DS-7aa0a20c-f9a1-445d-b871-ae4309f679f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-7848b2f9-5954-417b-b1eb-51412d5c4b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-416b6e5c-61d2-4b28-8d01-acc874e06c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-02935b7d-74e6-4de3-8764-95e6a7ac8284,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-c6a65930-9c68-422b-8160-6065b379fd32,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-19fbab98-2d54-408a-a6e5-c0b15aba25ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-0a21b2b1-2eea-4c33-b31f-7aa9f7cc7240,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-80ace9cd-abc9-4da6-a7f6-a42c9c1ab074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539144126-172.17.0.5-1597131774640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36398,DS-7aa0a20c-f9a1-445d-b871-ae4309f679f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-7848b2f9-5954-417b-b1eb-51412d5c4b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-416b6e5c-61d2-4b28-8d01-acc874e06c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-02935b7d-74e6-4de3-8764-95e6a7ac8284,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-c6a65930-9c68-422b-8160-6065b379fd32,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-19fbab98-2d54-408a-a6e5-c0b15aba25ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-0a21b2b1-2eea-4c33-b31f-7aa9f7cc7240,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-80ace9cd-abc9-4da6-a7f6-a42c9c1ab074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865870085-172.17.0.5-1597131869008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-92b24ddd-6914-48eb-9aac-17b335f90fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-803e7172-8b11-425f-b861-84635314b245,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-428f87cd-2453-4631-aa06-3ea94b511501,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-52d29435-2565-41cc-a985-5fc6006d7f90,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-0b23f5c1-8413-4c66-8f3f-e920efe08f72,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-616d0fcb-8f2c-45b8-8818-555d085246f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-2c90831f-aa4f-49da-bd97-4638314fc5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-e98167ab-eb3d-481c-9cbd-48c5d0ac74df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1865870085-172.17.0.5-1597131869008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39105,DS-92b24ddd-6914-48eb-9aac-17b335f90fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-803e7172-8b11-425f-b861-84635314b245,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-428f87cd-2453-4631-aa06-3ea94b511501,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-52d29435-2565-41cc-a985-5fc6006d7f90,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-0b23f5c1-8413-4c66-8f3f-e920efe08f72,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-616d0fcb-8f2c-45b8-8818-555d085246f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-2c90831f-aa4f-49da-bd97-4638314fc5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-e98167ab-eb3d-481c-9cbd-48c5d0ac74df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365131313-172.17.0.5-1597132012217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36049,DS-339a8e57-396e-4b93-b351-560f1f1dcc53,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-f2a92906-9d50-4b45-9642-af8ca340ac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-c3189a0a-e432-4707-a1fd-3008a103c85b,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-5f328e95-b470-472e-a854-bb69df530da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-d1c21c0f-e6fa-48a1-bb9d-61aaa3f2ea1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-d38240bc-7cf6-4924-92a3-a7515edaeb51,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-c38a6633-047e-4ffa-835a-fc40c9ee0873,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-82e24587-63dd-4f42-ba37-e9076efebb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365131313-172.17.0.5-1597132012217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36049,DS-339a8e57-396e-4b93-b351-560f1f1dcc53,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-f2a92906-9d50-4b45-9642-af8ca340ac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-c3189a0a-e432-4707-a1fd-3008a103c85b,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-5f328e95-b470-472e-a854-bb69df530da1,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-d1c21c0f-e6fa-48a1-bb9d-61aaa3f2ea1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-d38240bc-7cf6-4924-92a3-a7515edaeb51,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-c38a6633-047e-4ffa-835a-fc40c9ee0873,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-82e24587-63dd-4f42-ba37-e9076efebb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068249642-172.17.0.5-1597132108270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-bd8a611d-ce26-4338-8d0c-78cfde0bd5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-fc2044d8-d4f5-45c5-81fd-3426b5ff655d,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-8b0a19af-f4c6-4e0d-9073-1e2b67a686ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-78234bed-7e56-415b-a147-373b4a01c873,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-565b28b7-0f96-4de1-bf74-7f819990bbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-e802a840-eae5-424a-8658-730575bce92e,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-b044004b-5149-4d95-bade-c0796ea255ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-49fc8fa5-8d04-42cd-a8ed-c5f034d2950d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2068249642-172.17.0.5-1597132108270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-bd8a611d-ce26-4338-8d0c-78cfde0bd5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-fc2044d8-d4f5-45c5-81fd-3426b5ff655d,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-8b0a19af-f4c6-4e0d-9073-1e2b67a686ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-78234bed-7e56-415b-a147-373b4a01c873,DISK], DatanodeInfoWithStorage[127.0.0.1:45036,DS-565b28b7-0f96-4de1-bf74-7f819990bbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-e802a840-eae5-424a-8658-730575bce92e,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-b044004b-5149-4d95-bade-c0796ea255ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-49fc8fa5-8d04-42cd-a8ed-c5f034d2950d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957007928-172.17.0.5-1597132477138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46008,DS-97621ea2-801f-4479-89ef-7e7eee2059fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-e201364b-f66c-4b1d-8c68-af8cfab4521c,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-66a48262-3971-4d38-b181-d193ed5c21d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-3491aa21-2e79-4137-950e-a28a95ec34ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-8ef41a31-2827-4603-b4b4-0f5670a8e144,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-153e9788-cf24-4fec-87bc-14c1cd874f74,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-da33395b-84a0-4d6a-9694-782ba03def23,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-53651430-fb43-4578-a23b-ec93436ef8bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957007928-172.17.0.5-1597132477138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46008,DS-97621ea2-801f-4479-89ef-7e7eee2059fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-e201364b-f66c-4b1d-8c68-af8cfab4521c,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-66a48262-3971-4d38-b181-d193ed5c21d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-3491aa21-2e79-4137-950e-a28a95ec34ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-8ef41a31-2827-4603-b4b4-0f5670a8e144,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-153e9788-cf24-4fec-87bc-14c1cd874f74,DISK], DatanodeInfoWithStorage[127.0.0.1:43936,DS-da33395b-84a0-4d6a-9694-782ba03def23,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-53651430-fb43-4578-a23b-ec93436ef8bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498881904-172.17.0.5-1597132926001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-add87070-8d00-4d4b-8df2-38bf8926c561,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-6a181ba8-9cd9-477f-a37f-def350e672e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-af71dd1e-1e2e-4efe-95a7-44730df05036,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-7fca5313-8014-432d-8d43-e1916c113684,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-083980df-4099-45b0-a1e2-d3b04d9183e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-00cf4c59-94a6-4020-8140-f93bc674f489,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-ec07fbe4-1872-4423-8ee4-b5a91bf4c059,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-411aa54b-b2d8-459e-badf-e5d7f289fbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498881904-172.17.0.5-1597132926001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-add87070-8d00-4d4b-8df2-38bf8926c561,DISK], DatanodeInfoWithStorage[127.0.0.1:33558,DS-6a181ba8-9cd9-477f-a37f-def350e672e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-af71dd1e-1e2e-4efe-95a7-44730df05036,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-7fca5313-8014-432d-8d43-e1916c113684,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-083980df-4099-45b0-a1e2-d3b04d9183e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-00cf4c59-94a6-4020-8140-f93bc674f489,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-ec07fbe4-1872-4423-8ee4-b5a91bf4c059,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-411aa54b-b2d8-459e-badf-e5d7f289fbc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074634314-172.17.0.5-1597133075220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34287,DS-0c783b2e-183f-4024-a2a1-2f79947b9e53,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-5e56c76b-e689-400a-a068-53fb70d8ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-648646f0-7f86-4409-a237-0acf984a896d,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-1ef3bf46-3b44-4de5-889b-34a71f0a1d59,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-4e7b3813-5ee2-4873-a1f0-e726ab4771cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-f0d96635-7344-49ed-b3c2-5d3be1d7ffed,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-36d676da-4cc7-45ff-aef5-99110c22c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-95eaaf35-aac8-4c8c-b2a5-ed82a3607ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074634314-172.17.0.5-1597133075220:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34287,DS-0c783b2e-183f-4024-a2a1-2f79947b9e53,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-5e56c76b-e689-400a-a068-53fb70d8ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-648646f0-7f86-4409-a237-0acf984a896d,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-1ef3bf46-3b44-4de5-889b-34a71f0a1d59,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-4e7b3813-5ee2-4873-a1f0-e726ab4771cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41438,DS-f0d96635-7344-49ed-b3c2-5d3be1d7ffed,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-36d676da-4cc7-45ff-aef5-99110c22c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37806,DS-95eaaf35-aac8-4c8c-b2a5-ed82a3607ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637378550-172.17.0.5-1597133833603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40300,DS-bd03e83f-879f-47fe-9702-ddcf6cebddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-a729d112-927a-460a-91a3-28266128e306,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-810fab4a-b1c1-4664-8dcd-21f49bf6079e,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-d4dacb3b-c86c-444d-bf17-6aa6a0f496d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-e87632aa-8ec8-4f91-b5b7-6a83dd5c76fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-ecc50ae2-3747-4fdd-8f2d-cdc941636dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-54a86853-2a35-47db-96a1-1c934645051a,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-f48074cf-37ef-4f7f-9f19-be6aa42fc519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637378550-172.17.0.5-1597133833603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40300,DS-bd03e83f-879f-47fe-9702-ddcf6cebddc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-a729d112-927a-460a-91a3-28266128e306,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-810fab4a-b1c1-4664-8dcd-21f49bf6079e,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-d4dacb3b-c86c-444d-bf17-6aa6a0f496d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-e87632aa-8ec8-4f91-b5b7-6a83dd5c76fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-ecc50ae2-3747-4fdd-8f2d-cdc941636dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-54a86853-2a35-47db-96a1-1c934645051a,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-f48074cf-37ef-4f7f-9f19-be6aa42fc519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106549561-172.17.0.5-1597134061793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44760,DS-c8518901-d921-481f-bfd8-0cf605d2bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-80b816c0-ba5b-4bb7-83ed-08295091f844,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-f2a698e9-78d2-401b-b8b1-e259a4f08b87,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-083c16ee-8fae-4a3a-ae0b-35d9c679c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-dc70b960-4cb0-4101-9742-564a31d43764,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-db67205c-f696-4a4f-a993-f13699bd80b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-3ec08b27-eb34-4452-9cdc-17f6b2098d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-3559fbf3-d300-4862-8f63-e3bf32ae481a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106549561-172.17.0.5-1597134061793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44760,DS-c8518901-d921-481f-bfd8-0cf605d2bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-80b816c0-ba5b-4bb7-83ed-08295091f844,DISK], DatanodeInfoWithStorage[127.0.0.1:46309,DS-f2a698e9-78d2-401b-b8b1-e259a4f08b87,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-083c16ee-8fae-4a3a-ae0b-35d9c679c5e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-dc70b960-4cb0-4101-9742-564a31d43764,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-db67205c-f696-4a4f-a993-f13699bd80b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-3ec08b27-eb34-4452-9cdc-17f6b2098d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43195,DS-3559fbf3-d300-4862-8f63-e3bf32ae481a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46572014-172.17.0.5-1597134384029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44344,DS-84e0c983-70e4-4f23-a123-d1223c733e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-0ee4cffc-87b7-4727-9ccc-1395923d14fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-39011fa5-cf7b-49a8-8c07-05232bcab41d,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-beb81418-60b6-4022-8f6e-f3e55b3e4bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-7ffeb936-acf9-4479-ac27-2853ec2711ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-9ba2413c-2e88-49aa-90ea-11ebccfbae82,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-87eb8dc0-cf4c-4232-b371-437afff3537e,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-81f07fb7-37c3-4b1a-86b0-d08613456e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46572014-172.17.0.5-1597134384029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44344,DS-84e0c983-70e4-4f23-a123-d1223c733e34,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-0ee4cffc-87b7-4727-9ccc-1395923d14fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-39011fa5-cf7b-49a8-8c07-05232bcab41d,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-beb81418-60b6-4022-8f6e-f3e55b3e4bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-7ffeb936-acf9-4479-ac27-2853ec2711ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-9ba2413c-2e88-49aa-90ea-11ebccfbae82,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-87eb8dc0-cf4c-4232-b371-437afff3537e,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-81f07fb7-37c3-4b1a-86b0-d08613456e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.throttle.limit.ms.per.sec
component: hdfs:DataNode
v1: 1000
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211346368-172.17.0.5-1597134600963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34553,DS-9d72868f-8c01-46b6-bc1f-29d8faf920e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-b9d50f5e-dd40-4087-af55-16056347a12b,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-d15689d4-39c6-49cf-ad02-1eb31c00ba04,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-e357648e-763a-464b-8b1b-d179deca8f16,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-ba178e67-eb38-42d9-b973-6656c7c06ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-17693f90-b902-4c58-a7d2-b93978b275f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-ba40b2aa-401c-48c1-ac04-740e21f3c89c,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-2e3bfa06-0dca-4a5f-a65d-63d5209a36f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-211346368-172.17.0.5-1597134600963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34553,DS-9d72868f-8c01-46b6-bc1f-29d8faf920e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-b9d50f5e-dd40-4087-af55-16056347a12b,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-d15689d4-39c6-49cf-ad02-1eb31c00ba04,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-e357648e-763a-464b-8b1b-d179deca8f16,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-ba178e67-eb38-42d9-b973-6656c7c06ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-17693f90-b902-4c58-a7d2-b93978b275f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-ba40b2aa-401c-48c1-ac04-740e21f3c89c,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-2e3bfa06-0dca-4a5f-a65d-63d5209a36f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6704
