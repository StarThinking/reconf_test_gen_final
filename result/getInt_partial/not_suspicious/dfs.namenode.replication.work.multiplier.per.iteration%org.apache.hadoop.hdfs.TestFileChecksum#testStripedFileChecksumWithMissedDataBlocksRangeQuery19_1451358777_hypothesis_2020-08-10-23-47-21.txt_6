reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105439172-172.17.0.14-1597103293887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-e0beb706-abf6-498a-8fcc-ae1517e8e638,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-c975da5d-f105-428e-a93c-93172090598d,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-6229fb92-4ef5-4116-a5cc-4072af19af95,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-f1c3f7e2-6430-475d-895f-7a077ec5023e,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-7f3ff69d-b679-41d3-b649-c74c583fadc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-205d1ced-05f3-417b-bf2c-210be0400987,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-8ef9635f-5601-4705-a81b-5c0b6844c022,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-6a495da8-42de-446b-9adf-75c4324c8340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105439172-172.17.0.14-1597103293887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33864,DS-e0beb706-abf6-498a-8fcc-ae1517e8e638,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-c975da5d-f105-428e-a93c-93172090598d,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-6229fb92-4ef5-4116-a5cc-4072af19af95,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-f1c3f7e2-6430-475d-895f-7a077ec5023e,DISK], DatanodeInfoWithStorage[127.0.0.1:44452,DS-7f3ff69d-b679-41d3-b649-c74c583fadc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-205d1ced-05f3-417b-bf2c-210be0400987,DISK], DatanodeInfoWithStorage[127.0.0.1:45948,DS-8ef9635f-5601-4705-a81b-5c0b6844c022,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-6a495da8-42de-446b-9adf-75c4324c8340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540321818-172.17.0.14-1597103330611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34012,DS-53aa2003-a6e5-460b-9750-b83d755a640c,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-0ba710c1-c08f-4d73-bc98-798640ad6248,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-4c745775-2a1b-4b52-9931-1fd30316c096,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-de9ce189-3d2c-48f9-a5c2-e41b50cb3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-3c786080-6f8f-403b-af69-82ccab2eb915,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-f53a2eaf-ccef-4204-85a2-f8484e391d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-1ade2d71-cd5e-47a8-9dc1-ad72871c5036,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-4449cbce-6a46-4fdb-b0b4-b277fdf33fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540321818-172.17.0.14-1597103330611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34012,DS-53aa2003-a6e5-460b-9750-b83d755a640c,DISK], DatanodeInfoWithStorage[127.0.0.1:45999,DS-0ba710c1-c08f-4d73-bc98-798640ad6248,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-4c745775-2a1b-4b52-9931-1fd30316c096,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-de9ce189-3d2c-48f9-a5c2-e41b50cb3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-3c786080-6f8f-403b-af69-82ccab2eb915,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-f53a2eaf-ccef-4204-85a2-f8484e391d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-1ade2d71-cd5e-47a8-9dc1-ad72871c5036,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-4449cbce-6a46-4fdb-b0b4-b277fdf33fa1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645029879-172.17.0.14-1597104088153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-4b47a2a4-27e1-49cf-88d6-10ff1a359315,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-846dd060-2f3f-44d9-93f5-08aab8dbea81,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-9f075df3-4540-498f-b4c0-26eb0fdee473,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-164158d4-c348-4876-8169-8e2e89fa3cec,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-e4d2218f-4b6e-4709-9149-6d381ca87083,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-84d5cb08-9303-4894-8204-beccbacf9537,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-94acce6a-4f71-49c3-a04a-ab215ecbddad,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-af840e9a-5ac9-4204-af64-53ebb968895a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-645029879-172.17.0.14-1597104088153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44985,DS-4b47a2a4-27e1-49cf-88d6-10ff1a359315,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-846dd060-2f3f-44d9-93f5-08aab8dbea81,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-9f075df3-4540-498f-b4c0-26eb0fdee473,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-164158d4-c348-4876-8169-8e2e89fa3cec,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-e4d2218f-4b6e-4709-9149-6d381ca87083,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-84d5cb08-9303-4894-8204-beccbacf9537,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-94acce6a-4f71-49c3-a04a-ab215ecbddad,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-af840e9a-5ac9-4204-af64-53ebb968895a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996906468-172.17.0.14-1597104364178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-fbffd2f6-19fd-40b4-a164-d78fca633860,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-b361c422-4144-482b-a572-8d00c19c4f07,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-58379ece-5833-4147-9b5e-e5c02ac65517,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-176afa38-e87c-4761-95ca-05b582900bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-debf645f-2a15-44d7-8068-8e32cc8f75f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-cdfd05c7-c348-4a94-b7b5-ce8dd2ae670f,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-cd0f98b0-d380-4c70-ae25-0c1569f5c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-102018b5-7a67-4c40-b068-26b551a4a5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1996906468-172.17.0.14-1597104364178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44334,DS-fbffd2f6-19fd-40b4-a164-d78fca633860,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-b361c422-4144-482b-a572-8d00c19c4f07,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-58379ece-5833-4147-9b5e-e5c02ac65517,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-176afa38-e87c-4761-95ca-05b582900bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-debf645f-2a15-44d7-8068-8e32cc8f75f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-cdfd05c7-c348-4a94-b7b5-ce8dd2ae670f,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-cd0f98b0-d380-4c70-ae25-0c1569f5c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-102018b5-7a67-4c40-b068-26b551a4a5a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952344186-172.17.0.14-1597104396147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-a4c07fd9-4e80-4976-b282-d6a115794c71,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-40e3ca02-f098-4dd4-a97e-4a408fdea0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-6c9875fd-d951-431b-ae21-0fc7d4932803,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-7f9302b2-8b36-4225-b897-96847da2ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-3e8d6024-7abc-4d24-8b5d-05ddc00f9e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-35b99022-3f62-42fe-9034-dfe38672abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-fbf52d57-55ce-402f-8e8a-4e9f7c7a4f99,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-3b56878f-0d04-4428-ad9c-024e318dbea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-952344186-172.17.0.14-1597104396147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-a4c07fd9-4e80-4976-b282-d6a115794c71,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-40e3ca02-f098-4dd4-a97e-4a408fdea0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-6c9875fd-d951-431b-ae21-0fc7d4932803,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-7f9302b2-8b36-4225-b897-96847da2ab31,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-3e8d6024-7abc-4d24-8b5d-05ddc00f9e72,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-35b99022-3f62-42fe-9034-dfe38672abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-fbf52d57-55ce-402f-8e8a-4e9f7c7a4f99,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-3b56878f-0d04-4428-ad9c-024e318dbea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874505548-172.17.0.14-1597105221643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-9282100a-ea2c-41ac-9f67-ad40a6600030,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-bb48e834-fbe3-4ea2-9fee-32936e77e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-91dbd0fb-0261-4916-9387-5d726ea7d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-33c73347-df57-4427-bda5-28885f501fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-2f82a22a-b30a-424c-8ed7-8918223966c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-f4a3de5c-b80b-4905-abc9-08d620c46983,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-cfea09af-13a0-442d-853b-ecac584bf919,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-255c6259-3be1-4167-aa66-9bb6f2dbf6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874505548-172.17.0.14-1597105221643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46286,DS-9282100a-ea2c-41ac-9f67-ad40a6600030,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-bb48e834-fbe3-4ea2-9fee-32936e77e0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-91dbd0fb-0261-4916-9387-5d726ea7d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-33c73347-df57-4427-bda5-28885f501fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-2f82a22a-b30a-424c-8ed7-8918223966c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-f4a3de5c-b80b-4905-abc9-08d620c46983,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-cfea09af-13a0-442d-853b-ecac584bf919,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-255c6259-3be1-4167-aa66-9bb6f2dbf6d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478142633-172.17.0.14-1597105537936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-6ad0f3c5-c318-483f-9d2d-5f92c6ae0c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-a04fd4b4-c4df-4720-bfc7-a7559699a933,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-6c563cfa-ba55-4b21-acf4-b520355bc706,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-bd9439b5-4ef0-40d6-9f9c-843e01440eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-cb1999d7-1514-42f8-a603-f163f36e7e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-a0eb9c5f-e4ea-4d71-8c11-855071d68595,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-04f72e04-88d7-4891-b8e3-c060a42c8cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-010251b3-c37b-4681-a3a8-33f0cc1500dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1478142633-172.17.0.14-1597105537936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-6ad0f3c5-c318-483f-9d2d-5f92c6ae0c17,DISK], DatanodeInfoWithStorage[127.0.0.1:39178,DS-a04fd4b4-c4df-4720-bfc7-a7559699a933,DISK], DatanodeInfoWithStorage[127.0.0.1:35089,DS-6c563cfa-ba55-4b21-acf4-b520355bc706,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-bd9439b5-4ef0-40d6-9f9c-843e01440eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-cb1999d7-1514-42f8-a603-f163f36e7e34,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-a0eb9c5f-e4ea-4d71-8c11-855071d68595,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-04f72e04-88d7-4891-b8e3-c060a42c8cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-010251b3-c37b-4681-a3a8-33f0cc1500dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266613122-172.17.0.14-1597105777728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-66effb66-5ef7-485c-924f-29f85f260abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-55b47968-4423-4792-9c89-c0b4db0792eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-962a3086-834b-4d18-a498-856be391a635,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-39d94e7d-15f5-4b21-9fdc-ca0390cf37e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-430f5803-f7f7-40d6-a2e4-149b81540935,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-1bc118bc-6673-4c13-b41c-637fd26c579b,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-a00f7d43-eec5-4693-aebd-73dd7c8a4653,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-c271a466-a289-491d-a919-d9594a36a435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266613122-172.17.0.14-1597105777728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33166,DS-66effb66-5ef7-485c-924f-29f85f260abb,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-55b47968-4423-4792-9c89-c0b4db0792eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-962a3086-834b-4d18-a498-856be391a635,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-39d94e7d-15f5-4b21-9fdc-ca0390cf37e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-430f5803-f7f7-40d6-a2e4-149b81540935,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-1bc118bc-6673-4c13-b41c-637fd26c579b,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-a00f7d43-eec5-4693-aebd-73dd7c8a4653,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-c271a466-a289-491d-a919-d9594a36a435,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12887282-172.17.0.14-1597105806676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-6d39974a-7097-4251-8d4a-71d6bc6745e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-4e682885-7141-4414-b665-bd3579979b52,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-6d87040f-0c8e-4ec8-8949-22324a0232d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-08215164-b8fd-4b7c-998d-948b937a95b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-c6caa284-0536-4635-9431-469f7e1c7bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-a89147c4-6834-4be4-9002-167628eb05c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-7e5d739a-9ac6-4662-8a14-0d0eb743ed77,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-4047837f-a8d0-490e-91d2-f52a9909aab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-12887282-172.17.0.14-1597105806676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-6d39974a-7097-4251-8d4a-71d6bc6745e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38051,DS-4e682885-7141-4414-b665-bd3579979b52,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-6d87040f-0c8e-4ec8-8949-22324a0232d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-08215164-b8fd-4b7c-998d-948b937a95b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-c6caa284-0536-4635-9431-469f7e1c7bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-a89147c4-6834-4be4-9002-167628eb05c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-7e5d739a-9ac6-4662-8a14-0d0eb743ed77,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-4047837f-a8d0-490e-91d2-f52a9909aab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215861340-172.17.0.14-1597105931160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-57b03b89-9aae-479f-b759-679e6ce35b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-a711a6bf-9ca2-4893-a628-471524f34e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-e4abd500-71c1-4c6d-b3e3-74110985d098,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-a8fa83fb-6888-4b84-9633-c5329d2c1c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-681f2725-c871-458e-bc58-3d717b286a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-84182510-8279-442b-966a-9b5eca90ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-7d7e2aa4-2f50-44b6-af7a-fb30fd0c764c,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-a5e6c175-da71-4662-b2ae-d1c5e05e12b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-215861340-172.17.0.14-1597105931160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39527,DS-57b03b89-9aae-479f-b759-679e6ce35b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-a711a6bf-9ca2-4893-a628-471524f34e90,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-e4abd500-71c1-4c6d-b3e3-74110985d098,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-a8fa83fb-6888-4b84-9633-c5329d2c1c11,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-681f2725-c871-458e-bc58-3d717b286a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34439,DS-84182510-8279-442b-966a-9b5eca90ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-7d7e2aa4-2f50-44b6-af7a-fb30fd0c764c,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-a5e6c175-da71-4662-b2ae-d1c5e05e12b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649447496-172.17.0.14-1597106018443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45585,DS-502165da-4173-407f-ae99-c5bb12f3f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-75fa8b76-115b-40c2-98c1-2e790a7fbe17,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-b19a1806-34ba-4131-b2ca-3d3597a25f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-4b24dec2-ff8a-4948-b8ef-853c2aaf3901,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-70f35c0b-10b9-4c29-8645-ab175f1c5713,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-b6b94bdd-3558-41b7-aebb-77c7e867af73,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-85e85336-e6cf-4967-94d9-685188b4935e,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-2cd9a1dc-9ab8-4bc0-9b4c-0a19ba38bfc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649447496-172.17.0.14-1597106018443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45585,DS-502165da-4173-407f-ae99-c5bb12f3f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-75fa8b76-115b-40c2-98c1-2e790a7fbe17,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-b19a1806-34ba-4131-b2ca-3d3597a25f52,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-4b24dec2-ff8a-4948-b8ef-853c2aaf3901,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-70f35c0b-10b9-4c29-8645-ab175f1c5713,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-b6b94bdd-3558-41b7-aebb-77c7e867af73,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-85e85336-e6cf-4967-94d9-685188b4935e,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-2cd9a1dc-9ab8-4bc0-9b4c-0a19ba38bfc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496752644-172.17.0.14-1597106120085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41778,DS-7717fa0a-5c47-4c17-ba77-45c171f78efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-a2cd5abe-e41b-45da-8b3e-4d5c7f270fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-5ee3120f-a61d-4f85-af34-58ea239679c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-f5d7b931-c32c-4d25-98ed-976bb9bbb711,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-31ed0b0f-bf49-4611-bc42-27e0da7c689f,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-65a72887-f80e-4503-9e06-ce1c76d096d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-e44ee4d9-f5f9-41c4-ae71-154d7e981d67,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-7f9791a5-1385-471b-8e11-9e691af10cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1496752644-172.17.0.14-1597106120085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41778,DS-7717fa0a-5c47-4c17-ba77-45c171f78efb,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-a2cd5abe-e41b-45da-8b3e-4d5c7f270fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-5ee3120f-a61d-4f85-af34-58ea239679c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-f5d7b931-c32c-4d25-98ed-976bb9bbb711,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-31ed0b0f-bf49-4611-bc42-27e0da7c689f,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-65a72887-f80e-4503-9e06-ce1c76d096d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-e44ee4d9-f5f9-41c4-ae71-154d7e981d67,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-7f9791a5-1385-471b-8e11-9e691af10cc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144226885-172.17.0.14-1597106765298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-7c2e0f47-f559-4e0d-93f6-1814a4666449,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-3fa49a4f-04a2-444b-9e5e-6b4b81231b74,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-db07bdc0-8748-4152-8035-a58176649de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-a5489bbb-3d86-4b86-ace1-b15b34f6a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-d7c35d34-811e-434d-a7c4-4b5c9df74e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-0990b750-d4d3-417e-93bd-9af5bcdd67b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-665a3c8f-d01a-4e32-9a04-c64a7f5deb79,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-0d628017-8c05-4ec2-8e62-a21c5c3b0dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2144226885-172.17.0.14-1597106765298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39037,DS-7c2e0f47-f559-4e0d-93f6-1814a4666449,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-3fa49a4f-04a2-444b-9e5e-6b4b81231b74,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-db07bdc0-8748-4152-8035-a58176649de4,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-a5489bbb-3d86-4b86-ace1-b15b34f6a0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-d7c35d34-811e-434d-a7c4-4b5c9df74e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-0990b750-d4d3-417e-93bd-9af5bcdd67b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-665a3c8f-d01a-4e32-9a04-c64a7f5deb79,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-0d628017-8c05-4ec2-8e62-a21c5c3b0dfb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415835049-172.17.0.14-1597107101175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-eb46438c-ab9e-4e53-bd59-181fd954133f,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-7d55fd9b-5397-4291-8076-78b9f9835112,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-774547f4-cf50-445e-9901-1035f5437e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-a5d2332f-6132-494d-9471-d9b0f0321035,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-dcdafe15-3509-45a8-9478-1d8039a365e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-f697059e-e42e-4517-9d97-608b3fb640f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-7f0dd3c9-dba5-4f28-bb7c-17a19b58442f,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-ef427d5f-cffb-4dd0-a328-ed1046aebfe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-415835049-172.17.0.14-1597107101175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42115,DS-eb46438c-ab9e-4e53-bd59-181fd954133f,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-7d55fd9b-5397-4291-8076-78b9f9835112,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-774547f4-cf50-445e-9901-1035f5437e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-a5d2332f-6132-494d-9471-d9b0f0321035,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-dcdafe15-3509-45a8-9478-1d8039a365e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-f697059e-e42e-4517-9d97-608b3fb640f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-7f0dd3c9-dba5-4f28-bb7c-17a19b58442f,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-ef427d5f-cffb-4dd0-a328-ed1046aebfe3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149106769-172.17.0.14-1597107262526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-e88c9e3f-f57c-4dbe-aee8-a3eb72f475b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-3d0df34b-739e-44fc-a8fc-338fd569909e,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-f6ed5934-b88a-4988-ad4c-9468536e471f,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-46651c4f-2543-454b-899e-9a018a80e468,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-6303f4cb-7838-4cc7-8549-5fde85d38cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-0d998b74-bb81-42f3-955b-d6e6569e190b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-80e03649-564c-47bb-82b9-cc7bc6ca3ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-e80b079d-d202-478c-92da-7b56b865797c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149106769-172.17.0.14-1597107262526:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39540,DS-e88c9e3f-f57c-4dbe-aee8-a3eb72f475b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-3d0df34b-739e-44fc-a8fc-338fd569909e,DISK], DatanodeInfoWithStorage[127.0.0.1:33311,DS-f6ed5934-b88a-4988-ad4c-9468536e471f,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-46651c4f-2543-454b-899e-9a018a80e468,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-6303f4cb-7838-4cc7-8549-5fde85d38cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-0d998b74-bb81-42f3-955b-d6e6569e190b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-80e03649-564c-47bb-82b9-cc7bc6ca3ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-e80b079d-d202-478c-92da-7b56b865797c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308156905-172.17.0.14-1597107436056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38929,DS-3d829ad3-0f69-4435-a753-083c93567417,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-d9af0a8e-2073-41f8-9857-ba8552875c01,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-8c6b7bcc-1925-474a-9650-fa6d180b55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-ba0cef58-c379-4e23-84c8-aebf2a1bd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-e01d626d-8f05-4c0a-9cc0-f7a495fecd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-69904dcc-6f6b-4788-9ff7-bdfc10e114f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-1dd92824-9c6c-436e-8472-a3a8596b62e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-c2e4ff5d-cc68-4cef-b76b-0980715a2c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308156905-172.17.0.14-1597107436056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38929,DS-3d829ad3-0f69-4435-a753-083c93567417,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-d9af0a8e-2073-41f8-9857-ba8552875c01,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-8c6b7bcc-1925-474a-9650-fa6d180b55c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-ba0cef58-c379-4e23-84c8-aebf2a1bd6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-e01d626d-8f05-4c0a-9cc0-f7a495fecd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-69904dcc-6f6b-4788-9ff7-bdfc10e114f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-1dd92824-9c6c-436e-8472-a3a8596b62e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-c2e4ff5d-cc68-4cef-b76b-0980715a2c4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 1
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63667034-172.17.0.14-1597107556814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44165,DS-0b5ea7c7-1936-4b7b-a03f-0519b992c162,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-19cd60a6-18cc-40da-84f1-fb94e3c815f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-5a0a3273-7543-4b6f-a0ef-558a70814851,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-b459cd79-812e-4b56-a5db-c88d58ea0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-36bce53f-d319-42e6-b0ad-e097dc16ee6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-34f14db5-a172-4180-a049-60b44bfebcee,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-ed706d42-0812-4019-b0d2-b75f7b64bd73,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-5b8b6d47-d67a-43eb-91a9-634aadb8d8ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-63667034-172.17.0.14-1597107556814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44165,DS-0b5ea7c7-1936-4b7b-a03f-0519b992c162,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-19cd60a6-18cc-40da-84f1-fb94e3c815f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-5a0a3273-7543-4b6f-a0ef-558a70814851,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-b459cd79-812e-4b56-a5db-c88d58ea0e93,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-36bce53f-d319-42e6-b0ad-e097dc16ee6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-34f14db5-a172-4180-a049-60b44bfebcee,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-ed706d42-0812-4019-b0d2-b75f7b64bd73,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-5b8b6d47-d67a-43eb-91a9-634aadb8d8ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4791
