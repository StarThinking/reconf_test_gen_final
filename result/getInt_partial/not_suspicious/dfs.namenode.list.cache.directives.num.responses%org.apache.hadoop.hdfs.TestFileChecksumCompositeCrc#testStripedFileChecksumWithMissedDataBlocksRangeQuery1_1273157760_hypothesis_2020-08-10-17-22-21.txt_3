reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112290176-172.17.0.7-1597081094315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38554,DS-9e4904df-5248-4206-b5b1-c9d36ae8de16,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-78c9232d-010f-412a-94f0-9f8b559d3a91,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-0d901084-8012-44bb-9cad-2a71a934205c,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-82b4c2b3-dd19-43b3-bd79-40751f65b449,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-44e3d419-e2a0-4c71-a4e7-7438f1534824,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-4fc5b663-cd01-4202-b309-bfa5a988be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-d98188ca-be94-45c1-9102-08a1aab66514,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-ad936bd1-4d06-4c5d-9b5e-643402694056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2112290176-172.17.0.7-1597081094315:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38554,DS-9e4904df-5248-4206-b5b1-c9d36ae8de16,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-78c9232d-010f-412a-94f0-9f8b559d3a91,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-0d901084-8012-44bb-9cad-2a71a934205c,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-82b4c2b3-dd19-43b3-bd79-40751f65b449,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-44e3d419-e2a0-4c71-a4e7-7438f1534824,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-4fc5b663-cd01-4202-b309-bfa5a988be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-d98188ca-be94-45c1-9102-08a1aab66514,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-ad936bd1-4d06-4c5d-9b5e-643402694056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320277452-172.17.0.7-1597081132621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-43162754-2d99-4b8a-a616-cd60f6f7d483,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-b7bc9d96-fcca-4c12-aba9-a28c196200ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-5fa4c2e1-3521-411f-9120-d0b6d35dbd85,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-61ad7257-5846-411a-a590-e604b4cbe47d,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-72965e05-4c57-4f47-bbba-dad93cfab520,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-1b70c506-7905-4ce7-a8df-9143aeeb61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-e078eaaf-bf6a-4ca6-b7d2-4f97b5172128,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-7ce69be5-d35f-434f-9467-8f4c77ba4685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-320277452-172.17.0.7-1597081132621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45487,DS-43162754-2d99-4b8a-a616-cd60f6f7d483,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-b7bc9d96-fcca-4c12-aba9-a28c196200ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-5fa4c2e1-3521-411f-9120-d0b6d35dbd85,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-61ad7257-5846-411a-a590-e604b4cbe47d,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-72965e05-4c57-4f47-bbba-dad93cfab520,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-1b70c506-7905-4ce7-a8df-9143aeeb61cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-e078eaaf-bf6a-4ca6-b7d2-4f97b5172128,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-7ce69be5-d35f-434f-9467-8f4c77ba4685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119972075-172.17.0.7-1597081752410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34679,DS-b9c4af06-6c06-4b37-8939-34ad91ce8935,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-017f4d31-5cef-4056-abb7-fa36f15a07d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-9d063a82-d60d-43eb-8c5f-0f341276ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-c158d6cd-0fab-4aaa-a19c-59bd7d745627,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-a499c052-d7eb-48f0-98f9-1833738932dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-fddfa548-b329-408a-b982-f50d3597aa88,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-99de1d4a-66e7-43e0-81d2-55ce165ae4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-c278dda4-aaab-48ce-8b3d-020a2fac08f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119972075-172.17.0.7-1597081752410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34679,DS-b9c4af06-6c06-4b37-8939-34ad91ce8935,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-017f4d31-5cef-4056-abb7-fa36f15a07d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-9d063a82-d60d-43eb-8c5f-0f341276ec76,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-c158d6cd-0fab-4aaa-a19c-59bd7d745627,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-a499c052-d7eb-48f0-98f9-1833738932dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-fddfa548-b329-408a-b982-f50d3597aa88,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-99de1d4a-66e7-43e0-81d2-55ce165ae4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-c278dda4-aaab-48ce-8b3d-020a2fac08f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582799452-172.17.0.7-1597081954273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43988,DS-5b19f1ba-f184-4df9-852a-d56c06d2f7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-ad1c65b6-bfe2-4a17-9b63-1cfa685bec66,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-4e87f5be-2ff0-4246-ba79-b674138dac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-96c169a5-f922-41e3-a486-6d48c6212c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-92bc16c5-c7ca-4bc0-a1ba-6b7f143b26be,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-be355134-7f19-4d5f-b9e6-b12ab01da143,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-387850d3-a0a7-40ec-bea3-e439d77886f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-bf1788e7-f52b-4e5e-8713-a1f0c7dbb7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582799452-172.17.0.7-1597081954273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43988,DS-5b19f1ba-f184-4df9-852a-d56c06d2f7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-ad1c65b6-bfe2-4a17-9b63-1cfa685bec66,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-4e87f5be-2ff0-4246-ba79-b674138dac5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37972,DS-96c169a5-f922-41e3-a486-6d48c6212c02,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-92bc16c5-c7ca-4bc0-a1ba-6b7f143b26be,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-be355134-7f19-4d5f-b9e6-b12ab01da143,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-387850d3-a0a7-40ec-bea3-e439d77886f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-bf1788e7-f52b-4e5e-8713-a1f0c7dbb7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99287028-172.17.0.7-1597082291117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37444,DS-86dfe86a-2332-4ed6-843d-69a81d0e983e,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-0018b128-f7a4-4e30-9d09-f83b59f7bf16,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-6f786172-8721-4da4-8dc9-075441fd316c,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-a82f37b8-62c0-45b9-9b6d-979c23c1c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-667ad8cf-1383-42a9-9221-20fe96cb2d66,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-fd72b53d-8db4-45df-a48c-027f6b051277,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-c18c413f-eb90-499e-a541-05c5488cc98c,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-64e743d8-a73e-40ce-931d-953a10d686fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99287028-172.17.0.7-1597082291117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37444,DS-86dfe86a-2332-4ed6-843d-69a81d0e983e,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-0018b128-f7a4-4e30-9d09-f83b59f7bf16,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-6f786172-8721-4da4-8dc9-075441fd316c,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-a82f37b8-62c0-45b9-9b6d-979c23c1c2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-667ad8cf-1383-42a9-9221-20fe96cb2d66,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-fd72b53d-8db4-45df-a48c-027f6b051277,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-c18c413f-eb90-499e-a541-05c5488cc98c,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-64e743d8-a73e-40ce-931d-953a10d686fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280586834-172.17.0.7-1597082382611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46388,DS-c1c7dd6b-352d-418f-b377-cba51926255a,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-d4114883-ec57-42bb-8f85-28236e058db2,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-2058452d-6c73-4a10-ad11-5633e0e0b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-db743e8f-85b4-45e0-b237-b8f844b0edbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-63f5a471-21c7-4b35-8569-e07ffe78c951,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-3944da6a-ac25-430a-a008-804537cd83d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-c2e733ec-d346-41f9-b093-505d64025e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-bcf5e0fc-cbcf-4170-9232-47f1bc0f3e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-280586834-172.17.0.7-1597082382611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46388,DS-c1c7dd6b-352d-418f-b377-cba51926255a,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-d4114883-ec57-42bb-8f85-28236e058db2,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-2058452d-6c73-4a10-ad11-5633e0e0b6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46318,DS-db743e8f-85b4-45e0-b237-b8f844b0edbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-63f5a471-21c7-4b35-8569-e07ffe78c951,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-3944da6a-ac25-430a-a008-804537cd83d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-c2e733ec-d346-41f9-b093-505d64025e58,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-bcf5e0fc-cbcf-4170-9232-47f1bc0f3e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109798046-172.17.0.7-1597082574924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33842,DS-e0f6e12a-031d-4585-ba75-da917a533b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-c2340038-13cf-451a-bcb3-7ccddbe3d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-69f20aa3-0760-484c-821f-0d65d8bf61f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-afd3f79b-d0c3-4f7d-9835-5fbe9872ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-68566031-7241-46d3-ac1b-b2329fb0766c,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-a4470437-9830-4ec8-83c6-725eba4d609b,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-7b3885e6-78df-45ed-ac5b-f1baf59f34ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-3000d08c-9f53-450c-8d04-cc6e715338a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109798046-172.17.0.7-1597082574924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33842,DS-e0f6e12a-031d-4585-ba75-da917a533b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-c2340038-13cf-451a-bcb3-7ccddbe3d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-69f20aa3-0760-484c-821f-0d65d8bf61f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-afd3f79b-d0c3-4f7d-9835-5fbe9872ce56,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-68566031-7241-46d3-ac1b-b2329fb0766c,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-a4470437-9830-4ec8-83c6-725eba4d609b,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-7b3885e6-78df-45ed-ac5b-f1baf59f34ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-3000d08c-9f53-450c-8d04-cc6e715338a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669713886-172.17.0.7-1597082824314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45474,DS-def9c64b-51e3-40f7-9901-649962d6640d,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-627fe891-54cc-4a6e-9e3f-42c0128a778a,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-288df3df-6c78-45a0-8296-92448838131e,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-4b9b6546-dfe4-4b59-ba25-06078fe0510f,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-f803ee99-3247-4906-88c3-ae2c4e0ab53a,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-e8e24060-0284-4f51-aad1-fe72a27a29c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-381e769c-2e24-4ff5-acce-c8223e3ac199,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-c82313a1-f939-49be-9761-42643adc1f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669713886-172.17.0.7-1597082824314:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45474,DS-def9c64b-51e3-40f7-9901-649962d6640d,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-627fe891-54cc-4a6e-9e3f-42c0128a778a,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-288df3df-6c78-45a0-8296-92448838131e,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-4b9b6546-dfe4-4b59-ba25-06078fe0510f,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-f803ee99-3247-4906-88c3-ae2c4e0ab53a,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-e8e24060-0284-4f51-aad1-fe72a27a29c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-381e769c-2e24-4ff5-acce-c8223e3ac199,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-c82313a1-f939-49be-9761-42643adc1f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196838180-172.17.0.7-1597083022497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41967,DS-bfa52ce7-d786-4020-a610-c713cda3e651,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-b033052b-5fab-49e6-a44a-bf38ffb7047f,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-2f2efd05-52e2-4a87-8abd-05e10b48ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-ea2795b1-ed64-4d93-932c-039ca4936cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-26f4c090-fd64-4b73-b102-210e06ba5395,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-08144200-f5cc-46c1-8c3e-656b8bd02482,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-1e6ff921-254a-4d53-a2e8-c9df44836136,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-7854474e-9b18-430e-9619-c53ebc68cf3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-196838180-172.17.0.7-1597083022497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41967,DS-bfa52ce7-d786-4020-a610-c713cda3e651,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-b033052b-5fab-49e6-a44a-bf38ffb7047f,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-2f2efd05-52e2-4a87-8abd-05e10b48ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:44163,DS-ea2795b1-ed64-4d93-932c-039ca4936cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-26f4c090-fd64-4b73-b102-210e06ba5395,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-08144200-f5cc-46c1-8c3e-656b8bd02482,DISK], DatanodeInfoWithStorage[127.0.0.1:46111,DS-1e6ff921-254a-4d53-a2e8-c9df44836136,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-7854474e-9b18-430e-9619-c53ebc68cf3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627670365-172.17.0.7-1597083513453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-32be2ea9-ce8f-4304-bd16-4306dd139ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-a482d0c7-cee4-4082-a0ed-64e9801b3a30,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-21598221-a152-4397-bac7-4b207b0560a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-5ecae06d-79cf-47e3-abe5-6e7ed87eefc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-1c910e2e-bdf1-41fc-a53f-87222a787ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-94d102fa-dd8e-4d3a-941b-f4652a1e5917,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-381a81b6-b588-4d06-8df4-8ebf5f6d6c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-b6d405e2-f0a2-4c01-8c26-de98f86a7fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627670365-172.17.0.7-1597083513453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42211,DS-32be2ea9-ce8f-4304-bd16-4306dd139ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-a482d0c7-cee4-4082-a0ed-64e9801b3a30,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-21598221-a152-4397-bac7-4b207b0560a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-5ecae06d-79cf-47e3-abe5-6e7ed87eefc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-1c910e2e-bdf1-41fc-a53f-87222a787ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-94d102fa-dd8e-4d3a-941b-f4652a1e5917,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-381a81b6-b588-4d06-8df4-8ebf5f6d6c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-b6d405e2-f0a2-4c01-8c26-de98f86a7fc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32956061-172.17.0.7-1597083547331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-e51ba21d-0084-4f31-aff7-a27f6205db60,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-66772a43-653c-4bb0-ba05-b7c4c4292165,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-1ce5c6f3-83e4-48a1-a9c5-590f89030bde,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-b5e7ac47-6d3c-4104-851d-53dc935d089e,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-d83c7d5b-79e2-44a0-8d92-c8b92e081d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-01403770-89e2-41fd-8bba-4f4763a99935,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-3085cf83-bea5-41a4-b2ee-b247765c5f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-504662c4-fe0f-47f9-94c7-3dd6dd4af758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32956061-172.17.0.7-1597083547331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-e51ba21d-0084-4f31-aff7-a27f6205db60,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-66772a43-653c-4bb0-ba05-b7c4c4292165,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-1ce5c6f3-83e4-48a1-a9c5-590f89030bde,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-b5e7ac47-6d3c-4104-851d-53dc935d089e,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-d83c7d5b-79e2-44a0-8d92-c8b92e081d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-01403770-89e2-41fd-8bba-4f4763a99935,DISK], DatanodeInfoWithStorage[127.0.0.1:33012,DS-3085cf83-bea5-41a4-b2ee-b247765c5f87,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-504662c4-fe0f-47f9-94c7-3dd6dd4af758,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596921611-172.17.0.7-1597084226567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-cf439074-7e7d-4df4-b58b-904f1f2a06bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-db2b78fa-9993-4b59-b076-268177201290,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-4b085c43-699e-40b2-a5ae-b3b1569c000d,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-fd5fb65e-bf92-488f-af39-29577aebd34a,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-b4d2897b-8d47-422e-be2b-c708c3e98bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-2caa163b-f3f7-4eba-9ca5-fc30c157b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-4dc862b7-a1a5-4e1d-9d36-8b7b27728906,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-f7789c25-de2f-4c30-a27b-5d1dc0b6416e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596921611-172.17.0.7-1597084226567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42745,DS-cf439074-7e7d-4df4-b58b-904f1f2a06bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-db2b78fa-9993-4b59-b076-268177201290,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-4b085c43-699e-40b2-a5ae-b3b1569c000d,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-fd5fb65e-bf92-488f-af39-29577aebd34a,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-b4d2897b-8d47-422e-be2b-c708c3e98bda,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-2caa163b-f3f7-4eba-9ca5-fc30c157b8c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40149,DS-4dc862b7-a1a5-4e1d-9d36-8b7b27728906,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-f7789c25-de2f-4c30-a27b-5d1dc0b6416e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605777179-172.17.0.7-1597084566287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-bbfcda5a-9bfd-4db1-bbc9-ee19e2bb492b,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-21166802-7d2f-4041-b51a-1009706b6aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-fc4a31a9-fbbc-4023-8e2b-1a86f60cf816,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-28c28fa2-0c2f-4aee-81d7-d77aa5edd555,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-5a733d7e-f4f4-430d-be4b-b9fcf9da76e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-b8148547-8c63-4b91-b40f-7b207765025c,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-4bfc7571-b587-4ad4-96a5-06460159a176,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-d29584ab-8d11-4546-b220-33a504cd505e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605777179-172.17.0.7-1597084566287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-bbfcda5a-9bfd-4db1-bbc9-ee19e2bb492b,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-21166802-7d2f-4041-b51a-1009706b6aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-fc4a31a9-fbbc-4023-8e2b-1a86f60cf816,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-28c28fa2-0c2f-4aee-81d7-d77aa5edd555,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-5a733d7e-f4f4-430d-be4b-b9fcf9da76e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-b8148547-8c63-4b91-b40f-7b207765025c,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-4bfc7571-b587-4ad4-96a5-06460159a176,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-d29584ab-8d11-4546-b220-33a504cd505e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329504496-172.17.0.7-1597084601715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-31257f55-ffc7-4a98-a927-4d917a95097a,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-a1c5cbd6-24a3-4337-802b-c6f5cf7b87c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-a8cd4760-1f21-4dc2-b185-c722e1fc78f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-90f22efe-5a1b-42b7-bd70-a930a86d17f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-b6597152-250d-443e-a294-57bb82bb53ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-d1c2b2fc-5123-4769-81d4-798796b55eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-2d42a87a-e834-419b-8366-26d2a41ddffb,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-8f94de3b-8c48-4b26-b826-9427c70388d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329504496-172.17.0.7-1597084601715:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40709,DS-31257f55-ffc7-4a98-a927-4d917a95097a,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-a1c5cbd6-24a3-4337-802b-c6f5cf7b87c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-a8cd4760-1f21-4dc2-b185-c722e1fc78f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-90f22efe-5a1b-42b7-bd70-a930a86d17f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-b6597152-250d-443e-a294-57bb82bb53ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-d1c2b2fc-5123-4769-81d4-798796b55eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-2d42a87a-e834-419b-8366-26d2a41ddffb,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-8f94de3b-8c48-4b26-b826-9427c70388d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122774677-172.17.0.7-1597085351450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-1176d431-0722-409c-a166-bffed381cbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-ec957cbb-2e8b-4113-8417-cf3a5cf1e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-97f390be-f33e-4d5f-a0d8-6251a65dd30d,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-2eb6eec0-5b57-4bf7-a0f3-ccc7e1b4bc38,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-1335061c-5b16-40ec-91bb-37c2b7f66f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-c67e36cb-e523-459e-8327-03ee84c58f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-460bcf10-7b9c-426f-a8e4-e558072b1154,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-37d75f29-f287-47b9-abd8-0286d38a075d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122774677-172.17.0.7-1597085351450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36960,DS-1176d431-0722-409c-a166-bffed381cbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-ec957cbb-2e8b-4113-8417-cf3a5cf1e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38301,DS-97f390be-f33e-4d5f-a0d8-6251a65dd30d,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-2eb6eec0-5b57-4bf7-a0f3-ccc7e1b4bc38,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-1335061c-5b16-40ec-91bb-37c2b7f66f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-c67e36cb-e523-459e-8327-03ee84c58f01,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-460bcf10-7b9c-426f-a8e4-e558072b1154,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-37d75f29-f287-47b9-abd8-0286d38a075d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917478483-172.17.0.7-1597085791043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42295,DS-4e7c02ed-6a01-4c31-afe0-9dc2ed2fd2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-2a427065-3c31-4725-819c-3df79c40b98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-f6e02f55-a6ed-42f8-811d-ab60b3b4b939,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-00950f66-7436-4baf-b654-630f03142a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-a5556a61-1efa-4383-9f80-d985dcd97564,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-20c2e8e3-6350-4699-854b-1fd42d56673b,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-32616378-26e7-46c4-84e7-ecaf63888b89,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-03728276-2217-42d0-bfcc-84d9dea77d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917478483-172.17.0.7-1597085791043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42295,DS-4e7c02ed-6a01-4c31-afe0-9dc2ed2fd2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-2a427065-3c31-4725-819c-3df79c40b98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-f6e02f55-a6ed-42f8-811d-ab60b3b4b939,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-00950f66-7436-4baf-b654-630f03142a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-a5556a61-1efa-4383-9f80-d985dcd97564,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-20c2e8e3-6350-4699-854b-1fd42d56673b,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-32616378-26e7-46c4-84e7-ecaf63888b89,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-03728276-2217-42d0-bfcc-84d9dea77d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.list.cache.directives.num.responses
component: hdfs:NameNode
v1: 100
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208615880-172.17.0.7-1597086043509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-06a2d6e1-7de0-4a11-8324-2d357905b430,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-2953d5ac-ba48-4fac-96c6-cd5b90f7b8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-a14119ce-ab23-4e5f-882e-d3dde6f5efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-77e67306-96f0-4634-85f2-ac6b1ed98135,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-6b6cbf5c-a077-4d5e-9185-4a6ee4f26dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-d9c83b85-0d10-4050-adc7-08500ae6d72b,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-58974427-65bb-44cb-bec6-066259737a95,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-c39692cf-3bd0-4eb7-82a2-2f554a71fe1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208615880-172.17.0.7-1597086043509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-06a2d6e1-7de0-4a11-8324-2d357905b430,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-2953d5ac-ba48-4fac-96c6-cd5b90f7b8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-a14119ce-ab23-4e5f-882e-d3dde6f5efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-77e67306-96f0-4634-85f2-ac6b1ed98135,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-6b6cbf5c-a077-4d5e-9185-4a6ee4f26dee,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-d9c83b85-0d10-4050-adc7-08500ae6d72b,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-58974427-65bb-44cb-bec6-066259737a95,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-c39692cf-3bd0-4eb7-82a2-2f554a71fe1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6316
