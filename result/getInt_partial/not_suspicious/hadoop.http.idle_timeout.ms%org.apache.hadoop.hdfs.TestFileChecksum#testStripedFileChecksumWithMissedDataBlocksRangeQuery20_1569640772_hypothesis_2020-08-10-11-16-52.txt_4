reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175627448-172.17.0.15-1597058259718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-264d8280-6774-4e75-b72a-29411e59bacb,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-03f225ae-4853-4766-b209-1d735c789257,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-ca8c5bdc-1aae-4a35-99a0-90b5232739d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-7f786fbd-e9ca-4af3-9b40-a3fce82fbaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-83e8bb69-43dd-48be-8c0c-01a1d9ad1237,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-f1ae27a8-77ea-46ab-a5db-5ff920296e29,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-c938361d-40eb-4cb5-af3f-bfaa4064ed62,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-6368afea-19c3-448c-aa6d-feffc3492d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1175627448-172.17.0.15-1597058259718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-264d8280-6774-4e75-b72a-29411e59bacb,DISK], DatanodeInfoWithStorage[127.0.0.1:40248,DS-03f225ae-4853-4766-b209-1d735c789257,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-ca8c5bdc-1aae-4a35-99a0-90b5232739d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-7f786fbd-e9ca-4af3-9b40-a3fce82fbaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-83e8bb69-43dd-48be-8c0c-01a1d9ad1237,DISK], DatanodeInfoWithStorage[127.0.0.1:34083,DS-f1ae27a8-77ea-46ab-a5db-5ff920296e29,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-c938361d-40eb-4cb5-af3f-bfaa4064ed62,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-6368afea-19c3-448c-aa6d-feffc3492d84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091249710-172.17.0.15-1597058666626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35764,DS-ec0d142a-8bd7-4b18-ab52-9822b19105c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-450f2af8-675e-4d09-9322-31666e4432c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-614de5b3-7ad5-4b0d-9b7a-0de07404cf07,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-15587b3b-800c-4b1e-956b-85d7b6eab676,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-ff47fbc3-3b5f-472b-bfd3-f60652b983b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-64889733-0bd5-42fe-a50b-a541b1a39aef,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-548e91b2-34a3-4f18-9391-af971b354ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-344d89cb-3c35-47e5-abb7-85b8394efd01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091249710-172.17.0.15-1597058666626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35764,DS-ec0d142a-8bd7-4b18-ab52-9822b19105c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-450f2af8-675e-4d09-9322-31666e4432c8,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-614de5b3-7ad5-4b0d-9b7a-0de07404cf07,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-15587b3b-800c-4b1e-956b-85d7b6eab676,DISK], DatanodeInfoWithStorage[127.0.0.1:40455,DS-ff47fbc3-3b5f-472b-bfd3-f60652b983b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-64889733-0bd5-42fe-a50b-a541b1a39aef,DISK], DatanodeInfoWithStorage[127.0.0.1:45383,DS-548e91b2-34a3-4f18-9391-af971b354ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-344d89cb-3c35-47e5-abb7-85b8394efd01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036055592-172.17.0.15-1597058850091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45448,DS-bba31ea6-b204-4e29-ae5f-d5561af5ed87,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-e7f03fe7-3d7c-4c1c-9c46-95b13053a862,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-c3a46961-768a-4ea1-856c-79025ec9a2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-b597e171-4678-4bbf-b12f-fa296a658d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-5a63a719-7a87-4c3a-90d5-ba1cca300f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-97b8c2e0-9468-4011-a9db-29da4643baa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-d66117a4-5777-471e-8f47-280888593125,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-9b4d7c63-b2d1-4ee2-b999-82dbd6f0eee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036055592-172.17.0.15-1597058850091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45448,DS-bba31ea6-b204-4e29-ae5f-d5561af5ed87,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-e7f03fe7-3d7c-4c1c-9c46-95b13053a862,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-c3a46961-768a-4ea1-856c-79025ec9a2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-b597e171-4678-4bbf-b12f-fa296a658d77,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-5a63a719-7a87-4c3a-90d5-ba1cca300f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-97b8c2e0-9468-4011-a9db-29da4643baa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-d66117a4-5777-471e-8f47-280888593125,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-9b4d7c63-b2d1-4ee2-b999-82dbd6f0eee7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541036603-172.17.0.15-1597059295439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-4207b50b-b9c9-426f-9cfe-c6d8c8a21ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-576800d5-23d6-4485-b90f-7a170ad0dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-a99e5eff-65fc-45c5-ac99-d8ff29bd413a,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-50f11826-f25b-4e48-8c32-76b7558ffc39,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-ed943a23-fa8f-4a62-840d-ba5ff186c818,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-cad1e301-a875-4b95-b7c6-caaeb9e6ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-164ae914-27f5-4a84-aac3-bc94c6ad2553,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-8536c163-7c5f-45e2-9ae0-ca3ee8efac13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541036603-172.17.0.15-1597059295439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42778,DS-4207b50b-b9c9-426f-9cfe-c6d8c8a21ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-576800d5-23d6-4485-b90f-7a170ad0dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-a99e5eff-65fc-45c5-ac99-d8ff29bd413a,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-50f11826-f25b-4e48-8c32-76b7558ffc39,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-ed943a23-fa8f-4a62-840d-ba5ff186c818,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-cad1e301-a875-4b95-b7c6-caaeb9e6ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-164ae914-27f5-4a84-aac3-bc94c6ad2553,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-8536c163-7c5f-45e2-9ae0-ca3ee8efac13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603291418-172.17.0.15-1597060297529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39989,DS-a8c5abde-b6a7-4e22-94d2-88e2fdfb336b,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-75662429-0291-4c6d-9c39-a4cfec614a76,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-491712d8-70d1-45c4-8235-7f1abe5bc94a,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-fbf00fdd-76fa-4171-9ef3-be63e56e19f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-6b4a1ed8-c992-4d92-a199-6520846cd507,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-5f65df9f-af55-49fd-bdf9-81a5c63420f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-a70b5243-bcff-43d8-afd1-fa18313a01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-99621f2f-3e21-47eb-abfc-5eb7c2623bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-603291418-172.17.0.15-1597060297529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39989,DS-a8c5abde-b6a7-4e22-94d2-88e2fdfb336b,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-75662429-0291-4c6d-9c39-a4cfec614a76,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-491712d8-70d1-45c4-8235-7f1abe5bc94a,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-fbf00fdd-76fa-4171-9ef3-be63e56e19f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-6b4a1ed8-c992-4d92-a199-6520846cd507,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-5f65df9f-af55-49fd-bdf9-81a5c63420f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-a70b5243-bcff-43d8-afd1-fa18313a01b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-99621f2f-3e21-47eb-abfc-5eb7c2623bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416521946-172.17.0.15-1597060372780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39839,DS-3dd428ca-db8e-4811-8acd-d0edc410b2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-e1bfc62c-eafc-4566-a486-c219bce7947f,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-2ae54a38-a695-424b-a185-60a5776d7158,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-96987bf5-2f14-413a-b0e7-86deb6b407e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-a869c5e1-f8aa-4e0b-9b72-752d9c3d4f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-3ec8c56e-abfd-4804-a885-a20d8ec2e854,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-be4cc1aa-e95e-4c79-a545-e771407d92ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-91fc0bd3-6fd1-47b2-8228-c750c94a4ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416521946-172.17.0.15-1597060372780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39839,DS-3dd428ca-db8e-4811-8acd-d0edc410b2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-e1bfc62c-eafc-4566-a486-c219bce7947f,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-2ae54a38-a695-424b-a185-60a5776d7158,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-96987bf5-2f14-413a-b0e7-86deb6b407e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-a869c5e1-f8aa-4e0b-9b72-752d9c3d4f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-3ec8c56e-abfd-4804-a885-a20d8ec2e854,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-be4cc1aa-e95e-4c79-a545-e771407d92ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-91fc0bd3-6fd1-47b2-8228-c750c94a4ecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935241042-172.17.0.15-1597061454885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33111,DS-2f0d8ae8-cebd-4dc5-8972-8266d310aaef,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-fccc1b43-39fe-4a9c-bad9-974c229e1159,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-51777745-51ce-4a49-a899-eae26e961ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-932e6035-0d91-48b9-8e98-7c9bc5bdd37b,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-d89b261c-699d-48a9-a22f-723116d7b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-0c959d3f-d12f-44fe-a9f4-9782a0edaf96,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-42afab09-f68c-4698-abbd-a0beac3157b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-c9016b97-5792-4651-b3b7-12467e797d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1935241042-172.17.0.15-1597061454885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33111,DS-2f0d8ae8-cebd-4dc5-8972-8266d310aaef,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-fccc1b43-39fe-4a9c-bad9-974c229e1159,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-51777745-51ce-4a49-a899-eae26e961ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-932e6035-0d91-48b9-8e98-7c9bc5bdd37b,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-d89b261c-699d-48a9-a22f-723116d7b3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-0c959d3f-d12f-44fe-a9f4-9782a0edaf96,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-42afab09-f68c-4698-abbd-a0beac3157b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-c9016b97-5792-4651-b3b7-12467e797d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677424302-172.17.0.15-1597061623932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-c2c6b072-2b37-4410-82ef-a34a98006348,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-fbc03502-ed4c-4b25-b022-5399306f4add,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-0e9730c7-0438-42e3-9f7a-b674bbb4401e,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-127c6181-1a8c-4cb5-85f4-8335a5c6c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-eb79ad0f-79b3-4e3c-96a3-ac2d79777e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-69dbc421-8a15-42a7-900a-98a3bdbc890d,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-7a29e551-32a0-4a55-82e1-6eca86ac7c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-312bad36-4423-4d36-97b9-aa803f8a59a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-677424302-172.17.0.15-1597061623932:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-c2c6b072-2b37-4410-82ef-a34a98006348,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-fbc03502-ed4c-4b25-b022-5399306f4add,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-0e9730c7-0438-42e3-9f7a-b674bbb4401e,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-127c6181-1a8c-4cb5-85f4-8335a5c6c49e,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-eb79ad0f-79b3-4e3c-96a3-ac2d79777e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-69dbc421-8a15-42a7-900a-98a3bdbc890d,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-7a29e551-32a0-4a55-82e1-6eca86ac7c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-312bad36-4423-4d36-97b9-aa803f8a59a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275025396-172.17.0.15-1597061759137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38330,DS-c15b9699-b8a8-420a-8cfb-50309d8ef14e,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-056130eb-e6bc-4f2a-aa8b-acb136ebad3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-99be60f6-2056-4e94-92e5-e35d62059ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-e44a8379-8d2f-474a-bc1a-245febef0093,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-ccf4b3d7-01d4-4744-9f5a-1d318b81ee0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-70e45e80-9b45-4b47-bc8d-53a4c57d12ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-b835c7c6-206f-4c2c-bd67-a7496fe02547,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-16e13dd0-3333-4be4-8974-faa1bbea271c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-275025396-172.17.0.15-1597061759137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38330,DS-c15b9699-b8a8-420a-8cfb-50309d8ef14e,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-056130eb-e6bc-4f2a-aa8b-acb136ebad3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-99be60f6-2056-4e94-92e5-e35d62059ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-e44a8379-8d2f-474a-bc1a-245febef0093,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-ccf4b3d7-01d4-4744-9f5a-1d318b81ee0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-70e45e80-9b45-4b47-bc8d-53a4c57d12ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40737,DS-b835c7c6-206f-4c2c-bd67-a7496fe02547,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-16e13dd0-3333-4be4-8974-faa1bbea271c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413676784-172.17.0.15-1597062308702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-e47e01c7-5c66-4ca8-b017-70bcfe24d858,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-1ed35a7b-8195-4459-9f43-18b4a8c76551,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-7ec6bebe-6053-4af8-b8c9-a76db2b688d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-2ecb982e-2f44-41e8-b4e2-f7834389d3df,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-bcbfb672-888b-41b0-9338-ea2ad658b190,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-7e1b8e95-3517-471d-b6f1-b48aa41e4205,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-0ce3323b-49d8-41ed-affa-0e7e7d14ed5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-bb080eb4-d6b9-44a9-a73d-45f79b36dbbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-413676784-172.17.0.15-1597062308702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-e47e01c7-5c66-4ca8-b017-70bcfe24d858,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-1ed35a7b-8195-4459-9f43-18b4a8c76551,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-7ec6bebe-6053-4af8-b8c9-a76db2b688d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-2ecb982e-2f44-41e8-b4e2-f7834389d3df,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-bcbfb672-888b-41b0-9338-ea2ad658b190,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-7e1b8e95-3517-471d-b6f1-b48aa41e4205,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-0ce3323b-49d8-41ed-affa-0e7e7d14ed5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-bb080eb4-d6b9-44a9-a73d-45f79b36dbbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102027680-172.17.0.15-1597062775790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38991,DS-b82dcd6f-907b-4835-b70a-91a751d4fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-0908a557-2a9c-458d-8674-87a6efe552d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-2130775d-81c6-4815-b70d-a4daaf9db540,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-02c6107f-fd36-4a76-aa3c-24fcb3ced2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-4d514aba-716b-4e56-be8e-6a12bb11393a,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-d9b85361-158f-43aa-9546-6ed61f67a033,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-cdf5f593-fde0-4dfa-8c85-9290e094bad2,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-5c185d3f-1719-46cd-946a-d6c7e0233c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102027680-172.17.0.15-1597062775790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38991,DS-b82dcd6f-907b-4835-b70a-91a751d4fde4,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-0908a557-2a9c-458d-8674-87a6efe552d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-2130775d-81c6-4815-b70d-a4daaf9db540,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-02c6107f-fd36-4a76-aa3c-24fcb3ced2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38987,DS-4d514aba-716b-4e56-be8e-6a12bb11393a,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-d9b85361-158f-43aa-9546-6ed61f67a033,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-cdf5f593-fde0-4dfa-8c85-9290e094bad2,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-5c185d3f-1719-46cd-946a-d6c7e0233c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784589034-172.17.0.15-1597062809376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36899,DS-79cedad4-9b81-47b7-a7af-8db4ca924717,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-d972dc99-838b-4bdd-822f-9d65919a05f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-73b62337-878b-4c5a-bc98-07001a1ffe92,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-6fd73b18-cebf-48fc-a6d7-507fa92dc82b,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-0222df74-8e9c-4da0-99c5-3addd9eec2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-cc505499-b4e1-4808-9a97-abf6d9321d74,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-5935f294-a6a2-4dd8-bd97-4f49f49aec15,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-a77ffce6-323e-4e2b-9bf4-edd76016b9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-784589034-172.17.0.15-1597062809376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36899,DS-79cedad4-9b81-47b7-a7af-8db4ca924717,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-d972dc99-838b-4bdd-822f-9d65919a05f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-73b62337-878b-4c5a-bc98-07001a1ffe92,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-6fd73b18-cebf-48fc-a6d7-507fa92dc82b,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-0222df74-8e9c-4da0-99c5-3addd9eec2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-cc505499-b4e1-4808-9a97-abf6d9321d74,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-5935f294-a6a2-4dd8-bd97-4f49f49aec15,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-a77ffce6-323e-4e2b-9bf4-edd76016b9e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756514166-172.17.0.15-1597063109375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-37b50862-de91-4696-9506-c97a2e2831fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-631e4629-2cbd-4448-8dee-e1ea83180737,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-6c13b498-0c43-4594-8aed-a2623d51d3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-6f8c9f83-fab6-41e9-8116-24a2fbd1176e,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-6ba5dbb6-774f-428d-aec3-0b8cf502c968,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-d606d52c-be69-4819-8b19-55fe9822577d,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-451accea-ec92-4af5-9f3c-110d4fc64463,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-3d886e7a-1365-4b12-b8d9-ada0880d3de3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-756514166-172.17.0.15-1597063109375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42121,DS-37b50862-de91-4696-9506-c97a2e2831fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-631e4629-2cbd-4448-8dee-e1ea83180737,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-6c13b498-0c43-4594-8aed-a2623d51d3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-6f8c9f83-fab6-41e9-8116-24a2fbd1176e,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-6ba5dbb6-774f-428d-aec3-0b8cf502c968,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-d606d52c-be69-4819-8b19-55fe9822577d,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-451accea-ec92-4af5-9f3c-110d4fc64463,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-3d886e7a-1365-4b12-b8d9-ada0880d3de3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162383636-172.17.0.15-1597063173133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-15fd121b-b204-44d8-8b8d-8752f16d0b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-a3856ced-cd9b-461d-b264-ebee9e4b7241,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-bdb6fe4b-336c-40d2-b02f-d247756b3a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-0b701759-6224-44cd-9068-37e349892e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-8e56a663-805a-46ce-862a-6e4af295034a,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-8ae9933c-425b-4f33-80d8-ad8fbe9df06c,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-ff7bdc40-3f51-4917-b0a7-86c629ba1664,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-17c6e09d-da82-4ca2-8eb9-b498a3db1645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162383636-172.17.0.15-1597063173133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33757,DS-15fd121b-b204-44d8-8b8d-8752f16d0b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-a3856ced-cd9b-461d-b264-ebee9e4b7241,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-bdb6fe4b-336c-40d2-b02f-d247756b3a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-0b701759-6224-44cd-9068-37e349892e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-8e56a663-805a-46ce-862a-6e4af295034a,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-8ae9933c-425b-4f33-80d8-ad8fbe9df06c,DISK], DatanodeInfoWithStorage[127.0.0.1:33263,DS-ff7bdc40-3f51-4917-b0a7-86c629ba1664,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-17c6e09d-da82-4ca2-8eb9-b498a3db1645,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870149098-172.17.0.15-1597063381937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-041c7021-5cc2-49a4-96e8-02ab8dba70a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-ca4a61ff-f3e2-4196-9736-cadc51203e92,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-6c3e3b04-7197-45f1-9516-5558d85ee832,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-64714354-76a5-47ac-ab9f-913d5b0456f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-22387330-ce2d-452f-accc-4d7fc2502847,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-d487fcba-7fcd-4005-9555-c2690c1aa38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-5cd36c48-2d50-4851-acc0-9e912fc122c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-edaebb73-eb69-4dfe-800b-815c7c19b007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870149098-172.17.0.15-1597063381937:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-041c7021-5cc2-49a4-96e8-02ab8dba70a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-ca4a61ff-f3e2-4196-9736-cadc51203e92,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-6c3e3b04-7197-45f1-9516-5558d85ee832,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-64714354-76a5-47ac-ab9f-913d5b0456f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-22387330-ce2d-452f-accc-4d7fc2502847,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-d487fcba-7fcd-4005-9555-c2690c1aa38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-5cd36c48-2d50-4851-acc0-9e912fc122c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-edaebb73-eb69-4dfe-800b-815c7c19b007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5224
