reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205929266-172.17.0.4-1597184108840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-13745578-7f06-488e-9eac-62fc0e28f959,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-c0e4b834-307d-40ae-93ed-5028be3fa454,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-b0366fe4-8cf4-45af-9ea5-faf320c5d61b,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-4b90ff14-36d3-4e81-93ee-3f7d9f18a957,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-423613eb-d779-4092-9a4a-4b3b5af9d058,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-941876aa-bb97-4617-976e-8d311543f9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-142f0ca2-6a75-4961-b76d-5121e1d9a0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-4f813b57-2171-4748-a5fd-afa0d006bd4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205929266-172.17.0.4-1597184108840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-13745578-7f06-488e-9eac-62fc0e28f959,DISK], DatanodeInfoWithStorage[127.0.0.1:34747,DS-c0e4b834-307d-40ae-93ed-5028be3fa454,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-b0366fe4-8cf4-45af-9ea5-faf320c5d61b,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-4b90ff14-36d3-4e81-93ee-3f7d9f18a957,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-423613eb-d779-4092-9a4a-4b3b5af9d058,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-941876aa-bb97-4617-976e-8d311543f9af,DISK], DatanodeInfoWithStorage[127.0.0.1:40544,DS-142f0ca2-6a75-4961-b76d-5121e1d9a0a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-4f813b57-2171-4748-a5fd-afa0d006bd4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904262070-172.17.0.4-1597184494194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38799,DS-809f92ae-585e-4f2d-9990-4d9d304214a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-b7fe1efd-5cd4-4211-b43f-48236d3f57ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-0da13583-7c6e-471c-b067-13c7159e3e67,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-b8f84c2b-1b7f-4fd0-94d4-a15db88cb102,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-e6f8b64e-954c-4cc9-80b5-a85c3dfd27f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-95ef28f5-e065-47c3-9189-d8e30f2dde54,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-2f8f9a17-4a03-4ef0-8fdc-499d7d2dfdab,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d15efb32-0cd9-4bc3-9677-b1819b2b5352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904262070-172.17.0.4-1597184494194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38799,DS-809f92ae-585e-4f2d-9990-4d9d304214a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-b7fe1efd-5cd4-4211-b43f-48236d3f57ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-0da13583-7c6e-471c-b067-13c7159e3e67,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-b8f84c2b-1b7f-4fd0-94d4-a15db88cb102,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-e6f8b64e-954c-4cc9-80b5-a85c3dfd27f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-95ef28f5-e065-47c3-9189-d8e30f2dde54,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-2f8f9a17-4a03-4ef0-8fdc-499d7d2dfdab,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d15efb32-0cd9-4bc3-9677-b1819b2b5352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637934759-172.17.0.4-1597184586487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-9dfd5a95-9080-4dd5-a0d7-fcd4f0e68a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-6f3bd6d0-2308-4123-a79e-a7952795f54a,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-7be2efdf-7867-428d-87ee-7412a8815f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-01c92bfa-d012-4880-85f8-42c14aeec0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-cb208f42-d3dd-4575-9b9f-0c0ef671e292,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-01b5cf1a-a701-4447-a366-e1aa0c556c03,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-7f88b863-80f2-40a9-9b4c-d6548852e09f,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-ac9b7de5-e1f8-48aa-9817-531a78dd7eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637934759-172.17.0.4-1597184586487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-9dfd5a95-9080-4dd5-a0d7-fcd4f0e68a59,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-6f3bd6d0-2308-4123-a79e-a7952795f54a,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-7be2efdf-7867-428d-87ee-7412a8815f31,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-01c92bfa-d012-4880-85f8-42c14aeec0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-cb208f42-d3dd-4575-9b9f-0c0ef671e292,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-01b5cf1a-a701-4447-a366-e1aa0c556c03,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-7f88b863-80f2-40a9-9b4c-d6548852e09f,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-ac9b7de5-e1f8-48aa-9817-531a78dd7eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625788608-172.17.0.4-1597185233693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34498,DS-30d97b4e-4746-487c-8540-6ffb9b54cbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-570ab4b8-d082-41be-bd66-cf6e1b2780ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-4f4fe1bd-45a9-494a-98aa-fd46b6befdff,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-4236c80f-c0da-4e1d-8833-0712347caa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-a222537d-bf42-41d7-9bd9-795a69c1c71b,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-7841b5fd-aae1-4b61-be14-466c575b10a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-4956f220-c65f-42b6-bdb1-a471b75ce0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-44cddf0d-83e6-4e54-82de-841693967da0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625788608-172.17.0.4-1597185233693:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34498,DS-30d97b4e-4746-487c-8540-6ffb9b54cbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-570ab4b8-d082-41be-bd66-cf6e1b2780ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-4f4fe1bd-45a9-494a-98aa-fd46b6befdff,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-4236c80f-c0da-4e1d-8833-0712347caa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44637,DS-a222537d-bf42-41d7-9bd9-795a69c1c71b,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-7841b5fd-aae1-4b61-be14-466c575b10a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-4956f220-c65f-42b6-bdb1-a471b75ce0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-44cddf0d-83e6-4e54-82de-841693967da0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725699273-172.17.0.4-1597185637602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33262,DS-507141cb-62c4-49a5-89d7-080a2d9e542b,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-0dad42a7-73d9-4562-b73b-8ad06a876151,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-5496254b-bc0b-4e50-aee6-46726779f412,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-a38c71ad-d58d-4433-b2e3-dcb7c0723aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-98d0cb65-a683-428d-8c69-69326f4c8bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-6fdbd5f1-00ae-4283-9096-d26c9ffc20c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-b7ef1c51-22ca-4b3e-8ddc-4f390fb132f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-ffe8e38c-df20-42fc-bf69-a032cc6c59e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725699273-172.17.0.4-1597185637602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33262,DS-507141cb-62c4-49a5-89d7-080a2d9e542b,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-0dad42a7-73d9-4562-b73b-8ad06a876151,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-5496254b-bc0b-4e50-aee6-46726779f412,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-a38c71ad-d58d-4433-b2e3-dcb7c0723aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-98d0cb65-a683-428d-8c69-69326f4c8bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-6fdbd5f1-00ae-4283-9096-d26c9ffc20c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-b7ef1c51-22ca-4b3e-8ddc-4f390fb132f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-ffe8e38c-df20-42fc-bf69-a032cc6c59e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217692378-172.17.0.4-1597185674347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-6eec5e27-46f6-41f9-88b8-1c5d47a58510,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-9315e7e6-6cdf-44d9-84e6-0b3291c1d92a,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-216686b9-71f0-42dc-8600-3a4f77a61e85,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-9dda33f7-001e-4687-bb06-1944eaa5d10b,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-c80bbb23-490a-4837-a40d-6e9b2ed33353,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-efb926fd-3373-4a2f-a40f-9bfbc7bb5e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-7d8cc2df-5810-4519-be86-6a87c0c27713,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-d7a499b3-4429-460d-9a5e-bd7f05a6897d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217692378-172.17.0.4-1597185674347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-6eec5e27-46f6-41f9-88b8-1c5d47a58510,DISK], DatanodeInfoWithStorage[127.0.0.1:44225,DS-9315e7e6-6cdf-44d9-84e6-0b3291c1d92a,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-216686b9-71f0-42dc-8600-3a4f77a61e85,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-9dda33f7-001e-4687-bb06-1944eaa5d10b,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-c80bbb23-490a-4837-a40d-6e9b2ed33353,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-efb926fd-3373-4a2f-a40f-9bfbc7bb5e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-7d8cc2df-5810-4519-be86-6a87c0c27713,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-d7a499b3-4429-460d-9a5e-bd7f05a6897d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288197503-172.17.0.4-1597186297190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-da45ac9a-7bf7-416f-9cd2-bdc88691afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-6d6fb9b3-e4e0-479f-a2d0-4f63f6765b95,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-a5d9174c-0682-453d-9895-89eaa2ef99d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-c31c3ed8-8f68-42c5-9c4b-9555c9044d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-8534e39c-709d-40a1-8d87-274e33a008e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-9eeadfa8-d332-4745-bddd-a8a2f3baa50a,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-2cbb373c-454e-42d4-976f-ba012b5baf28,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-25c59223-6c8d-42b4-80d1-39ab94d74169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288197503-172.17.0.4-1597186297190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36896,DS-da45ac9a-7bf7-416f-9cd2-bdc88691afdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-6d6fb9b3-e4e0-479f-a2d0-4f63f6765b95,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-a5d9174c-0682-453d-9895-89eaa2ef99d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-c31c3ed8-8f68-42c5-9c4b-9555c9044d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-8534e39c-709d-40a1-8d87-274e33a008e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-9eeadfa8-d332-4745-bddd-a8a2f3baa50a,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-2cbb373c-454e-42d4-976f-ba012b5baf28,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-25c59223-6c8d-42b4-80d1-39ab94d74169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866218113-172.17.0.4-1597186762933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-05161ee8-e95d-47f9-9c8c-8b5dbc0936be,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-83c9331c-b6ff-4c96-8ae2-bbd66aeae8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-099e21a3-c290-4452-bb33-fb81c10ef8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-6497b48e-a4b3-40ea-8dbc-928de3bd58dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-abaf4130-8f71-44a6-9ff0-742b6e95e454,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c857db01-8189-4ce5-aebf-cb4ec466548f,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-b46a80e4-e768-4ee8-b676-7d858653b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-05c598b7-79a4-4573-be72-64e9547cc044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1866218113-172.17.0.4-1597186762933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38166,DS-05161ee8-e95d-47f9-9c8c-8b5dbc0936be,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-83c9331c-b6ff-4c96-8ae2-bbd66aeae8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-099e21a3-c290-4452-bb33-fb81c10ef8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-6497b48e-a4b3-40ea-8dbc-928de3bd58dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33016,DS-abaf4130-8f71-44a6-9ff0-742b6e95e454,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-c857db01-8189-4ce5-aebf-cb4ec466548f,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-b46a80e4-e768-4ee8-b676-7d858653b95c,DISK], DatanodeInfoWithStorage[127.0.0.1:32926,DS-05c598b7-79a4-4573-be72-64e9547cc044,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194066930-172.17.0.4-1597188433637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43051,DS-c6c6e9e3-d99b-49f5-af77-6c83a0122462,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-106de01c-8632-46ff-9660-72ac8569cf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-74bd0788-8357-476e-aff8-6fed6f6b12b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-ada2503c-fd78-4d63-ba1d-1110926fb25c,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-d8a4e3f6-82e5-4e9e-ba09-764449378ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-163dd79f-35d2-448f-961b-4a62b520ebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-76e4cb92-9b3a-46b9-a77d-784f73f4a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-6fa60dd1-67ad-42b7-8760-2e68038b32df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194066930-172.17.0.4-1597188433637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43051,DS-c6c6e9e3-d99b-49f5-af77-6c83a0122462,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-106de01c-8632-46ff-9660-72ac8569cf9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-74bd0788-8357-476e-aff8-6fed6f6b12b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-ada2503c-fd78-4d63-ba1d-1110926fb25c,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-d8a4e3f6-82e5-4e9e-ba09-764449378ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-163dd79f-35d2-448f-961b-4a62b520ebaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-76e4cb92-9b3a-46b9-a77d-784f73f4a1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-6fa60dd1-67ad-42b7-8760-2e68038b32df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971880592-172.17.0.4-1597188521419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-0a48bb54-02a9-45b5-8e7d-8d7e0f742550,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-bd3d816f-def0-4316-89d6-24f9ac47b778,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-ffa618f2-7bf5-462c-81fa-dff8d140e4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-d1c6a5fd-83b5-4fe8-af8e-edd5c2d7babb,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-6e2b2230-6480-4ba8-a756-24e9d8de4f18,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-5fc0f8d6-125e-406e-8009-9526fd5d2cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-60890fc7-b569-4f9c-a8b2-f2477802370d,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-109e79a7-a7ff-45b6-bd83-88fb050e0c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971880592-172.17.0.4-1597188521419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-0a48bb54-02a9-45b5-8e7d-8d7e0f742550,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-bd3d816f-def0-4316-89d6-24f9ac47b778,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-ffa618f2-7bf5-462c-81fa-dff8d140e4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-d1c6a5fd-83b5-4fe8-af8e-edd5c2d7babb,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-6e2b2230-6480-4ba8-a756-24e9d8de4f18,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-5fc0f8d6-125e-406e-8009-9526fd5d2cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-60890fc7-b569-4f9c-a8b2-f2477802370d,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-109e79a7-a7ff-45b6-bd83-88fb050e0c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333957332-172.17.0.4-1597188739179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-5fd3468a-131b-4857-9ff8-2640874d2665,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-d39f9a80-f192-4a24-8379-2ddf118116b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-797fc6e0-0da9-4cc5-93f3-45df86300faf,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-770e157d-2785-4f63-9a0e-6103ec9dc816,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-605bdfae-e976-4efc-80f1-eb0984db0844,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-ae45b64c-cc13-4857-bafc-4a8930dcf49e,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-97aa92d2-bfea-425e-989a-229a91eff466,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-529337b8-36c2-4037-9053-75283a4aaeb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1333957332-172.17.0.4-1597188739179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38984,DS-5fd3468a-131b-4857-9ff8-2640874d2665,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-d39f9a80-f192-4a24-8379-2ddf118116b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-797fc6e0-0da9-4cc5-93f3-45df86300faf,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-770e157d-2785-4f63-9a0e-6103ec9dc816,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-605bdfae-e976-4efc-80f1-eb0984db0844,DISK], DatanodeInfoWithStorage[127.0.0.1:32976,DS-ae45b64c-cc13-4857-bafc-4a8930dcf49e,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-97aa92d2-bfea-425e-989a-229a91eff466,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-529337b8-36c2-4037-9053-75283a4aaeb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316689855-172.17.0.4-1597188837160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32822,DS-9fecb444-94ef-4dd8-a7fe-28508f0c74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-dc45a1de-6775-49ba-a14c-18c38163e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-afaae7f2-7334-4431-bb50-8d2ebd6c5a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-0cbfd52f-92f2-4fd9-b106-f4a267399c33,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-a11d7608-b74c-41b7-8829-ee53b0a36298,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-34d94959-124a-40eb-bc62-30455f14300b,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-b3c635be-845f-4f72-bb31-266b0f2371a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-721e352a-3483-40de-b62e-d2f558150bbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-316689855-172.17.0.4-1597188837160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32822,DS-9fecb444-94ef-4dd8-a7fe-28508f0c74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-dc45a1de-6775-49ba-a14c-18c38163e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-afaae7f2-7334-4431-bb50-8d2ebd6c5a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-0cbfd52f-92f2-4fd9-b106-f4a267399c33,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-a11d7608-b74c-41b7-8829-ee53b0a36298,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-34d94959-124a-40eb-bc62-30455f14300b,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-b3c635be-845f-4f72-bb31-266b0f2371a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-721e352a-3483-40de-b62e-d2f558150bbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454149922-172.17.0.4-1597188887350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35308,DS-8c052364-0f8a-4e4f-a154-1099bb9e32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-c312ba7d-dca6-4e57-9421-c4e6db903a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-937d3310-b6f1-4fbc-8659-77589f9e3756,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-e3d99f34-c093-48cd-a3e3-23d581855355,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-8bd74854-55f4-4f71-880d-04bdc9c691ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-603a6d07-60d7-4a2b-ac71-3864ee5eed16,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-80b24037-78b8-49a1-b2ea-50ad2190d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-15281f49-f9c1-413d-b6fb-88531499d70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454149922-172.17.0.4-1597188887350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35308,DS-8c052364-0f8a-4e4f-a154-1099bb9e32ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-c312ba7d-dca6-4e57-9421-c4e6db903a89,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-937d3310-b6f1-4fbc-8659-77589f9e3756,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-e3d99f34-c093-48cd-a3e3-23d581855355,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-8bd74854-55f4-4f71-880d-04bdc9c691ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-603a6d07-60d7-4a2b-ac71-3864ee5eed16,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-80b24037-78b8-49a1-b2ea-50ad2190d7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-15281f49-f9c1-413d-b6fb-88531499d70a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424853160-172.17.0.4-1597189319110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41807,DS-7771226c-02ce-4d17-a49d-82740f17f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-8530f434-fc2b-4555-b788-3c5c2158db31,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-8f9e153a-fb8a-4b53-91ad-9af99213f25c,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-3eaeddd3-8a2e-4e07-ab4c-915190095083,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-f6693b34-1691-4528-80f3-b031fb7b1960,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-eb67d838-3a7d-48c7-b3dd-54f50569cd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-9b9f7f55-163b-41dc-b1d3-52da0853f55a,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-7ea1ce62-d5a6-4894-bed0-64028f1337c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424853160-172.17.0.4-1597189319110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41807,DS-7771226c-02ce-4d17-a49d-82740f17f75c,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-8530f434-fc2b-4555-b788-3c5c2158db31,DISK], DatanodeInfoWithStorage[127.0.0.1:40401,DS-8f9e153a-fb8a-4b53-91ad-9af99213f25c,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-3eaeddd3-8a2e-4e07-ab4c-915190095083,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-f6693b34-1691-4528-80f3-b031fb7b1960,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-eb67d838-3a7d-48c7-b3dd-54f50569cd7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-9b9f7f55-163b-41dc-b1d3-52da0853f55a,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-7ea1ce62-d5a6-4894-bed0-64028f1337c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168672908-172.17.0.4-1597189627678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-0d78b8e6-c6e7-4e2d-911b-c1159d24623a,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-e4e5c334-1eb4-4c60-b4c6-86c13ed22d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-253e8d82-9927-4047-90d3-b7fee4c60e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-e84eb132-90b3-4ca4-a3c6-d789d8d87ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-fadcabb8-1915-4eb2-99e0-26b99a5066e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-3708a63b-e486-4840-ad83-314d84282f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-523cefe5-179a-4e6d-995b-2e77cf150fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-e85a79ed-eb46-499e-9ca1-281cb3cf7b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168672908-172.17.0.4-1597189627678:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40452,DS-0d78b8e6-c6e7-4e2d-911b-c1159d24623a,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-e4e5c334-1eb4-4c60-b4c6-86c13ed22d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:41785,DS-253e8d82-9927-4047-90d3-b7fee4c60e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-e84eb132-90b3-4ca4-a3c6-d789d8d87ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-fadcabb8-1915-4eb2-99e0-26b99a5066e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-3708a63b-e486-4840-ad83-314d84282f57,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-523cefe5-179a-4e6d-995b-2e77cf150fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-e85a79ed-eb46-499e-9ca1-281cb3cf7b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975490615-172.17.0.4-1597190163974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43670,DS-0584acb9-e368-4860-ae70-c973dfbdff3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-b8d18379-88b5-4e94-9f96-a1d462c08c40,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-a96fc77d-3546-435a-8f17-db3fce7a1b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-ffd77cbc-7301-4174-a853-3264b9bf0068,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-c9710955-62fa-4905-9d56-a3ad7f83b321,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-5959c480-e9f0-4fc8-9710-bdea41fe29fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-818cd167-e78c-40cf-921c-e6c0aa0f3742,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-fb91934c-5b0e-49c5-a703-91a5d97e4adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975490615-172.17.0.4-1597190163974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43670,DS-0584acb9-e368-4860-ae70-c973dfbdff3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-b8d18379-88b5-4e94-9f96-a1d462c08c40,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-a96fc77d-3546-435a-8f17-db3fce7a1b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-ffd77cbc-7301-4174-a853-3264b9bf0068,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-c9710955-62fa-4905-9d56-a3ad7f83b321,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-5959c480-e9f0-4fc8-9710-bdea41fe29fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-818cd167-e78c-40cf-921c-e6c0aa0f3742,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-fb91934c-5b0e-49c5-a703-91a5d97e4adf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814102731-172.17.0.4-1597190248005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-9062e6ea-2670-402b-9d57-7fecb1e3b425,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-2a161e0e-9a8b-450e-9cc5-ab24f6a1c2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-f0e46c98-90a0-42d7-9bd2-d2272e456038,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-7b7740f0-0928-4d59-9547-d722fd813fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-9704ee84-cc5b-4eed-b62c-2a12a4a89cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-094d5f05-5a07-45c7-b775-3b08b78b5782,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-cd308f8d-0f6f-4f44-8060-c040ffdcb4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-2642ea49-04eb-4d56-8bf3-ebe4cf4c46ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814102731-172.17.0.4-1597190248005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43961,DS-9062e6ea-2670-402b-9d57-7fecb1e3b425,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-2a161e0e-9a8b-450e-9cc5-ab24f6a1c2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-f0e46c98-90a0-42d7-9bd2-d2272e456038,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-7b7740f0-0928-4d59-9547-d722fd813fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39418,DS-9704ee84-cc5b-4eed-b62c-2a12a4a89cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-094d5f05-5a07-45c7-b775-3b08b78b5782,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-cd308f8d-0f6f-4f44-8060-c040ffdcb4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-2642ea49-04eb-4d56-8bf3-ebe4cf4c46ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.handler.count
component: hdfs:NameNode
v1: 10
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708087988-172.17.0.4-1597190287394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33902,DS-86c2772d-74d7-437a-836c-7980d48a0bde,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-4c37a2de-35a1-4230-a4d2-459f8ad4acce,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-e155cf58-6d11-4cb2-aa92-77b0f88f9196,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-de893bf8-1cc4-457a-90d9-2fc9076ecb61,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-ab7f15d3-9452-4d81-9be6-0ca262eb9937,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-0787b6ed-fefc-4dec-967f-f15eef95bac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-273f1abe-df25-4e67-b73e-442da24f9267,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-922ea610-ecb3-410e-a88f-565b26053a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708087988-172.17.0.4-1597190287394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33902,DS-86c2772d-74d7-437a-836c-7980d48a0bde,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-4c37a2de-35a1-4230-a4d2-459f8ad4acce,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-e155cf58-6d11-4cb2-aa92-77b0f88f9196,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-de893bf8-1cc4-457a-90d9-2fc9076ecb61,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-ab7f15d3-9452-4d81-9be6-0ca262eb9937,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-0787b6ed-fefc-4dec-967f-f15eef95bac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-273f1abe-df25-4e67-b73e-442da24f9267,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-922ea610-ecb3-410e-a88f-565b26053a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6547
