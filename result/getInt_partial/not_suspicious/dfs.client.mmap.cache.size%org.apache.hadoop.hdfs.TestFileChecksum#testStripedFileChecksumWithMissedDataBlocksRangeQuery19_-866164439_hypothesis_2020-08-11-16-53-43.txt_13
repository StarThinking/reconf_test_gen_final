reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347983082-172.17.0.17-1597165285911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-bb932db5-1f2e-4053-9748-900444f85ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-c5841654-98d3-45fa-8743-3b4cc1b4d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-fae3ff7e-ad82-44a9-a1be-1284a3320d25,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-fccbfa47-6c14-472f-b8d0-972a578e9216,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-9e9a562c-2cd3-441b-b0de-9c6bfa5c4014,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-3c677c12-3261-479d-92e9-fcfda8b4f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-cf44423a-6348-41c0-9bdb-0ce34936366a,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-fece381d-a972-495d-b5b6-ab23efdc99bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-347983082-172.17.0.17-1597165285911:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35837,DS-bb932db5-1f2e-4053-9748-900444f85ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-c5841654-98d3-45fa-8743-3b4cc1b4d1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41925,DS-fae3ff7e-ad82-44a9-a1be-1284a3320d25,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-fccbfa47-6c14-472f-b8d0-972a578e9216,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-9e9a562c-2cd3-441b-b0de-9c6bfa5c4014,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-3c677c12-3261-479d-92e9-fcfda8b4f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-cf44423a-6348-41c0-9bdb-0ce34936366a,DISK], DatanodeInfoWithStorage[127.0.0.1:46228,DS-fece381d-a972-495d-b5b6-ab23efdc99bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999109327-172.17.0.17-1597165487584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37007,DS-6e21b761-6c41-4676-8520-b274877c3144,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-0805c833-f806-42b0-811d-5e5f5b823895,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-1d59428f-d948-4d4c-ba91-d4d3c7b659c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-2cc49c0a-13ab-49f9-9320-c76881aed9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-103e8f5d-6fd7-41dd-af2a-07743ca5695b,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-9726fb36-468c-41bb-bd4d-1c9987458e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-239cddaa-bf3b-4e3c-a95d-a856b96ee671,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-29c5da6d-0dad-4a7d-9983-2d4efc3c515e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-999109327-172.17.0.17-1597165487584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37007,DS-6e21b761-6c41-4676-8520-b274877c3144,DISK], DatanodeInfoWithStorage[127.0.0.1:36680,DS-0805c833-f806-42b0-811d-5e5f5b823895,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-1d59428f-d948-4d4c-ba91-d4d3c7b659c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-2cc49c0a-13ab-49f9-9320-c76881aed9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-103e8f5d-6fd7-41dd-af2a-07743ca5695b,DISK], DatanodeInfoWithStorage[127.0.0.1:36850,DS-9726fb36-468c-41bb-bd4d-1c9987458e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-239cddaa-bf3b-4e3c-a95d-a856b96ee671,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-29c5da6d-0dad-4a7d-9983-2d4efc3c515e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747960124-172.17.0.17-1597165616133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40395,DS-e6bd5cce-dc3c-4f68-9e8f-b981f5414ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-1747ead8-c01b-435b-b303-538abb93628e,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-0e40e0ef-c499-4f8c-94d8-1ec1d7b56559,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-5640f926-3b39-4984-bd5b-2e9d51e7a97c,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-4c9e295d-f681-4686-8589-9bd120cc03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-f3b034b3-28fd-4c28-beea-61c94d03c89a,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-5f45d91b-4881-4feb-816e-5c3104bbafdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-39552b87-387a-4ddb-bd31-d500a66a39e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747960124-172.17.0.17-1597165616133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40395,DS-e6bd5cce-dc3c-4f68-9e8f-b981f5414ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-1747ead8-c01b-435b-b303-538abb93628e,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-0e40e0ef-c499-4f8c-94d8-1ec1d7b56559,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-5640f926-3b39-4984-bd5b-2e9d51e7a97c,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-4c9e295d-f681-4686-8589-9bd120cc03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-f3b034b3-28fd-4c28-beea-61c94d03c89a,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-5f45d91b-4881-4feb-816e-5c3104bbafdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-39552b87-387a-4ddb-bd31-d500a66a39e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980708414-172.17.0.17-1597166209389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-6d5ac7ef-dd8c-4d51-9506-180c454a9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-8f843ead-3d9f-4c91-bccd-dda8fa0a5cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-64bd96db-5ce2-4037-92ee-71861835d58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-53a894a3-ef52-4caf-865f-f040194ad092,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-6f47d169-8d62-47be-8c79-d4e341e393a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-acd4a397-aa7d-4979-9d1d-a220f2c93e80,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-dc196af2-3093-444f-9e97-264ac32da03f,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-1eeed94e-6f29-438e-80ef-4d30703b7fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980708414-172.17.0.17-1597166209389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45114,DS-6d5ac7ef-dd8c-4d51-9506-180c454a9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-8f843ead-3d9f-4c91-bccd-dda8fa0a5cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-64bd96db-5ce2-4037-92ee-71861835d58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-53a894a3-ef52-4caf-865f-f040194ad092,DISK], DatanodeInfoWithStorage[127.0.0.1:37245,DS-6f47d169-8d62-47be-8c79-d4e341e393a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-acd4a397-aa7d-4979-9d1d-a220f2c93e80,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-dc196af2-3093-444f-9e97-264ac32da03f,DISK], DatanodeInfoWithStorage[127.0.0.1:38226,DS-1eeed94e-6f29-438e-80ef-4d30703b7fa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955377575-172.17.0.17-1597166398311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-5becc24d-5529-4ff0-a133-eb7a1b5cf05e,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-c8180b52-0a61-485e-8941-38a6c71071b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-df6e449e-59dc-4c40-a687-a69f6b96ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-27afb277-47a8-4aed-9ba0-1e459059900c,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-61507087-ee80-4121-9f24-78f86a88105a,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-9a0142bc-2628-4fd3-b685-c2fffaea4bed,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-8dc524a1-7a36-4fa9-92ae-53b4ca716f05,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-369fcbca-e405-4f3c-9fb3-13581340640f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-955377575-172.17.0.17-1597166398311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36174,DS-5becc24d-5529-4ff0-a133-eb7a1b5cf05e,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-c8180b52-0a61-485e-8941-38a6c71071b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-df6e449e-59dc-4c40-a687-a69f6b96ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-27afb277-47a8-4aed-9ba0-1e459059900c,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-61507087-ee80-4121-9f24-78f86a88105a,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-9a0142bc-2628-4fd3-b685-c2fffaea4bed,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-8dc524a1-7a36-4fa9-92ae-53b4ca716f05,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-369fcbca-e405-4f3c-9fb3-13581340640f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244474184-172.17.0.17-1597166645143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-c452fa11-7895-4755-9796-43c622626316,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-066f5b02-7236-4fbb-9cee-a9f2771da9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-4c5266cb-9dc3-411d-b96d-cf86087ffa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-bfc72c02-344a-4d0f-91a7-f49fb31fe7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-abe15d5d-01db-4579-a327-a23d184e874d,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-4378d2a7-7af5-4b79-a178-90f3683461e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-6d876597-8abe-40c1-b9b3-cabd267c1fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-f5697e54-73c3-44c9-87d7-b9bedb21d0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1244474184-172.17.0.17-1597166645143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33886,DS-c452fa11-7895-4755-9796-43c622626316,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-066f5b02-7236-4fbb-9cee-a9f2771da9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-4c5266cb-9dc3-411d-b96d-cf86087ffa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-bfc72c02-344a-4d0f-91a7-f49fb31fe7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-abe15d5d-01db-4579-a327-a23d184e874d,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-4378d2a7-7af5-4b79-a178-90f3683461e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-6d876597-8abe-40c1-b9b3-cabd267c1fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-f5697e54-73c3-44c9-87d7-b9bedb21d0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782465704-172.17.0.17-1597166720541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-d73d6dd5-6331-4a75-9be6-aa05136cb217,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-46707583-aa30-4c4c-8bd0-36ab2322bc57,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-44407dd9-f29a-4c56-b9b2-c9f8feefe75a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-db8e742a-f534-4c9f-8f24-77f9ef7bfdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-15709bbb-2cee-4baa-be53-4c162398afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-57660bc2-3d50-4e91-b74b-40a7ceea9016,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-36978f35-5e61-4bbb-9602-8b223c69e6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-14cefda1-ab66-483b-b27b-71da6685705d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-782465704-172.17.0.17-1597166720541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-d73d6dd5-6331-4a75-9be6-aa05136cb217,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-46707583-aa30-4c4c-8bd0-36ab2322bc57,DISK], DatanodeInfoWithStorage[127.0.0.1:33833,DS-44407dd9-f29a-4c56-b9b2-c9f8feefe75a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-db8e742a-f534-4c9f-8f24-77f9ef7bfdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-15709bbb-2cee-4baa-be53-4c162398afcf,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-57660bc2-3d50-4e91-b74b-40a7ceea9016,DISK], DatanodeInfoWithStorage[127.0.0.1:36773,DS-36978f35-5e61-4bbb-9602-8b223c69e6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-14cefda1-ab66-483b-b27b-71da6685705d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889467190-172.17.0.17-1597167408235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42023,DS-b0fdaf2c-2597-4723-909c-607635e2ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-2fd44160-0809-4b77-bd91-6bd9e2dbd0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-b7efe22a-25a4-4c7c-bc76-adc7d6b9070d,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-4d2d7fb6-6918-493a-8f63-aab56f299b24,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-f4a70a94-68e6-407b-ad43-2d560604b947,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-e52b3ee2-fd4b-4ec1-bf23-dc16fc323ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-0cf96320-1b70-4b0b-b294-d93fdb91a24d,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-c3cdaf2b-4238-4ee3-a58b-8d9ebf042db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889467190-172.17.0.17-1597167408235:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42023,DS-b0fdaf2c-2597-4723-909c-607635e2ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-2fd44160-0809-4b77-bd91-6bd9e2dbd0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-b7efe22a-25a4-4c7c-bc76-adc7d6b9070d,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-4d2d7fb6-6918-493a-8f63-aab56f299b24,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-f4a70a94-68e6-407b-ad43-2d560604b947,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-e52b3ee2-fd4b-4ec1-bf23-dc16fc323ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-0cf96320-1b70-4b0b-b294-d93fdb91a24d,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-c3cdaf2b-4238-4ee3-a58b-8d9ebf042db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359846145-172.17.0.17-1597167517756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33673,DS-fa176af8-8ece-4923-ab1a-86277d3fde56,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-6de193ae-71e0-44d2-be3d-dc29ddcc12bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-ccfe2dce-f00a-47d5-bc98-01b34f35017d,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-68aaa574-ea3c-4a7d-bff1-622395bf2e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-094e143f-2dfb-478c-bee9-f0b30122f159,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-41ff2aed-32f3-430d-8516-ce7dfabf0162,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-3d1baea7-58d3-4bb7-a421-6ccf21f1aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-9d4eb6b2-d3f7-4686-aa18-ad611c7cbd9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359846145-172.17.0.17-1597167517756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33673,DS-fa176af8-8ece-4923-ab1a-86277d3fde56,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-6de193ae-71e0-44d2-be3d-dc29ddcc12bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40645,DS-ccfe2dce-f00a-47d5-bc98-01b34f35017d,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-68aaa574-ea3c-4a7d-bff1-622395bf2e52,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-094e143f-2dfb-478c-bee9-f0b30122f159,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-41ff2aed-32f3-430d-8516-ce7dfabf0162,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-3d1baea7-58d3-4bb7-a421-6ccf21f1aa08,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-9d4eb6b2-d3f7-4686-aa18-ad611c7cbd9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564025346-172.17.0.17-1597168236581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35573,DS-e9b4d4dd-57bb-4b6a-a8c4-015480f163b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-7626a488-de9d-435b-a2f4-57a37ea7ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-7ef81285-0bad-4209-8b26-6e63146b2600,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-80460347-5523-41d9-8de6-4e7e12be6d77,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-3a087b48-5024-4776-8e38-bde56a75d486,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-62b6801d-a5b2-448e-bdfb-928a0196e9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-d25bc2dd-9942-4e92-8c09-02f604926a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-1f33f13c-a2df-44b6-854c-7f3d8fc57142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-564025346-172.17.0.17-1597168236581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35573,DS-e9b4d4dd-57bb-4b6a-a8c4-015480f163b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-7626a488-de9d-435b-a2f4-57a37ea7ce2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42130,DS-7ef81285-0bad-4209-8b26-6e63146b2600,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-80460347-5523-41d9-8de6-4e7e12be6d77,DISK], DatanodeInfoWithStorage[127.0.0.1:42164,DS-3a087b48-5024-4776-8e38-bde56a75d486,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-62b6801d-a5b2-448e-bdfb-928a0196e9ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44001,DS-d25bc2dd-9942-4e92-8c09-02f604926a18,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-1f33f13c-a2df-44b6-854c-7f3d8fc57142,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772837339-172.17.0.17-1597169268456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-9c8248f4-d797-4b5d-83c2-3c4214c58941,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-69b0fce1-6e51-4039-af28-2b04807d783c,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-200aa7b8-0920-41d4-b60b-9ce5b4d1d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-f85b19bc-5b0f-49f6-8a7b-c07076c4e04b,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-2e6901e7-2432-4a22-913e-a78d1df0430b,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-da00073d-f6cc-403b-86c4-9c69860d8682,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-a5662fd4-dc5f-4740-b22e-190d233c91d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-d54a0733-ce70-4703-9f89-fa3bf1b6cb40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1772837339-172.17.0.17-1597169268456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34993,DS-9c8248f4-d797-4b5d-83c2-3c4214c58941,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-69b0fce1-6e51-4039-af28-2b04807d783c,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-200aa7b8-0920-41d4-b60b-9ce5b4d1d64a,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-f85b19bc-5b0f-49f6-8a7b-c07076c4e04b,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-2e6901e7-2432-4a22-913e-a78d1df0430b,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-da00073d-f6cc-403b-86c4-9c69860d8682,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-a5662fd4-dc5f-4740-b22e-190d233c91d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-d54a0733-ce70-4703-9f89-fa3bf1b6cb40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.size
component: hdfs:NameNode
v1: 0
v2: 256
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625468866-172.17.0.17-1597169735088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44839,DS-08dd9b29-d976-4cdd-9255-3b4bfe752848,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-07281406-d5f4-46b0-8091-bd568031acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-b06f8957-2774-4e36-9b61-d9396dbf7c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-075526e6-5aee-4a8e-b843-31e45db35852,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-25d01339-a598-41f0-9458-636fd33ca761,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-5f182df6-1000-400f-89b3-179e09c5cf90,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-d5a0f870-9ca5-4c89-acb6-32149aa6d0da,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-bb980387-5e3d-4810-bbbc-ac309974175b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1625468866-172.17.0.17-1597169735088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44839,DS-08dd9b29-d976-4cdd-9255-3b4bfe752848,DISK], DatanodeInfoWithStorage[127.0.0.1:42079,DS-07281406-d5f4-46b0-8091-bd568031acc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-b06f8957-2774-4e36-9b61-d9396dbf7c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-075526e6-5aee-4a8e-b843-31e45db35852,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-25d01339-a598-41f0-9458-636fd33ca761,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-5f182df6-1000-400f-89b3-179e09c5cf90,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-d5a0f870-9ca5-4c89-acb6-32149aa6d0da,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-bb980387-5e3d-4810-bbbc-ac309974175b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5266
