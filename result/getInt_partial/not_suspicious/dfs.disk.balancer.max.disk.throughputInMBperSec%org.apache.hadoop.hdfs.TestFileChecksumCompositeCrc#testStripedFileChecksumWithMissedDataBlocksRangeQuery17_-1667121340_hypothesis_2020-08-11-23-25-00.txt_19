reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313574849-172.17.0.19-1597188360146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36018,DS-1488d9e4-64b8-4f5a-829b-5b38b9cd9d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-e57c1213-a782-4cfe-b648-9bff75cf8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-91750793-d9e4-478f-953c-69574163d7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-bf648011-a2b6-4072-b70c-e2d4be8dd323,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-644db42d-f69c-4f2d-87eb-969320f075d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-ee727de5-242a-4a2d-a71d-b692baa8d023,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-56e03d07-91f6-4b72-a942-3d93c44d2a04,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-9484b464-508a-4ec4-b23e-075d611b2fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1313574849-172.17.0.19-1597188360146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36018,DS-1488d9e4-64b8-4f5a-829b-5b38b9cd9d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-e57c1213-a782-4cfe-b648-9bff75cf8b00,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-91750793-d9e4-478f-953c-69574163d7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-bf648011-a2b6-4072-b70c-e2d4be8dd323,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-644db42d-f69c-4f2d-87eb-969320f075d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-ee727de5-242a-4a2d-a71d-b692baa8d023,DISK], DatanodeInfoWithStorage[127.0.0.1:38818,DS-56e03d07-91f6-4b72-a942-3d93c44d2a04,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-9484b464-508a-4ec4-b23e-075d611b2fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6125007-172.17.0.19-1597188573960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-49f1bcaf-a227-48d9-a4e6-d81b323511c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-a4e575a3-3524-4270-a967-188769e1d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-90663253-2c21-4578-9902-2550890d1100,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-f57d5591-2c9c-414d-b538-5ac11a91a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-2eba4b15-fea7-4ca4-bd2a-d2478f2a0f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-98383cdc-dcfa-47d6-8b77-0de01db05526,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-8613ce2a-3fea-4dd7-804b-6ebd20379162,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-4c44c64a-fd53-49b8-acc3-b3000177f99e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6125007-172.17.0.19-1597188573960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43305,DS-49f1bcaf-a227-48d9-a4e6-d81b323511c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-a4e575a3-3524-4270-a967-188769e1d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-90663253-2c21-4578-9902-2550890d1100,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-f57d5591-2c9c-414d-b538-5ac11a91a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-2eba4b15-fea7-4ca4-bd2a-d2478f2a0f23,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-98383cdc-dcfa-47d6-8b77-0de01db05526,DISK], DatanodeInfoWithStorage[127.0.0.1:35984,DS-8613ce2a-3fea-4dd7-804b-6ebd20379162,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-4c44c64a-fd53-49b8-acc3-b3000177f99e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871644880-172.17.0.19-1597188625500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35952,DS-23b31c77-46bb-4478-b730-80daa22a2907,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-a8be5962-fff3-44a6-a7e9-09925ea69cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-f5bcef2e-a2c0-4920-9e7a-0db0079c900b,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-6ad16820-0461-4087-bb61-d4d4c3f87933,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-e48923f3-af7d-4782-90ec-ab63dd75a446,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-385b9cef-ed87-4f11-8923-3c122a325370,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-82c6e351-b551-4060-b076-32eb4257bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-b96ab703-5336-414b-b369-0dd7de60879a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-871644880-172.17.0.19-1597188625500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35952,DS-23b31c77-46bb-4478-b730-80daa22a2907,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-a8be5962-fff3-44a6-a7e9-09925ea69cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-f5bcef2e-a2c0-4920-9e7a-0db0079c900b,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-6ad16820-0461-4087-bb61-d4d4c3f87933,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-e48923f3-af7d-4782-90ec-ab63dd75a446,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-385b9cef-ed87-4f11-8923-3c122a325370,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-82c6e351-b551-4060-b076-32eb4257bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-b96ab703-5336-414b-b369-0dd7de60879a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830712973-172.17.0.19-1597188665378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-714376df-0149-4a76-812f-53250a12b7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-b5672ead-3473-4519-9466-9d9cd5fdf91a,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-98b938b9-aefa-4931-802f-4f6f1b80becb,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-f0fd75a9-77a2-4173-bfd3-7bf6c7e9def8,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-4b63050a-bc66-479b-a9be-277297f8f8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-115856da-4a5c-4883-b905-05bc7148db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-5da8a40e-cab4-4725-9025-02d1588513b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-c84a530b-5bfd-4cb6-bb08-7beecb8447c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830712973-172.17.0.19-1597188665378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38318,DS-714376df-0149-4a76-812f-53250a12b7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-b5672ead-3473-4519-9466-9d9cd5fdf91a,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-98b938b9-aefa-4931-802f-4f6f1b80becb,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-f0fd75a9-77a2-4173-bfd3-7bf6c7e9def8,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-4b63050a-bc66-479b-a9be-277297f8f8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-115856da-4a5c-4883-b905-05bc7148db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-5da8a40e-cab4-4725-9025-02d1588513b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-c84a530b-5bfd-4cb6-bb08-7beecb8447c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130837338-172.17.0.19-1597188846938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35239,DS-2c0d064f-574e-4cb6-92a5-373ac92d72a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-a7d9454d-5f6a-4f77-a8c7-3a27258803a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-4d06c50f-b09f-41f3-b2d2-794b96eccd41,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-226952ae-99c7-4c4c-bd21-ad542b2491be,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-eaa1c8bb-fbf2-450e-a34a-050b393a9a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-92b4d2ee-733c-4509-bba5-9cbe53538b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-8fd98352-c705-44d3-a557-8a3fbac93383,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-d0b70b0d-5b13-4f1c-a202-cf5222305b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130837338-172.17.0.19-1597188846938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35239,DS-2c0d064f-574e-4cb6-92a5-373ac92d72a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-a7d9454d-5f6a-4f77-a8c7-3a27258803a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-4d06c50f-b09f-41f3-b2d2-794b96eccd41,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-226952ae-99c7-4c4c-bd21-ad542b2491be,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-eaa1c8bb-fbf2-450e-a34a-050b393a9a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-92b4d2ee-733c-4509-bba5-9cbe53538b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-8fd98352-c705-44d3-a557-8a3fbac93383,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-d0b70b0d-5b13-4f1c-a202-cf5222305b43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252919034-172.17.0.19-1597188969638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39840,DS-54db281a-f86e-4e57-beb2-4aa125325c71,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-edbab160-733a-4de6-b479-31a32106e1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-88e4ce54-c160-4dba-afe2-c031c0a846ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-51aea4b1-c5ce-4098-a9b2-3b2ba6ea6c41,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-5e68603d-ea88-440a-9962-06a63e4784a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-8d63165f-4752-4342-9cec-b47ed6ebda41,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-dddcc14e-d923-4cd3-a18d-bd5f1ead06e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-1c86b6d1-e3a8-4e7f-b493-8795faa64463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-252919034-172.17.0.19-1597188969638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39840,DS-54db281a-f86e-4e57-beb2-4aa125325c71,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-edbab160-733a-4de6-b479-31a32106e1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-88e4ce54-c160-4dba-afe2-c031c0a846ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-51aea4b1-c5ce-4098-a9b2-3b2ba6ea6c41,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-5e68603d-ea88-440a-9962-06a63e4784a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-8d63165f-4752-4342-9cec-b47ed6ebda41,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-dddcc14e-d923-4cd3-a18d-bd5f1ead06e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-1c86b6d1-e3a8-4e7f-b493-8795faa64463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941160563-172.17.0.19-1597189100606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34271,DS-9c7360be-5743-4cfa-a2ed-dfa4e582b4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-bedf0d8d-ad48-42b8-91ce-c95d1676d26e,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-d8eca136-cd63-4342-bd54-3d23a6e91552,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-b4e6c6b2-c2a3-42db-805a-1cd7357fff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-2ccad766-c715-4e6d-88bd-fa8c798a194c,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-48451e23-be4a-4d6f-b4e8-3b247a07ca74,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-02da5d9f-e53b-48c0-8fc0-6abe29850946,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-0844c0f7-f978-477c-89da-cda19e5621e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941160563-172.17.0.19-1597189100606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34271,DS-9c7360be-5743-4cfa-a2ed-dfa4e582b4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-bedf0d8d-ad48-42b8-91ce-c95d1676d26e,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-d8eca136-cd63-4342-bd54-3d23a6e91552,DISK], DatanodeInfoWithStorage[127.0.0.1:42646,DS-b4e6c6b2-c2a3-42db-805a-1cd7357fff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-2ccad766-c715-4e6d-88bd-fa8c798a194c,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-48451e23-be4a-4d6f-b4e8-3b247a07ca74,DISK], DatanodeInfoWithStorage[127.0.0.1:43770,DS-02da5d9f-e53b-48c0-8fc0-6abe29850946,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-0844c0f7-f978-477c-89da-cda19e5621e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588664625-172.17.0.19-1597190378396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43232,DS-6086048c-0e2d-4147-b51a-6ca7d7cc8f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-f8e5ec84-0158-4d92-a22a-ec4a24921536,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-d55f38cb-f9b7-4593-aea5-3b8039e60b76,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-cd010f7f-afc0-4d1f-9655-5509c73f8dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-67f3dad2-b79d-4fdf-9ed0-4f8663e52e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-76d510e8-192d-4329-8e72-584cfac81f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-8b110b12-d2f5-43d2-a3b7-6ca359d47bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-0c547860-0510-4956-a39f-fa2cfb42aefc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-588664625-172.17.0.19-1597190378396:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43232,DS-6086048c-0e2d-4147-b51a-6ca7d7cc8f21,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-f8e5ec84-0158-4d92-a22a-ec4a24921536,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-d55f38cb-f9b7-4593-aea5-3b8039e60b76,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-cd010f7f-afc0-4d1f-9655-5509c73f8dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-67f3dad2-b79d-4fdf-9ed0-4f8663e52e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-76d510e8-192d-4329-8e72-584cfac81f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-8b110b12-d2f5-43d2-a3b7-6ca359d47bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-0c547860-0510-4956-a39f-fa2cfb42aefc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117760972-172.17.0.19-1597190503785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34294,DS-bc3a3592-a34c-419e-a006-f5789f909ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-9194da6a-74fb-463a-9a79-da582bce7913,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-fcc22ad4-32b7-4403-8342-a4f3956f697c,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-3fda6808-2838-4938-af29-cdeb518277ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-c3c4a762-a90c-4999-a3a0-d7be16da8d73,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-cf0d14f1-6949-4079-a423-5f90d267df97,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-a36f79fa-0c7c-450c-99f0-21e8c11a4668,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-e72c6135-64c5-4ecc-b427-352fb2de7d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117760972-172.17.0.19-1597190503785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34294,DS-bc3a3592-a34c-419e-a006-f5789f909ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-9194da6a-74fb-463a-9a79-da582bce7913,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-fcc22ad4-32b7-4403-8342-a4f3956f697c,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-3fda6808-2838-4938-af29-cdeb518277ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-c3c4a762-a90c-4999-a3a0-d7be16da8d73,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-cf0d14f1-6949-4079-a423-5f90d267df97,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-a36f79fa-0c7c-450c-99f0-21e8c11a4668,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-e72c6135-64c5-4ecc-b427-352fb2de7d29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497923576-172.17.0.19-1597190550141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41834,DS-ac0a4d3a-90ff-4f7c-a052-2a3e649c977d,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-6a68976f-659c-42b0-9cee-55c84056324d,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-2e67d345-98d9-443e-ad57-adfe84a661e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-911a92c4-2645-4d6a-8103-c0f1d8c3c20e,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-2d9e51d1-0495-42cc-86a2-d0d261be4670,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-e92ae084-7ea6-48e4-9b6b-ecb946c3907d,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-aa723b3c-c650-4289-849e-60d538c10fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-ff90c9fb-e854-4daf-b45f-97d8a7234209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497923576-172.17.0.19-1597190550141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41834,DS-ac0a4d3a-90ff-4f7c-a052-2a3e649c977d,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-6a68976f-659c-42b0-9cee-55c84056324d,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-2e67d345-98d9-443e-ad57-adfe84a661e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-911a92c4-2645-4d6a-8103-c0f1d8c3c20e,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-2d9e51d1-0495-42cc-86a2-d0d261be4670,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-e92ae084-7ea6-48e4-9b6b-ecb946c3907d,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-aa723b3c-c650-4289-849e-60d538c10fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-ff90c9fb-e854-4daf-b45f-97d8a7234209,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829523688-172.17.0.19-1597191361828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34469,DS-479c0538-2702-40e4-9760-76dd279528a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-e76edd76-4c13-4edb-8c23-bb46fd3c6b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-59ff87ca-b850-4d0c-b674-266826681307,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-a07fa96c-1c24-4964-94cb-11b9dcf0be53,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-ae850b39-7fb1-4f05-be54-182b6908a6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-a6f36e5d-f54d-471c-8f9b-759a22b6065c,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-0c957c94-94a9-4a6e-a92b-9126ed151b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-b16d2135-5628-4b45-9104-92595b7dd2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1829523688-172.17.0.19-1597191361828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34469,DS-479c0538-2702-40e4-9760-76dd279528a3,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-e76edd76-4c13-4edb-8c23-bb46fd3c6b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-59ff87ca-b850-4d0c-b674-266826681307,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-a07fa96c-1c24-4964-94cb-11b9dcf0be53,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-ae850b39-7fb1-4f05-be54-182b6908a6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-a6f36e5d-f54d-471c-8f9b-759a22b6065c,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-0c957c94-94a9-4a6e-a92b-9126ed151b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-b16d2135-5628-4b45-9104-92595b7dd2d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962720445-172.17.0.19-1597192782614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43274,DS-36601bc2-c564-4535-b364-ab86cd6eff0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-805acc9e-725e-4a1b-a7b7-a3966c538129,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-678941c9-d5ba-48a8-a39f-ed181f36a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-c142b56d-8987-4408-9bd4-ed27732e4834,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-119c6fba-b49a-477c-97b0-d1469109a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-1e08e66b-244a-4685-bf3a-7ab508fa9c33,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-7a3a04e9-c356-4727-927c-6a044d906d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-b4db1459-8110-4e90-a550-855e57301315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-962720445-172.17.0.19-1597192782614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43274,DS-36601bc2-c564-4535-b364-ab86cd6eff0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-805acc9e-725e-4a1b-a7b7-a3966c538129,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-678941c9-d5ba-48a8-a39f-ed181f36a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-c142b56d-8987-4408-9bd4-ed27732e4834,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-119c6fba-b49a-477c-97b0-d1469109a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-1e08e66b-244a-4685-bf3a-7ab508fa9c33,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-7a3a04e9-c356-4727-927c-6a044d906d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-b4db1459-8110-4e90-a550-855e57301315,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104682588-172.17.0.19-1597193416120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40477,DS-49607159-5744-46a1-a12f-af3675a0d0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-a3c87e67-1a96-4b1e-bd84-8028ca1a33ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-07472f36-7429-4a73-bef1-d93ffb492503,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-828ce9bd-96c2-466e-be3e-06658f84151e,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-0dcb890f-c881-4950-9a9a-b58550503d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-87377734-b129-4f8c-b6e0-c37a47186860,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-85b14609-02ed-4629-98fc-fb5ff3a5e351,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-5e296fc6-12ee-4742-97a6-40add4bd3609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-104682588-172.17.0.19-1597193416120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40477,DS-49607159-5744-46a1-a12f-af3675a0d0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-a3c87e67-1a96-4b1e-bd84-8028ca1a33ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-07472f36-7429-4a73-bef1-d93ffb492503,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-828ce9bd-96c2-466e-be3e-06658f84151e,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-0dcb890f-c881-4950-9a9a-b58550503d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-87377734-b129-4f8c-b6e0-c37a47186860,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-85b14609-02ed-4629-98fc-fb5ff3a5e351,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-5e296fc6-12ee-4742-97a6-40add4bd3609,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098705500-172.17.0.19-1597193677162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42817,DS-4eee7524-5044-468e-9c72-2d1ed6ee8363,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-10121a4b-9874-45c1-b99b-af20381a5a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-e6992bde-67f6-449a-a9df-a32302c70682,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-a195c27e-5e26-48fb-9b32-c3e275dbc8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-d77476f3-bf4d-4a77-a716-a78e25b9e224,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-99543505-5a54-434f-aa88-1d4609500551,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-29b8cee9-18fa-41c3-aed2-0be40a138ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-2ff8fafe-4aad-4df1-9b5f-915b7bf20d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098705500-172.17.0.19-1597193677162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42817,DS-4eee7524-5044-468e-9c72-2d1ed6ee8363,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-10121a4b-9874-45c1-b99b-af20381a5a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-e6992bde-67f6-449a-a9df-a32302c70682,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-a195c27e-5e26-48fb-9b32-c3e275dbc8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-d77476f3-bf4d-4a77-a716-a78e25b9e224,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-99543505-5a54-434f-aa88-1d4609500551,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-29b8cee9-18fa-41c3-aed2-0be40a138ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-2ff8fafe-4aad-4df1-9b5f-915b7bf20d4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385152947-172.17.0.19-1597194329227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-fb804476-3958-4dab-9c2a-60598b9236d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-d95ba2f4-4ac2-4c1c-983f-0a17353df969,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-15bd1201-94d5-4e8f-9db3-d7c935ac2071,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-eed79281-ae57-4f6b-ba41-f958c2b45a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-de8b54ff-c68a-40bd-a165-54e18dcc60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-4e61083c-4927-4c35-a3f2-8abc4dbe0eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-e8a759c1-56ce-490d-9a9c-4bee569e4742,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-f1b7546a-7d59-4e3d-a7a3-f14842a5295e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1385152947-172.17.0.19-1597194329227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37900,DS-fb804476-3958-4dab-9c2a-60598b9236d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40948,DS-d95ba2f4-4ac2-4c1c-983f-0a17353df969,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-15bd1201-94d5-4e8f-9db3-d7c935ac2071,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-eed79281-ae57-4f6b-ba41-f958c2b45a30,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-de8b54ff-c68a-40bd-a165-54e18dcc60ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-4e61083c-4927-4c35-a3f2-8abc4dbe0eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-e8a759c1-56ce-490d-9a9c-4bee569e4742,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-f1b7546a-7d59-4e3d-a7a3-f14842a5295e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.throughputInMBperSec
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154766483-172.17.0.19-1597194382799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-1359b879-ebc8-4b91-871f-522e0af6467d,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-a774a603-d2ec-4852-b891-7304220ca3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-d23997b1-aaa8-4a82-9655-5d9fea974ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-290dea6c-5f25-40a4-acad-d5e17dadec22,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-a4eeff71-8ee2-47f2-9291-1b7a02a4d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-59241454-be02-4505-bcea-6311122283bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-bf3fdf87-613d-4e7b-99f9-79daae470567,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-50c28d2d-4532-49c2-baad-8a15d8c8c723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154766483-172.17.0.19-1597194382799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40007,DS-1359b879-ebc8-4b91-871f-522e0af6467d,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-a774a603-d2ec-4852-b891-7304220ca3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-d23997b1-aaa8-4a82-9655-5d9fea974ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-290dea6c-5f25-40a4-acad-d5e17dadec22,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-a4eeff71-8ee2-47f2-9291-1b7a02a4d03f,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-59241454-be02-4505-bcea-6311122283bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-bf3fdf87-613d-4e7b-99f9-79daae470567,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-50c28d2d-4532-49c2-baad-8a15d8c8c723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 6495
