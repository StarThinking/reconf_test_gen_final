reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917379361-172.17.0.17-1597124373814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44611,DS-8448b04c-32c8-4c70-988e-ae15d10073ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-dd985dfa-4864-4ccc-ae6d-32c07795190d,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-3c3576a8-cf32-444d-90a5-a69190800a24,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-800d0063-c484-4a47-914f-9007767e0a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-1c6eb166-69cb-443c-a7a0-0c618f26bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-53e70d61-d213-474c-a41b-080ea5ed0500,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-af9faf4c-07a0-4bdb-a08e-fce0ccb3d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-dab89dc5-7651-4b7c-96e5-58e71843c154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917379361-172.17.0.17-1597124373814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44611,DS-8448b04c-32c8-4c70-988e-ae15d10073ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-dd985dfa-4864-4ccc-ae6d-32c07795190d,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-3c3576a8-cf32-444d-90a5-a69190800a24,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-800d0063-c484-4a47-914f-9007767e0a27,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-1c6eb166-69cb-443c-a7a0-0c618f26bcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-53e70d61-d213-474c-a41b-080ea5ed0500,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-af9faf4c-07a0-4bdb-a08e-fce0ccb3d9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-dab89dc5-7651-4b7c-96e5-58e71843c154,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730471635-172.17.0.17-1597124411473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-4c4ecccc-4670-437c-88f5-a02c9d0a0ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-171a1ef0-9c92-43cb-ab2c-5b6d1a0b234f,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-f744dba9-86aa-4b45-9a0c-a4fbba3805f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-29524b4e-f15b-48c4-aacf-ea52454654f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-02de46a8-2d6a-49bb-9cf5-4836077de7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-419901d5-e570-4a1d-b707-807fbe0e3035,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-ff0590cf-8806-4203-a9f1-83e6c3db32c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-758910e1-85af-46b5-82d3-468e700d2027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1730471635-172.17.0.17-1597124411473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42725,DS-4c4ecccc-4670-437c-88f5-a02c9d0a0ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-171a1ef0-9c92-43cb-ab2c-5b6d1a0b234f,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-f744dba9-86aa-4b45-9a0c-a4fbba3805f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-29524b4e-f15b-48c4-aacf-ea52454654f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-02de46a8-2d6a-49bb-9cf5-4836077de7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-419901d5-e570-4a1d-b707-807fbe0e3035,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-ff0590cf-8806-4203-a9f1-83e6c3db32c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-758910e1-85af-46b5-82d3-468e700d2027,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190262046-172.17.0.17-1597124555254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-a51a0e65-b0b4-41c6-b28e-c7c90fd7275d,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-38f6868d-9148-40a9-93f9-23686bbc841b,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-19d96588-8767-4957-82d9-74eae5fb782c,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-56b01ca5-b2a0-47f1-a5e7-b6968eef891e,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-6f529cb2-04eb-45fb-a10f-15ed67481eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-3797b6e0-7237-4834-b718-32e621ae54d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-5dfe0516-61c3-415b-922c-610cb7faeadd,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-fb9cc354-d3ab-4fa7-9117-fec752630964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190262046-172.17.0.17-1597124555254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-a51a0e65-b0b4-41c6-b28e-c7c90fd7275d,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-38f6868d-9148-40a9-93f9-23686bbc841b,DISK], DatanodeInfoWithStorage[127.0.0.1:37791,DS-19d96588-8767-4957-82d9-74eae5fb782c,DISK], DatanodeInfoWithStorage[127.0.0.1:42926,DS-56b01ca5-b2a0-47f1-a5e7-b6968eef891e,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-6f529cb2-04eb-45fb-a10f-15ed67481eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-3797b6e0-7237-4834-b718-32e621ae54d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-5dfe0516-61c3-415b-922c-610cb7faeadd,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-fb9cc354-d3ab-4fa7-9117-fec752630964,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565159265-172.17.0.17-1597125593589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46269,DS-1675fb67-ed61-4191-98ca-7df064cd70ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-3d2d0238-d11f-4899-bad8-51c7a208fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-ca1aebdb-b40f-4bea-9e09-4c8d17445554,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-61d094c6-27ff-4ab2-84f2-3c7ba5a1cf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-3749d936-25fe-45cc-af76-4b1f4096b052,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-fec7fa22-959f-4cea-927f-fa462cb090d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-5484ed66-575e-4b94-bc20-884027e79090,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-6003dbf8-717c-44cd-84a8-a602ebb08b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565159265-172.17.0.17-1597125593589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46269,DS-1675fb67-ed61-4191-98ca-7df064cd70ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-3d2d0238-d11f-4899-bad8-51c7a208fea3,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-ca1aebdb-b40f-4bea-9e09-4c8d17445554,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-61d094c6-27ff-4ab2-84f2-3c7ba5a1cf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-3749d936-25fe-45cc-af76-4b1f4096b052,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-fec7fa22-959f-4cea-927f-fa462cb090d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-5484ed66-575e-4b94-bc20-884027e79090,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-6003dbf8-717c-44cd-84a8-a602ebb08b83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765281276-172.17.0.17-1597125845723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40760,DS-19f933e6-fc4c-44ec-b442-10a0af64bbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-4a573404-0634-40e9-9928-84e41ee4f34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-eb2578fe-f370-46da-ad9f-6e839d66b62b,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-c696ba10-fe8e-4909-ab51-8d7853e14ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-c81f67f0-7b14-4141-9f0e-8136e15e93b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-13ccd678-1b22-43f9-a6b7-7ec5c2063024,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-d814bc3f-9831-4700-8e2e-7df41ce8c049,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-1cdecb93-3e25-4c3a-97d3-03ae846e32a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765281276-172.17.0.17-1597125845723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40760,DS-19f933e6-fc4c-44ec-b442-10a0af64bbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-4a573404-0634-40e9-9928-84e41ee4f34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-eb2578fe-f370-46da-ad9f-6e839d66b62b,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-c696ba10-fe8e-4909-ab51-8d7853e14ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-c81f67f0-7b14-4141-9f0e-8136e15e93b0,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-13ccd678-1b22-43f9-a6b7-7ec5c2063024,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-d814bc3f-9831-4700-8e2e-7df41ce8c049,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-1cdecb93-3e25-4c3a-97d3-03ae846e32a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718542781-172.17.0.17-1597126253929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-0ff8bfba-3e9a-4fa8-8a28-2f906392fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-7b8c648f-95a9-4685-afaa-948b3dd2962c,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-60bd3517-272d-46dd-b69c-114a8af748ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-15f26927-e4a3-479d-afa6-35b8a4e060ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-4c808251-53b5-4e7b-a469-a43903176a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-669c3cea-0e77-4d69-b03d-a996fe95bf23,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-e009e510-11b8-4574-9616-20f4133c5498,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-57214870-d0e9-4aab-b55d-a418e6b000f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718542781-172.17.0.17-1597126253929:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37307,DS-0ff8bfba-3e9a-4fa8-8a28-2f906392fedd,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-7b8c648f-95a9-4685-afaa-948b3dd2962c,DISK], DatanodeInfoWithStorage[127.0.0.1:43983,DS-60bd3517-272d-46dd-b69c-114a8af748ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-15f26927-e4a3-479d-afa6-35b8a4e060ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-4c808251-53b5-4e7b-a469-a43903176a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-669c3cea-0e77-4d69-b03d-a996fe95bf23,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-e009e510-11b8-4574-9616-20f4133c5498,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-57214870-d0e9-4aab-b55d-a418e6b000f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697383209-172.17.0.17-1597126811161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-4ebbf48f-0107-4b02-b920-e65b4e52a517,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-28c5d477-b2f8-465f-bbec-c0f2100089bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-06b866bf-0a9f-4123-b0ee-658aed36e463,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-44c75aa4-fb2c-4e05-8771-54d513ac1b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-34b1f077-91d7-4243-8cb9-a196b49e66b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-8604e5b6-98f7-45c5-8455-504a4b23829d,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-c41db702-08a1-4fb8-8aa0-f729be737fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-e3afb9b4-cca3-44f5-8e68-27072fd7f640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697383209-172.17.0.17-1597126811161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32888,DS-4ebbf48f-0107-4b02-b920-e65b4e52a517,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-28c5d477-b2f8-465f-bbec-c0f2100089bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-06b866bf-0a9f-4123-b0ee-658aed36e463,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-44c75aa4-fb2c-4e05-8771-54d513ac1b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-34b1f077-91d7-4243-8cb9-a196b49e66b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-8604e5b6-98f7-45c5-8455-504a4b23829d,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-c41db702-08a1-4fb8-8aa0-f729be737fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-e3afb9b4-cca3-44f5-8e68-27072fd7f640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405940801-172.17.0.17-1597126975207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44723,DS-f5bafbac-8bad-4080-985a-eefe1b339e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-b8180722-4eed-4214-a03e-fcad212031ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-91403d69-d236-42f5-9df9-4cc8d7541ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-b28bb0ed-f099-431a-87a8-0d0ed253d978,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-8aa090fc-1e38-4269-bd26-3545e2a7467f,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-fcb982ee-7897-45c3-94e7-461b13985528,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-9fcf1e4f-63e2-43c9-ba6e-480016f3245a,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-e47a9d82-4061-45f4-bce7-2de0bad90466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405940801-172.17.0.17-1597126975207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44723,DS-f5bafbac-8bad-4080-985a-eefe1b339e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-b8180722-4eed-4214-a03e-fcad212031ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-91403d69-d236-42f5-9df9-4cc8d7541ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-b28bb0ed-f099-431a-87a8-0d0ed253d978,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-8aa090fc-1e38-4269-bd26-3545e2a7467f,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-fcb982ee-7897-45c3-94e7-461b13985528,DISK], DatanodeInfoWithStorage[127.0.0.1:45707,DS-9fcf1e4f-63e2-43c9-ba6e-480016f3245a,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-e47a9d82-4061-45f4-bce7-2de0bad90466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938900884-172.17.0.17-1597127073219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-fa7f21cb-8493-49b5-a9d2-9d984b8440ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-617f2640-71fc-4dbb-bdfb-083b6251886c,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-0df33dea-cbcc-4a1c-96b5-23bd51a70363,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-6c5cbe1c-93c8-4d85-970a-72f7ad20500d,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-08a1da93-bf95-4e69-b13c-3bfff65eab40,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-b11f4b4e-0028-415b-801d-f5f1b60cef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-370c1019-bdd9-4a16-85eb-3a622380519b,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-93653b30-2909-4dea-8312-b23f843045cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938900884-172.17.0.17-1597127073219:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-fa7f21cb-8493-49b5-a9d2-9d984b8440ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-617f2640-71fc-4dbb-bdfb-083b6251886c,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-0df33dea-cbcc-4a1c-96b5-23bd51a70363,DISK], DatanodeInfoWithStorage[127.0.0.1:37105,DS-6c5cbe1c-93c8-4d85-970a-72f7ad20500d,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-08a1da93-bf95-4e69-b13c-3bfff65eab40,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-b11f4b4e-0028-415b-801d-f5f1b60cef3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-370c1019-bdd9-4a16-85eb-3a622380519b,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-93653b30-2909-4dea-8312-b23f843045cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259652236-172.17.0.17-1597127795677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42847,DS-5bc16b81-81ee-4037-b1e8-c2fb4713c3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-9a09026a-eef1-47ed-a162-08d6102419b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-847df86a-7b82-4fe6-8774-33ec10e1e10c,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-83bd16e3-76e0-42b9-9d7a-b1e5d3a6d0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-346a3f06-b963-4374-8081-0819e297091a,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-73f751a3-92be-4a82-bcca-a175c8b890b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-579ac4a4-d3ee-463e-910e-768b07a5df15,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-65f98262-76c1-43b7-8e30-0a704c84dfbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259652236-172.17.0.17-1597127795677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42847,DS-5bc16b81-81ee-4037-b1e8-c2fb4713c3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-9a09026a-eef1-47ed-a162-08d6102419b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-847df86a-7b82-4fe6-8774-33ec10e1e10c,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-83bd16e3-76e0-42b9-9d7a-b1e5d3a6d0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-346a3f06-b963-4374-8081-0819e297091a,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-73f751a3-92be-4a82-bcca-a175c8b890b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-579ac4a4-d3ee-463e-910e-768b07a5df15,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-65f98262-76c1-43b7-8e30-0a704c84dfbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537195089-172.17.0.17-1597127859546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-61e12020-4175-4112-a829-387a4989b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-a4a20d2c-0b5c-489c-a85e-30eef0132f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-6efa7321-b7c3-4184-9ace-b7d49a8a7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-01bd7751-2308-46db-a6c0-688dbcab0947,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-22a13a22-c907-45cc-b1e6-5825441befaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-44ae859d-f6d8-497e-b3a7-ba11853e9411,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-a65da283-79c7-45e9-8510-c95a0cba6ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-5e4744f3-62ae-4200-ad03-0a13ae1174da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537195089-172.17.0.17-1597127859546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-61e12020-4175-4112-a829-387a4989b10c,DISK], DatanodeInfoWithStorage[127.0.0.1:33437,DS-a4a20d2c-0b5c-489c-a85e-30eef0132f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-6efa7321-b7c3-4184-9ace-b7d49a8a7bad,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-01bd7751-2308-46db-a6c0-688dbcab0947,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-22a13a22-c907-45cc-b1e6-5825441befaf,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-44ae859d-f6d8-497e-b3a7-ba11853e9411,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-a65da283-79c7-45e9-8510-c95a0cba6ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-5e4744f3-62ae-4200-ad03-0a13ae1174da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302663438-172.17.0.17-1597128420997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36034,DS-a5d0a453-b94f-45fd-8389-cdd46641fe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-3a61acdc-1a06-4940-af70-9658d686cda1,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-acee4a59-cb6f-4501-9ef8-ebb97557e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-14a3daee-3206-4dc9-a4d9-395bb86f13f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-65eb235c-96ea-4697-8df1-0350497d191d,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-eec3dcac-d0d1-4eed-9a83-8be054ad418e,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-e80b86b6-d25b-462c-ae69-034a0aac4ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-8b490175-4bf9-4ef7-85a9-4ac9d1fbfdad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302663438-172.17.0.17-1597128420997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36034,DS-a5d0a453-b94f-45fd-8389-cdd46641fe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-3a61acdc-1a06-4940-af70-9658d686cda1,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-acee4a59-cb6f-4501-9ef8-ebb97557e46a,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-14a3daee-3206-4dc9-a4d9-395bb86f13f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-65eb235c-96ea-4697-8df1-0350497d191d,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-eec3dcac-d0d1-4eed-9a83-8be054ad418e,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-e80b86b6-d25b-462c-ae69-034a0aac4ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-8b490175-4bf9-4ef7-85a9-4ac9d1fbfdad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940803617-172.17.0.17-1597128709794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37943,DS-babe7300-4d9d-457a-a410-8c4fe92da554,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-8448f285-2912-4fd6-9ce3-f4f730175e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-68f97cfe-b3f5-45aa-8e26-0061681f1b42,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-dd2ea2ad-7ed2-43d9-bd7d-a8f7bfdfeb89,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-6d68a197-031b-4dcb-a808-297d26c527d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-d9f0d34e-862f-40bd-a26f-4f66964262af,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-0560fed5-3482-4faf-b0da-254710ad59ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-be0f2ead-a5f4-40ed-87d5-a576165a6a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940803617-172.17.0.17-1597128709794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37943,DS-babe7300-4d9d-457a-a410-8c4fe92da554,DISK], DatanodeInfoWithStorage[127.0.0.1:44112,DS-8448f285-2912-4fd6-9ce3-f4f730175e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-68f97cfe-b3f5-45aa-8e26-0061681f1b42,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-dd2ea2ad-7ed2-43d9-bd7d-a8f7bfdfeb89,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-6d68a197-031b-4dcb-a808-297d26c527d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-d9f0d34e-862f-40bd-a26f-4f66964262af,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-0560fed5-3482-4faf-b0da-254710ad59ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-be0f2ead-a5f4-40ed-87d5-a576165a6a8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595257525-172.17.0.17-1597128777244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33055,DS-e9cccd19-3dcb-46f4-a29e-8589b4f5d271,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-426902e1-d3f0-4581-aaef-7d5d9b717690,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-a8472659-b869-4759-a4c5-01f7c23e23c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-803130f3-728b-46f7-ab15-441a8bd877f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-58792156-b24c-4ff1-a6c5-2c83413ff023,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-943e4e5e-8911-4256-a675-936d3a27c81f,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-c98c53c3-13da-49df-8b4a-d19435f91e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-373cc6d1-42ad-446e-a109-723311516185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595257525-172.17.0.17-1597128777244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33055,DS-e9cccd19-3dcb-46f4-a29e-8589b4f5d271,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-426902e1-d3f0-4581-aaef-7d5d9b717690,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-a8472659-b869-4759-a4c5-01f7c23e23c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-803130f3-728b-46f7-ab15-441a8bd877f5,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-58792156-b24c-4ff1-a6c5-2c83413ff023,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-943e4e5e-8911-4256-a675-936d3a27c81f,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-c98c53c3-13da-49df-8b4a-d19435f91e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-373cc6d1-42ad-446e-a109-723311516185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.replication.work.multiplier.per.iteration
component: hdfs:NameNode
v1: 100
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434114953-172.17.0.17-1597129328452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-63fcdd83-d728-4bd1-8d64-a820b9ae45ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-2027059e-c2d1-46b7-b0e0-163ce8a0f93a,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-6a6cb2ed-78e7-4c58-b83c-7c034e8f2d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-18a11ee5-4a8b-409f-b33c-407ac844f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-f36b1f56-45a7-4a8c-b06d-f536b0103b72,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-813afc3b-05b0-42ae-8d70-e021dc543225,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-322411e8-edf7-4a2b-8484-c3a114e2324e,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-dbf82cb1-a7b6-4202-a0df-e00eb4034c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1434114953-172.17.0.17-1597129328452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45124,DS-63fcdd83-d728-4bd1-8d64-a820b9ae45ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-2027059e-c2d1-46b7-b0e0-163ce8a0f93a,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-6a6cb2ed-78e7-4c58-b83c-7c034e8f2d41,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-18a11ee5-4a8b-409f-b33c-407ac844f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36880,DS-f36b1f56-45a7-4a8c-b06d-f536b0103b72,DISK], DatanodeInfoWithStorage[127.0.0.1:36347,DS-813afc3b-05b0-42ae-8d70-e021dc543225,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-322411e8-edf7-4a2b-8484-c3a114e2324e,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-dbf82cb1-a7b6-4202-a0df-e00eb4034c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5248
