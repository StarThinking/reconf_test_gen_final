reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86916825-172.17.0.7-1597095064164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41033,DS-0f5b8ccb-4aba-4ecb-a667-4c61807c6c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-67481c54-8489-4863-a79e-5e9508c7adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-94f9248b-20ff-4cf7-9b6d-52a26fbbd3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-9c91d42e-127e-40d2-b3b1-0097f45c4fed,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-5132cab2-5864-45f2-a28f-af459b60aa86,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-e263d05b-a174-43f4-a208-2095be7bb01b,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-8921f0cc-e1ef-4dbf-9fab-02aea4a606a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-f0c4adbd-898e-421c-8db6-6c07bef696b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-86916825-172.17.0.7-1597095064164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41033,DS-0f5b8ccb-4aba-4ecb-a667-4c61807c6c46,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-67481c54-8489-4863-a79e-5e9508c7adb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-94f9248b-20ff-4cf7-9b6d-52a26fbbd3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-9c91d42e-127e-40d2-b3b1-0097f45c4fed,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-5132cab2-5864-45f2-a28f-af459b60aa86,DISK], DatanodeInfoWithStorage[127.0.0.1:34141,DS-e263d05b-a174-43f4-a208-2095be7bb01b,DISK], DatanodeInfoWithStorage[127.0.0.1:35361,DS-8921f0cc-e1ef-4dbf-9fab-02aea4a606a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38302,DS-f0c4adbd-898e-421c-8db6-6c07bef696b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235575700-172.17.0.7-1597095231249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-6398dc95-f8c4-48f1-935c-f16047e4f42b,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-e1cbeffd-f347-407a-8de6-34ea07e77606,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-29e3c642-c6b8-4a5a-b973-8076ba681463,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-1dc4e0b5-81a8-4474-801e-1a7ba6a73a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-7ccbbe3f-d673-4ffb-9fa2-0a859fc6bb23,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-a909f95e-5db1-4b23-9103-ae2fdf066711,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-0ffe2acf-c502-480b-8ced-500d9199b09e,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-fc433f2e-0e46-4273-91f5-af2275f1f160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235575700-172.17.0.7-1597095231249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36161,DS-6398dc95-f8c4-48f1-935c-f16047e4f42b,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-e1cbeffd-f347-407a-8de6-34ea07e77606,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-29e3c642-c6b8-4a5a-b973-8076ba681463,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-1dc4e0b5-81a8-4474-801e-1a7ba6a73a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38456,DS-7ccbbe3f-d673-4ffb-9fa2-0a859fc6bb23,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-a909f95e-5db1-4b23-9103-ae2fdf066711,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-0ffe2acf-c502-480b-8ced-500d9199b09e,DISK], DatanodeInfoWithStorage[127.0.0.1:43013,DS-fc433f2e-0e46-4273-91f5-af2275f1f160,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742811133-172.17.0.7-1597095465541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-2815191b-610d-4719-995b-394ed37744da,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-89ae040b-d755-46e9-aebe-c157180daec7,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-4098a822-0c03-4028-8c12-7de827509e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-97e18b7a-edc7-47cf-8ac5-54d269d7f89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-dca51c42-96f5-430f-b9cf-869828d72767,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-91de768e-c61e-4536-9535-d71116ea2ada,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-edc45e94-bf05-4b73-b3fa-9dc5bfd33d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-c9fba7b5-69bd-4aee-9290-278c59c3cebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742811133-172.17.0.7-1597095465541:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-2815191b-610d-4719-995b-394ed37744da,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-89ae040b-d755-46e9-aebe-c157180daec7,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-4098a822-0c03-4028-8c12-7de827509e44,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-97e18b7a-edc7-47cf-8ac5-54d269d7f89c,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-dca51c42-96f5-430f-b9cf-869828d72767,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-91de768e-c61e-4536-9535-d71116ea2ada,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-edc45e94-bf05-4b73-b3fa-9dc5bfd33d27,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-c9fba7b5-69bd-4aee-9290-278c59c3cebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554163598-172.17.0.7-1597095694837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-d1e7b558-883e-4a69-80fe-48bbfd0da598,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-ba1924f6-6b16-4f3d-b2bd-3beb32b74372,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-02768b8a-b72b-4739-9776-893a1bc32769,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-9faada80-c965-4a7a-b277-d4136454e610,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-aad4f03e-08f2-44d5-9d7e-fe21062c1e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-a3564320-b13d-485b-83a9-5abb13e544f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-3ee4e5d6-0a99-470f-9d8f-3aa80b9c223d,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-cf1a632a-d2d5-4a3d-a986-eef643dbb514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554163598-172.17.0.7-1597095694837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-d1e7b558-883e-4a69-80fe-48bbfd0da598,DISK], DatanodeInfoWithStorage[127.0.0.1:40299,DS-ba1924f6-6b16-4f3d-b2bd-3beb32b74372,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-02768b8a-b72b-4739-9776-893a1bc32769,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-9faada80-c965-4a7a-b277-d4136454e610,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-aad4f03e-08f2-44d5-9d7e-fe21062c1e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-a3564320-b13d-485b-83a9-5abb13e544f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-3ee4e5d6-0a99-470f-9d8f-3aa80b9c223d,DISK], DatanodeInfoWithStorage[127.0.0.1:40589,DS-cf1a632a-d2d5-4a3d-a986-eef643dbb514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118051256-172.17.0.7-1597096025903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-98ba8dd0-6932-45d4-bd15-050ebbe4cb59,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-52aa531f-e485-4005-bbec-f465647883d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-0c0ea3f0-cf32-44ba-bb30-c20563aec4be,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-d5f75d1a-5a2d-4dc6-b100-6fdd747a4878,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-7042f0f3-e20b-449a-9403-d08281aae41d,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-2185adc5-d2ba-4ca8-9791-3b459640f8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-38dba54c-c084-4aa5-b9aa-a4b607ff5047,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-c0f8762e-7dfa-435e-8c1a-9c8092a36849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118051256-172.17.0.7-1597096025903:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35943,DS-98ba8dd0-6932-45d4-bd15-050ebbe4cb59,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-52aa531f-e485-4005-bbec-f465647883d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-0c0ea3f0-cf32-44ba-bb30-c20563aec4be,DISK], DatanodeInfoWithStorage[127.0.0.1:35788,DS-d5f75d1a-5a2d-4dc6-b100-6fdd747a4878,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-7042f0f3-e20b-449a-9403-d08281aae41d,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-2185adc5-d2ba-4ca8-9791-3b459640f8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-38dba54c-c084-4aa5-b9aa-a4b607ff5047,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-c0f8762e-7dfa-435e-8c1a-9c8092a36849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957529804-172.17.0.7-1597096254282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-4f7a27ef-fe74-429b-b929-aa63546b6fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-ea5b0a16-ff94-43de-9183-2c9b7ca85561,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-3c373a33-bf1e-41cb-a57a-145906165d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-918d6198-3456-4c49-b441-4d57d3b24627,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-ee14dbea-6ddc-4857-b0db-ecab13cba874,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-9ab7a683-a234-410e-8fb9-d9369de21b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-a427bdde-1b1a-41e8-950c-07bc00a1bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-d9bf4910-1f35-45c4-a696-69457a056b01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1957529804-172.17.0.7-1597096254282:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37075,DS-4f7a27ef-fe74-429b-b929-aa63546b6fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-ea5b0a16-ff94-43de-9183-2c9b7ca85561,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-3c373a33-bf1e-41cb-a57a-145906165d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-918d6198-3456-4c49-b441-4d57d3b24627,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-ee14dbea-6ddc-4857-b0db-ecab13cba874,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-9ab7a683-a234-410e-8fb9-d9369de21b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-a427bdde-1b1a-41e8-950c-07bc00a1bb79,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-d9bf4910-1f35-45c4-a696-69457a056b01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220721138-172.17.0.7-1597096470988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40677,DS-5fcbf2de-1710-4207-bf6f-6e9dbdbf7a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-fbae746b-1826-4402-837b-331bad52498d,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-966bf7bf-b3a3-4c11-b13c-d491199c91cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-dbca0f38-c992-41bb-b2bc-a87b8d1ebd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-5bf62213-2e14-4b75-96e2-356baf29ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-895dbc57-6ef8-4563-8864-b126146caec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-39c7b5a7-b9ed-4399-9103-e39b7b09342e,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-669de5a5-da83-47c2-b202-3791ae727ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1220721138-172.17.0.7-1597096470988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40677,DS-5fcbf2de-1710-4207-bf6f-6e9dbdbf7a61,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-fbae746b-1826-4402-837b-331bad52498d,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-966bf7bf-b3a3-4c11-b13c-d491199c91cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-dbca0f38-c992-41bb-b2bc-a87b8d1ebd6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-5bf62213-2e14-4b75-96e2-356baf29ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-895dbc57-6ef8-4563-8864-b126146caec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-39c7b5a7-b9ed-4399-9103-e39b7b09342e,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-669de5a5-da83-47c2-b202-3791ae727ad1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963636966-172.17.0.7-1597096580805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-e03bed37-ddb4-4adb-b753-b861d8e70929,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-7dccdf4a-93c3-416a-a461-134c30f7ddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-792ec222-b9e1-434a-ba1f-4905b1e53903,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-c438aab5-68da-4bcb-bf37-ebddcba73660,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-9421beb9-df0a-4d45-9f2d-4cb65d1c67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-bf22a723-c364-409f-8448-70e0c6c5280c,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-3a010800-edc8-4b11-a420-bc444b9e7dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-c98999e7-8a58-405b-b38e-8744cb7441ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1963636966-172.17.0.7-1597096580805:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42390,DS-e03bed37-ddb4-4adb-b753-b861d8e70929,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-7dccdf4a-93c3-416a-a461-134c30f7ddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-792ec222-b9e1-434a-ba1f-4905b1e53903,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-c438aab5-68da-4bcb-bf37-ebddcba73660,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-9421beb9-df0a-4d45-9f2d-4cb65d1c67ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-bf22a723-c364-409f-8448-70e0c6c5280c,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-3a010800-edc8-4b11-a420-bc444b9e7dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-c98999e7-8a58-405b-b38e-8744cb7441ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463769260-172.17.0.7-1597097035182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-053377a2-1ddc-4f14-8f9b-9b46f556ab94,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-6486fbee-b093-4f97-ac3d-11ff27383dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-a1b60ec9-9775-47d3-9b40-fd27b58c7579,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-ade279a3-7055-4b67-a49a-30cbf09cbbef,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-b2dd5419-8347-4260-a3d8-6317afb9d3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-fa9dba38-d7d5-4b42-ace0-fbc0e1432738,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-9e3cbabf-b2fd-48d8-9eac-773905538330,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-348dcef0-bd72-4f11-8701-7e934925b8f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-463769260-172.17.0.7-1597097035182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38243,DS-053377a2-1ddc-4f14-8f9b-9b46f556ab94,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-6486fbee-b093-4f97-ac3d-11ff27383dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-a1b60ec9-9775-47d3-9b40-fd27b58c7579,DISK], DatanodeInfoWithStorage[127.0.0.1:35395,DS-ade279a3-7055-4b67-a49a-30cbf09cbbef,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-b2dd5419-8347-4260-a3d8-6317afb9d3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43430,DS-fa9dba38-d7d5-4b42-ace0-fbc0e1432738,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-9e3cbabf-b2fd-48d8-9eac-773905538330,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-348dcef0-bd72-4f11-8701-7e934925b8f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-718269550-172.17.0.7-1597097591905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-a13c3e32-344c-4887-91c3-d0b0f424922d,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-71ff0c33-d5a4-45f1-9a67-4cbb949711db,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-d6a5e74f-a413-4891-817e-0a0bfbf895ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-3426b763-59f4-4563-adad-10b53100b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-6e25daa9-3df5-4ee7-a190-e26f2157ba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-6d210fcd-0e38-4498-87de-dd39dedd28b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-ae7e1a0e-e072-4b2a-b341-acb3c32a4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-1b50501d-3a6b-4003-99d0-2d58f17b4f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-718269550-172.17.0.7-1597097591905:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36832,DS-a13c3e32-344c-4887-91c3-d0b0f424922d,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-71ff0c33-d5a4-45f1-9a67-4cbb949711db,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-d6a5e74f-a413-4891-817e-0a0bfbf895ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-3426b763-59f4-4563-adad-10b53100b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-6e25daa9-3df5-4ee7-a190-e26f2157ba1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-6d210fcd-0e38-4498-87de-dd39dedd28b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-ae7e1a0e-e072-4b2a-b341-acb3c32a4f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-1b50501d-3a6b-4003-99d0-2d58f17b4f87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395550760-172.17.0.7-1597097767173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-045a675e-e612-4c61-ad20-e493c0691063,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-bc145c6d-9f77-46d0-b5a6-5b207a81462e,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-761f9328-6cdd-4a14-98fe-7a77ab6a6e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-d960fcb5-8118-4437-b190-554816f595bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-af180fce-9124-4789-bcae-10a2a2a262c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-77f8e5d0-d6d2-4d08-83bf-f12b41eea2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-8c4f1cf4-fa8e-46e8-b2a5-8d15be37043c,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-1f3f88ed-e08e-44c9-98f8-c571ae7d6017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395550760-172.17.0.7-1597097767173:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34698,DS-045a675e-e612-4c61-ad20-e493c0691063,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-bc145c6d-9f77-46d0-b5a6-5b207a81462e,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-761f9328-6cdd-4a14-98fe-7a77ab6a6e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-d960fcb5-8118-4437-b190-554816f595bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-af180fce-9124-4789-bcae-10a2a2a262c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-77f8e5d0-d6d2-4d08-83bf-f12b41eea2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-8c4f1cf4-fa8e-46e8-b2a5-8d15be37043c,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-1f3f88ed-e08e-44c9-98f8-c571ae7d6017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874732057-172.17.0.7-1597097804757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37239,DS-df4de2eb-31f6-431f-a24d-1ffdd384b611,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-f71e3e28-7ce4-494a-8aa8-64a3961f17d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-143c664c-29d1-41b6-8319-526ad62366cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-58f1c713-62cf-4b5c-a86c-0a08a5234d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-a57040a3-f206-44db-93ed-afc2ec4dfa80,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-b94a1c5c-3b48-4623-b2c4-a04920893086,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-222c5fcc-7919-44e1-9ef4-fa00551392a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-54f0e165-54a0-4a17-aa62-a2ab7f4b62c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874732057-172.17.0.7-1597097804757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37239,DS-df4de2eb-31f6-431f-a24d-1ffdd384b611,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-f71e3e28-7ce4-494a-8aa8-64a3961f17d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-143c664c-29d1-41b6-8319-526ad62366cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-58f1c713-62cf-4b5c-a86c-0a08a5234d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-a57040a3-f206-44db-93ed-afc2ec4dfa80,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-b94a1c5c-3b48-4623-b2c4-a04920893086,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-222c5fcc-7919-44e1-9ef4-fa00551392a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-54f0e165-54a0-4a17-aa62-a2ab7f4b62c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457953177-172.17.0.7-1597098083183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-37ccb15c-7694-4a78-b67d-79ea73c55fac,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-88b82d8e-4bbe-43df-b652-e58f78b737f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-0fbecf96-3523-40d7-82f8-2dabc667d042,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-d00ce868-0945-49a6-b11e-250b76f8fe60,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-ed7ab6b8-d5e5-4e4b-bf0c-d546faa428fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-8b2754d8-1ee6-4246-b0e7-54e193c11084,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-b9f77a89-364f-4f38-940b-91dfc0ef96a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-257ed0f0-5386-4c08-8427-5c4c818fb66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-457953177-172.17.0.7-1597098083183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-37ccb15c-7694-4a78-b67d-79ea73c55fac,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-88b82d8e-4bbe-43df-b652-e58f78b737f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-0fbecf96-3523-40d7-82f8-2dabc667d042,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-d00ce868-0945-49a6-b11e-250b76f8fe60,DISK], DatanodeInfoWithStorage[127.0.0.1:33843,DS-ed7ab6b8-d5e5-4e4b-bf0c-d546faa428fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-8b2754d8-1ee6-4246-b0e7-54e193c11084,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-b9f77a89-364f-4f38-940b-91dfc0ef96a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-257ed0f0-5386-4c08-8427-5c4c818fb66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482336414-172.17.0.7-1597099057191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-288d8b99-22d7-454d-afb4-95a720eb31ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-666b5c59-9ae6-4753-81d1-857ebcc4298c,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-f00a0bf6-9b03-435b-a251-811742645d99,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-174e11af-166b-4d0d-9935-0c9561831637,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-5a95ee48-41a5-4b44-b66c-151cb5ee6a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-69b696b2-935a-44b1-9805-50751354d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-d3e7b791-c44c-475e-b5b0-bb2fe6f76a13,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-be7463a8-b857-4e5c-b598-a9888cef3954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1482336414-172.17.0.7-1597099057191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-288d8b99-22d7-454d-afb4-95a720eb31ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-666b5c59-9ae6-4753-81d1-857ebcc4298c,DISK], DatanodeInfoWithStorage[127.0.0.1:33326,DS-f00a0bf6-9b03-435b-a251-811742645d99,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-174e11af-166b-4d0d-9935-0c9561831637,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-5a95ee48-41a5-4b44-b66c-151cb5ee6a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-69b696b2-935a-44b1-9805-50751354d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-d3e7b791-c44c-475e-b5b0-bb2fe6f76a13,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-be7463a8-b857-4e5c-b598-a9888cef3954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217560354-172.17.0.7-1597099084533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38513,DS-27d4b483-ac75-42dd-8241-8b843836a4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-76aa3dca-6b46-467a-86bf-ac6f1eee0233,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-46461d94-201d-4d1a-8469-cca6aab78058,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-3b64bc5e-2a73-44cc-88bd-cb3db9cf7146,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-90edb173-46f6-488d-b83a-c88928319f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-ef88722a-8591-4d5f-a7e6-0691fc17a02d,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-577bea4c-9a77-4d8c-bb2c-56263a7c6419,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-67973279-93a7-4d77-8ab0-ffddaea0d5b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217560354-172.17.0.7-1597099084533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38513,DS-27d4b483-ac75-42dd-8241-8b843836a4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-76aa3dca-6b46-467a-86bf-ac6f1eee0233,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-46461d94-201d-4d1a-8469-cca6aab78058,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-3b64bc5e-2a73-44cc-88bd-cb3db9cf7146,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-90edb173-46f6-488d-b83a-c88928319f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41674,DS-ef88722a-8591-4d5f-a7e6-0691fc17a02d,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-577bea4c-9a77-4d8c-bb2c-56263a7c6419,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-67973279-93a7-4d77-8ab0-ffddaea0d5b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960933783-172.17.0.7-1597099169978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36199,DS-ce14b09b-3d13-4a4c-a71f-f073a8a761ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-c8bd91bc-c787-4fe9-a186-afff15a45727,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-c0e7a5a6-80e7-4f6c-a004-6eba272e84e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-2b56055a-e5f3-4f65-962d-656385e3cda4,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-2f8e9159-a098-4a60-8e5b-abb0ae433f35,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-78c1a077-ed79-410e-ac20-9b922163cc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-a95b8ec7-eae0-4160-8c7b-6d4262484e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-b908f8d8-2db1-4058-965a-92a231ff87be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960933783-172.17.0.7-1597099169978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36199,DS-ce14b09b-3d13-4a4c-a71f-f073a8a761ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-c8bd91bc-c787-4fe9-a186-afff15a45727,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-c0e7a5a6-80e7-4f6c-a004-6eba272e84e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40841,DS-2b56055a-e5f3-4f65-962d-656385e3cda4,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-2f8e9159-a098-4a60-8e5b-abb0ae433f35,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-78c1a077-ed79-410e-ac20-9b922163cc5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40523,DS-a95b8ec7-eae0-4160-8c7b-6d4262484e77,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-b908f8d8-2db1-4058-965a-92a231ff87be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connect.max.retries
component: hdfs:DataNode
v1: 1000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83868639-172.17.0.7-1597099326461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34163,DS-1e5742b8-5ffb-4b34-9154-78b54e88bd72,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-b410fcd7-55df-49b3-b586-7bb768f231a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-67dfe3a0-bab3-40e9-9c51-3f931726cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-c0f5f761-9a06-42c1-8d54-ed15fb7c4566,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-389cc187-cdfc-4cbc-af7a-0ab89c13805d,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-1401b3f1-d6f9-400f-8b90-ceede9b97aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-906bb80d-b9c5-41df-b62c-e00e9bca127e,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-27aa1336-5d89-4882-b5a4-fd7fbd63fce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-83868639-172.17.0.7-1597099326461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34163,DS-1e5742b8-5ffb-4b34-9154-78b54e88bd72,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-b410fcd7-55df-49b3-b586-7bb768f231a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-67dfe3a0-bab3-40e9-9c51-3f931726cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-c0f5f761-9a06-42c1-8d54-ed15fb7c4566,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-389cc187-cdfc-4cbc-af7a-0ab89c13805d,DISK], DatanodeInfoWithStorage[127.0.0.1:36718,DS-1401b3f1-d6f9-400f-8b90-ceede9b97aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-906bb80d-b9c5-41df-b62c-e00e9bca127e,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-27aa1336-5d89-4882-b5a4-fd7fbd63fce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5123
