reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523034479-172.17.0.11-1597106021486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-449ad533-e0c7-4828-8f31-cce027906703,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-c72fb735-600c-441f-afa3-f7cec2f55e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-c616868b-7125-4eec-b995-acb23c09e0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-2ba1231c-79ea-4aff-bc06-bcfb5db8db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-d8b2d4e8-bcb0-4edf-896e-f95260890ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-24770112-674b-4a39-8bc5-61104907e963,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-9af36fc7-37e5-4fd6-bc8a-12ff4b862094,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-34575771-5a30-4df0-9502-dee2a886fb33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523034479-172.17.0.11-1597106021486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41059,DS-449ad533-e0c7-4828-8f31-cce027906703,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-c72fb735-600c-441f-afa3-f7cec2f55e48,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-c616868b-7125-4eec-b995-acb23c09e0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-2ba1231c-79ea-4aff-bc06-bcfb5db8db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-d8b2d4e8-bcb0-4edf-896e-f95260890ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:38632,DS-24770112-674b-4a39-8bc5-61104907e963,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-9af36fc7-37e5-4fd6-bc8a-12ff4b862094,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-34575771-5a30-4df0-9502-dee2a886fb33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284473601-172.17.0.11-1597106435310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-52d951a5-c02b-424c-b181-ae27eba6fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-b2d84a94-2391-4fea-bdfe-8bb1df540502,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-1b7fc61b-b671-484b-b589-01fe2ed3902e,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-f16f55d5-fd4f-4a71-9a39-8173d4827f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-2413a1b2-0d63-44bc-85c8-ea1620636709,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-8a0c1614-6313-4c16-8587-b528c7846178,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-242a2b7a-ec42-4e05-8ff9-d9dae392b17d,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-0fbca333-db0c-4bfd-a369-715eacd02a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284473601-172.17.0.11-1597106435310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40694,DS-52d951a5-c02b-424c-b181-ae27eba6fb28,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-b2d84a94-2391-4fea-bdfe-8bb1df540502,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-1b7fc61b-b671-484b-b589-01fe2ed3902e,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-f16f55d5-fd4f-4a71-9a39-8173d4827f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-2413a1b2-0d63-44bc-85c8-ea1620636709,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-8a0c1614-6313-4c16-8587-b528c7846178,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-242a2b7a-ec42-4e05-8ff9-d9dae392b17d,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-0fbca333-db0c-4bfd-a369-715eacd02a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682440550-172.17.0.11-1597106590885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43607,DS-0937895c-0926-4dfe-9e76-1484d8fcbbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-50456138-8e10-4c63-8d21-c403589b3cba,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-a6430d8b-4295-47f0-ad00-92f973020cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-75fdc586-3eb5-4c71-b9a5-def5a4ad52f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-f8fdd645-3c44-49e1-b574-420695247ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-8a5cd073-60f8-498d-b0a4-a55631ebffff,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-9c09f637-77d4-4bff-b4d5-d2559b53c850,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-456660be-2c51-4d6b-b6e0-b0429b64c4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1682440550-172.17.0.11-1597106590885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43607,DS-0937895c-0926-4dfe-9e76-1484d8fcbbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46329,DS-50456138-8e10-4c63-8d21-c403589b3cba,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-a6430d8b-4295-47f0-ad00-92f973020cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-75fdc586-3eb5-4c71-b9a5-def5a4ad52f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-f8fdd645-3c44-49e1-b574-420695247ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-8a5cd073-60f8-498d-b0a4-a55631ebffff,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-9c09f637-77d4-4bff-b4d5-d2559b53c850,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-456660be-2c51-4d6b-b6e0-b0429b64c4a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087584053-172.17.0.11-1597106738515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-b7952dcc-dccb-4160-98bf-98516df09908,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-1524d916-00d4-4b7c-9f9b-9545560f980d,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-cd2b0a12-beea-4b1c-b450-5e1d5a85b612,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-c97caaf3-ce0b-40ee-b07c-672483b9487a,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-024d04f8-292d-46d5-99fa-703486a4d210,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-e590eda6-9a7b-4922-801c-d6562eb9754d,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-0d326907-b541-4d4e-a706-982e53848271,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-fe63c207-d206-490d-9eaf-d44039015c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1087584053-172.17.0.11-1597106738515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36607,DS-b7952dcc-dccb-4160-98bf-98516df09908,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-1524d916-00d4-4b7c-9f9b-9545560f980d,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-cd2b0a12-beea-4b1c-b450-5e1d5a85b612,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-c97caaf3-ce0b-40ee-b07c-672483b9487a,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-024d04f8-292d-46d5-99fa-703486a4d210,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-e590eda6-9a7b-4922-801c-d6562eb9754d,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-0d326907-b541-4d4e-a706-982e53848271,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-fe63c207-d206-490d-9eaf-d44039015c25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259763751-172.17.0.11-1597107219088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-d7a730dd-6ab8-4589-b34f-027047a03601,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-b87fe6e5-c6a9-4484-a3a9-0833d519fde3,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-0955e7d5-7fde-418f-b6c0-a13b9c7af057,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-b63e7b43-dd32-43d5-85ea-044f75724906,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-a49789e3-9914-41a8-acaf-df28bf1a2bff,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-3e69e780-9903-4327-857b-ce2b0a482ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-ee95fef9-269e-4d60-a56d-3af04266957e,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-a7006b42-a723-4f86-ab89-2c0b00e4a051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259763751-172.17.0.11-1597107219088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-d7a730dd-6ab8-4589-b34f-027047a03601,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-b87fe6e5-c6a9-4484-a3a9-0833d519fde3,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-0955e7d5-7fde-418f-b6c0-a13b9c7af057,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-b63e7b43-dd32-43d5-85ea-044f75724906,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-a49789e3-9914-41a8-acaf-df28bf1a2bff,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-3e69e780-9903-4327-857b-ce2b0a482ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:34575,DS-ee95fef9-269e-4d60-a56d-3af04266957e,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-a7006b42-a723-4f86-ab89-2c0b00e4a051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816499063-172.17.0.11-1597107253235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35890,DS-bde59f10-0972-415f-a88a-2b78df3273e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-d938aec8-9558-4764-a887-ad0cdd2bb59a,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-799be3f3-fdbe-472c-b863-d5e2713600b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-db8428a3-f51b-4a78-bad3-51a82fc702ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-ed61df76-353f-4e83-8b8c-ecf89ee45dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-e2f78074-fb33-413d-b0d6-ee1fb688d209,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-7890adb4-0672-44ae-9019-1aee1dd1c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-81c0abac-7db6-4fe8-b91a-ff2803398291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816499063-172.17.0.11-1597107253235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35890,DS-bde59f10-0972-415f-a88a-2b78df3273e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-d938aec8-9558-4764-a887-ad0cdd2bb59a,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-799be3f3-fdbe-472c-b863-d5e2713600b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-db8428a3-f51b-4a78-bad3-51a82fc702ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-ed61df76-353f-4e83-8b8c-ecf89ee45dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-e2f78074-fb33-413d-b0d6-ee1fb688d209,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-7890adb4-0672-44ae-9019-1aee1dd1c3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-81c0abac-7db6-4fe8-b91a-ff2803398291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311510782-172.17.0.11-1597107367264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45144,DS-91398665-c0a6-4de1-a9bd-b64e75397fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-e807c1fe-317d-4376-83bb-15f91f6e39c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-93ccd619-0272-4277-9956-6f74c5bd04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-356528c8-8112-4371-8023-dfb800dc9872,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-3e1680ea-9de7-47cf-b046-847d18774487,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-c0e5e568-9bb1-49c3-b2d7-a0363c6577d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-30f5ed29-aac0-49c8-aa09-96b57a886428,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-4835fb33-5751-4f24-99b8-04f3372c958d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-311510782-172.17.0.11-1597107367264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45144,DS-91398665-c0a6-4de1-a9bd-b64e75397fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-e807c1fe-317d-4376-83bb-15f91f6e39c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-93ccd619-0272-4277-9956-6f74c5bd04f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-356528c8-8112-4371-8023-dfb800dc9872,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-3e1680ea-9de7-47cf-b046-847d18774487,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-c0e5e568-9bb1-49c3-b2d7-a0363c6577d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-30f5ed29-aac0-49c8-aa09-96b57a886428,DISK], DatanodeInfoWithStorage[127.0.0.1:46383,DS-4835fb33-5751-4f24-99b8-04f3372c958d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103855550-172.17.0.11-1597107945881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33035,DS-31e279d9-45bb-46a8-a05e-064a367245e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-88d9f9f4-9b5f-40c3-aad5-e0d1b35729f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-d504807f-f19f-462f-815f-ae022e490b66,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-5d3d15cc-bd41-49a0-8096-73841b1a82e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-94b690f3-c750-4c2d-bec1-470109c0ec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-3738a3ff-6e40-4d69-8b1d-513b1b50f652,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-ff412bf7-a8ce-43fd-b9ec-9526dbb48660,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-4cdefff0-fd4a-41f8-989e-561304cfbfaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2103855550-172.17.0.11-1597107945881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33035,DS-31e279d9-45bb-46a8-a05e-064a367245e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-88d9f9f4-9b5f-40c3-aad5-e0d1b35729f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-d504807f-f19f-462f-815f-ae022e490b66,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-5d3d15cc-bd41-49a0-8096-73841b1a82e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-94b690f3-c750-4c2d-bec1-470109c0ec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-3738a3ff-6e40-4d69-8b1d-513b1b50f652,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-ff412bf7-a8ce-43fd-b9ec-9526dbb48660,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-4cdefff0-fd4a-41f8-989e-561304cfbfaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587480407-172.17.0.11-1597108146407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-8c31fd23-3604-4070-aa87-80d9df61e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-6b053d70-36ac-416e-a00f-ce576e22f7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-2cf056e3-b689-431e-8943-a84959e5dbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-bc3bdf1f-2897-4ab9-8802-eb2ac7dcc319,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-36d5982c-7569-4601-9e2b-4af577397e22,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-0348ddeb-952c-44b9-a40c-4b3f83d0533c,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-fb129fd2-3536-418c-9351-baff284dece7,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-179bbe9c-b4b4-44a8-8d2a-69ce3ffc58fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587480407-172.17.0.11-1597108146407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46721,DS-8c31fd23-3604-4070-aa87-80d9df61e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-6b053d70-36ac-416e-a00f-ce576e22f7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-2cf056e3-b689-431e-8943-a84959e5dbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-bc3bdf1f-2897-4ab9-8802-eb2ac7dcc319,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-36d5982c-7569-4601-9e2b-4af577397e22,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-0348ddeb-952c-44b9-a40c-4b3f83d0533c,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-fb129fd2-3536-418c-9351-baff284dece7,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-179bbe9c-b4b4-44a8-8d2a-69ce3ffc58fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923596981-172.17.0.11-1597108247407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37598,DS-00c3b7c3-773b-4f7d-af23-821748525b94,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-67067d0c-f197-4c1f-8c9b-d18fccfee377,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-88c74965-01e5-49ea-b051-255aa60bb894,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-6d1c1500-7aad-4473-8637-8f6448c268b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-77f9660e-afa1-42b4-ac11-b7e394a7fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-e9f75e05-da52-4ecb-a89e-77c9ff857368,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-c3b18d59-a8ac-49a6-a45f-fd7b4dd6a318,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-182d7788-f7b4-4274-9666-ee67073fda77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923596981-172.17.0.11-1597108247407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37598,DS-00c3b7c3-773b-4f7d-af23-821748525b94,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-67067d0c-f197-4c1f-8c9b-d18fccfee377,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-88c74965-01e5-49ea-b051-255aa60bb894,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-6d1c1500-7aad-4473-8637-8f6448c268b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-77f9660e-afa1-42b4-ac11-b7e394a7fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-e9f75e05-da52-4ecb-a89e-77c9ff857368,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-c3b18d59-a8ac-49a6-a45f-fd7b4dd6a318,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-182d7788-f7b4-4274-9666-ee67073fda77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573565315-172.17.0.11-1597109049514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35973,DS-c4a4c999-d8c3-41b5-a351-857c91a33d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-6d11a84d-058f-479f-aaaa-a3193a32d2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-8360ecf9-3adf-4140-9385-30d1872a2579,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-185fa813-2ba9-4a4e-9531-8eda0c3c0f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-a645c3c6-1442-4f6b-b0f3-dcb4244aa018,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-f7ff842e-0847-4f9a-856b-45bc00232b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-a9654656-d821-4646-912b-9629d9a2e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-397d892c-8765-4c4d-a336-168671509ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573565315-172.17.0.11-1597109049514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35973,DS-c4a4c999-d8c3-41b5-a351-857c91a33d27,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-6d11a84d-058f-479f-aaaa-a3193a32d2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-8360ecf9-3adf-4140-9385-30d1872a2579,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-185fa813-2ba9-4a4e-9531-8eda0c3c0f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-a645c3c6-1442-4f6b-b0f3-dcb4244aa018,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-f7ff842e-0847-4f9a-856b-45bc00232b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-a9654656-d821-4646-912b-9629d9a2e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-397d892c-8765-4c4d-a336-168671509ab7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144791233-172.17.0.11-1597109159985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-db4e6479-2742-415c-a5d8-4c410f1a7640,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-b8c5c562-5ef0-4365-a5c1-ec4eed66d093,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-5ad130f4-cdd7-47a3-9ccb-3b846bb715c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-6dfe8fe5-38a6-4c5d-8d73-8730346098b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-e5f40587-88e0-4190-a022-8f56e4d6065f,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-c8d95ee4-a750-4e7e-9b8e-b6d70ed863c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-cb48c67f-b9eb-49bf-9ccf-1e44be747b07,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-75d1a7ab-64cd-4925-a16b-05924fd7dce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1144791233-172.17.0.11-1597109159985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42124,DS-db4e6479-2742-415c-a5d8-4c410f1a7640,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-b8c5c562-5ef0-4365-a5c1-ec4eed66d093,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-5ad130f4-cdd7-47a3-9ccb-3b846bb715c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-6dfe8fe5-38a6-4c5d-8d73-8730346098b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-e5f40587-88e0-4190-a022-8f56e4d6065f,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-c8d95ee4-a750-4e7e-9b8e-b6d70ed863c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-cb48c67f-b9eb-49bf-9ccf-1e44be747b07,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-75d1a7ab-64cd-4925-a16b-05924fd7dce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650015667-172.17.0.11-1597110091001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36907,DS-ed0fee29-29e8-4be5-b9f6-aa3ebdf828b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-13f6be57-999a-43db-89c4-4e352b12853f,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-96620b88-c4be-45b5-92bc-a892d7ab7486,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-e1bbe56f-2a3a-494c-9055-88e2dfff988e,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-ad8bfcd8-43e3-4ea5-8e3e-a73153929b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-2d2b3464-2e71-4235-b47c-f43647fa9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-246922d2-d027-4f23-bfd6-8ee1021b15c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-03539ab6-b5c9-4e46-978d-1abcb479519e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650015667-172.17.0.11-1597110091001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36907,DS-ed0fee29-29e8-4be5-b9f6-aa3ebdf828b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-13f6be57-999a-43db-89c4-4e352b12853f,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-96620b88-c4be-45b5-92bc-a892d7ab7486,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-e1bbe56f-2a3a-494c-9055-88e2dfff988e,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-ad8bfcd8-43e3-4ea5-8e3e-a73153929b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-2d2b3464-2e71-4235-b47c-f43647fa9ade,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-246922d2-d027-4f23-bfd6-8ee1021b15c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-03539ab6-b5c9-4e46-978d-1abcb479519e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337684449-172.17.0.11-1597110255487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39159,DS-ef38f6eb-a18a-4060-bc3d-7a87c6251714,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-4898d117-a5b2-412a-bf74-59f087e1b52e,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-5e0e9164-ae1c-4b7a-8dbd-379d668c15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-70ec927e-265b-4bdc-bc08-43676104f192,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-4e7828c4-ee37-4029-95cd-ce8eb064667c,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-5d493660-377b-47d6-8185-cc9543896bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-96c71d0c-3303-41ca-80e4-ef6ac93550ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-e08cafde-7f14-4839-9144-2c0b50901a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337684449-172.17.0.11-1597110255487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39159,DS-ef38f6eb-a18a-4060-bc3d-7a87c6251714,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-4898d117-a5b2-412a-bf74-59f087e1b52e,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-5e0e9164-ae1c-4b7a-8dbd-379d668c15c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-70ec927e-265b-4bdc-bc08-43676104f192,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-4e7828c4-ee37-4029-95cd-ce8eb064667c,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-5d493660-377b-47d6-8185-cc9543896bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-96c71d0c-3303-41ca-80e4-ef6ac93550ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-e08cafde-7f14-4839-9144-2c0b50901a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274372571-172.17.0.11-1597110483368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42904,DS-10cc4364-6065-4bc5-8fd1-795f76ce2bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-85239c48-8fb3-45d8-a5a4-fc068c7addba,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-50224bac-62a2-4aa8-946f-23e52b49a7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-c4389e73-405c-4de7-9579-e2671dcb6bec,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-729dea6d-32d0-42a9-a8c5-0e5fb2219e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-8de26b5a-969d-4bdc-b2a9-2760bcb6b8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-88731d45-86eb-4d99-95c8-89ee5ae15995,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-e04107fc-de76-4817-995c-41d01d319c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-274372571-172.17.0.11-1597110483368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42904,DS-10cc4364-6065-4bc5-8fd1-795f76ce2bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-85239c48-8fb3-45d8-a5a4-fc068c7addba,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-50224bac-62a2-4aa8-946f-23e52b49a7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37772,DS-c4389e73-405c-4de7-9579-e2671dcb6bec,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-729dea6d-32d0-42a9-a8c5-0e5fb2219e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-8de26b5a-969d-4bdc-b2a9-2760bcb6b8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-88731d45-86eb-4d99-95c8-89ee5ae15995,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-e04107fc-de76-4817-995c-41d01d319c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.safemode.replication.min
component: hdfs:NameNode
v1: 4
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971267372-172.17.0.11-1597110891994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-94b9ac4f-7537-4e6c-8f41-2a505b7fd83a,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-bb68d192-2e36-4155-9eaf-f4fbed6f5151,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-4e4a0c46-8a5a-44df-840e-ee49ee8957d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-44ff1f83-376b-4736-8b1d-6fefa8be026d,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-199352f6-1aac-426b-ae5f-3c01057b9a06,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-ea2fda62-dce7-4bff-8c8c-49d9acd5f52c,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-5a61384d-b4a7-4aa7-95aa-2d6512092b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-c68d19a8-f18e-418e-a2a4-4fb2b4673624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971267372-172.17.0.11-1597110891994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-94b9ac4f-7537-4e6c-8f41-2a505b7fd83a,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-bb68d192-2e36-4155-9eaf-f4fbed6f5151,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-4e4a0c46-8a5a-44df-840e-ee49ee8957d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-44ff1f83-376b-4736-8b1d-6fefa8be026d,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-199352f6-1aac-426b-ae5f-3c01057b9a06,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-ea2fda62-dce7-4bff-8c8c-49d9acd5f52c,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-5a61384d-b4a7-4aa7-95aa-2d6512092b80,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-c68d19a8-f18e-418e-a2a4-4fb2b4673624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5430
