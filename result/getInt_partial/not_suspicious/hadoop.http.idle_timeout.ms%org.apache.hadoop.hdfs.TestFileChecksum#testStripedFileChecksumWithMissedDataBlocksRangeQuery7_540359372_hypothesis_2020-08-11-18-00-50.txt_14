reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104902232-172.17.0.18-1597168905121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40567,DS-7d2577c3-0b6c-4b8c-8f67-da9fcf302cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-0ceb2051-03a4-4a43-aef2-912dd8018c09,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-887dd03b-6217-4b14-ba5c-c0888113874d,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-ed327ed2-9e6e-47f7-b972-c287016057f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-7fbe7ffe-fd33-4087-9cdd-4f33f7e37ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-c97a1f0f-c495-4741-a319-7736e6fcea44,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-b5bd12af-290b-4cfb-a9ae-6326385bb97e,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-d8b7cd2a-6b2d-4435-8a6c-87b734e191c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104902232-172.17.0.18-1597168905121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40567,DS-7d2577c3-0b6c-4b8c-8f67-da9fcf302cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-0ceb2051-03a4-4a43-aef2-912dd8018c09,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-887dd03b-6217-4b14-ba5c-c0888113874d,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-ed327ed2-9e6e-47f7-b972-c287016057f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-7fbe7ffe-fd33-4087-9cdd-4f33f7e37ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-c97a1f0f-c495-4741-a319-7736e6fcea44,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-b5bd12af-290b-4cfb-a9ae-6326385bb97e,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-d8b7cd2a-6b2d-4435-8a6c-87b734e191c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54789892-172.17.0.18-1597169181264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-8605411f-1bfd-4775-910b-3bba95227748,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-536aa59a-cd20-45a9-a741-4ecb52e68e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-94fb30dc-118a-4583-a652-ee48992525fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-36d40d1e-3870-4274-a499-8106073047fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-d85dd8d0-2e87-453f-aac4-1bbd16235070,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-2d03cb84-2b8f-466e-9661-1d304ae74b94,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-331b62ea-6576-46ad-ac92-b3458b1b9677,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-2ae42d0e-48dc-487b-a323-5a2208dc4555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54789892-172.17.0.18-1597169181264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-8605411f-1bfd-4775-910b-3bba95227748,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-536aa59a-cd20-45a9-a741-4ecb52e68e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-94fb30dc-118a-4583-a652-ee48992525fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-36d40d1e-3870-4274-a499-8106073047fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-d85dd8d0-2e87-453f-aac4-1bbd16235070,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-2d03cb84-2b8f-466e-9661-1d304ae74b94,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-331b62ea-6576-46ad-ac92-b3458b1b9677,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-2ae42d0e-48dc-487b-a323-5a2208dc4555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893325792-172.17.0.18-1597169310669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44061,DS-1d6755a8-08cb-442b-8f89-458ac5e4c071,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-26a98359-994b-4281-8d48-3a6247cbde93,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-698041c3-612f-4ff5-9c32-092cfef6288f,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-81ac4289-3dfa-44f6-bee4-01821b5d2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-340d558f-4be5-42ac-9c4a-69eda362a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-b05f4fb6-f639-4eee-bb8f-eb3776316f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-3f46676a-7add-4a16-b0ff-e9374de12e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-5f6a2daf-12fa-41bb-aadf-ab4fc4e00aca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1893325792-172.17.0.18-1597169310669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44061,DS-1d6755a8-08cb-442b-8f89-458ac5e4c071,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-26a98359-994b-4281-8d48-3a6247cbde93,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-698041c3-612f-4ff5-9c32-092cfef6288f,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-81ac4289-3dfa-44f6-bee4-01821b5d2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-340d558f-4be5-42ac-9c4a-69eda362a85d,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-b05f4fb6-f639-4eee-bb8f-eb3776316f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-3f46676a-7add-4a16-b0ff-e9374de12e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-5f6a2daf-12fa-41bb-aadf-ab4fc4e00aca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358370892-172.17.0.18-1597169509821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-37be51bf-355c-4708-93d5-67cff0c87746,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-8a41e930-20ef-4026-9417-1374e84ba315,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-2ee2b74b-26df-4282-9474-e91d56c83464,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-f371378b-be44-4923-875c-4d88296c0ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-849962cf-0cb6-4a69-b84f-f0ff77e143df,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-236e45ff-79e8-4627-9e3e-63eed5fb2aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-665c234c-0e6c-4994-a452-935f7cde2548,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-774c2226-0a6f-4e92-9e47-c476e477f66d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358370892-172.17.0.18-1597169509821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-37be51bf-355c-4708-93d5-67cff0c87746,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-8a41e930-20ef-4026-9417-1374e84ba315,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-2ee2b74b-26df-4282-9474-e91d56c83464,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-f371378b-be44-4923-875c-4d88296c0ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-849962cf-0cb6-4a69-b84f-f0ff77e143df,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-236e45ff-79e8-4627-9e3e-63eed5fb2aab,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-665c234c-0e6c-4994-a452-935f7cde2548,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-774c2226-0a6f-4e92-9e47-c476e477f66d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107342992-172.17.0.18-1597169622687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42089,DS-04591272-5786-45a3-b847-cc237cb93aab,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-bd8f1038-5609-4d6c-80fa-410c3417b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-8fba3720-b876-4e9d-960f-f937be651255,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-a667d544-fd64-4490-af40-a4f95dd753cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-58bf87b9-36fd-49cc-9539-2d84be360008,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-39708b95-bd39-4b14-8b8a-967614b8f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-c7794c3f-6575-4726-ac90-291bfe6e3864,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-19049e6e-5625-49fb-ad73-b942a1d821a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-107342992-172.17.0.18-1597169622687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42089,DS-04591272-5786-45a3-b847-cc237cb93aab,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-bd8f1038-5609-4d6c-80fa-410c3417b3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-8fba3720-b876-4e9d-960f-f937be651255,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-a667d544-fd64-4490-af40-a4f95dd753cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45543,DS-58bf87b9-36fd-49cc-9539-2d84be360008,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-39708b95-bd39-4b14-8b8a-967614b8f7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-c7794c3f-6575-4726-ac90-291bfe6e3864,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-19049e6e-5625-49fb-ad73-b942a1d821a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572154483-172.17.0.18-1597169655224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33761,DS-c64356b1-9f25-4235-98b1-7674e2613c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-d2022866-4af7-48cc-a483-94b76c4e0139,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-b630c0b9-bb41-4dbc-ac60-995cad5dbedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-9fe5fb1d-7bfa-4d74-91a5-9e6aa153f022,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-df1a228f-dc84-4f48-8481-fb4a1f0aadc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-e9805163-4b2b-42af-aa9a-f166a9821af9,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-a6373130-1db9-418a-8a84-19c927c462f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-b62be8f6-3aea-40d6-8ae4-af8272055e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-572154483-172.17.0.18-1597169655224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33761,DS-c64356b1-9f25-4235-98b1-7674e2613c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-d2022866-4af7-48cc-a483-94b76c4e0139,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-b630c0b9-bb41-4dbc-ac60-995cad5dbedc,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-9fe5fb1d-7bfa-4d74-91a5-9e6aa153f022,DISK], DatanodeInfoWithStorage[127.0.0.1:41402,DS-df1a228f-dc84-4f48-8481-fb4a1f0aadc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-e9805163-4b2b-42af-aa9a-f166a9821af9,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-a6373130-1db9-418a-8a84-19c927c462f1,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-b62be8f6-3aea-40d6-8ae4-af8272055e3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593915756-172.17.0.18-1597169726547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-9f6acc94-1c0e-4845-8529-74c258efc287,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-28522ebb-60d2-438b-ba0f-07d9142f0810,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-fe8e00b2-e872-45c3-bde0-669042c78c73,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-3d500cd5-c7d7-4c4f-a4eb-886cca315606,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-9ea737d6-4dce-483c-97c2-ab0c895df8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-d9a1fa39-72d2-4256-8f7f-25ce3d4b44c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-278185e4-ac1a-4875-afae-c0c90e56ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-f58d9bd3-bb57-432b-aeea-7c2cc5b6c52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593915756-172.17.0.18-1597169726547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-9f6acc94-1c0e-4845-8529-74c258efc287,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-28522ebb-60d2-438b-ba0f-07d9142f0810,DISK], DatanodeInfoWithStorage[127.0.0.1:39683,DS-fe8e00b2-e872-45c3-bde0-669042c78c73,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-3d500cd5-c7d7-4c4f-a4eb-886cca315606,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-9ea737d6-4dce-483c-97c2-ab0c895df8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-d9a1fa39-72d2-4256-8f7f-25ce3d4b44c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-278185e4-ac1a-4875-afae-c0c90e56ab87,DISK], DatanodeInfoWithStorage[127.0.0.1:42250,DS-f58d9bd3-bb57-432b-aeea-7c2cc5b6c52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041339695-172.17.0.18-1597170212830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33571,DS-0767db90-4b4e-44ba-9e37-bf301f72bd27,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-0d01746d-e5e9-4691-af0b-a7a20a224da2,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-9e0796f7-b2f5-4de2-a7a6-b628bfaaedd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-f18582c9-81be-4e05-838a-5528820c32d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-43983dc8-0c83-4053-a7c6-9ff4d5f53531,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-82024136-e172-4cae-9792-43b3baa19db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-d578165d-cc2e-4930-a00c-190634d050c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-504e0ef6-8e7e-4f13-bedc-efacd9847ec9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041339695-172.17.0.18-1597170212830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33571,DS-0767db90-4b4e-44ba-9e37-bf301f72bd27,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-0d01746d-e5e9-4691-af0b-a7a20a224da2,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-9e0796f7-b2f5-4de2-a7a6-b628bfaaedd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35441,DS-f18582c9-81be-4e05-838a-5528820c32d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-43983dc8-0c83-4053-a7c6-9ff4d5f53531,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-82024136-e172-4cae-9792-43b3baa19db0,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-d578165d-cc2e-4930-a00c-190634d050c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-504e0ef6-8e7e-4f13-bedc-efacd9847ec9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246948363-172.17.0.18-1597170360511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-feee98ed-87ea-492f-b380-810e22a805d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-058182d6-6a73-4ef1-8ad0-3d7803351ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-90cc8c7f-4bc1-4a15-8365-ff422062695b,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-d9e89183-b799-4ec0-8629-0557b06023b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-c53ea8e7-9cc9-4af5-aa6e-a3af168657b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-a33b233a-21b1-4d15-8202-a64ace4d033f,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-f11d21d1-0324-4900-8f22-50582cfea915,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-e05bab4a-4493-44e9-bcee-da8a1453afc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246948363-172.17.0.18-1597170360511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36930,DS-feee98ed-87ea-492f-b380-810e22a805d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-058182d6-6a73-4ef1-8ad0-3d7803351ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:36578,DS-90cc8c7f-4bc1-4a15-8365-ff422062695b,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-d9e89183-b799-4ec0-8629-0557b06023b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-c53ea8e7-9cc9-4af5-aa6e-a3af168657b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-a33b233a-21b1-4d15-8202-a64ace4d033f,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-f11d21d1-0324-4900-8f22-50582cfea915,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-e05bab4a-4493-44e9-bcee-da8a1453afc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70049662-172.17.0.18-1597170439538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46196,DS-dd130ec0-4e12-4cde-963f-b7f5b7591862,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-45419920-3fd6-4fdf-b43a-e98d81baa995,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-7cb3d97b-6245-497c-9817-ed0572880c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-fbffca29-1777-4d7a-8e30-b8b3fc82ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-f6d2a8c0-b72d-4c1b-9c9b-d3c4e4fb876c,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-d8ed2611-f8aa-4427-9f32-743038f70c72,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-b2d23ca4-73bd-4fb6-acfb-e21c3f5eb345,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-0cbdaf8d-f7c9-4508-a723-b9d9c2edebac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70049662-172.17.0.18-1597170439538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46196,DS-dd130ec0-4e12-4cde-963f-b7f5b7591862,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-45419920-3fd6-4fdf-b43a-e98d81baa995,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-7cb3d97b-6245-497c-9817-ed0572880c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-fbffca29-1777-4d7a-8e30-b8b3fc82ddc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-f6d2a8c0-b72d-4c1b-9c9b-d3c4e4fb876c,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-d8ed2611-f8aa-4427-9f32-743038f70c72,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-b2d23ca4-73bd-4fb6-acfb-e21c3f5eb345,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-0cbdaf8d-f7c9-4508-a723-b9d9c2edebac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543457044-172.17.0.18-1597170509022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36298,DS-0164252b-c921-43ea-a89a-704dbc96bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-405a50df-f1a5-4d79-9365-a9f67be7d6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-8f67d8ba-9e4d-4fcd-8575-b7824170e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-13715964-ab67-4cd1-94f2-1280687cad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-70848846-c4ce-4ce7-9d01-c88f29bd2439,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-240a4dd8-6326-4c8e-9594-e5835c205c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-6607d2f4-25db-483b-8caa-42e4654c851a,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-981181fe-e9f1-4485-9b02-cc34de2fedeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-543457044-172.17.0.18-1597170509022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36298,DS-0164252b-c921-43ea-a89a-704dbc96bf2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-405a50df-f1a5-4d79-9365-a9f67be7d6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-8f67d8ba-9e4d-4fcd-8575-b7824170e57f,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-13715964-ab67-4cd1-94f2-1280687cad8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-70848846-c4ce-4ce7-9d01-c88f29bd2439,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-240a4dd8-6326-4c8e-9594-e5835c205c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-6607d2f4-25db-483b-8caa-42e4654c851a,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-981181fe-e9f1-4485-9b02-cc34de2fedeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108657953-172.17.0.18-1597170850222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-d8f2eccc-e00f-4f63-85e7-6dea68b38c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-501ea97b-9507-4062-8518-eab3b0a339dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-2ad7db3d-d68e-41df-9bd1-e42d55a86f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-3e6bd909-4026-4d51-89ef-a71cca4204d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-f037494c-0136-424b-b6d9-9af8137ab113,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-7d8f1bb5-7e59-474d-ba0a-d3e408b66894,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-270a6745-b475-4669-8daa-30c0edfe9ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-682a7309-f440-4363-8efb-007875ce44ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1108657953-172.17.0.18-1597170850222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-d8f2eccc-e00f-4f63-85e7-6dea68b38c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-501ea97b-9507-4062-8518-eab3b0a339dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-2ad7db3d-d68e-41df-9bd1-e42d55a86f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-3e6bd909-4026-4d51-89ef-a71cca4204d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-f037494c-0136-424b-b6d9-9af8137ab113,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-7d8f1bb5-7e59-474d-ba0a-d3e408b66894,DISK], DatanodeInfoWithStorage[127.0.0.1:34269,DS-270a6745-b475-4669-8daa-30c0edfe9ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-682a7309-f440-4363-8efb-007875ce44ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455116843-172.17.0.18-1597170888949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39962,DS-6ba983a6-133b-4e4f-be7b-e0b7ce2e50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-5c40718c-6e57-42d9-bb8d-32d24375211f,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-973a5be3-f5fe-4f79-a0b2-822e4d421602,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-0ac9202a-37fc-4b9e-934f-ab5c085cb0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-54c163ed-f0d7-42a7-a93c-cf506eb49cde,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-960d7531-fef7-4db3-84de-c2fc4a67d577,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-2a149542-5d2c-4cf2-843c-d4d1b6188702,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-6ba29b48-488b-4464-9206-1d3a59a14ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455116843-172.17.0.18-1597170888949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39962,DS-6ba983a6-133b-4e4f-be7b-e0b7ce2e50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-5c40718c-6e57-42d9-bb8d-32d24375211f,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-973a5be3-f5fe-4f79-a0b2-822e4d421602,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-0ac9202a-37fc-4b9e-934f-ab5c085cb0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-54c163ed-f0d7-42a7-a93c-cf506eb49cde,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-960d7531-fef7-4db3-84de-c2fc4a67d577,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-2a149542-5d2c-4cf2-843c-d4d1b6188702,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-6ba29b48-488b-4464-9206-1d3a59a14ba5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511559865-172.17.0.18-1597171083484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-bb137f37-1e82-44bf-afc2-5e32d8e013a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-6bd506d9-3ecc-478a-beb9-84437dc5678a,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-ebdbd8d0-5e79-4624-95bf-1fc10c3bafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-3c835b68-b83d-4c32-955f-c6694194e8df,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-ea6e19de-e21a-4257-aca0-ebf2eaee5e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-0768b763-e2d6-411c-ba10-05c23245455a,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-25a75c91-1e01-4c32-8dfc-5bd637d84374,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-fbf20599-2d7c-4b44-95e6-1ece24fd6c30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511559865-172.17.0.18-1597171083484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36627,DS-bb137f37-1e82-44bf-afc2-5e32d8e013a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-6bd506d9-3ecc-478a-beb9-84437dc5678a,DISK], DatanodeInfoWithStorage[127.0.0.1:37261,DS-ebdbd8d0-5e79-4624-95bf-1fc10c3bafd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-3c835b68-b83d-4c32-955f-c6694194e8df,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-ea6e19de-e21a-4257-aca0-ebf2eaee5e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-0768b763-e2d6-411c-ba10-05c23245455a,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-25a75c91-1e01-4c32-8dfc-5bd637d84374,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-fbf20599-2d7c-4b44-95e6-1ece24fd6c30,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855050329-172.17.0.18-1597171160933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-4e2470fc-030e-42da-beae-b66c711b2d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-49b695af-0459-41f3-b69d-da883e9810c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-5a42e58d-657e-4baf-a692-cb278e22bf60,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-66266caa-c2d6-4073-a4ce-5673a99f8a51,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-5a6388b4-0439-4e2e-8f51-a2867d4b7b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-da353e88-a6e3-433c-8db4-5c6a51e0bbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-aebafdbb-f5ed-4495-a394-b343d3c5cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-c9b4c274-e93d-48e8-87a3-e6b82701cbdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855050329-172.17.0.18-1597171160933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35482,DS-4e2470fc-030e-42da-beae-b66c711b2d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-49b695af-0459-41f3-b69d-da883e9810c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-5a42e58d-657e-4baf-a692-cb278e22bf60,DISK], DatanodeInfoWithStorage[127.0.0.1:37815,DS-66266caa-c2d6-4073-a4ce-5673a99f8a51,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-5a6388b4-0439-4e2e-8f51-a2867d4b7b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-da353e88-a6e3-433c-8db4-5c6a51e0bbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-aebafdbb-f5ed-4495-a394-b343d3c5cbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-c9b4c274-e93d-48e8-87a3-e6b82701cbdb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131953844-172.17.0.18-1597171227686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36150,DS-9788c444-36e1-420c-98a9-cc602257aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-4e078da7-4fca-4adb-99de-274dc54b31b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-e419e4b4-62cb-4795-9f53-c306ff138648,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-e9c9b93c-96a4-4d8e-a048-708beb179931,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-a5bad175-fdd7-40d0-bab2-21eb9a10b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-3a5ea002-9b05-4dcb-83cb-e89fa7aa05f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-4acd688d-af80-4c7c-b53d-099582f53c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-d216a201-b6aa-4852-b5ad-5be99cd3f390,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131953844-172.17.0.18-1597171227686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36150,DS-9788c444-36e1-420c-98a9-cc602257aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-4e078da7-4fca-4adb-99de-274dc54b31b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-e419e4b4-62cb-4795-9f53-c306ff138648,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-e9c9b93c-96a4-4d8e-a048-708beb179931,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-a5bad175-fdd7-40d0-bab2-21eb9a10b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-3a5ea002-9b05-4dcb-83cb-e89fa7aa05f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-4acd688d-af80-4c7c-b53d-099582f53c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-d216a201-b6aa-4852-b5ad-5be99cd3f390,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115787931-172.17.0.18-1597171774505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37217,DS-784a2c41-a708-499b-b4ec-4533c2f212ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-58da8e57-2e54-45dd-873d-177d460fcfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-3e4b63a7-e98d-4ed9-8f0e-04cd63482112,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-b64267e0-7b28-4d59-924c-6d632ef1a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-c4575520-ba05-4adb-88b8-9aeef95384d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-4e92053a-88e1-4586-a2d1-6dd284f99bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-64ffeab1-545a-44fc-b07d-7ee188a79d05,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-1fe0ab1b-516a-449b-b4a6-3cdbd8c7eda5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115787931-172.17.0.18-1597171774505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37217,DS-784a2c41-a708-499b-b4ec-4533c2f212ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-58da8e57-2e54-45dd-873d-177d460fcfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-3e4b63a7-e98d-4ed9-8f0e-04cd63482112,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-b64267e0-7b28-4d59-924c-6d632ef1a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-c4575520-ba05-4adb-88b8-9aeef95384d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-4e92053a-88e1-4586-a2d1-6dd284f99bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:41444,DS-64ffeab1-545a-44fc-b07d-7ee188a79d05,DISK], DatanodeInfoWithStorage[127.0.0.1:35709,DS-1fe0ab1b-516a-449b-b4a6-3cdbd8c7eda5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809971425-172.17.0.18-1597171852696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39938,DS-b487cf01-3e15-4dbe-8937-0f7f99971bba,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-c5578428-34bc-4537-a9f8-d57d755992d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-54e5fe22-adce-4139-899a-ea26a7805787,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-6553eba7-ff7c-4fac-a421-bc85385bd082,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-2ba7b213-0af0-46b0-8e70-0d9cb9916a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-385fb2dc-468e-49c1-a921-5c1ad3414fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-f51888a1-445e-4089-a909-55994dfe44d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-3ac64d56-3875-47a8-abc6-a25cf3e93ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809971425-172.17.0.18-1597171852696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39938,DS-b487cf01-3e15-4dbe-8937-0f7f99971bba,DISK], DatanodeInfoWithStorage[127.0.0.1:46637,DS-c5578428-34bc-4537-a9f8-d57d755992d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-54e5fe22-adce-4139-899a-ea26a7805787,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-6553eba7-ff7c-4fac-a421-bc85385bd082,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-2ba7b213-0af0-46b0-8e70-0d9cb9916a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-385fb2dc-468e-49c1-a921-5c1ad3414fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-f51888a1-445e-4089-a909-55994dfe44d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-3ac64d56-3875-47a8-abc6-a25cf3e93ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688226214-172.17.0.18-1597171888675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44030,DS-90133ff4-dbc3-4254-bf78-31634e494ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-90a56321-b155-43ab-9117-8c622a32a790,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-ff74fd68-1570-41db-9830-ba3f65eb18c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-cc48e35a-2226-4c95-be07-e8cb2ca5f491,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-1be16c84-80ec-41eb-9bb8-b927f8fddf19,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-d3fefe47-4759-4d24-b9f8-585ff529aacb,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-94d86f91-3c33-4c2c-aaa5-696b95237ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-5fcf53e2-b181-4baa-8a0a-9ee73bb194ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688226214-172.17.0.18-1597171888675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44030,DS-90133ff4-dbc3-4254-bf78-31634e494ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-90a56321-b155-43ab-9117-8c622a32a790,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-ff74fd68-1570-41db-9830-ba3f65eb18c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-cc48e35a-2226-4c95-be07-e8cb2ca5f491,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-1be16c84-80ec-41eb-9bb8-b927f8fddf19,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-d3fefe47-4759-4d24-b9f8-585ff529aacb,DISK], DatanodeInfoWithStorage[127.0.0.1:33260,DS-94d86f91-3c33-4c2c-aaa5-696b95237ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-5fcf53e2-b181-4baa-8a0a-9ee73bb194ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176285705-172.17.0.18-1597171965813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40605,DS-61ab5396-bbba-4664-aca4-67ac5c423725,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-e5d67409-28f2-488f-9eb8-4f242ba06094,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f3bb87ec-b26a-4b64-b1c5-834f9b43a4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-8a5693a1-dfcd-47a6-8e63-e188190b6b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-9d05a6af-8528-402d-ab57-02b3693699a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-7c13976a-ab72-4890-8930-fdaf4b41e7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-2ce5056f-6f85-4e17-a798-0077169cc36f,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-a397c392-2f34-4670-9b4f-ff2bb4a28627,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-176285705-172.17.0.18-1597171965813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40605,DS-61ab5396-bbba-4664-aca4-67ac5c423725,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-e5d67409-28f2-488f-9eb8-4f242ba06094,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-f3bb87ec-b26a-4b64-b1c5-834f9b43a4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-8a5693a1-dfcd-47a6-8e63-e188190b6b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-9d05a6af-8528-402d-ab57-02b3693699a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-7c13976a-ab72-4890-8930-fdaf4b41e7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-2ce5056f-6f85-4e17-a798-0077169cc36f,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-a397c392-2f34-4670-9b4f-ff2bb4a28627,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754816010-172.17.0.18-1597172079778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46492,DS-22a95db1-fc5b-4187-8f41-1e6fba2d7683,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-132c0e90-3f4d-4406-97f0-a9e8f5805648,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-ce09e372-ee42-4c0e-a4cc-bc27da4827a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-ded0fdb6-2b1b-494e-8626-a4852dbd17dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-68e01099-ea4a-4b9f-8a40-288760864191,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-c45769ea-f6e0-4378-a1d0-a9fdfa1a0a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-adf9a845-aea5-44d6-a409-c5d973708a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-4206a5e5-3831-478b-8191-9e236d28d96b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754816010-172.17.0.18-1597172079778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46492,DS-22a95db1-fc5b-4187-8f41-1e6fba2d7683,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-132c0e90-3f4d-4406-97f0-a9e8f5805648,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-ce09e372-ee42-4c0e-a4cc-bc27da4827a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-ded0fdb6-2b1b-494e-8626-a4852dbd17dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-68e01099-ea4a-4b9f-8a40-288760864191,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-c45769ea-f6e0-4378-a1d0-a9fdfa1a0a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-adf9a845-aea5-44d6-a409-c5d973708a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-4206a5e5-3831-478b-8191-9e236d28d96b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483032563-172.17.0.18-1597172206645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-071ace7d-d029-4975-b2d9-ffcdf898e88e,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-c60bc9b0-d6d7-4485-bc39-967ac3eac56d,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-9faabfcc-7a5d-4acb-9381-f233413a3c94,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-4d692a88-746e-4f23-9ef8-78a160cddfef,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-91f830da-eb27-4414-b7f0-4ea0f5eaa163,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-7d6b50f5-fd22-403f-99c0-d34cc7aa0667,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-cc5d2938-ca57-440c-99d2-1dd5daa64387,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-9ccf4536-2400-407a-aa36-4ba9e5f33edf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483032563-172.17.0.18-1597172206645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-071ace7d-d029-4975-b2d9-ffcdf898e88e,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-c60bc9b0-d6d7-4485-bc39-967ac3eac56d,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-9faabfcc-7a5d-4acb-9381-f233413a3c94,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-4d692a88-746e-4f23-9ef8-78a160cddfef,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-91f830da-eb27-4414-b7f0-4ea0f5eaa163,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-7d6b50f5-fd22-403f-99c0-d34cc7aa0667,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-cc5d2938-ca57-440c-99d2-1dd5daa64387,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-9ccf4536-2400-407a-aa36-4ba9e5f33edf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119069719-172.17.0.18-1597172468099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-b491444d-2bef-40d7-9103-0c967e192e85,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-eea51302-b396-4a3f-aeaa-172a4be42b17,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-e8000809-c896-47bb-8780-2ab3cd6df774,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-7f249107-bf02-4847-8d8c-dfb1a4f2bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-25fd9cd5-5e70-4594-8a7f-bd6fb0412ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-112f6b36-3eeb-4155-a208-cec89a9d9530,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-cce52332-90a0-4694-8fc7-0aaf139e7e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-0592a46c-d8ff-4108-9a66-951360862e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2119069719-172.17.0.18-1597172468099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39181,DS-b491444d-2bef-40d7-9103-0c967e192e85,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-eea51302-b396-4a3f-aeaa-172a4be42b17,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-e8000809-c896-47bb-8780-2ab3cd6df774,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-7f249107-bf02-4847-8d8c-dfb1a4f2bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-25fd9cd5-5e70-4594-8a7f-bd6fb0412ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33238,DS-112f6b36-3eeb-4155-a208-cec89a9d9530,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-cce52332-90a0-4694-8fc7-0aaf139e7e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-0592a46c-d8ff-4108-9a66-951360862e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309761375-172.17.0.18-1597172512317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-d6da1ffa-f13e-46df-8263-e578cbb0255b,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-5fdf8f98-1662-40ad-8024-21bfe0578515,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-b5d903f6-e5fa-4fdb-aa14-f302909f74bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-9720cdad-c1e7-4439-b4ce-5a3fc3b379b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-d6c41c77-f11a-4a5e-bb0b-cc77574c7e34,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-1bc33502-0343-46e1-b40c-8adcd2004e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-1a0c3748-8525-453a-9472-56befe4a8673,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-78da1f81-b319-4cb7-adba-43a5f6d6fa88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309761375-172.17.0.18-1597172512317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-d6da1ffa-f13e-46df-8263-e578cbb0255b,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-5fdf8f98-1662-40ad-8024-21bfe0578515,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-b5d903f6-e5fa-4fdb-aa14-f302909f74bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-9720cdad-c1e7-4439-b4ce-5a3fc3b379b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-d6c41c77-f11a-4a5e-bb0b-cc77574c7e34,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-1bc33502-0343-46e1-b40c-8adcd2004e84,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-1a0c3748-8525-453a-9472-56befe4a8673,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-78da1f81-b319-4cb7-adba-43a5f6d6fa88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461330780-172.17.0.18-1597172558084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-39854a40-540f-4e1b-b19a-6aae51a3c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-18552efd-d2ad-488f-b2f4-ee9f14b4ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-e2120cc5-25ab-4585-9fd6-dd2c96d70dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-52e0a674-94c3-4d8e-bc9b-0283287c4fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-3f85d534-bf52-4216-94dc-3eb160b78f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-f37cbd37-2c4b-4889-a44b-d5b7f5d0e103,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-4be03911-ef32-4ef6-89ff-8c3ac674116f,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-1d8c7074-00d4-4e60-a73b-5ceba34d9557,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461330780-172.17.0.18-1597172558084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46618,DS-39854a40-540f-4e1b-b19a-6aae51a3c4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-18552efd-d2ad-488f-b2f4-ee9f14b4ce99,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-e2120cc5-25ab-4585-9fd6-dd2c96d70dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-52e0a674-94c3-4d8e-bc9b-0283287c4fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-3f85d534-bf52-4216-94dc-3eb160b78f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-f37cbd37-2c4b-4889-a44b-d5b7f5d0e103,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-4be03911-ef32-4ef6-89ff-8c3ac674116f,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-1d8c7074-00d4-4e60-a73b-5ceba34d9557,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082964391-172.17.0.18-1597172755476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44446,DS-d693d619-2f1c-4abe-ab94-f918e976f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-3d5e0f0a-4535-498b-b3bd-e104be9dfc59,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-d1c7332d-eb25-4e9e-b462-1d03480f42d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-3dd40f78-4f75-4317-96fd-0e8801615c48,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-88620e55-ad47-4b3c-b2e1-9c90069ad0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-df4091c7-7242-4112-81ad-3d5b239d4eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-daa3940c-34bd-46cb-80ce-73c77dd4d749,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-7bb693bf-e2ce-4a17-8c45-c13796b1c83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082964391-172.17.0.18-1597172755476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44446,DS-d693d619-2f1c-4abe-ab94-f918e976f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-3d5e0f0a-4535-498b-b3bd-e104be9dfc59,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-d1c7332d-eb25-4e9e-b462-1d03480f42d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-3dd40f78-4f75-4317-96fd-0e8801615c48,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-88620e55-ad47-4b3c-b2e1-9c90069ad0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-df4091c7-7242-4112-81ad-3d5b239d4eea,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-daa3940c-34bd-46cb-80ce-73c77dd4d749,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-7bb693bf-e2ce-4a17-8c45-c13796b1c83d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697333072-172.17.0.18-1597172996338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-b806d5ec-d7a2-4635-b4ac-af48b7c14fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-63fc97ef-4a6d-4c57-a931-a61b76495efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-7ba99177-ceae-4bf3-8190-51b00eda5f83,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-e264085e-844d-4f10-be8d-8abcc8ab08bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-c72e0f82-ba18-43a6-a660-e8eb199639b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-607531ff-8fe5-46e3-8c37-9253fd38161d,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-daafb507-e4f0-4824-a550-ad4ac86c6b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-5a06d4ae-f504-420e-8fd1-bafa768d2141,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697333072-172.17.0.18-1597172996338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-b806d5ec-d7a2-4635-b4ac-af48b7c14fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33612,DS-63fc97ef-4a6d-4c57-a931-a61b76495efd,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-7ba99177-ceae-4bf3-8190-51b00eda5f83,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-e264085e-844d-4f10-be8d-8abcc8ab08bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-c72e0f82-ba18-43a6-a660-e8eb199639b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-607531ff-8fe5-46e3-8c37-9253fd38161d,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-daafb507-e4f0-4824-a550-ad4ac86c6b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-5a06d4ae-f504-420e-8fd1-bafa768d2141,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122189486-172.17.0.18-1597173026406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36600,DS-ed91c020-58e1-4114-99a7-8e84f3e2f355,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-c4a34f0c-ecce-4c41-8e25-644de1e45654,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-baa489d6-a4c9-4aa6-90c4-c3025c65d3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-30d4f154-e907-4a3b-b866-1a2f14ee5a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-dbc53711-49c6-4059-b3ea-eb1ef6763ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-b0da610c-06e4-4e66-a195-efc3566ac1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-f12e70e8-7586-4d40-b81e-f434e6f4eeee,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-f66ed777-0481-4f73-810c-f4c0f688bf87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-122189486-172.17.0.18-1597173026406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36600,DS-ed91c020-58e1-4114-99a7-8e84f3e2f355,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-c4a34f0c-ecce-4c41-8e25-644de1e45654,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-baa489d6-a4c9-4aa6-90c4-c3025c65d3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-30d4f154-e907-4a3b-b866-1a2f14ee5a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-dbc53711-49c6-4059-b3ea-eb1ef6763ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-b0da610c-06e4-4e66-a195-efc3566ac1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36995,DS-f12e70e8-7586-4d40-b81e-f434e6f4eeee,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-f66ed777-0481-4f73-810c-f4c0f688bf87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110571124-172.17.0.18-1597173094271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33131,DS-5d09dad8-c9bc-4873-a4f7-d94da5441e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-6c453e0d-4564-464f-9057-37a7bb0dab20,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-319c6787-294b-40ba-b9e6-b27aaf661280,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-b7d2393e-ad01-484f-8cbc-3de9fcfb482f,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-680d9dfb-44a5-4126-9522-11726c78b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-6b4fa38e-f5fd-4024-9f49-035ec4d43504,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-3e0f6694-74c5-4bfb-8db2-c024af28bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-eecef553-d5a9-404c-a3b3-15c381ebaea4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110571124-172.17.0.18-1597173094271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33131,DS-5d09dad8-c9bc-4873-a4f7-d94da5441e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-6c453e0d-4564-464f-9057-37a7bb0dab20,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-319c6787-294b-40ba-b9e6-b27aaf661280,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-b7d2393e-ad01-484f-8cbc-3de9fcfb482f,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-680d9dfb-44a5-4126-9522-11726c78b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-6b4fa38e-f5fd-4024-9f49-035ec4d43504,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-3e0f6694-74c5-4bfb-8db2-c024af28bf55,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-eecef553-d5a9-404c-a3b3-15c381ebaea4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505115665-172.17.0.18-1597173226682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-1f45cbf9-5745-420a-8f8b-c7ab1435b802,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-fbd2be0e-1f17-4a49-b317-0e7e9fe1e4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-410ee380-bf86-404b-9da4-1afe57426a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-eb76c0fc-d9bf-4824-ad86-a5f155c25468,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-9cd8985f-7889-44f1-892d-18183846f368,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-7c31a0b7-1344-4fb0-9715-1ed8d0ea0b84,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-3881a3a1-d8d0-4b9d-b68a-148b330bc4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-ea2916ca-8f7a-48e1-8d6f-cb9d5a98d91f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505115665-172.17.0.18-1597173226682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43374,DS-1f45cbf9-5745-420a-8f8b-c7ab1435b802,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-fbd2be0e-1f17-4a49-b317-0e7e9fe1e4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-410ee380-bf86-404b-9da4-1afe57426a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-eb76c0fc-d9bf-4824-ad86-a5f155c25468,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-9cd8985f-7889-44f1-892d-18183846f368,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-7c31a0b7-1344-4fb0-9715-1ed8d0ea0b84,DISK], DatanodeInfoWithStorage[127.0.0.1:39335,DS-3881a3a1-d8d0-4b9d-b68a-148b330bc4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-ea2916ca-8f7a-48e1-8d6f-cb9d5a98d91f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364710746-172.17.0.18-1597173552116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36603,DS-f3d32eb6-7ba4-4329-af9c-6ea88e54fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-d8d859e9-c14d-4d63-8993-00c940f5dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-53be16be-89ad-49d6-916f-574929181818,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-59beccdb-1703-48d5-a3d8-c6201c286f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-a3744554-082f-4750-a1e0-e13cc0a2a4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-d560f451-c0b1-416b-871b-3b96f013a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-a78b98a7-29c8-48c5-9061-e0bf9f2f382d,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-fa058835-bf5d-4ba0-8a64-3a8b190dec87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364710746-172.17.0.18-1597173552116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36603,DS-f3d32eb6-7ba4-4329-af9c-6ea88e54fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-d8d859e9-c14d-4d63-8993-00c940f5dda6,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-53be16be-89ad-49d6-916f-574929181818,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-59beccdb-1703-48d5-a3d8-c6201c286f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-a3744554-082f-4750-a1e0-e13cc0a2a4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37530,DS-d560f451-c0b1-416b-871b-3b96f013a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-a78b98a7-29c8-48c5-9061-e0bf9f2f382d,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-fa058835-bf5d-4ba0-8a64-3a8b190dec87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610626490-172.17.0.18-1597173607481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40956,DS-993321fc-f06b-42d1-9fcb-2ea222821cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-d7fc6d91-0a09-401c-819c-7f2bae39ace7,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-615192c5-f871-4210-a4d5-71b7f3112ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-9e27ab34-781b-493d-8317-a7972d34c434,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-bd355fa9-6773-4d3c-aa9c-df1ca9793a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-3c2b88e4-cd45-489d-8c92-7030de4ebf29,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-cb75e640-6cf9-4232-9251-24d6b493afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-c739d56c-be1b-49e4-aea0-b556cff7a369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610626490-172.17.0.18-1597173607481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40956,DS-993321fc-f06b-42d1-9fcb-2ea222821cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-d7fc6d91-0a09-401c-819c-7f2bae39ace7,DISK], DatanodeInfoWithStorage[127.0.0.1:40456,DS-615192c5-f871-4210-a4d5-71b7f3112ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-9e27ab34-781b-493d-8317-a7972d34c434,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-bd355fa9-6773-4d3c-aa9c-df1ca9793a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-3c2b88e4-cd45-489d-8c92-7030de4ebf29,DISK], DatanodeInfoWithStorage[127.0.0.1:42659,DS-cb75e640-6cf9-4232-9251-24d6b493afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-c739d56c-be1b-49e4-aea0-b556cff7a369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417735058-172.17.0.18-1597173901708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43729,DS-dc9317d3-62a3-4241-90cb-b654cf022409,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-36551868-e8b6-4fcf-bd52-64cd9884603f,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-7136a2b0-4172-43a8-a6b7-e05d6f2beb46,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-f73c1379-0c9c-4e32-a200-38014c9de77b,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-ea7b702d-1398-4b36-930e-cdba50846488,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-ee607b0f-1591-4a66-91fc-17476e301b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-caa9fabe-2f78-4fe4-bf85-eaf92f985cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-a15ad9f0-f90f-4020-820c-9a356bbffa5b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417735058-172.17.0.18-1597173901708:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43729,DS-dc9317d3-62a3-4241-90cb-b654cf022409,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-36551868-e8b6-4fcf-bd52-64cd9884603f,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-7136a2b0-4172-43a8-a6b7-e05d6f2beb46,DISK], DatanodeInfoWithStorage[127.0.0.1:33435,DS-f73c1379-0c9c-4e32-a200-38014c9de77b,DISK], DatanodeInfoWithStorage[127.0.0.1:44228,DS-ea7b702d-1398-4b36-930e-cdba50846488,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-ee607b0f-1591-4a66-91fc-17476e301b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-caa9fabe-2f78-4fe4-bf85-eaf92f985cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-a15ad9f0-f90f-4020-820c-9a356bbffa5b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915993852-172.17.0.18-1597173937820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-3e1c5535-71c9-4adf-807d-0698eeeb5461,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-8168f81f-7d48-4528-a418-48c079071602,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-38549e49-f4d3-42e3-953c-7671a4ed4365,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-b4d1eca3-9ccb-44a2-959c-cbe91e640302,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-7a544aa1-2eef-4a78-820b-79eac86c160b,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-91280479-6d4a-44f3-9175-94fb0dddfb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-dd7286f5-5181-4366-a8d3-c9567e77dd56,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-637ea093-6dc6-4498-930b-3fb75e637de8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915993852-172.17.0.18-1597173937820:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45175,DS-3e1c5535-71c9-4adf-807d-0698eeeb5461,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-8168f81f-7d48-4528-a418-48c079071602,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-38549e49-f4d3-42e3-953c-7671a4ed4365,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-b4d1eca3-9ccb-44a2-959c-cbe91e640302,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-7a544aa1-2eef-4a78-820b-79eac86c160b,DISK], DatanodeInfoWithStorage[127.0.0.1:35511,DS-91280479-6d4a-44f3-9175-94fb0dddfb4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-dd7286f5-5181-4366-a8d3-c9567e77dd56,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-637ea093-6dc6-4498-930b-3fb75e637de8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284321770-172.17.0.18-1597174015553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-cf019ab3-13d6-46d7-8140-60c8461a4118,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-14d911bd-d205-42d7-858a-564ff1238a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-c2eca004-b086-4651-91f8-e8e72fef4cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-f026f87c-6626-4ac1-a2d3-f409b657d8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-f3270399-beb2-4a3a-bc2b-3bbb54c54ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-f541bc95-0ea2-4ab5-9fcc-625b94751da7,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-0caf22cd-1e2b-4eb5-9859-f1e64d08c9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-5392499f-eda3-407d-92d5-6ba75e68995e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-284321770-172.17.0.18-1597174015553:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38468,DS-cf019ab3-13d6-46d7-8140-60c8461a4118,DISK], DatanodeInfoWithStorage[127.0.0.1:43482,DS-14d911bd-d205-42d7-858a-564ff1238a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-c2eca004-b086-4651-91f8-e8e72fef4cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37327,DS-f026f87c-6626-4ac1-a2d3-f409b657d8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-f3270399-beb2-4a3a-bc2b-3bbb54c54ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-f541bc95-0ea2-4ab5-9fcc-625b94751da7,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-0caf22cd-1e2b-4eb5-9859-f1e64d08c9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-5392499f-eda3-407d-92d5-6ba75e68995e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626835673-172.17.0.18-1597174126499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-206a0114-344c-422f-a6fb-2245ce4cff48,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-1a51b3b1-3b4a-4e06-b9bf-e825c1d458a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-99a7ccbf-3527-44b3-b2f3-c3f562c8d8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-f1a02ef2-d732-4356-91d3-689235da0d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-baf5769e-122a-431c-9db0-7bbb121104b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-b8d627fb-50bc-4422-b06c-4e84aa97f15c,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-ff8f7ff4-8fc3-4868-9cff-c87eee4c60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-8fec19db-9ffc-438e-bfdf-e8294ab6a728,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626835673-172.17.0.18-1597174126499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-206a0114-344c-422f-a6fb-2245ce4cff48,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-1a51b3b1-3b4a-4e06-b9bf-e825c1d458a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-99a7ccbf-3527-44b3-b2f3-c3f562c8d8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37362,DS-f1a02ef2-d732-4356-91d3-689235da0d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-baf5769e-122a-431c-9db0-7bbb121104b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42384,DS-b8d627fb-50bc-4422-b06c-4e84aa97f15c,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-ff8f7ff4-8fc3-4868-9cff-c87eee4c60ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-8fec19db-9ffc-438e-bfdf-e8294ab6a728,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797743322-172.17.0.18-1597174162698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46786,DS-a6748ea7-df10-41fa-a64d-f4f75d0df24d,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-398ee55d-eb61-43f8-836e-303d2069ae5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-844d81cf-1ec9-4ac6-b189-7d0e7340e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-980b53ae-9786-4dcf-b6a5-4413a5257397,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-8ae1133a-dadc-483a-8821-c0a584600676,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-e3b8ad69-5010-4dc5-9dc3-2f1a1e0034b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-d67f0541-e5ae-4d14-9a93-dfcad795b10a,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-fb9af36a-d16f-4c39-8607-b841cc295da3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797743322-172.17.0.18-1597174162698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46786,DS-a6748ea7-df10-41fa-a64d-f4f75d0df24d,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-398ee55d-eb61-43f8-836e-303d2069ae5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-844d81cf-1ec9-4ac6-b189-7d0e7340e02d,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-980b53ae-9786-4dcf-b6a5-4413a5257397,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-8ae1133a-dadc-483a-8821-c0a584600676,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-e3b8ad69-5010-4dc5-9dc3-2f1a1e0034b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-d67f0541-e5ae-4d14-9a93-dfcad795b10a,DISK], DatanodeInfoWithStorage[127.0.0.1:36734,DS-fb9af36a-d16f-4c39-8607-b841cc295da3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5486
