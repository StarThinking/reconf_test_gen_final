reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453763036-172.17.0.6-1597074237956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-b21076ba-0ffd-4af0-beb2-156c1545eff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-8a4b8f9d-33a2-4117-a186-777adfbe6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-108f1859-84d7-45fa-b2ed-e11fce689392,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-e18f9fb6-149d-4d86-b406-123c2604a867,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-ec01f9c6-d2bd-4b71-9bf6-3cee5751ed27,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-89bddacd-49f3-4353-a9ad-78ecf1574714,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-3df40257-e7f4-4ab2-be86-77c171789447,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-1a817b8b-43ae-4e23-9ff1-ea7146ae49ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1453763036-172.17.0.6-1597074237956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33970,DS-b21076ba-0ffd-4af0-beb2-156c1545eff9,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-8a4b8f9d-33a2-4117-a186-777adfbe6eac,DISK], DatanodeInfoWithStorage[127.0.0.1:33916,DS-108f1859-84d7-45fa-b2ed-e11fce689392,DISK], DatanodeInfoWithStorage[127.0.0.1:41703,DS-e18f9fb6-149d-4d86-b406-123c2604a867,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-ec01f9c6-d2bd-4b71-9bf6-3cee5751ed27,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-89bddacd-49f3-4353-a9ad-78ecf1574714,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-3df40257-e7f4-4ab2-be86-77c171789447,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-1a817b8b-43ae-4e23-9ff1-ea7146ae49ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348759869-172.17.0.6-1597075260626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40621,DS-4553bfd0-90d3-4fd6-90ef-6ab98cff0f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-f47a488b-ad36-4cdd-9b5e-72c2b7c443eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-d07cf339-2e27-44a3-a31e-1c00282bdaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-636427be-e985-4c82-930e-250959f89a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-c8254fb8-c6d1-4b92-aa7f-15681ff45244,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-e3a5f7de-30fd-42a9-92ff-83d09148182e,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-576bfbc0-f8b2-4e39-a160-a89f50be220d,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-f9257d2c-9445-4826-ae51-704fa3e960d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348759869-172.17.0.6-1597075260626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40621,DS-4553bfd0-90d3-4fd6-90ef-6ab98cff0f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-f47a488b-ad36-4cdd-9b5e-72c2b7c443eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37136,DS-d07cf339-2e27-44a3-a31e-1c00282bdaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-636427be-e985-4c82-930e-250959f89a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-c8254fb8-c6d1-4b92-aa7f-15681ff45244,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-e3a5f7de-30fd-42a9-92ff-83d09148182e,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-576bfbc0-f8b2-4e39-a160-a89f50be220d,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-f9257d2c-9445-4826-ae51-704fa3e960d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268459320-172.17.0.6-1597075813925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37711,DS-d3b86af5-8cbb-4cc9-9088-c93460a5e760,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-f28bdcab-5cb6-4442-a2bd-ccf3732f6dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-2da5e066-25cd-4907-b5cb-c6d0bf1be51d,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-50862f9e-6f86-49ca-a6be-a16689577b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-073a8644-74d6-4552-98c3-588027f7fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-955eb72e-187c-4d3d-9e1d-74f9b344952a,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-7df65a45-363c-40dc-a539-9531507a8cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-580547f0-03ae-4c6e-8e71-f8c9a7e5504d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268459320-172.17.0.6-1597075813925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37711,DS-d3b86af5-8cbb-4cc9-9088-c93460a5e760,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-f28bdcab-5cb6-4442-a2bd-ccf3732f6dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-2da5e066-25cd-4907-b5cb-c6d0bf1be51d,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-50862f9e-6f86-49ca-a6be-a16689577b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-073a8644-74d6-4552-98c3-588027f7fceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-955eb72e-187c-4d3d-9e1d-74f9b344952a,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-7df65a45-363c-40dc-a539-9531507a8cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-580547f0-03ae-4c6e-8e71-f8c9a7e5504d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389454951-172.17.0.6-1597076029798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-ce949cb9-5ceb-4332-843e-f65a51f9a15c,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-39563d06-62cb-44a7-a629-fbfb2d546265,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-27d5b76e-57da-4eda-b386-42299e8ae818,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-3ccdcca9-ca3a-40cc-81af-148ec84f304a,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-faa0c0c4-085a-445d-96e9-f6457147e049,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-ea75cacd-db80-4899-b6bd-00b12208a445,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-2791c3cc-0107-498b-b7e8-55ec57cd5a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-32ded361-fce8-421c-bf1f-70c47f7c381d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389454951-172.17.0.6-1597076029798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41853,DS-ce949cb9-5ceb-4332-843e-f65a51f9a15c,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-39563d06-62cb-44a7-a629-fbfb2d546265,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-27d5b76e-57da-4eda-b386-42299e8ae818,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-3ccdcca9-ca3a-40cc-81af-148ec84f304a,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-faa0c0c4-085a-445d-96e9-f6457147e049,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-ea75cacd-db80-4899-b6bd-00b12208a445,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-2791c3cc-0107-498b-b7e8-55ec57cd5a55,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-32ded361-fce8-421c-bf1f-70c47f7c381d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938256067-172.17.0.6-1597076592761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-89093412-3804-444b-91b6-8a76ad31b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-00e518d8-c3c4-4e61-8bda-4c9b9ce62ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-7806cf68-3e73-4290-a800-41b49841ad09,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-989920cb-79eb-4463-91c1-2bf7c7972cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-652dea2a-8f48-4d1c-94b2-4ad36319ae76,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-ce3b91df-55de-4530-ad04-a38f14508f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-6b869075-bd73-4672-b03b-ab8283ee9d11,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-2494f53f-19e9-4acb-bd59-553f0c839c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-938256067-172.17.0.6-1597076592761:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-89093412-3804-444b-91b6-8a76ad31b6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-00e518d8-c3c4-4e61-8bda-4c9b9ce62ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-7806cf68-3e73-4290-a800-41b49841ad09,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-989920cb-79eb-4463-91c1-2bf7c7972cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-652dea2a-8f48-4d1c-94b2-4ad36319ae76,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-ce3b91df-55de-4530-ad04-a38f14508f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-6b869075-bd73-4672-b03b-ab8283ee9d11,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-2494f53f-19e9-4acb-bd59-553f0c839c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428413857-172.17.0.6-1597076889819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-a960c96a-e50c-462d-9ebe-06b143928cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-4a32d4db-8314-44d3-affd-61500ac95f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-0dbeffe4-8b9f-4eab-9fd0-0637277bda13,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-70ff3a39-67cc-44f9-8bb4-e6fa152d9219,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-19696d11-670d-4e37-8059-3004454a12bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-6f2cbff4-514f-42a1-8ac2-e5978d3166e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-df31ef35-e212-424f-bdb9-c6c126c47574,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-207a6076-27ba-4850-9665-54250cad346a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-428413857-172.17.0.6-1597076889819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42043,DS-a960c96a-e50c-462d-9ebe-06b143928cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-4a32d4db-8314-44d3-affd-61500ac95f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-0dbeffe4-8b9f-4eab-9fd0-0637277bda13,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-70ff3a39-67cc-44f9-8bb4-e6fa152d9219,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-19696d11-670d-4e37-8059-3004454a12bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-6f2cbff4-514f-42a1-8ac2-e5978d3166e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-df31ef35-e212-424f-bdb9-c6c126c47574,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-207a6076-27ba-4850-9665-54250cad346a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337605136-172.17.0.6-1597076931637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39178,DS-61fbf80e-cd15-4da6-b693-194290a44b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-f5e9d611-f8a1-4fa8-a5fb-047fadc0cf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-73f53194-21f7-4e91-ab60-79da7dd1ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-5a3d642a-6482-4a26-84c1-c56cbcf623f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-2310e1ac-b0de-4f50-902a-9b4ddd7d6c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-7b482ecb-cfdf-4b65-a2d8-a798682745e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-17357909-20b3-4706-bcd2-31903b1bd78d,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-1c9c6713-997d-4173-892c-a0968d27075e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337605136-172.17.0.6-1597076931637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39178,DS-61fbf80e-cd15-4da6-b693-194290a44b26,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-f5e9d611-f8a1-4fa8-a5fb-047fadc0cf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-73f53194-21f7-4e91-ab60-79da7dd1ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-5a3d642a-6482-4a26-84c1-c56cbcf623f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-2310e1ac-b0de-4f50-902a-9b4ddd7d6c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-7b482ecb-cfdf-4b65-a2d8-a798682745e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-17357909-20b3-4706-bcd2-31903b1bd78d,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-1c9c6713-997d-4173-892c-a0968d27075e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311319710-172.17.0.6-1597076964891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-772023a5-c792-4354-bd3f-69f1ff48b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-b57f68eb-dc8c-4e5d-998d-5661339a512d,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-f547d229-50a5-4e96-a840-c0ba35ff8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-0e5078f5-d8f1-4b98-b3fe-604f6d643871,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-3c740c96-b90e-4bcf-80e2-91159ead25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-1e7cab24-2197-4360-a5d0-42c8bded1e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-e08c54b3-b338-4df4-bdfe-7174ed0adb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-570487fa-c1bc-4cac-a1f4-fbaaf7b0d0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311319710-172.17.0.6-1597076964891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35560,DS-772023a5-c792-4354-bd3f-69f1ff48b7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-b57f68eb-dc8c-4e5d-998d-5661339a512d,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-f547d229-50a5-4e96-a840-c0ba35ff8a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-0e5078f5-d8f1-4b98-b3fe-604f6d643871,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-3c740c96-b90e-4bcf-80e2-91159ead25c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-1e7cab24-2197-4360-a5d0-42c8bded1e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-e08c54b3-b338-4df4-bdfe-7174ed0adb8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-570487fa-c1bc-4cac-a1f4-fbaaf7b0d0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456800155-172.17.0.6-1597077148192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38441,DS-6a014ca9-7e19-4673-8a42-9bdb6d26f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-ed09ead6-b87b-4ff3-b2da-08de7f59d557,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-eb622366-d508-4db9-9732-d892742bb7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-be45d071-7303-49dd-8b7b-87f69d157c16,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-17a63109-e10b-4110-87ef-2a3960b11869,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-9f935d42-6ae5-44c2-a028-299720714f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-b16f2283-f667-4755-b2ff-ed3cd1bbd4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-da510110-c1c5-408b-acf8-0c945ea672f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456800155-172.17.0.6-1597077148192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38441,DS-6a014ca9-7e19-4673-8a42-9bdb6d26f5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-ed09ead6-b87b-4ff3-b2da-08de7f59d557,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-eb622366-d508-4db9-9732-d892742bb7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-be45d071-7303-49dd-8b7b-87f69d157c16,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-17a63109-e10b-4110-87ef-2a3960b11869,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-9f935d42-6ae5-44c2-a028-299720714f34,DISK], DatanodeInfoWithStorage[127.0.0.1:46043,DS-b16f2283-f667-4755-b2ff-ed3cd1bbd4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-da510110-c1c5-408b-acf8-0c945ea672f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731991168-172.17.0.6-1597077418295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-0bfe9431-d756-47ae-90b4-44e13be95ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-ab7bc10a-3e35-413b-bab7-05d4e6393758,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8f46702c-840e-4e7d-80a3-5d1be1d85536,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-081fdbc9-0799-486a-bbab-38e900b0f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-e62adcdd-6004-4812-a98f-8be76ae48d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-bc85bac6-4d41-46cd-8d7d-2f9e8bdf185b,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-90c9297b-c000-45e9-97b4-e0c4deb52121,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-2b2aa6ea-8931-40a7-9feb-97fa2f297a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731991168-172.17.0.6-1597077418295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43799,DS-0bfe9431-d756-47ae-90b4-44e13be95ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-ab7bc10a-3e35-413b-bab7-05d4e6393758,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-8f46702c-840e-4e7d-80a3-5d1be1d85536,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-081fdbc9-0799-486a-bbab-38e900b0f6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-e62adcdd-6004-4812-a98f-8be76ae48d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39289,DS-bc85bac6-4d41-46cd-8d7d-2f9e8bdf185b,DISK], DatanodeInfoWithStorage[127.0.0.1:45190,DS-90c9297b-c000-45e9-97b4-e0c4deb52121,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-2b2aa6ea-8931-40a7-9feb-97fa2f297a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466174939-172.17.0.6-1597077925964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33936,DS-14795b57-6259-4143-af57-0614b0b75613,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-a53e9600-1d98-424f-b202-1023ba275cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-c2c212cc-d330-4dc2-a1b6-842bed4c2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-e49463f8-1b05-42b9-85f7-9936819f88bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-154cc181-5833-40f2-a1b7-e6c58f3df8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-198f17ec-fd6b-4ad3-9adb-fedd79e76fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-613dbfe9-ccb1-48d4-932c-e329d8cdfa32,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-4bceeb5a-0bf0-4ec5-baf0-08429134b6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1466174939-172.17.0.6-1597077925964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33936,DS-14795b57-6259-4143-af57-0614b0b75613,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-a53e9600-1d98-424f-b202-1023ba275cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-c2c212cc-d330-4dc2-a1b6-842bed4c2a26,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-e49463f8-1b05-42b9-85f7-9936819f88bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-154cc181-5833-40f2-a1b7-e6c58f3df8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-198f17ec-fd6b-4ad3-9adb-fedd79e76fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-613dbfe9-ccb1-48d4-932c-e329d8cdfa32,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-4bceeb5a-0bf0-4ec5-baf0-08429134b6f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069395325-172.17.0.6-1597078445130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45232,DS-f73dd2f8-ffab-4415-a276-4ee32438b55e,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-c160c141-f54a-410b-9c44-dd36e7b6889a,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-3850c3aa-4b6a-46e4-abad-50d9939b6728,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-7d7e5325-cf18-4ae7-a33f-85f2cc0de6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-11e5ffa3-0e0c-4299-a5a0-496caed91caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-bc3c521e-48d5-4bcb-9bf6-16a9ad4e8c15,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-3e21b087-7743-4e43-8872-3b9669d53400,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-04354230-1942-42a7-a6af-2a740db373b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069395325-172.17.0.6-1597078445130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45232,DS-f73dd2f8-ffab-4415-a276-4ee32438b55e,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-c160c141-f54a-410b-9c44-dd36e7b6889a,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-3850c3aa-4b6a-46e4-abad-50d9939b6728,DISK], DatanodeInfoWithStorage[127.0.0.1:36868,DS-7d7e5325-cf18-4ae7-a33f-85f2cc0de6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-11e5ffa3-0e0c-4299-a5a0-496caed91caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-bc3c521e-48d5-4bcb-9bf6-16a9ad4e8c15,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-3e21b087-7743-4e43-8872-3b9669d53400,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-04354230-1942-42a7-a6af-2a740db373b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.connection.maxidletime
component: hdfs:DataNode
v1: 1000000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391919589-172.17.0.6-1597078853845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33911,DS-58350494-91f7-4359-b466-e04364056a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-dcd0e698-03a3-4aa3-91c0-c40adb6caee7,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-bb0dfc44-ed8e-4bb6-a34c-af54b64aaf85,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-0ac7685a-a8e9-4702-b50c-670cd689086d,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-787c867d-a0bb-4329-8d90-dd0509b168fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-3d4c1943-fb04-47cb-b077-1c3141c633a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-e3162e30-c6b1-4595-9302-73ece2fffe6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-76294518-773f-4426-a8fd-d31aa080ef22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391919589-172.17.0.6-1597078853845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33911,DS-58350494-91f7-4359-b466-e04364056a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-dcd0e698-03a3-4aa3-91c0-c40adb6caee7,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-bb0dfc44-ed8e-4bb6-a34c-af54b64aaf85,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-0ac7685a-a8e9-4702-b50c-670cd689086d,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-787c867d-a0bb-4329-8d90-dd0509b168fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-3d4c1943-fb04-47cb-b077-1c3141c633a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-e3162e30-c6b1-4595-9302-73ece2fffe6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-76294518-773f-4426-a8fd-d31aa080ef22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5275
