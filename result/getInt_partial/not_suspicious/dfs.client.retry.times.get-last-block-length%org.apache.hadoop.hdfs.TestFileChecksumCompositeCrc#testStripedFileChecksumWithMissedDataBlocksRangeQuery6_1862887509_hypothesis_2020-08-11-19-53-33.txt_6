reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098585980-172.17.0.11-1597175664928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39951,DS-d7787ded-a582-416b-8eb3-0fc4b11ab8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-8b27087f-e731-4213-a116-53c168cbc370,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-3dbdc284-7665-401c-880b-e7fd118bcbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-a940898b-a5d5-41a8-9149-30f48090052c,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-2d29d9d1-5435-4bd5-b32e-ac9d295a3f88,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-7900fe93-9dec-431a-90c6-c4eb735b9efe,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a5b3d956-63ef-4988-adec-c0e4437bf85d,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-1e319a90-fb20-4019-9d0a-b8139b4666c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2098585980-172.17.0.11-1597175664928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39951,DS-d7787ded-a582-416b-8eb3-0fc4b11ab8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-8b27087f-e731-4213-a116-53c168cbc370,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-3dbdc284-7665-401c-880b-e7fd118bcbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-a940898b-a5d5-41a8-9149-30f48090052c,DISK], DatanodeInfoWithStorage[127.0.0.1:37769,DS-2d29d9d1-5435-4bd5-b32e-ac9d295a3f88,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-7900fe93-9dec-431a-90c6-c4eb735b9efe,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-a5b3d956-63ef-4988-adec-c0e4437bf85d,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-1e319a90-fb20-4019-9d0a-b8139b4666c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52911375-172.17.0.11-1597175733201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41873,DS-f8a6460e-756c-46a8-804f-aaf6ab32d93a,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-bdcc1a0b-294b-477a-8ced-7fa8ec0c76f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-c18ff939-c024-43a9-9847-8c88d181a264,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-83d863fe-8d56-473f-b31e-b0d9a595c446,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-5e08f323-fb14-4f12-9821-9e44a1a0bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-2482f4e8-25cd-42ef-aaa2-434de5d6cf34,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-cc948317-db06-410b-9a8e-eb9d1cdc09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-2f6343ab-f75f-4d7f-8340-beb888d76fb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-52911375-172.17.0.11-1597175733201:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41873,DS-f8a6460e-756c-46a8-804f-aaf6ab32d93a,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-bdcc1a0b-294b-477a-8ced-7fa8ec0c76f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34706,DS-c18ff939-c024-43a9-9847-8c88d181a264,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-83d863fe-8d56-473f-b31e-b0d9a595c446,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-5e08f323-fb14-4f12-9821-9e44a1a0bc7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-2482f4e8-25cd-42ef-aaa2-434de5d6cf34,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-cc948317-db06-410b-9a8e-eb9d1cdc09fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-2f6343ab-f75f-4d7f-8340-beb888d76fb9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908391699-172.17.0.11-1597175939571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43589,DS-df76d6db-b70f-418a-8953-7e899fab93b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-ccaa63c4-953b-4ca4-ad35-33b772580085,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-279b2ad8-61ce-4e73-8176-86e73a5ac056,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-82cd4a24-d372-4e59-af6e-4521543f7f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-8beb42ce-8972-4381-8f12-01092a222aca,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-e298f40a-8762-4c59-a6c7-aabf7dfff287,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-ccbdaef0-1e43-403a-919a-e014f3710bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-0e965395-1b9d-4172-bd09-e950edf928e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908391699-172.17.0.11-1597175939571:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43589,DS-df76d6db-b70f-418a-8953-7e899fab93b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-ccaa63c4-953b-4ca4-ad35-33b772580085,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-279b2ad8-61ce-4e73-8176-86e73a5ac056,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-82cd4a24-d372-4e59-af6e-4521543f7f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-8beb42ce-8972-4381-8f12-01092a222aca,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-e298f40a-8762-4c59-a6c7-aabf7dfff287,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-ccbdaef0-1e43-403a-919a-e014f3710bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-0e965395-1b9d-4172-bd09-e950edf928e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109506773-172.17.0.11-1597176228890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37225,DS-c9d1846a-ffb3-4140-9d5a-a6427be2b8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-635fb682-f728-4daa-808f-75fcc0a9988f,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-81a85a0c-13ac-4656-bec4-28fce34906d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-d0ef20d4-b853-46b8-9d35-73c50c37b751,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-560bbe07-8f37-45b9-8c79-05bfa0970c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-0a35fdc1-5fa7-42d0-bcd5-a9da3a01fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-463a17f2-28a9-4bd0-b05a-a034f49c40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-b02fbbcf-7d89-4014-8954-f8a7847e0922,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109506773-172.17.0.11-1597176228890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37225,DS-c9d1846a-ffb3-4140-9d5a-a6427be2b8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42663,DS-635fb682-f728-4daa-808f-75fcc0a9988f,DISK], DatanodeInfoWithStorage[127.0.0.1:36255,DS-81a85a0c-13ac-4656-bec4-28fce34906d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-d0ef20d4-b853-46b8-9d35-73c50c37b751,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-560bbe07-8f37-45b9-8c79-05bfa0970c04,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-0a35fdc1-5fa7-42d0-bcd5-a9da3a01fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-463a17f2-28a9-4bd0-b05a-a034f49c40e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-b02fbbcf-7d89-4014-8954-f8a7847e0922,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063868476-172.17.0.11-1597176263730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-1e55c6c8-8fbe-48dd-9998-130e8c9ad49f,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-f9ae8309-8d56-4081-a5fa-9caa4ccf414d,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-68690964-ec6f-4eb2-876b-da0537c7c1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-c3c39e5f-fc75-43f8-b827-3c0177d433a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-e4676ae5-44ab-48d6-807c-745263771e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-d4fb0c30-e480-465d-8df9-83e17f0b9a73,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-c005620b-0442-4398-93a8-d20e14c382d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-299bbd7c-8c85-4f0f-9d3f-88056db4a4c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063868476-172.17.0.11-1597176263730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32951,DS-1e55c6c8-8fbe-48dd-9998-130e8c9ad49f,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-f9ae8309-8d56-4081-a5fa-9caa4ccf414d,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-68690964-ec6f-4eb2-876b-da0537c7c1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40781,DS-c3c39e5f-fc75-43f8-b827-3c0177d433a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-e4676ae5-44ab-48d6-807c-745263771e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-d4fb0c30-e480-465d-8df9-83e17f0b9a73,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-c005620b-0442-4398-93a8-d20e14c382d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-299bbd7c-8c85-4f0f-9d3f-88056db4a4c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748361461-172.17.0.11-1597176344265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-b85f0c68-f1cb-4e69-91c7-e322135e29b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-019feed1-e4bb-4c4f-9295-94060dff0e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-e2f32ec7-3a72-4205-b46b-cc9456b4478a,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-9d30c015-ec8a-44cc-8788-1afecc88f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ef358329-eb70-4599-a793-05331c3fe0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-c488f578-1f20-4b5c-a42f-e4498b1f2574,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-1bb236ee-59bd-411b-8d61-117c5b6d4c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-b05d5b60-0be6-4b55-b44f-33ec42cc5833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-748361461-172.17.0.11-1597176344265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-b85f0c68-f1cb-4e69-91c7-e322135e29b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-019feed1-e4bb-4c4f-9295-94060dff0e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-e2f32ec7-3a72-4205-b46b-cc9456b4478a,DISK], DatanodeInfoWithStorage[127.0.0.1:44322,DS-9d30c015-ec8a-44cc-8788-1afecc88f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ef358329-eb70-4599-a793-05331c3fe0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-c488f578-1f20-4b5c-a42f-e4498b1f2574,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-1bb236ee-59bd-411b-8d61-117c5b6d4c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-b05d5b60-0be6-4b55-b44f-33ec42cc5833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819001803-172.17.0.11-1597176642939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34128,DS-27a86229-2ceb-429b-8745-fe52c444ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-eca8a676-e0d4-4103-b986-46340a5524d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-829287d0-01a6-4aab-b770-bbf2a10265e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-136e21a3-ae21-4788-a3e1-292a674f3101,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-3334df40-538c-4965-b759-5bd6280e95d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-8d1bac42-b3d2-49a4-ab66-b9ab67001af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-1e39eebf-8897-464e-b534-4b4a5604132f,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-524b9fb0-0841-4601-b1e0-2c9acbbe26c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-819001803-172.17.0.11-1597176642939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34128,DS-27a86229-2ceb-429b-8745-fe52c444ea0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-eca8a676-e0d4-4103-b986-46340a5524d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-829287d0-01a6-4aab-b770-bbf2a10265e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-136e21a3-ae21-4788-a3e1-292a674f3101,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-3334df40-538c-4965-b759-5bd6280e95d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-8d1bac42-b3d2-49a4-ab66-b9ab67001af6,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-1e39eebf-8897-464e-b534-4b4a5604132f,DISK], DatanodeInfoWithStorage[127.0.0.1:46257,DS-524b9fb0-0841-4601-b1e0-2c9acbbe26c3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112206136-172.17.0.11-1597176754234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-50f64f5b-bd8b-46f1-8811-5b9abaeadd85,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-e6f7a3f3-7547-40e0-9241-cb825b792df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-41eed005-58ab-41f5-9f10-2a3042286c13,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-51cb2729-d54c-4e9b-a97f-b0bd5fe4f046,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-f9ac31ae-1cae-42b1-8587-c79dd5c8883d,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-848cc304-ef69-428f-b412-a98dc1284d48,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-7f0a0628-e0df-4436-b1de-fd89762cd884,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-74f383f7-2a24-4fd3-aae4-4213c715ccbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1112206136-172.17.0.11-1597176754234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43293,DS-50f64f5b-bd8b-46f1-8811-5b9abaeadd85,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-e6f7a3f3-7547-40e0-9241-cb825b792df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-41eed005-58ab-41f5-9f10-2a3042286c13,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-51cb2729-d54c-4e9b-a97f-b0bd5fe4f046,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-f9ac31ae-1cae-42b1-8587-c79dd5c8883d,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-848cc304-ef69-428f-b412-a98dc1284d48,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-7f0a0628-e0df-4436-b1de-fd89762cd884,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-74f383f7-2a24-4fd3-aae4-4213c715ccbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318848244-172.17.0.11-1597176868568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-93f0544e-bf2c-42d0-a03c-dfda08917050,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-3666a713-769c-4ccc-a30e-f0a6251408d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-55736880-6619-479e-818a-5060b2d5399d,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-2a80ad4a-9650-4cde-b924-a2f9b39c2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-b38cf77f-85d6-4f7f-a144-52cbebcbf88c,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-c600c038-1293-4724-9e21-6d03f1db2e32,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-c8a5dafa-7213-4689-83bb-0b23b554de05,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-37ed55f0-4ad9-477e-9a31-26b5c9834d98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318848244-172.17.0.11-1597176868568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44400,DS-93f0544e-bf2c-42d0-a03c-dfda08917050,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-3666a713-769c-4ccc-a30e-f0a6251408d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-55736880-6619-479e-818a-5060b2d5399d,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-2a80ad4a-9650-4cde-b924-a2f9b39c2ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-b38cf77f-85d6-4f7f-a144-52cbebcbf88c,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-c600c038-1293-4724-9e21-6d03f1db2e32,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-c8a5dafa-7213-4689-83bb-0b23b554de05,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-37ed55f0-4ad9-477e-9a31-26b5c9834d98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826302831-172.17.0.11-1597177050869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-caaa9ebf-3d47-4c78-b59b-99c12c050fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-c3f2062b-5d56-438e-a992-c3ae44ff1696,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-df218407-6cdd-4bb6-9aeb-7d00ae07e3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-f4f37f4f-255e-43e2-95f6-dffbed7f2191,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-ccd659c0-ca97-4804-b6fd-ed48ea65e6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-9c2f2b96-4d7b-42f1-891a-b7fcbe1dcd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-dd788c4b-2b3a-4d59-981f-38894db77f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-826e7934-c77f-44a7-a722-7ff70ae90ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826302831-172.17.0.11-1597177050869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33304,DS-caaa9ebf-3d47-4c78-b59b-99c12c050fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-c3f2062b-5d56-438e-a992-c3ae44ff1696,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-df218407-6cdd-4bb6-9aeb-7d00ae07e3d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-f4f37f4f-255e-43e2-95f6-dffbed7f2191,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-ccd659c0-ca97-4804-b6fd-ed48ea65e6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-9c2f2b96-4d7b-42f1-891a-b7fcbe1dcd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-dd788c4b-2b3a-4d59-981f-38894db77f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-826e7934-c77f-44a7-a722-7ff70ae90ef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859738283-172.17.0.11-1597177177123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36890,DS-895a191c-b6b0-489a-91ae-ef5680a141b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-97fad7f7-f928-46bd-a934-d07c5ecdf4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-1377d893-968d-41a7-94dd-06b98ef66ece,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-893dd4c8-9dea-491c-b623-b178e53a2e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-8d335b4a-6ccf-493e-a9f6-415931581393,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-a40b3171-c454-4043-8bfe-b51915b8ea8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-ef21937b-7827-47c7-a6bc-632e6052c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-45c1d2b8-0630-439f-82f4-2f91f78df151,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-859738283-172.17.0.11-1597177177123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36890,DS-895a191c-b6b0-489a-91ae-ef5680a141b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-97fad7f7-f928-46bd-a934-d07c5ecdf4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-1377d893-968d-41a7-94dd-06b98ef66ece,DISK], DatanodeInfoWithStorage[127.0.0.1:39148,DS-893dd4c8-9dea-491c-b623-b178e53a2e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-8d335b4a-6ccf-493e-a9f6-415931581393,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-a40b3171-c454-4043-8bfe-b51915b8ea8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-ef21937b-7827-47c7-a6bc-632e6052c66d,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-45c1d2b8-0630-439f-82f4-2f91f78df151,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421315498-172.17.0.11-1597177326438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-1c1469ac-b8a0-4798-ad3a-c01e13511e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-8953be01-9238-4a49-8824-e9f6e97bbe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-a8de5093-a9aa-4862-802a-9557b28f06a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-69d235bd-57b6-4092-a682-de0e181027de,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-3d4aa17d-5574-4477-ab09-8f52eb7e4719,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-6906b1aa-253b-4d77-a7f2-6a94b69cf333,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-aeaac001-4cd0-474e-9ecf-ddddf6257903,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-111cec6c-97b5-4426-8ec0-15cafa030f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421315498-172.17.0.11-1597177326438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33224,DS-1c1469ac-b8a0-4798-ad3a-c01e13511e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-8953be01-9238-4a49-8824-e9f6e97bbe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-a8de5093-a9aa-4862-802a-9557b28f06a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-69d235bd-57b6-4092-a682-de0e181027de,DISK], DatanodeInfoWithStorage[127.0.0.1:38322,DS-3d4aa17d-5574-4477-ab09-8f52eb7e4719,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-6906b1aa-253b-4d77-a7f2-6a94b69cf333,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-aeaac001-4cd0-474e-9ecf-ddddf6257903,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-111cec6c-97b5-4426-8ec0-15cafa030f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055162868-172.17.0.11-1597177440379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-aac17f38-20f3-4fc0-bbf7-d699e3ae5b29,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-1d22854c-8444-401e-906d-2dcc430a5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-fe82fa0d-5864-4a88-8a49-d118620527ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-50e08d72-0a3e-4ed4-9be6-4def51e74728,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-418c1bb6-c765-49a6-9f26-3390493bdd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-653f11db-cd1b-4f3b-8eee-bb52088d3a71,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-e90f6860-2a56-4a94-ad4f-a0a4cebfd28f,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-5fa2face-e63c-4169-ae10-3d74a5ebbf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055162868-172.17.0.11-1597177440379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36850,DS-aac17f38-20f3-4fc0-bbf7-d699e3ae5b29,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-1d22854c-8444-401e-906d-2dcc430a5ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-fe82fa0d-5864-4a88-8a49-d118620527ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33809,DS-50e08d72-0a3e-4ed4-9be6-4def51e74728,DISK], DatanodeInfoWithStorage[127.0.0.1:44352,DS-418c1bb6-c765-49a6-9f26-3390493bdd2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-653f11db-cd1b-4f3b-8eee-bb52088d3a71,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-e90f6860-2a56-4a94-ad4f-a0a4cebfd28f,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-5fa2face-e63c-4169-ae10-3d74a5ebbf58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835955900-172.17.0.11-1597177758803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-3a7b0956-da09-4be2-ac72-62f9cb208ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-147be2ef-489e-4f6a-a125-0eea8115095c,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-30b33622-1a06-473d-a5d1-e3f2b2699545,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-18041d7a-c7f1-4cb6-bd4c-365f33610b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-bc6d764a-560c-4a95-aa34-240676f71da3,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-eb3cddd6-c029-492e-8a6a-3817edbc9ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-bbcbc599-a312-46f4-867b-47e89cfb440f,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-0a5e3953-0c02-48ad-ab43-a2a011c9c780,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835955900-172.17.0.11-1597177758803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33697,DS-3a7b0956-da09-4be2-ac72-62f9cb208ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-147be2ef-489e-4f6a-a125-0eea8115095c,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-30b33622-1a06-473d-a5d1-e3f2b2699545,DISK], DatanodeInfoWithStorage[127.0.0.1:42313,DS-18041d7a-c7f1-4cb6-bd4c-365f33610b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34494,DS-bc6d764a-560c-4a95-aa34-240676f71da3,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-eb3cddd6-c029-492e-8a6a-3817edbc9ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-bbcbc599-a312-46f4-867b-47e89cfb440f,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-0a5e3953-0c02-48ad-ab43-a2a011c9c780,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115743445-172.17.0.11-1597177822839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45639,DS-6fc9bcf0-8987-48e2-b020-7cc4ea98dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-26857576-f2ba-4de1-a3e3-26de8a4ed9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-658f2b5c-af05-411d-b011-0714d5fc33c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-de00f9f7-04b9-4e4c-aa6c-fedcfab8475a,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-0c2f5ad2-0f9a-49f7-83c8-af83188a1765,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-725a64db-0e53-40fd-a0bb-010b0cfe8ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-123af93b-17d8-41cb-ab80-861f4647eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-b330ef1b-3f3e-44d9-a7de-7248daa47273,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2115743445-172.17.0.11-1597177822839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45639,DS-6fc9bcf0-8987-48e2-b020-7cc4ea98dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-26857576-f2ba-4de1-a3e3-26de8a4ed9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-658f2b5c-af05-411d-b011-0714d5fc33c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-de00f9f7-04b9-4e4c-aa6c-fedcfab8475a,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-0c2f5ad2-0f9a-49f7-83c8-af83188a1765,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-725a64db-0e53-40fd-a0bb-010b0cfe8ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:33019,DS-123af93b-17d8-41cb-ab80-861f4647eca3,DISK], DatanodeInfoWithStorage[127.0.0.1:34784,DS-b330ef1b-3f3e-44d9-a7de-7248daa47273,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489534633-172.17.0.11-1597177850452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-bd5b8d07-daa0-40d4-881a-335956775e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-8de0a8fd-659a-418e-8ca5-93f3429c40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-06b7b457-6d6b-43b8-928f-252c8008da5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-d5c159dc-c791-48b0-a642-c0df2ab256b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-113ba363-34c8-481d-8217-6b099ed28887,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-53ce0176-f604-4712-a7f3-d20e51b90471,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-32f3e47e-7e7a-42d0-b056-7cd508f1fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-f015d39f-6b3c-42d5-b7fc-f83214f56468,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489534633-172.17.0.11-1597177850452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40872,DS-bd5b8d07-daa0-40d4-881a-335956775e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-8de0a8fd-659a-418e-8ca5-93f3429c40ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-06b7b457-6d6b-43b8-928f-252c8008da5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-d5c159dc-c791-48b0-a642-c0df2ab256b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-113ba363-34c8-481d-8217-6b099ed28887,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-53ce0176-f604-4712-a7f3-d20e51b90471,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-32f3e47e-7e7a-42d0-b056-7cd508f1fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-f015d39f-6b3c-42d5-b7fc-f83214f56468,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688993266-172.17.0.11-1597178228964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40696,DS-8e63f323-85b6-4b07-b47f-2e7e7b822836,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-f504e13b-80d9-402b-b6a3-8cd2a98a3b24,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-1fce0e22-a4b5-4dcd-88ac-6adcdb4c8db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-80995dd6-2287-48f6-a3f5-7ea351cd12fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-a1b8f8f8-6ed4-4add-a645-124a3569775b,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-ae96fdb6-829b-41e6-bb82-c615d3d54765,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-d7bc230b-8fd7-4bc7-8b41-b7205b563638,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-249d6137-9f08-4da7-af2e-ed13ea96b13d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688993266-172.17.0.11-1597178228964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40696,DS-8e63f323-85b6-4b07-b47f-2e7e7b822836,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-f504e13b-80d9-402b-b6a3-8cd2a98a3b24,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-1fce0e22-a4b5-4dcd-88ac-6adcdb4c8db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-80995dd6-2287-48f6-a3f5-7ea351cd12fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-a1b8f8f8-6ed4-4add-a645-124a3569775b,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-ae96fdb6-829b-41e6-bb82-c615d3d54765,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-d7bc230b-8fd7-4bc7-8b41-b7205b563638,DISK], DatanodeInfoWithStorage[127.0.0.1:34971,DS-249d6137-9f08-4da7-af2e-ed13ea96b13d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244595990-172.17.0.11-1597178364310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35152,DS-979ca388-5d44-40d1-9a18-2b0a6e9497eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-671e9d88-7c8f-4cfc-8d52-49f966424c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-385e0820-b09f-47c1-be91-761070903a76,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-cbd57db4-2624-4a88-8d0f-0d06f52816a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-b9538e31-7ee5-4e3a-921d-67c90c126fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-5e9e3511-ec3e-4c28-9048-fb46ef7453b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-dd42b2aa-c590-4bd1-8746-19f7c128c091,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-cceb26d5-7c15-4646-b3f0-c47408bda624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244595990-172.17.0.11-1597178364310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35152,DS-979ca388-5d44-40d1-9a18-2b0a6e9497eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-671e9d88-7c8f-4cfc-8d52-49f966424c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-385e0820-b09f-47c1-be91-761070903a76,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-cbd57db4-2624-4a88-8d0f-0d06f52816a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-b9538e31-7ee5-4e3a-921d-67c90c126fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:34516,DS-5e9e3511-ec3e-4c28-9048-fb46ef7453b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-dd42b2aa-c590-4bd1-8746-19f7c128c091,DISK], DatanodeInfoWithStorage[127.0.0.1:36993,DS-cceb26d5-7c15-4646-b3f0-c47408bda624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911713408-172.17.0.11-1597178542727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-14f8cfc4-61a5-4901-90a3-d214036b8925,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-6ae8c1bf-17e8-4667-a832-b79c556d43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-b89e3857-dd6c-4128-86bd-9eacad31d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-29759b5c-dec2-4bd5-9bcd-76c15b6ea7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-6c167533-c6c4-42fc-b84a-64d7fb5884ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-faa54b28-d007-404b-995f-3b6d39616759,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-28c3f8a3-d2b4-456a-8172-0d26c2370e32,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-92390031-d17a-4378-b6a0-d4b14c19f66f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911713408-172.17.0.11-1597178542727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39625,DS-14f8cfc4-61a5-4901-90a3-d214036b8925,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-6ae8c1bf-17e8-4667-a832-b79c556d43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-b89e3857-dd6c-4128-86bd-9eacad31d0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-29759b5c-dec2-4bd5-9bcd-76c15b6ea7cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-6c167533-c6c4-42fc-b84a-64d7fb5884ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-faa54b28-d007-404b-995f-3b6d39616759,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-28c3f8a3-d2b4-456a-8172-0d26c2370e32,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-92390031-d17a-4378-b6a0-d4b14c19f66f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423594520-172.17.0.11-1597178610606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-78ee0676-63fb-4793-9ef4-4e207a7b2a59,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-7016b462-9d0d-425e-9d9e-1d785e696168,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-6a0fa65d-fbba-4984-9387-e3fea4cc0f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-b2807f5e-b618-49e6-aada-ab8bccc80408,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-c6635abf-b019-4734-8e5e-931f2f60bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-93fddefd-27c2-4527-9059-c5b5446dca80,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-2fa8d071-3cdd-436a-b59e-4132d4c05c58,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-416060ed-5a45-437b-8bb7-27fff1dc1b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423594520-172.17.0.11-1597178610606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35649,DS-78ee0676-63fb-4793-9ef4-4e207a7b2a59,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-7016b462-9d0d-425e-9d9e-1d785e696168,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-6a0fa65d-fbba-4984-9387-e3fea4cc0f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-b2807f5e-b618-49e6-aada-ab8bccc80408,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-c6635abf-b019-4734-8e5e-931f2f60bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-93fddefd-27c2-4527-9059-c5b5446dca80,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-2fa8d071-3cdd-436a-b59e-4132d4c05c58,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-416060ed-5a45-437b-8bb7-27fff1dc1b76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898891925-172.17.0.11-1597178712746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-93161793-1c1e-48ff-a1b4-763d4732c6de,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-42a74036-8d4e-46a8-bd15-5cee0b1c062a,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-130fdbbf-6fe7-4c20-a5a7-a3550fe5b2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-ee91754e-bcb5-4c71-9666-16f41e048a96,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-c7905e56-f539-4895-933d-c3af1910d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-97787cef-8a9e-4ad0-b8a6-6fb1794d6edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-83e08929-28e9-4049-9223-766a76e29177,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-bc014a11-8b49-42cc-92f1-b1687436a38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898891925-172.17.0.11-1597178712746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-93161793-1c1e-48ff-a1b4-763d4732c6de,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-42a74036-8d4e-46a8-bd15-5cee0b1c062a,DISK], DatanodeInfoWithStorage[127.0.0.1:33199,DS-130fdbbf-6fe7-4c20-a5a7-a3550fe5b2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-ee91754e-bcb5-4c71-9666-16f41e048a96,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-c7905e56-f539-4895-933d-c3af1910d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-97787cef-8a9e-4ad0-b8a6-6fb1794d6edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-83e08929-28e9-4049-9223-766a76e29177,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-bc014a11-8b49-42cc-92f1-b1687436a38f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258773810-172.17.0.11-1597178823323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35501,DS-1497f825-9b1e-483b-bdd4-0e36b8a7c2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-491ff602-8960-4fff-89e4-0a173c9539ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-353a0719-2f44-4de8-bb1a-ddf9fc55d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-fa83f431-3107-46f3-81a4-56c867b10b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-6c168cfc-9e1b-4521-964c-51b022915fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-5facb23d-5d31-4edd-a18b-359854d113e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-fa4945fa-e643-4ed2-bb71-fd6fbd908f76,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-7eda64f7-78b4-4e0e-83c9-115fd9f85781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258773810-172.17.0.11-1597178823323:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35501,DS-1497f825-9b1e-483b-bdd4-0e36b8a7c2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-491ff602-8960-4fff-89e4-0a173c9539ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-353a0719-2f44-4de8-bb1a-ddf9fc55d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-fa83f431-3107-46f3-81a4-56c867b10b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36333,DS-6c168cfc-9e1b-4521-964c-51b022915fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-5facb23d-5d31-4edd-a18b-359854d113e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-fa4945fa-e643-4ed2-bb71-fd6fbd908f76,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-7eda64f7-78b4-4e0e-83c9-115fd9f85781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183372985-172.17.0.11-1597178985965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44835,DS-eac2d064-b8df-4fef-8f7f-a483ce244cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-d14dc468-b602-4dc1-934a-f54ba35d9f12,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-6f92f832-969a-4d78-b776-4a3ffdc24340,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-8148aa8b-b827-48a1-97f7-529f802764e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-809ac925-aab0-4e57-978a-86312ae6d4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-ecc31a43-f5bc-444f-be4b-806097bb4049,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-1cdc6e0c-702e-409a-8b46-73bbce874f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-1b022d95-3b21-4bb3-9b60-fc83d377a0f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-183372985-172.17.0.11-1597178985965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44835,DS-eac2d064-b8df-4fef-8f7f-a483ce244cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-d14dc468-b602-4dc1-934a-f54ba35d9f12,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-6f92f832-969a-4d78-b776-4a3ffdc24340,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-8148aa8b-b827-48a1-97f7-529f802764e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-809ac925-aab0-4e57-978a-86312ae6d4fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-ecc31a43-f5bc-444f-be4b-806097bb4049,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-1cdc6e0c-702e-409a-8b46-73bbce874f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-1b022d95-3b21-4bb3-9b60-fc83d377a0f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542053483-172.17.0.11-1597179160536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45335,DS-46119efb-eb34-446c-ae0f-6dcc97cf1634,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-aff8edfc-e913-4832-a6fd-aa92880c564f,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-157e94ed-2748-4cc0-8bcb-bb03afd97871,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-db724bb5-d0b7-401a-8f7c-66c5520f3316,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-efef0103-80cf-4227-92f4-8c585d2b2a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-00c56cdf-92ac-4681-97b7-514ecee256c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-9d857555-d4ba-4f2f-ac20-71546cca6583,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-bfb6740e-9d4d-4e6a-9521-c30b3da53e85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542053483-172.17.0.11-1597179160536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45335,DS-46119efb-eb34-446c-ae0f-6dcc97cf1634,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-aff8edfc-e913-4832-a6fd-aa92880c564f,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-157e94ed-2748-4cc0-8bcb-bb03afd97871,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-db724bb5-d0b7-401a-8f7c-66c5520f3316,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-efef0103-80cf-4227-92f4-8c585d2b2a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34221,DS-00c56cdf-92ac-4681-97b7-514ecee256c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-9d857555-d4ba-4f2f-ac20-71546cca6583,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-bfb6740e-9d4d-4e6a-9521-c30b3da53e85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60643782-172.17.0.11-1597179191636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39575,DS-f3344d5e-11f2-46d0-8852-8beee76e5706,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-ea340bc1-61a3-4335-9bd6-f81255d1630f,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-ff525632-5c03-4dbd-ba51-6db37ba7c11c,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-dc339cfb-bfa9-4d71-a946-2d255929855d,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-f90eb488-ca2a-468e-af7b-7aa21f4d63a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-dcae82a8-ce8f-4354-978e-c3c5692f8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-0cb68c3d-eb98-4ad8-adf3-026654071eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-225bc643-e55d-4a10-ae13-066fb67de487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60643782-172.17.0.11-1597179191636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39575,DS-f3344d5e-11f2-46d0-8852-8beee76e5706,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-ea340bc1-61a3-4335-9bd6-f81255d1630f,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-ff525632-5c03-4dbd-ba51-6db37ba7c11c,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-dc339cfb-bfa9-4d71-a946-2d255929855d,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-f90eb488-ca2a-468e-af7b-7aa21f4d63a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-dcae82a8-ce8f-4354-978e-c3c5692f8ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44525,DS-0cb68c3d-eb98-4ad8-adf3-026654071eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-225bc643-e55d-4a10-ae13-066fb67de487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483840778-172.17.0.11-1597179224641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-4d45026c-ac8a-404b-9eb9-6a9be2fa22e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-00984d19-7f82-49a8-9a33-ebd849f0282b,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-0415ab4c-ae3e-4832-a79a-ffcb8656a45a,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-e1e29bcd-1d41-4fba-9922-94a2f214972b,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-879bd79f-8beb-4ca1-a9b9-8aef65fa3c19,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-dd464118-2eff-4363-9694-dce3df060610,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-60bdf7c4-3493-4e13-b423-cf5718c68059,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-cbbe06e9-5fb2-4ae2-b4ee-45a9ccf0d825,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483840778-172.17.0.11-1597179224641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37804,DS-4d45026c-ac8a-404b-9eb9-6a9be2fa22e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36567,DS-00984d19-7f82-49a8-9a33-ebd849f0282b,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-0415ab4c-ae3e-4832-a79a-ffcb8656a45a,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-e1e29bcd-1d41-4fba-9922-94a2f214972b,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-879bd79f-8beb-4ca1-a9b9-8aef65fa3c19,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-dd464118-2eff-4363-9694-dce3df060610,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-60bdf7c4-3493-4e13-b423-cf5718c68059,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-cbbe06e9-5fb2-4ae2-b4ee-45a9ccf0d825,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028137303-172.17.0.11-1597179522337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37496,DS-4495da28-1dfc-4c4a-b401-c90b4cce68ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-97a7c9ff-43ed-40d7-8a10-cbc15c102991,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-469cef52-2966-423f-baca-07a50f3a4b82,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-1bab584c-42d9-4bf7-95b7-01368e9e365e,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-502c9e52-014e-4114-b4b9-541f7a705314,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-20a2b0ff-81cf-4c26-a5d7-b899ef03b995,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-aee22906-9929-4637-8e0e-eb1c19d9355c,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-a20e632a-d0dd-4013-8d57-e5a3603706b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028137303-172.17.0.11-1597179522337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37496,DS-4495da28-1dfc-4c4a-b401-c90b4cce68ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-97a7c9ff-43ed-40d7-8a10-cbc15c102991,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-469cef52-2966-423f-baca-07a50f3a4b82,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-1bab584c-42d9-4bf7-95b7-01368e9e365e,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-502c9e52-014e-4114-b4b9-541f7a705314,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-20a2b0ff-81cf-4c26-a5d7-b899ef03b995,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-aee22906-9929-4637-8e0e-eb1c19d9355c,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-a20e632a-d0dd-4013-8d57-e5a3603706b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091621631-172.17.0.11-1597179552322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-5cc31860-2c5c-4887-a45d-db1e78fdc0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-29477633-611c-484c-97df-18df912f5f61,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-366cc3ad-9ce7-4331-a72e-054322143c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-49d845c3-6fb1-45da-842c-147635dce3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-a3832d90-bc3d-427b-8454-852af4027fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-c55b9039-ca56-48e6-960a-370f4447d375,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-caebac40-69a8-4d0c-a35f-a1ce46b9be15,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-54386b69-328c-4bd2-924b-2cf79a748f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1091621631-172.17.0.11-1597179552322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42164,DS-5cc31860-2c5c-4887-a45d-db1e78fdc0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-29477633-611c-484c-97df-18df912f5f61,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-366cc3ad-9ce7-4331-a72e-054322143c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-49d845c3-6fb1-45da-842c-147635dce3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-a3832d90-bc3d-427b-8454-852af4027fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-c55b9039-ca56-48e6-960a-370f4447d375,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-caebac40-69a8-4d0c-a35f-a1ce46b9be15,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-54386b69-328c-4bd2-924b-2cf79a748f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539432838-172.17.0.11-1597179584739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38314,DS-f6897621-b184-42c2-b742-a480646e925d,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-5cf56237-e1d6-4a61-83f7-c932e629e2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-5b665b86-201a-4e9a-8eb0-0aff3d2b5dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-69205148-83b2-44a5-a5b7-970773493750,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-8637f403-43b8-4aee-ba24-5572bbd316eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-50ad4adb-690d-4e27-8dcb-d39c94f8c52c,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-8d64f8c0-1108-42eb-bd9c-cb969e5b1cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-d6d87acc-3b23-4051-930f-412e0f2a9207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539432838-172.17.0.11-1597179584739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38314,DS-f6897621-b184-42c2-b742-a480646e925d,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-5cf56237-e1d6-4a61-83f7-c932e629e2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-5b665b86-201a-4e9a-8eb0-0aff3d2b5dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-69205148-83b2-44a5-a5b7-970773493750,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-8637f403-43b8-4aee-ba24-5572bbd316eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-50ad4adb-690d-4e27-8dcb-d39c94f8c52c,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-8d64f8c0-1108-42eb-bd9c-cb969e5b1cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-d6d87acc-3b23-4051-930f-412e0f2a9207,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623063517-172.17.0.11-1597180062714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39126,DS-10f37759-dba1-4429-b4cc-9b452b4b5383,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-2fb1adab-33fb-420d-ad61-0990bcb41366,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-d8a581df-80a2-41f6-9035-b653ad2914ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-34188885-efdd-4a2c-ac09-09da82e3edf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-312d1cf5-85d3-4df2-9615-a73416d447e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-5832cc0b-09b7-4ada-8e5b-5ab0cbeef594,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-331c8f1d-1c43-4edd-ba46-e1cb78da6429,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-20a1eebf-6c5e-420f-a040-aad53a218f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-623063517-172.17.0.11-1597180062714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39126,DS-10f37759-dba1-4429-b4cc-9b452b4b5383,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-2fb1adab-33fb-420d-ad61-0990bcb41366,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-d8a581df-80a2-41f6-9035-b653ad2914ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-34188885-efdd-4a2c-ac09-09da82e3edf7,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-312d1cf5-85d3-4df2-9615-a73416d447e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-5832cc0b-09b7-4ada-8e5b-5ab0cbeef594,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-331c8f1d-1c43-4edd-ba46-e1cb78da6429,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-20a1eebf-6c5e-420f-a040-aad53a218f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924890172-172.17.0.11-1597180137775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-b8afdbbe-2536-4622-977f-67390ab3cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-dcba649d-d983-4d49-a182-21cdfa97ddee,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-af653740-56ba-425a-85ae-16f7383df0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-98bc55d2-6f0f-4fd6-997d-06decb5784e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-52703522-5603-438b-b462-7678c4f8590d,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-075e5cd7-f901-4f35-9e25-432c26a2db83,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-da1b8a28-cf90-41a0-bc7e-32917c820d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-1fc70f5d-37d9-42c1-99f3-67f31bf13b0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924890172-172.17.0.11-1597180137775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37968,DS-b8afdbbe-2536-4622-977f-67390ab3cd36,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-dcba649d-d983-4d49-a182-21cdfa97ddee,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-af653740-56ba-425a-85ae-16f7383df0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-98bc55d2-6f0f-4fd6-997d-06decb5784e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-52703522-5603-438b-b462-7678c4f8590d,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-075e5cd7-f901-4f35-9e25-432c26a2db83,DISK], DatanodeInfoWithStorage[127.0.0.1:46064,DS-da1b8a28-cf90-41a0-bc7e-32917c820d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-1fc70f5d-37d9-42c1-99f3-67f31bf13b0e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867476000-172.17.0.11-1597180464349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-12f40bd2-dfce-4517-bf3f-8d85499e3f97,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-149e5fc9-9cd8-4ce5-828d-ec38adada9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-cca6c589-e294-445c-a612-9d3bf1c49a56,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-01d0d322-a74d-4575-9653-3a3e3304fe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-2dcd4428-6a21-4507-96bb-cc52d0971261,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-6aae227c-68ab-4b37-b113-632f9e95323b,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-f322ba4d-eee6-4b56-9f11-7be74ff2b08b,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-517ae663-c747-428d-afe8-8330e349a03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867476000-172.17.0.11-1597180464349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34910,DS-12f40bd2-dfce-4517-bf3f-8d85499e3f97,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-149e5fc9-9cd8-4ce5-828d-ec38adada9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-cca6c589-e294-445c-a612-9d3bf1c49a56,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-01d0d322-a74d-4575-9653-3a3e3304fe0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-2dcd4428-6a21-4507-96bb-cc52d0971261,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-6aae227c-68ab-4b37-b113-632f9e95323b,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-f322ba4d-eee6-4b56-9f11-7be74ff2b08b,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-517ae663-c747-428d-afe8-8330e349a03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622067330-172.17.0.11-1597180498203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-9a45e8d8-3a64-4bd1-ba12-a94cf830a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-a4d5debc-c203-4231-ac74-9c4d12dab0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-3fffc269-b1dd-464e-9bfe-1b0e38f2e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-6798df25-a2e2-4fa7-82f2-3999462dbc50,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-c15e2a0f-c6c8-4c07-9aa1-562aa24aed32,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-9fdd8161-ee8e-4288-bb5d-a9378dacc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-8364fec1-9dac-45ea-a483-3b5ba4d6196b,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-2c77a4dc-b63a-4096-a61e-b56248bf34b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622067330-172.17.0.11-1597180498203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-9a45e8d8-3a64-4bd1-ba12-a94cf830a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-a4d5debc-c203-4231-ac74-9c4d12dab0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38919,DS-3fffc269-b1dd-464e-9bfe-1b0e38f2e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-6798df25-a2e2-4fa7-82f2-3999462dbc50,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-c15e2a0f-c6c8-4c07-9aa1-562aa24aed32,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-9fdd8161-ee8e-4288-bb5d-a9378dacc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-8364fec1-9dac-45ea-a483-3b5ba4d6196b,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-2c77a4dc-b63a-4096-a61e-b56248bf34b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800579115-172.17.0.11-1597180534135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38069,DS-8e1734c9-dc96-46f8-96f7-aea6eb65cf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-aa8b21a4-b319-4aab-ad01-cf90242a8c80,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-3c7f8d29-eff5-462b-ab42-06389a57f53c,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-dcb66022-f5a8-4c35-9435-603b9b5f0208,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-372fe2e7-bed7-4080-8f1f-e3d81ff159bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-bea4faaf-95ab-4dbd-b3da-125981189044,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-6ad65b71-76e6-4228-8770-694a72266bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-9cafc3ac-55db-4d9f-8a71-a3ded9d0991e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800579115-172.17.0.11-1597180534135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38069,DS-8e1734c9-dc96-46f8-96f7-aea6eb65cf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-aa8b21a4-b319-4aab-ad01-cf90242a8c80,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-3c7f8d29-eff5-462b-ab42-06389a57f53c,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-dcb66022-f5a8-4c35-9435-603b9b5f0208,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-372fe2e7-bed7-4080-8f1f-e3d81ff159bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42347,DS-bea4faaf-95ab-4dbd-b3da-125981189044,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-6ad65b71-76e6-4228-8770-694a72266bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-9cafc3ac-55db-4d9f-8a71-a3ded9d0991e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735173020-172.17.0.11-1597180617252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-2e5ddd44-938f-4c3e-acf2-7fecd486eab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-1f0e1b48-387f-49ea-b650-703f98704d01,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-f0fc042e-9a0f-4969-9151-2d2f2fc07ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-eb6a850a-1499-4bb2-89fa-4b9d4742e50a,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-fb076e22-9ecb-4f43-a8e4-f6ca8d7cb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-1cf0191a-c13b-4d36-860d-508e37fb8a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-3e7c2581-f323-4121-853f-ae097772cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-03e77a5f-d94d-4024-ac2f-37a966f4a0b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735173020-172.17.0.11-1597180617252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-2e5ddd44-938f-4c3e-acf2-7fecd486eab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-1f0e1b48-387f-49ea-b650-703f98704d01,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-f0fc042e-9a0f-4969-9151-2d2f2fc07ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-eb6a850a-1499-4bb2-89fa-4b9d4742e50a,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-fb076e22-9ecb-4f43-a8e4-f6ca8d7cb6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-1cf0191a-c13b-4d36-860d-508e37fb8a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-3e7c2581-f323-4121-853f-ae097772cee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-03e77a5f-d94d-4024-ac2f-37a966f4a0b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780493778-172.17.0.11-1597180686299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42014,DS-a52b8b47-e244-43b3-973f-fa65ef4348cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-d9b50422-b6b1-4cc7-97ac-f8825b55133f,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-d99c2aee-4a81-4f3b-bb54-262cadef6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-5ad435ef-1e4b-4c03-badc-966f1c11189b,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-47420cef-1971-4c4e-96ef-90642bbd7c12,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-8e918a61-6f8a-40b0-a453-baac80b26ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-862c2fa9-92d2-4c37-a006-3c05feaebb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-35c3dfad-9c8a-46f8-a741-dbce454bacc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780493778-172.17.0.11-1597180686299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42014,DS-a52b8b47-e244-43b3-973f-fa65ef4348cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-d9b50422-b6b1-4cc7-97ac-f8825b55133f,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-d99c2aee-4a81-4f3b-bb54-262cadef6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-5ad435ef-1e4b-4c03-badc-966f1c11189b,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-47420cef-1971-4c4e-96ef-90642bbd7c12,DISK], DatanodeInfoWithStorage[127.0.0.1:44469,DS-8e918a61-6f8a-40b0-a453-baac80b26ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-862c2fa9-92d2-4c37-a006-3c05feaebb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-35c3dfad-9c8a-46f8-a741-dbce454bacc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.retry.times.get-last-block-length
component: hdfs:NameNode
v1: 5
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681977027-172.17.0.11-1597180843311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45769,DS-2bc78f9b-9e3e-4d86-926f-1ac2e8353ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-dd640007-dd86-49ab-b6b2-1f69dea59326,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-12fa146f-bc34-45bc-adbe-7540558775bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-dd547f55-177b-494a-8cc1-369020117f58,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-fad6e93f-4f02-4819-8b32-b547d3b27274,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-8d3b0cf7-5186-4778-8a8b-3b7d23034196,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-cb595dc8-245d-42f7-8677-45b9eb5a5b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-958c8dc0-5fbc-44f0-b52b-68ff1661e6a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1681977027-172.17.0.11-1597180843311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45769,DS-2bc78f9b-9e3e-4d86-926f-1ac2e8353ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-dd640007-dd86-49ab-b6b2-1f69dea59326,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-12fa146f-bc34-45bc-adbe-7540558775bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-dd547f55-177b-494a-8cc1-369020117f58,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-fad6e93f-4f02-4819-8b32-b547d3b27274,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-8d3b0cf7-5186-4778-8a8b-3b7d23034196,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-cb595dc8-245d-42f7-8677-45b9eb5a5b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46045,DS-958c8dc0-5fbc-44f0-b52b-68ff1661e6a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 5283
