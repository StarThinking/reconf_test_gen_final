reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75081900-172.17.0.12-1597102968504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-f7bcdaea-8d64-49ce-88e0-29ba3c29e854,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-f8d87f6b-ee0d-44b0-85db-42cb8e7b648b,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-f292622a-fa88-479e-99b8-272bf780a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-5cb6d5b1-afa4-4ad7-81e8-ef9c03060777,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-40d422e9-7c6a-4e34-b706-3041a1fc21b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-e1be8e0b-caea-463d-818a-b046b92ba98a,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-1ca5447d-84b1-4896-8ffc-f5a30279231e,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-afeaba9e-dd46-45cc-9089-e76281d9e0a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-75081900-172.17.0.12-1597102968504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33341,DS-f7bcdaea-8d64-49ce-88e0-29ba3c29e854,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-f8d87f6b-ee0d-44b0-85db-42cb8e7b648b,DISK], DatanodeInfoWithStorage[127.0.0.1:34032,DS-f292622a-fa88-479e-99b8-272bf780a0db,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-5cb6d5b1-afa4-4ad7-81e8-ef9c03060777,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-40d422e9-7c6a-4e34-b706-3041a1fc21b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-e1be8e0b-caea-463d-818a-b046b92ba98a,DISK], DatanodeInfoWithStorage[127.0.0.1:36839,DS-1ca5447d-84b1-4896-8ffc-f5a30279231e,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-afeaba9e-dd46-45cc-9089-e76281d9e0a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351393222-172.17.0.12-1597103080941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-0d466a19-7e9f-4432-aa8c-769ab337f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-f2953f6e-84e1-4328-82d1-0cf1a144bf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-2031a9d4-f2f2-47ea-a523-7480cb76693e,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-b3dc4327-cf5d-41ba-b81a-1973d13ecb86,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-e19a6af6-6d9b-44f1-94a2-9b0ce35c9150,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-793d3aad-2a5f-4a0a-a630-aa04b9d82470,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-6cb1156d-928f-4e6e-b4a1-eed0314fc325,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-59ba88d8-1214-4412-b859-137699ef225d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1351393222-172.17.0.12-1597103080941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-0d466a19-7e9f-4432-aa8c-769ab337f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-f2953f6e-84e1-4328-82d1-0cf1a144bf29,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-2031a9d4-f2f2-47ea-a523-7480cb76693e,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-b3dc4327-cf5d-41ba-b81a-1973d13ecb86,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-e19a6af6-6d9b-44f1-94a2-9b0ce35c9150,DISK], DatanodeInfoWithStorage[127.0.0.1:45957,DS-793d3aad-2a5f-4a0a-a630-aa04b9d82470,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-6cb1156d-928f-4e6e-b4a1-eed0314fc325,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-59ba88d8-1214-4412-b859-137699ef225d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340986345-172.17.0.12-1597103852329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35501,DS-0d836491-2c9f-4b40-ba61-071ceb1528d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-db909394-06f1-4ae5-a66e-b879e51f282d,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-18550736-a87c-4396-b4ef-b36d13887daa,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-a81a1334-1d7c-4862-b494-a3476978bc27,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-69c9aa94-f4ae-4e92-9c5b-9ec4f7811763,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-aa47a366-f511-4146-b2a2-5c150432fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-2f3a9737-9896-48c9-af9c-4a525c2ccdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-79c88007-a3f9-45dd-af86-90f502091d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1340986345-172.17.0.12-1597103852329:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35501,DS-0d836491-2c9f-4b40-ba61-071ceb1528d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-db909394-06f1-4ae5-a66e-b879e51f282d,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-18550736-a87c-4396-b4ef-b36d13887daa,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-a81a1334-1d7c-4862-b494-a3476978bc27,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-69c9aa94-f4ae-4e92-9c5b-9ec4f7811763,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-aa47a366-f511-4146-b2a2-5c150432fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-2f3a9737-9896-48c9-af9c-4a525c2ccdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35847,DS-79c88007-a3f9-45dd-af86-90f502091d08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312388635-172.17.0.12-1597103924465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40951,DS-8ec620c5-ffad-428c-875f-90db8f85c338,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-a18a518c-b3a8-42e1-b7e3-595f4de2f300,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-bf0db36c-a19b-435a-b1ca-d68e62177a33,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-3a293bd0-a50f-4ec7-a187-22fc61936173,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-5fc0a695-b620-4026-aa1a-ca6279b6210f,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-51329f34-5925-4adb-b6ff-71331f2f3853,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-d3175a1b-a2bf-4647-a0a3-8f554eb2602c,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-63e5dd22-482a-49b8-86ff-8b38192ecf28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312388635-172.17.0.12-1597103924465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40951,DS-8ec620c5-ffad-428c-875f-90db8f85c338,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-a18a518c-b3a8-42e1-b7e3-595f4de2f300,DISK], DatanodeInfoWithStorage[127.0.0.1:39838,DS-bf0db36c-a19b-435a-b1ca-d68e62177a33,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-3a293bd0-a50f-4ec7-a187-22fc61936173,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-5fc0a695-b620-4026-aa1a-ca6279b6210f,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-51329f34-5925-4adb-b6ff-71331f2f3853,DISK], DatanodeInfoWithStorage[127.0.0.1:34302,DS-d3175a1b-a2bf-4647-a0a3-8f554eb2602c,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-63e5dd22-482a-49b8-86ff-8b38192ecf28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737896578-172.17.0.12-1597104000729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-0db7060a-78f5-4bd9-a83f-3495edf482a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-13cdf6ec-126d-4239-88f0-e5b14dfa84fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-3b04ad3b-84b6-4916-a3cb-22393a106b32,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-b5cba321-b4d5-4a4a-a129-9c9479e37b31,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-55d09c92-1491-4bcc-99ba-15b8fc0453d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-4546226e-712c-4ccd-b409-0f67423141d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-5784f0da-4e91-4ebe-95de-4a460264849c,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-c59181b2-810b-489d-b16c-37f6f1370cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-737896578-172.17.0.12-1597104000729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43843,DS-0db7060a-78f5-4bd9-a83f-3495edf482a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-13cdf6ec-126d-4239-88f0-e5b14dfa84fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-3b04ad3b-84b6-4916-a3cb-22393a106b32,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-b5cba321-b4d5-4a4a-a129-9c9479e37b31,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-55d09c92-1491-4bcc-99ba-15b8fc0453d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-4546226e-712c-4ccd-b409-0f67423141d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-5784f0da-4e91-4ebe-95de-4a460264849c,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-c59181b2-810b-489d-b16c-37f6f1370cd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825735711-172.17.0.12-1597104401315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-e778859b-52a6-4bd6-b3ef-95bbfc49487e,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-e29a13b3-6c1b-4a35-9215-8944174e9872,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-474d1e2e-e2b9-4178-b191-63c59511ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-47d415d9-fe4f-48db-b605-53c4fd556576,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-669790e3-a53f-40fb-a286-c8d8d47df052,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-0e9f581c-8257-421e-9d97-ee7c8fa9861e,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-491a8b25-714b-49db-9df9-33f943d7abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-3f6f27b2-69c5-4fbf-9060-289419d0082e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-825735711-172.17.0.12-1597104401315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-e778859b-52a6-4bd6-b3ef-95bbfc49487e,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-e29a13b3-6c1b-4a35-9215-8944174e9872,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-474d1e2e-e2b9-4178-b191-63c59511ee9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-47d415d9-fe4f-48db-b605-53c4fd556576,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-669790e3-a53f-40fb-a286-c8d8d47df052,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-0e9f581c-8257-421e-9d97-ee7c8fa9861e,DISK], DatanodeInfoWithStorage[127.0.0.1:35289,DS-491a8b25-714b-49db-9df9-33f943d7abb8,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-3f6f27b2-69c5-4fbf-9060-289419d0082e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279126190-172.17.0.12-1597104577268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41797,DS-d5366759-c1cc-4cc0-8c54-bfff796e0cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-4e8aa5e4-8758-4324-beb5-d5a485fb1a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-9182b302-4e8a-49c0-bb39-61f4c8bbd6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-8f95cae8-d5c4-4b4e-8694-b01db4a6168b,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-54d78e2f-c9a2-4557-9768-1341c2c29681,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-35170b93-734d-41f2-bfe7-8470eb67e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-a772c24a-0d95-4c1e-9e1e-f94569055e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-4582bf7f-6c21-4e5c-adb9-bab352540599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279126190-172.17.0.12-1597104577268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41797,DS-d5366759-c1cc-4cc0-8c54-bfff796e0cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-4e8aa5e4-8758-4324-beb5-d5a485fb1a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-9182b302-4e8a-49c0-bb39-61f4c8bbd6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-8f95cae8-d5c4-4b4e-8694-b01db4a6168b,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-54d78e2f-c9a2-4557-9768-1341c2c29681,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-35170b93-734d-41f2-bfe7-8470eb67e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-a772c24a-0d95-4c1e-9e1e-f94569055e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-4582bf7f-6c21-4e5c-adb9-bab352540599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820183528-172.17.0.12-1597104868640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-1cdcd910-66bd-4e66-9e26-0c25078ce3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-b32ca232-b0c6-416f-a2e1-6ca55deb1514,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-baff605d-3c5c-4580-a622-b770c0f3afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-4b6b3648-b897-4a34-ad26-99681df1cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-f91fb607-9ee9-4a8a-a9f4-edfd23b52f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-3c835a16-3d5b-436b-bcdf-cf9d15077110,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-e3cd29c9-240f-4e3c-9d6a-e5ccd59196e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-b41a70ab-6600-4786-91bc-81a431779f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820183528-172.17.0.12-1597104868640:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42806,DS-1cdcd910-66bd-4e66-9e26-0c25078ce3d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-b32ca232-b0c6-416f-a2e1-6ca55deb1514,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-baff605d-3c5c-4580-a622-b770c0f3afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-4b6b3648-b897-4a34-ad26-99681df1cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-f91fb607-9ee9-4a8a-a9f4-edfd23b52f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-3c835a16-3d5b-436b-bcdf-cf9d15077110,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-e3cd29c9-240f-4e3c-9d6a-e5ccd59196e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-b41a70ab-6600-4786-91bc-81a431779f3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954653422-172.17.0.12-1597105245318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37394,DS-21dd7c09-2a54-41e4-b3a8-ddb1ac5c832d,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-0d12f941-4cce-42b8-8926-99819ffdf15f,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-db6d65e1-9f00-46dc-a0e7-7a4532487e16,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-dbb237aa-0fad-4b0b-b044-51573e35f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-cf56000f-9e60-4c77-ab87-9807c510f151,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-cc4805f2-d7a2-4570-94f9-efb7a33fa3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-9694fb1e-dc70-47b6-a2d0-048f9f8a9cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-5e893cee-0010-4966-821a-b9b5243a4a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954653422-172.17.0.12-1597105245318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37394,DS-21dd7c09-2a54-41e4-b3a8-ddb1ac5c832d,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-0d12f941-4cce-42b8-8926-99819ffdf15f,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-db6d65e1-9f00-46dc-a0e7-7a4532487e16,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-dbb237aa-0fad-4b0b-b044-51573e35f7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-cf56000f-9e60-4c77-ab87-9807c510f151,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-cc4805f2-d7a2-4570-94f9-efb7a33fa3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-9694fb1e-dc70-47b6-a2d0-048f9f8a9cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-5e893cee-0010-4966-821a-b9b5243a4a6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386470786-172.17.0.12-1597105385011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-145541b3-16a3-44c2-9947-f96763eb6177,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-17cc14fa-ecd7-4bb5-ad14-9ea394c55cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-59e723da-e6db-496f-9a70-6deb9d955e19,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-f16b4825-495d-43d0-abdb-868913108263,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-c05c6e7e-fdde-4ece-a903-d6e2e1158a36,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-4b1fbffc-d849-4a33-bb77-94967d70f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-24507f33-65d9-4677-9e64-5951ff6110f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-255cf54a-a957-42f9-b33a-e5020ceb3657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386470786-172.17.0.12-1597105385011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39074,DS-145541b3-16a3-44c2-9947-f96763eb6177,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-17cc14fa-ecd7-4bb5-ad14-9ea394c55cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-59e723da-e6db-496f-9a70-6deb9d955e19,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-f16b4825-495d-43d0-abdb-868913108263,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-c05c6e7e-fdde-4ece-a903-d6e2e1158a36,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-4b1fbffc-d849-4a33-bb77-94967d70f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-24507f33-65d9-4677-9e64-5951ff6110f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-255cf54a-a957-42f9-b33a-e5020ceb3657,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401716890-172.17.0.12-1597105712025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-0d768848-7c28-4614-89b8-f1e544e9e39a,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-16aa9537-7fb8-42cd-b73c-2152bf09e033,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-415cfe00-3a0b-4ad8-ae7d-f4f9d13c3f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-bd701bcc-7e12-4e7e-aeb0-d0bde134768b,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-3c22865a-ebf1-4edf-afa0-12ac94f91986,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-19180857-336b-44ce-882a-6fa1e22aa076,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-7617cec5-d0ee-4341-be9f-2efa033e8a32,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-548ae103-66be-427a-8c9e-ce09b4951278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401716890-172.17.0.12-1597105712025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41531,DS-0d768848-7c28-4614-89b8-f1e544e9e39a,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-16aa9537-7fb8-42cd-b73c-2152bf09e033,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-415cfe00-3a0b-4ad8-ae7d-f4f9d13c3f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-bd701bcc-7e12-4e7e-aeb0-d0bde134768b,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-3c22865a-ebf1-4edf-afa0-12ac94f91986,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-19180857-336b-44ce-882a-6fa1e22aa076,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-7617cec5-d0ee-4341-be9f-2efa033e8a32,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-548ae103-66be-427a-8c9e-ce09b4951278,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139689879-172.17.0.12-1597106200070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-d7e0ba33-152f-4368-9b9e-1c9e0485c490,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-726739f0-48a7-40b0-966c-1dc84a4baf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-fa52735b-8ed9-4f88-8a28-2965a6c4f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-c0d8d78b-8721-4779-a236-7718e1d61005,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-52b1f5a0-693e-40af-812f-950e2584d170,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-3c5bfef4-5702-4e46-aadb-1be78c5bb79f,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-a8faf178-3c25-4ec4-af12-59df9357407a,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-523ca4be-8eb9-42d0-afd9-d5afa861a259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139689879-172.17.0.12-1597106200070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-d7e0ba33-152f-4368-9b9e-1c9e0485c490,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-726739f0-48a7-40b0-966c-1dc84a4baf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-fa52735b-8ed9-4f88-8a28-2965a6c4f59a,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-c0d8d78b-8721-4779-a236-7718e1d61005,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-52b1f5a0-693e-40af-812f-950e2584d170,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-3c5bfef4-5702-4e46-aadb-1be78c5bb79f,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-a8faf178-3c25-4ec4-af12-59df9357407a,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-523ca4be-8eb9-42d0-afd9-d5afa861a259,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989599430-172.17.0.12-1597106488745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39518,DS-bb23e293-59a4-40d4-b2b2-05560c142ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-5e957e98-8917-4572-a509-e66cd4efe72b,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-6dfedf30-f7d6-456f-8e01-7f55488df313,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-cad21b0a-49a2-486d-9657-d4af54b9c36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-cacbc59a-3d2f-4246-b16d-2ff6ad4d3aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-8e78a31a-9966-41a9-a79a-d09dcb4dee03,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-4f17c5b3-a8af-4043-874e-26d6f08a9ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-255fd57d-4cc2-4456-b22e-a64b9bca0d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989599430-172.17.0.12-1597106488745:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39518,DS-bb23e293-59a4-40d4-b2b2-05560c142ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-5e957e98-8917-4572-a509-e66cd4efe72b,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-6dfedf30-f7d6-456f-8e01-7f55488df313,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-cad21b0a-49a2-486d-9657-d4af54b9c36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-cacbc59a-3d2f-4246-b16d-2ff6ad4d3aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-8e78a31a-9966-41a9-a79a-d09dcb4dee03,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-4f17c5b3-a8af-4043-874e-26d6f08a9ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-255fd57d-4cc2-4456-b22e-a64b9bca0d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520226889-172.17.0.12-1597106730347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40994,DS-f9877dcf-3884-4c81-b7a1-18f4fa7c1d01,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-db069ae5-e80f-4dca-83f6-ac5fe5cafbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-bb7b5ada-8c45-4ec5-91c7-5d09ba73015c,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-4aaa8658-af89-45b4-836f-ab1cdb377f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-49b5cf53-9567-4eb7-8c29-676a6c0826b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-6def1911-7ebe-4cd9-86d9-c41c3f481c47,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-ec662d32-09d8-432d-9bf4-9310b98e0486,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-d54ef7f1-79b6-4398-b623-593fb3a782ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520226889-172.17.0.12-1597106730347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40994,DS-f9877dcf-3884-4c81-b7a1-18f4fa7c1d01,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-db069ae5-e80f-4dca-83f6-ac5fe5cafbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-bb7b5ada-8c45-4ec5-91c7-5d09ba73015c,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-4aaa8658-af89-45b4-836f-ab1cdb377f61,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-49b5cf53-9567-4eb7-8c29-676a6c0826b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-6def1911-7ebe-4cd9-86d9-c41c3f481c47,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-ec662d32-09d8-432d-9bf4-9310b98e0486,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-d54ef7f1-79b6-4398-b623-593fb3a782ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957782395-172.17.0.12-1597107197869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41455,DS-e8514f17-4494-4960-9796-d1affe07ac27,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-689cae24-a636-4c1a-9ded-f9a8b1cf33db,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-1527c904-594d-4f66-86ad-0f710257db84,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-c987af9e-6f02-4f2e-b78a-df8584f3ccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-555ab37d-1d04-4f3d-ac19-498750bf4afe,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-d4cdacd1-b867-444e-8e2b-008b7a88dd19,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-c43ed25c-d13f-4ea4-9e4f-d16cc954601b,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-d0779ef4-2bad-4656-b561-2566539fe334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957782395-172.17.0.12-1597107197869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41455,DS-e8514f17-4494-4960-9796-d1affe07ac27,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-689cae24-a636-4c1a-9ded-f9a8b1cf33db,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-1527c904-594d-4f66-86ad-0f710257db84,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-c987af9e-6f02-4f2e-b78a-df8584f3ccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-555ab37d-1d04-4f3d-ac19-498750bf4afe,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-d4cdacd1-b867-444e-8e2b-008b7a88dd19,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-c43ed25c-d13f-4ea4-9e4f-d16cc954601b,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-d0779ef4-2bad-4656-b561-2566539fe334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468435775-172.17.0.12-1597107269766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42565,DS-84df13ce-154e-40fc-b7c7-2f3e18258881,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-adba5cb4-b25d-419c-9788-be5e4ad25f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-d4c7e0fe-46e2-4130-a607-2eb57605d83f,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-e70b2c93-2b53-427a-b5d5-6e3c40f80234,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-bc8c4d33-9391-4a61-a592-bdc339c88b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-bb87e570-b1c6-4149-8cb2-db94d0b94f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-804470f7-ebfe-4668-be2c-8f14fab9d71a,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-e64958c3-e983-4f8b-b5d8-ada6b57506f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468435775-172.17.0.12-1597107269766:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42565,DS-84df13ce-154e-40fc-b7c7-2f3e18258881,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-adba5cb4-b25d-419c-9788-be5e4ad25f08,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-d4c7e0fe-46e2-4130-a607-2eb57605d83f,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-e70b2c93-2b53-427a-b5d5-6e3c40f80234,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-bc8c4d33-9391-4a61-a592-bdc339c88b44,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-bb87e570-b1c6-4149-8cb2-db94d0b94f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-804470f7-ebfe-4668-be2c-8f14fab9d71a,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-e64958c3-e983-4f8b-b5d8-ada6b57506f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.idle_timeout.ms
component: hdfs:NameNode
v1: 10000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781360372-172.17.0.12-1597107301369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44367,DS-4cd3e600-d9b2-4c6e-ac05-4d4b204a21dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-cb77e55d-07c9-4cbd-8b85-0f3e7e08482e,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-730b5d80-da03-41de-9870-8899a8b38423,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-6c2da5a7-6eea-4941-a883-6ca8d179eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-e1442c19-c06d-4b4f-9986-ae55791dd2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-bb73f258-54b2-4e59-9c33-589f36ee1159,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-3e9eba79-1d25-4f9d-abf3-1a180fa70be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-c7084508-31fa-4061-86cf-918fbf4af006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781360372-172.17.0.12-1597107301369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44367,DS-4cd3e600-d9b2-4c6e-ac05-4d4b204a21dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-cb77e55d-07c9-4cbd-8b85-0f3e7e08482e,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-730b5d80-da03-41de-9870-8899a8b38423,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-6c2da5a7-6eea-4941-a883-6ca8d179eacd,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-e1442c19-c06d-4b4f-9986-ae55791dd2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-bb73f258-54b2-4e59-9c33-589f36ee1159,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-3e9eba79-1d25-4f9d-abf3-1a180fa70be0,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-c7084508-31fa-4061-86cf-918fbf4af006,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5288
