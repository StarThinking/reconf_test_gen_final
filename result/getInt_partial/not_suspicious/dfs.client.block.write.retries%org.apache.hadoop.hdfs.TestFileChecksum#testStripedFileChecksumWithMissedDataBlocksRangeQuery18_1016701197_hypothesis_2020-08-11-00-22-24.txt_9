reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803177258-172.17.0.8-1597105594758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-aa2a36d6-ac19-47f1-933e-510fe3a713c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-4e4ed493-724a-4735-9e11-159b7015839b,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-062f3c5a-394f-4959-997b-d3e911a0eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-f79ad1c8-afe7-468e-bbdb-92c4b7311b67,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-054e0d07-5e01-4ab5-93d0-95aff95642d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-988e9b80-0c61-4952-9bbb-e52aa0ce5b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-7261a366-c005-412a-90f0-99c5fb579269,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-8b4ffd37-8f5f-4e05-bb06-4129c26341be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803177258-172.17.0.8-1597105594758:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35193,DS-aa2a36d6-ac19-47f1-933e-510fe3a713c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-4e4ed493-724a-4735-9e11-159b7015839b,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-062f3c5a-394f-4959-997b-d3e911a0eb38,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-f79ad1c8-afe7-468e-bbdb-92c4b7311b67,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-054e0d07-5e01-4ab5-93d0-95aff95642d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-988e9b80-0c61-4952-9bbb-e52aa0ce5b16,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-7261a366-c005-412a-90f0-99c5fb579269,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-8b4ffd37-8f5f-4e05-bb06-4129c26341be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738814337-172.17.0.8-1597105628146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34240,DS-fb7ea625-6b54-4aea-8c78-6af8ad10778b,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-f98a1176-4621-45c4-9f89-39ca122d4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-dde2f4bd-9c8a-4410-bce6-4ee85cce66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-5dcb5c8c-9ebe-4935-9171-36917c0c97a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-0bfb9d29-09b2-43d8-b092-ae7672952214,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-14b73a51-2060-48ce-ac25-0c025a69af17,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-fdc0d579-71e5-41c5-85ee-398f3ac06816,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-c60c8833-0d5e-4ba3-9fbf-c7d92256c775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-738814337-172.17.0.8-1597105628146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34240,DS-fb7ea625-6b54-4aea-8c78-6af8ad10778b,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-f98a1176-4621-45c4-9f89-39ca122d4a65,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-dde2f4bd-9c8a-4410-bce6-4ee85cce66c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-5dcb5c8c-9ebe-4935-9171-36917c0c97a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-0bfb9d29-09b2-43d8-b092-ae7672952214,DISK], DatanodeInfoWithStorage[127.0.0.1:34037,DS-14b73a51-2060-48ce-ac25-0c025a69af17,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-fdc0d579-71e5-41c5-85ee-398f3ac06816,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-c60c8833-0d5e-4ba3-9fbf-c7d92256c775,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190343809-172.17.0.8-1597106048165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-0e8e53bf-1498-4b55-b7c0-44295db867cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-41605614-dc93-43e7-a9c2-0fd36865d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-f608fc0c-cc4d-4b2c-b1dc-a1c69e345b79,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-2bbcac01-1d30-4fa5-87f5-4f71397e7f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-0f56b347-1413-4a70-ae82-df6c0884b24d,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-45a8d929-d019-4e07-8659-758fd7f2f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-6e6a07e6-f982-4f33-819d-3b097a616672,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-1b941d00-64a1-484b-b83f-0ec903f3be6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190343809-172.17.0.8-1597106048165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-0e8e53bf-1498-4b55-b7c0-44295db867cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-41605614-dc93-43e7-a9c2-0fd36865d6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-f608fc0c-cc4d-4b2c-b1dc-a1c69e345b79,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-2bbcac01-1d30-4fa5-87f5-4f71397e7f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-0f56b347-1413-4a70-ae82-df6c0884b24d,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-45a8d929-d019-4e07-8659-758fd7f2f2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-6e6a07e6-f982-4f33-819d-3b097a616672,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-1b941d00-64a1-484b-b83f-0ec903f3be6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139241514-172.17.0.8-1597106114873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46549,DS-682bac2b-d24d-408d-ba63-f00bd041e4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-80e90625-a535-42be-ab88-4403a6775378,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-2120111d-e8f2-4b02-886c-bd0493d5cc15,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-6aa1337a-ae66-4cb9-b54a-9d8e755725c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-d7a79c63-d576-4cb6-9442-81446eb08712,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-67b605b7-a212-4c42-b5f4-3e7385b79e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-340101e1-607f-45f2-86a6-a87eee95cd24,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-e24507b7-5a00-45a5-8b2a-ab41a72805ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1139241514-172.17.0.8-1597106114873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46549,DS-682bac2b-d24d-408d-ba63-f00bd041e4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-80e90625-a535-42be-ab88-4403a6775378,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-2120111d-e8f2-4b02-886c-bd0493d5cc15,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-6aa1337a-ae66-4cb9-b54a-9d8e755725c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-d7a79c63-d576-4cb6-9442-81446eb08712,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-67b605b7-a212-4c42-b5f4-3e7385b79e82,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-340101e1-607f-45f2-86a6-a87eee95cd24,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-e24507b7-5a00-45a5-8b2a-ab41a72805ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378706002-172.17.0.8-1597106259721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-39e8d43d-f34b-4525-ae82-9cd67492cb88,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-409f967a-c55b-4a97-9668-9dd0699b1efd,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-4379e646-02a5-4d99-8ac3-8730fc400562,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-94f55482-f4fa-49b6-9481-94ca47f050fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-6ba577c7-1a90-4366-bf93-34fd81bfda9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-12306631-2521-4e82-bf61-7a713ef18992,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-48f27556-5be5-4c00-abfc-29f4a2a72e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-1101aa58-b5a8-4c9c-ac11-57fa2917afbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-378706002-172.17.0.8-1597106259721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42229,DS-39e8d43d-f34b-4525-ae82-9cd67492cb88,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-409f967a-c55b-4a97-9668-9dd0699b1efd,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-4379e646-02a5-4d99-8ac3-8730fc400562,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-94f55482-f4fa-49b6-9481-94ca47f050fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-6ba577c7-1a90-4366-bf93-34fd81bfda9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-12306631-2521-4e82-bf61-7a713ef18992,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-48f27556-5be5-4c00-abfc-29f4a2a72e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-1101aa58-b5a8-4c9c-ac11-57fa2917afbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844510915-172.17.0.8-1597106809233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-af7756f9-dca3-4106-83dd-ac407e8d770d,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-99e65d01-df74-4368-9bd3-751350a0f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-0e5ab651-1d7d-4aa7-9f1a-39bde1284638,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-70dd0905-8d13-497a-a141-942528021004,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-0ba9a654-7498-4034-8d6e-4cfc0aae9265,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-adba0720-5ff3-43ce-a507-cac0ba4fca23,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-54b1a054-ad94-4b59-92e8-5a3267e371a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-dba1f7ac-bd3f-428c-b196-552441a68ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1844510915-172.17.0.8-1597106809233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-af7756f9-dca3-4106-83dd-ac407e8d770d,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-99e65d01-df74-4368-9bd3-751350a0f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-0e5ab651-1d7d-4aa7-9f1a-39bde1284638,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-70dd0905-8d13-497a-a141-942528021004,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-0ba9a654-7498-4034-8d6e-4cfc0aae9265,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-adba0720-5ff3-43ce-a507-cac0ba4fca23,DISK], DatanodeInfoWithStorage[127.0.0.1:32821,DS-54b1a054-ad94-4b59-92e8-5a3267e371a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-dba1f7ac-bd3f-428c-b196-552441a68ed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135718512-172.17.0.8-1597106973854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40663,DS-15f441a0-4379-49f6-a923-3819ba3d1dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-a4c5d9eb-57da-40ce-9f65-213f77fef59e,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-8415a332-9c8c-418e-a04f-4e814e3165db,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-5825f2da-9e5e-4296-bcc9-5892e25d3626,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-5ef6bc5f-3d49-40c4-8199-ec56932286d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-743c46c0-0032-4309-ae55-ce29ec96f920,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-92a17df1-b6a3-47f8-a6ea-03aa19207e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-ff6f6920-51de-4fb0-b28b-fff104812536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135718512-172.17.0.8-1597106973854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40663,DS-15f441a0-4379-49f6-a923-3819ba3d1dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-a4c5d9eb-57da-40ce-9f65-213f77fef59e,DISK], DatanodeInfoWithStorage[127.0.0.1:43585,DS-8415a332-9c8c-418e-a04f-4e814e3165db,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-5825f2da-9e5e-4296-bcc9-5892e25d3626,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-5ef6bc5f-3d49-40c4-8199-ec56932286d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-743c46c0-0032-4309-ae55-ce29ec96f920,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-92a17df1-b6a3-47f8-a6ea-03aa19207e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-ff6f6920-51de-4fb0-b28b-fff104812536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626654289-172.17.0.8-1597107268471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-d737b650-c2c5-4f9d-b648-5aa9cc4939e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-09e4f7c8-6f0f-47bd-a898-7d962d3caaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-96c82c1f-88c9-44c9-9d97-b8da34c8732c,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-0ffec3e7-3539-4f29-af08-bfee074bb300,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-0fef251e-8ad5-4f2f-ae9c-d5036353c249,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-db91eb97-0696-4fed-98be-6f8e8b48d83c,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-9475bc49-18bb-417f-9327-62e67f035651,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-231930a8-c755-4557-9ee9-ece849deaa65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1626654289-172.17.0.8-1597107268471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-d737b650-c2c5-4f9d-b648-5aa9cc4939e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-09e4f7c8-6f0f-47bd-a898-7d962d3caaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-96c82c1f-88c9-44c9-9d97-b8da34c8732c,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-0ffec3e7-3539-4f29-af08-bfee074bb300,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-0fef251e-8ad5-4f2f-ae9c-d5036353c249,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-db91eb97-0696-4fed-98be-6f8e8b48d83c,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-9475bc49-18bb-417f-9327-62e67f035651,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-231930a8-c755-4557-9ee9-ece849deaa65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300206265-172.17.0.8-1597107655518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-7c9814e2-58b2-4826-a923-08d6a19817ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-4b61e48e-1517-486e-8355-20b9a60a0ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-57abc8a9-feaa-45c0-ba44-4ef81f531fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-2509613e-eac1-41ac-82e4-e03b73c69c41,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-15f85d0d-01ee-4c67-bcd3-5c006375eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-43f61556-babb-4767-bf46-a1f658343bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-e640bf06-60a5-4e90-80b1-733bf99d0d71,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-7d19bfb8-9236-43c3-8ede-2a6d0cceb31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300206265-172.17.0.8-1597107655518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41429,DS-7c9814e2-58b2-4826-a923-08d6a19817ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-4b61e48e-1517-486e-8355-20b9a60a0ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-57abc8a9-feaa-45c0-ba44-4ef81f531fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-2509613e-eac1-41ac-82e4-e03b73c69c41,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-15f85d0d-01ee-4c67-bcd3-5c006375eef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-43f61556-babb-4767-bf46-a1f658343bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-e640bf06-60a5-4e90-80b1-733bf99d0d71,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-7d19bfb8-9236-43c3-8ede-2a6d0cceb31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670634578-172.17.0.8-1597107836736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-b41557d3-f7e8-4914-b606-35bc02ff8247,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-ef3721b2-86b7-473c-8928-280cf3641d54,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-496e1a68-b5ed-41a3-b7bb-7a8f13854024,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-3c8e084d-b96d-412e-8483-a23a8037b517,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-f7cd8d41-9690-4aeb-a275-2c37c6b635dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-fb4744a9-5dcd-48d4-8578-228978904e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-66a6d08c-0b83-4e52-a107-eb7d054459f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-cbb9eb1e-bc2d-42c1-bf5c-ac1cee22bf7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670634578-172.17.0.8-1597107836736:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32912,DS-b41557d3-f7e8-4914-b606-35bc02ff8247,DISK], DatanodeInfoWithStorage[127.0.0.1:45814,DS-ef3721b2-86b7-473c-8928-280cf3641d54,DISK], DatanodeInfoWithStorage[127.0.0.1:35866,DS-496e1a68-b5ed-41a3-b7bb-7a8f13854024,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-3c8e084d-b96d-412e-8483-a23a8037b517,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-f7cd8d41-9690-4aeb-a275-2c37c6b635dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-fb4744a9-5dcd-48d4-8578-228978904e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-66a6d08c-0b83-4e52-a107-eb7d054459f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-cbb9eb1e-bc2d-42c1-bf5c-ac1cee22bf7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555877448-172.17.0.8-1597108096295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37506,DS-7a81083d-fa6d-45d0-bb51-12077e135c85,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-d0093666-ed1a-45c4-b67d-7a87a784a681,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-cdfc95c7-1083-45fd-9aec-4ad1e83bb42c,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-8d4bc2f7-6235-40a8-aa04-566347af3a70,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-0f6c4dae-165f-49ce-be8d-b2342d6c5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-05b9401b-2bfc-49ee-9c22-f1f8d6d30739,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-f8a59977-2141-46a6-bd31-8800a7d52c04,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-8582cb8f-fadc-42e5-a207-1ff926edd66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555877448-172.17.0.8-1597108096295:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37506,DS-7a81083d-fa6d-45d0-bb51-12077e135c85,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-d0093666-ed1a-45c4-b67d-7a87a784a681,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-cdfc95c7-1083-45fd-9aec-4ad1e83bb42c,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-8d4bc2f7-6235-40a8-aa04-566347af3a70,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-0f6c4dae-165f-49ce-be8d-b2342d6c5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-05b9401b-2bfc-49ee-9c22-f1f8d6d30739,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-f8a59977-2141-46a6-bd31-8800a7d52c04,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-8582cb8f-fadc-42e5-a207-1ff926edd66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129002164-172.17.0.8-1597108381298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-71b4fa79-076d-49fb-99b1-7b25dbf81679,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-0077c048-54b2-43f7-b0c9-4187da7b1dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-6dc023d0-650b-47bd-a8cb-bb97af7fd311,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-b48979ec-0d45-44c9-b91b-3425d92fb2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-267eba1e-e9cb-4fdf-bcf1-ef8c87bb5092,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-f4b9d5f5-5fab-4ff8-8a40-83c0f53fe307,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-b350d561-8f14-4651-8aff-46d59ed5ad9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-e00e3b62-2bcc-43f9-bc36-f57800fc0a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1129002164-172.17.0.8-1597108381298:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-71b4fa79-076d-49fb-99b1-7b25dbf81679,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-0077c048-54b2-43f7-b0c9-4187da7b1dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-6dc023d0-650b-47bd-a8cb-bb97af7fd311,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-b48979ec-0d45-44c9-b91b-3425d92fb2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-267eba1e-e9cb-4fdf-bcf1-ef8c87bb5092,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-f4b9d5f5-5fab-4ff8-8a40-83c0f53fe307,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-b350d561-8f14-4651-8aff-46d59ed5ad9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-e00e3b62-2bcc-43f9-bc36-f57800fc0a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308983747-172.17.0.8-1597108455149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37960,DS-a35ae5c5-5607-4bd5-add1-bfbde997ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-99292efb-aad6-4190-87ab-4a34ddf9b397,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-475d4643-c6bd-44b8-9e56-cd58219ecb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-cc85547a-ed22-4440-97c6-c3072a3872c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-555ac288-c208-4b1f-8c79-927d838f97ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-2809adcc-1869-41d5-9dd9-54b7c3e60eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-1aa762b3-2b28-4197-98e3-903fdcb1cf09,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-96ea9326-c3ff-4cde-9112-714bdff36de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1308983747-172.17.0.8-1597108455149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37960,DS-a35ae5c5-5607-4bd5-add1-bfbde997ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-99292efb-aad6-4190-87ab-4a34ddf9b397,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-475d4643-c6bd-44b8-9e56-cd58219ecb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-cc85547a-ed22-4440-97c6-c3072a3872c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-555ac288-c208-4b1f-8c79-927d838f97ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-2809adcc-1869-41d5-9dd9-54b7c3e60eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-1aa762b3-2b28-4197-98e3-903fdcb1cf09,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-96ea9326-c3ff-4cde-9112-714bdff36de1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960698714-172.17.0.8-1597108676848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33507,DS-9cdf74d5-a245-4c18-8c56-9e3b0cbe64da,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-b9dd9a23-eab8-4ed3-8755-307dfdfac6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-99ef0efa-26e7-4991-9186-19cf8ae04c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-30a2ab97-bad1-44cc-901e-9f8833724073,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-27ca4fba-8a99-4b92-8465-f9fab74c3329,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c34a3d00-1934-4768-b554-75bd4ccf9bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-45f6d79f-271a-4284-9abe-0bb694cefa60,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-f1c5d372-4030-4608-aac0-27940bb5761b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-960698714-172.17.0.8-1597108676848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33507,DS-9cdf74d5-a245-4c18-8c56-9e3b0cbe64da,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-b9dd9a23-eab8-4ed3-8755-307dfdfac6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-99ef0efa-26e7-4991-9186-19cf8ae04c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-30a2ab97-bad1-44cc-901e-9f8833724073,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-27ca4fba-8a99-4b92-8465-f9fab74c3329,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c34a3d00-1934-4768-b554-75bd4ccf9bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-45f6d79f-271a-4284-9abe-0bb694cefa60,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-f1c5d372-4030-4608-aac0-27940bb5761b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007365075-172.17.0.8-1597108748793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33053,DS-62d96026-6fc1-4215-9f48-2494fc510d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-7669da8c-7673-4fb8-a619-ff10cb29d49f,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-589462f8-1b31-4fd4-869b-dae771dfcf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-e74c4979-4e53-4f74-9eb5-8674403a6756,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-d02c1fe0-1222-4da2-b37c-29c79ae82c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-c7659915-d5c2-4c15-a054-862b85f02b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-e1d2fca5-2f90-4184-b684-631534c51858,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-aad31b15-8c98-4b29-8c6c-7ad5708d104c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1007365075-172.17.0.8-1597108748793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33053,DS-62d96026-6fc1-4215-9f48-2494fc510d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-7669da8c-7673-4fb8-a619-ff10cb29d49f,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-589462f8-1b31-4fd4-869b-dae771dfcf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-e74c4979-4e53-4f74-9eb5-8674403a6756,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-d02c1fe0-1222-4da2-b37c-29c79ae82c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-c7659915-d5c2-4c15-a054-862b85f02b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-e1d2fca5-2f90-4184-b684-631534c51858,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-aad31b15-8c98-4b29-8c6c-7ad5708d104c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497615533-172.17.0.8-1597109322586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39504,DS-ffb91ce0-810f-4d0e-88b2-bb790b6e4873,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-256330dd-181b-4f8d-b039-7e32cd681e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-bb371b0d-f8e4-455e-beeb-dffaf777c016,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-a2266227-4a10-4ada-96f7-d25f2b1ec49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-de459397-8e09-45ff-b1d7-1f228a58f007,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-4f8150b1-c747-4174-be21-b491577e3f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-8901c58d-0dc3-4ce9-9fa2-5bdd1e71f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-398637f7-b4f1-42e8-99f7-48d564fa79bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1497615533-172.17.0.8-1597109322586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39504,DS-ffb91ce0-810f-4d0e-88b2-bb790b6e4873,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-256330dd-181b-4f8d-b039-7e32cd681e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-bb371b0d-f8e4-455e-beeb-dffaf777c016,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-a2266227-4a10-4ada-96f7-d25f2b1ec49a,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-de459397-8e09-45ff-b1d7-1f228a58f007,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-4f8150b1-c747-4174-be21-b491577e3f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-8901c58d-0dc3-4ce9-9fa2-5bdd1e71f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-398637f7-b4f1-42e8-99f7-48d564fa79bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874130991-172.17.0.8-1597109700706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-a441fcdd-37f6-42a7-8f0a-90fccf11e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-452d0da6-6bcf-4d32-87a0-bd94e4147952,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-cdd12022-f300-4093-bb3e-d27d83020f26,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-0f583263-ff5b-42a3-98e0-1f97f604017a,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-771697fd-fdf3-4cce-8a57-e9b769d5092e,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-89d84c5e-c8b0-4a90-8521-24198f96870e,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-65f49032-a5bb-4e07-a31b-2dd182685521,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-5ee027ab-ec9e-4676-b421-04c888a53633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1874130991-172.17.0.8-1597109700706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45117,DS-a441fcdd-37f6-42a7-8f0a-90fccf11e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-452d0da6-6bcf-4d32-87a0-bd94e4147952,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-cdd12022-f300-4093-bb3e-d27d83020f26,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-0f583263-ff5b-42a3-98e0-1f97f604017a,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-771697fd-fdf3-4cce-8a57-e9b769d5092e,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-89d84c5e-c8b0-4a90-8521-24198f96870e,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-65f49032-a5bb-4e07-a31b-2dd182685521,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-5ee027ab-ec9e-4676-b421-04c888a53633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583646990-172.17.0.8-1597110274584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43174,DS-806601c7-7016-4bbd-9199-cdbbcc62b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-46bef575-952c-4ee0-80fd-f4ccf6f8633e,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-0805288b-071d-4a9f-8359-514f57c19593,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-1f768302-2e46-47b0-b317-2e7a136e299b,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-76f9461b-67c3-491c-8102-7616f12cad29,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-f4469eff-6a87-485a-84d3-1d86c9808a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-525a6fb6-3cd2-4d00-bdbb-1e4d98db02d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-2ba928d9-3550-4526-ab37-980f85ba6e70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1583646990-172.17.0.8-1597110274584:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43174,DS-806601c7-7016-4bbd-9199-cdbbcc62b78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-46bef575-952c-4ee0-80fd-f4ccf6f8633e,DISK], DatanodeInfoWithStorage[127.0.0.1:32887,DS-0805288b-071d-4a9f-8359-514f57c19593,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-1f768302-2e46-47b0-b317-2e7a136e299b,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-76f9461b-67c3-491c-8102-7616f12cad29,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-f4469eff-6a87-485a-84d3-1d86c9808a49,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-525a6fb6-3cd2-4d00-bdbb-1e4d98db02d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38086,DS-2ba928d9-3550-4526-ab37-980f85ba6e70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.retries
component: hdfs:NameNode
v1: 1000
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41671664-172.17.0.8-1597110448829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40534,DS-855003c7-c790-4b69-8bdf-6026061da8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-eda83cc7-68c3-4127-b179-1bc094b2537a,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-4964fa4b-8798-49cd-9313-bc09bc4bbf60,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-bd4829c9-a7ed-461d-9820-0e209b9f226c,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-6992e469-c9de-4198-8d1f-9690d63e39d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-9cf26a2a-bbec-4765-986f-a08dc7ea519b,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-6c68f998-e14f-4ebb-b7b8-3e4216267253,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-0e0d1b48-eceb-4b2a-82b6-fd33027c480e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41671664-172.17.0.8-1597110448829:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40534,DS-855003c7-c790-4b69-8bdf-6026061da8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-eda83cc7-68c3-4127-b179-1bc094b2537a,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-4964fa4b-8798-49cd-9313-bc09bc4bbf60,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-bd4829c9-a7ed-461d-9820-0e209b9f226c,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-6992e469-c9de-4198-8d1f-9690d63e39d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-9cf26a2a-bbec-4765-986f-a08dc7ea519b,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-6c68f998-e14f-4ebb-b7b8-3e4216267253,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-0e0d1b48-eceb-4b2a-82b6-fd33027c480e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5162
