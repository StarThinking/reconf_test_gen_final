reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866601239-172.17.0.6-1597042045883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-731cd69d-fe87-4847-9ae3-edc02abec4da,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-7b2c38f2-7900-4011-a254-5e2ea7ecb265,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-5216145b-db08-4a78-8cbc-d24f2fa8a61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-fcf612a5-909c-40b1-aca7-e4a4217d2131,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-3f89e257-58a2-4d21-b1b2-f2cba0f24189,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-ef319908-d732-4995-b57f-d5ca2fc16c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-4fc3f38f-324b-4baa-9e43-729f2fd01187,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-eed06a77-c04d-4303-9299-65da37d12e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866601239-172.17.0.6-1597042045883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44058,DS-731cd69d-fe87-4847-9ae3-edc02abec4da,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-7b2c38f2-7900-4011-a254-5e2ea7ecb265,DISK], DatanodeInfoWithStorage[127.0.0.1:44288,DS-5216145b-db08-4a78-8cbc-d24f2fa8a61b,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-fcf612a5-909c-40b1-aca7-e4a4217d2131,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-3f89e257-58a2-4d21-b1b2-f2cba0f24189,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-ef319908-d732-4995-b57f-d5ca2fc16c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-4fc3f38f-324b-4baa-9e43-729f2fd01187,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-eed06a77-c04d-4303-9299-65da37d12e3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161753889-172.17.0.6-1597042190733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42734,DS-2d2937fd-06f7-492b-abfc-94cd87fc4773,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-df3d33cf-fcc9-43ad-81cf-bdaf21a47a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-bfd4b5f6-e1c6-409c-8926-dda9a7409a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-bd666a31-b844-4c21-91f1-913ea18de19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-a0e8cf80-39ea-496e-8444-62973794875d,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-9ea6610d-baab-466f-a47b-bc936ec444f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-252963b7-3ac8-4450-b08d-4d80345190df,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-9904ceaa-9b38-4803-8aae-435acced4126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161753889-172.17.0.6-1597042190733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42734,DS-2d2937fd-06f7-492b-abfc-94cd87fc4773,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-df3d33cf-fcc9-43ad-81cf-bdaf21a47a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-bfd4b5f6-e1c6-409c-8926-dda9a7409a02,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-bd666a31-b844-4c21-91f1-913ea18de19d,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-a0e8cf80-39ea-496e-8444-62973794875d,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-9ea6610d-baab-466f-a47b-bc936ec444f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-252963b7-3ac8-4450-b08d-4d80345190df,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-9904ceaa-9b38-4803-8aae-435acced4126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687129281-172.17.0.6-1597042260296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43434,DS-eb147c3a-1b49-4a00-9428-fab86ecd423f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-27db35f6-352e-4eb3-9f3f-1fafa5add21c,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-71471971-3b6a-4ef2-b73d-af538e6786a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-45fd3480-f303-4fe8-bb86-f324e35707bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-cf54519f-20ba-44fb-bae9-c08e32b47899,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-963d2e29-6900-471a-a19a-10b02c67539d,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-289c4519-db8e-4bcd-a292-df63f82d805b,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-11102d31-d6b4-4f77-a474-81969d77c874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687129281-172.17.0.6-1597042260296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43434,DS-eb147c3a-1b49-4a00-9428-fab86ecd423f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-27db35f6-352e-4eb3-9f3f-1fafa5add21c,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-71471971-3b6a-4ef2-b73d-af538e6786a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-45fd3480-f303-4fe8-bb86-f324e35707bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-cf54519f-20ba-44fb-bae9-c08e32b47899,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-963d2e29-6900-471a-a19a-10b02c67539d,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-289c4519-db8e-4bcd-a292-df63f82d805b,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-11102d31-d6b4-4f77-a474-81969d77c874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126201228-172.17.0.6-1597042363265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-9a952800-2fff-4f5d-a3b8-0fe25119e9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-4b48e8df-5a63-4a94-adc9-1ca87fa5d7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-0ec3656a-c9a0-4cc4-a141-39dfb68c3361,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-c8a3c965-770e-440a-97eb-bf60b391b6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-0a140871-9565-4d8c-811c-62ac0a99ccb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-7b415fb5-0541-4c1a-a313-03e7560fe129,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-37cbb3ba-4350-47fc-ad94-6934c5657a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-252c3167-8ce7-4b00-9972-48b62e3497cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126201228-172.17.0.6-1597042363265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37782,DS-9a952800-2fff-4f5d-a3b8-0fe25119e9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-4b48e8df-5a63-4a94-adc9-1ca87fa5d7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-0ec3656a-c9a0-4cc4-a141-39dfb68c3361,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-c8a3c965-770e-440a-97eb-bf60b391b6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36483,DS-0a140871-9565-4d8c-811c-62ac0a99ccb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-7b415fb5-0541-4c1a-a313-03e7560fe129,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-37cbb3ba-4350-47fc-ad94-6934c5657a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-252c3167-8ce7-4b00-9972-48b62e3497cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904659147-172.17.0.6-1597042489709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37814,DS-6bb5b0f1-6fb1-45b9-8dba-f123cf3acbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-33ef5cdb-a193-424e-b14c-924bd73c4d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-688ef918-6115-4a71-971e-00fa8b80df43,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-ee9a0be7-fc4f-497b-a84e-f74286c54a17,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-c91aa89e-9238-443f-9f79-5ab770209391,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-5c4b243b-f36b-49d6-a09c-a11a3c53b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-560495d5-211a-43d3-a266-8add318b74d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-95c21079-00eb-4926-b5c8-b32dc28c8658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904659147-172.17.0.6-1597042489709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37814,DS-6bb5b0f1-6fb1-45b9-8dba-f123cf3acbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-33ef5cdb-a193-424e-b14c-924bd73c4d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-688ef918-6115-4a71-971e-00fa8b80df43,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-ee9a0be7-fc4f-497b-a84e-f74286c54a17,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-c91aa89e-9238-443f-9f79-5ab770209391,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-5c4b243b-f36b-49d6-a09c-a11a3c53b0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-560495d5-211a-43d3-a266-8add318b74d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-95c21079-00eb-4926-b5c8-b32dc28c8658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032947752-172.17.0.6-1597043554007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36000,DS-e463f30d-67ed-44e2-a14f-d33ec4ca534e,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-82ef2842-e12b-4785-bca3-e0e02b10a72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-136e375f-9517-47b7-a6c5-b040ad6aca69,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-c50a2994-a296-4eb0-930b-5d00d4c04f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-66edc463-660b-4c6f-94f9-12bedf168d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-22b95794-4ea8-469c-8291-b362506d01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-77e398aa-9116-4575-a896-198c631026a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-3a09e119-2cb0-4738-828a-8c7cebf12e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032947752-172.17.0.6-1597043554007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36000,DS-e463f30d-67ed-44e2-a14f-d33ec4ca534e,DISK], DatanodeInfoWithStorage[127.0.0.1:41732,DS-82ef2842-e12b-4785-bca3-e0e02b10a72b,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-136e375f-9517-47b7-a6c5-b040ad6aca69,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-c50a2994-a296-4eb0-930b-5d00d4c04f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-66edc463-660b-4c6f-94f9-12bedf168d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-22b95794-4ea8-469c-8291-b362506d01fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-77e398aa-9116-4575-a896-198c631026a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-3a09e119-2cb0-4738-828a-8c7cebf12e76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545954883-172.17.0.6-1597043684401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38366,DS-8f715882-f5d7-440a-ac4c-98827a6f46c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-94868482-e4ff-4cf4-a160-52a2ec901d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-0a21ebba-c5f7-471f-8af4-3fe21047d2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-e575fb1c-3a68-4e23-994d-8c011424eab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-a78874b5-26ce-48f1-9790-ee6f59ff9964,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-2f94f1e5-0f4b-4c4a-b232-ae5750a7ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-48c60624-a82c-4546-954d-fb5fb59531ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-57e8ccfa-b870-4554-87d8-0896e184ac62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545954883-172.17.0.6-1597043684401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38366,DS-8f715882-f5d7-440a-ac4c-98827a6f46c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-94868482-e4ff-4cf4-a160-52a2ec901d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-0a21ebba-c5f7-471f-8af4-3fe21047d2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-e575fb1c-3a68-4e23-994d-8c011424eab1,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-a78874b5-26ce-48f1-9790-ee6f59ff9964,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-2f94f1e5-0f4b-4c4a-b232-ae5750a7ec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-48c60624-a82c-4546-954d-fb5fb59531ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-57e8ccfa-b870-4554-87d8-0896e184ac62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950576645-172.17.0.6-1597044095728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32958,DS-d3b37a20-b02a-4c6c-a40a-66095fb0c8db,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-096605de-e2b5-484f-9a67-a1a8aa8cd080,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-4eade619-0fe0-4b05-99fd-b35d0016688c,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-ce1df7c9-1ff9-42b3-b2d1-70ad9bd32173,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-bbd82d69-32b4-4d93-86d2-c86cfdc0ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-5bef0a00-b416-48cf-a3eb-172533ad56d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-b0e34b39-7dc2-4a4d-bb78-6eb86045a4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-ab2afd13-f773-4ae0-86b3-c9fffbaf19cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-950576645-172.17.0.6-1597044095728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32958,DS-d3b37a20-b02a-4c6c-a40a-66095fb0c8db,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-096605de-e2b5-484f-9a67-a1a8aa8cd080,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-4eade619-0fe0-4b05-99fd-b35d0016688c,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-ce1df7c9-1ff9-42b3-b2d1-70ad9bd32173,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-bbd82d69-32b4-4d93-86d2-c86cfdc0ff31,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-5bef0a00-b416-48cf-a3eb-172533ad56d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-b0e34b39-7dc2-4a4d-bb78-6eb86045a4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-ab2afd13-f773-4ae0-86b3-c9fffbaf19cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540370055-172.17.0.6-1597044476216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-cefeec2a-756a-42dd-901b-c0d9f48a30bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-b30beb15-b3e3-44bb-a7f5-baddf61f6262,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-c5e59d71-9e7e-40c8-a845-7eaddce03c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-73aeeb99-044e-461b-be57-f6b86e44e471,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-719f8c0c-a672-4fdd-9b45-a3c9cbc59dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-5d0470c1-dbeb-4fa5-b890-0aa5c02bd915,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-c8d6b844-e0b9-4ab3-8e21-a671de7961d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-7c43bf6d-aa12-4c2f-9d59-8290f575a974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540370055-172.17.0.6-1597044476216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41224,DS-cefeec2a-756a-42dd-901b-c0d9f48a30bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-b30beb15-b3e3-44bb-a7f5-baddf61f6262,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-c5e59d71-9e7e-40c8-a845-7eaddce03c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-73aeeb99-044e-461b-be57-f6b86e44e471,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-719f8c0c-a672-4fdd-9b45-a3c9cbc59dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-5d0470c1-dbeb-4fa5-b890-0aa5c02bd915,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-c8d6b844-e0b9-4ab3-8e21-a671de7961d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-7c43bf6d-aa12-4c2f-9d59-8290f575a974,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733743774-172.17.0.6-1597044512199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-e147bb01-b135-4c89-8a2d-5d498879584d,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-50d6a33b-f810-4ba8-9fdc-39858519c562,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-f38586ba-508c-42b7-99c1-b4c5bb96f622,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-cc97a679-9ad2-42a4-b30e-69ba8868758f,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-9a8f646c-7fd8-43cd-8b41-252330293bac,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-f64392a1-8d43-4416-874d-9304024454d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-0f3b471c-19d2-4a20-bfbf-87c469e4fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-3bde74f5-f674-4f84-ad55-cd5a135f48d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-733743774-172.17.0.6-1597044512199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43242,DS-e147bb01-b135-4c89-8a2d-5d498879584d,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-50d6a33b-f810-4ba8-9fdc-39858519c562,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-f38586ba-508c-42b7-99c1-b4c5bb96f622,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-cc97a679-9ad2-42a4-b30e-69ba8868758f,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-9a8f646c-7fd8-43cd-8b41-252330293bac,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-f64392a1-8d43-4416-874d-9304024454d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-0f3b471c-19d2-4a20-bfbf-87c469e4fbca,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-3bde74f5-f674-4f84-ad55-cd5a135f48d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737717206-172.17.0.6-1597044679940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-da6fe92a-fcd0-4bfc-97cd-f9a118fdc1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-42577335-82c3-45ce-a192-954b3ee05d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-5d1598b4-3d93-45a2-9bf7-6fda30fe42d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-cc1c5694-0aa8-4ca4-80fa-8aef4982121f,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e1acfa5a-0d36-4353-ad94-2f308fdb842f,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-0ae49208-f1e1-4569-a338-e73969b7a005,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-515b8ace-ae33-458a-b2b3-207e0618371d,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-fd43bce5-8d70-4c05-9ffa-4fc6b5bc0db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737717206-172.17.0.6-1597044679940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-da6fe92a-fcd0-4bfc-97cd-f9a118fdc1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-42577335-82c3-45ce-a192-954b3ee05d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-5d1598b4-3d93-45a2-9bf7-6fda30fe42d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-cc1c5694-0aa8-4ca4-80fa-8aef4982121f,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-e1acfa5a-0d36-4353-ad94-2f308fdb842f,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-0ae49208-f1e1-4569-a338-e73969b7a005,DISK], DatanodeInfoWithStorage[127.0.0.1:32779,DS-515b8ace-ae33-458a-b2b3-207e0618371d,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-fd43bce5-8d70-4c05-9ffa-4fc6b5bc0db7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765194780-172.17.0.6-1597045156530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40512,DS-dd5a18cd-8a80-4859-9bb3-c937fccf5ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-0e3a7a3e-bcdb-4b56-9a30-4b61b24d6ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-672c2437-5c07-4c13-aec7-9c39575a3c43,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-3978f586-9680-493c-bb87-d3fb58329198,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-df9d76e7-18ee-410b-ad9e-a6458ec5cc83,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-9c98ce20-b6bc-4306-9cd5-5aace6e4ae24,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-da79f145-1dc5-4702-bf26-ace0c99557af,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-3ab7b2f0-c540-4aae-91fb-a8048f199c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765194780-172.17.0.6-1597045156530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40512,DS-dd5a18cd-8a80-4859-9bb3-c937fccf5ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-0e3a7a3e-bcdb-4b56-9a30-4b61b24d6ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-672c2437-5c07-4c13-aec7-9c39575a3c43,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-3978f586-9680-493c-bb87-d3fb58329198,DISK], DatanodeInfoWithStorage[127.0.0.1:41521,DS-df9d76e7-18ee-410b-ad9e-a6458ec5cc83,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-9c98ce20-b6bc-4306-9cd5-5aace6e4ae24,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-da79f145-1dc5-4702-bf26-ace0c99557af,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-3ab7b2f0-c540-4aae-91fb-a8048f199c9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671583477-172.17.0.6-1597045490944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-ca22fcbc-b32e-4b60-8433-f01dee1389b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-1b844de6-f851-45a8-afff-34f9f5f2c71f,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-b60e3141-6d44-4d2c-923a-f06bc10a7d48,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-367eb52c-6df6-44a7-b9ef-4e9580a26040,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-4def71f7-eccf-4e87-99e9-c3c6b82d02ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-802d045f-7efa-41b2-b5a3-12a00768ca34,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-a798dee6-6af6-44cb-8422-d4921c40c1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-22f02f0f-b328-45cc-9587-441420a967aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1671583477-172.17.0.6-1597045490944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-ca22fcbc-b32e-4b60-8433-f01dee1389b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-1b844de6-f851-45a8-afff-34f9f5f2c71f,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-b60e3141-6d44-4d2c-923a-f06bc10a7d48,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-367eb52c-6df6-44a7-b9ef-4e9580a26040,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-4def71f7-eccf-4e87-99e9-c3c6b82d02ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42617,DS-802d045f-7efa-41b2-b5a3-12a00768ca34,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-a798dee6-6af6-44cb-8422-d4921c40c1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34740,DS-22f02f0f-b328-45cc-9587-441420a967aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991165022-172.17.0.6-1597045645370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-975d80e3-b209-4172-9d1e-a6a3a34f593a,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-5329bee2-7f5e-4883-b66c-f9de69c5e70f,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-45550e51-14ac-4e2f-a88f-a631f9f4a365,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-0b231f9f-0725-485f-b2b3-950c35bec92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-4900ec8a-0481-4eb6-9d11-3ea3e3a9f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-7ba491e2-21fb-4844-a6a2-0494f03559ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-89a33a29-bf45-4d9a-9478-d2799463db38,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-1840d660-131e-472e-9a79-2f0c87a6c163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991165022-172.17.0.6-1597045645370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-975d80e3-b209-4172-9d1e-a6a3a34f593a,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-5329bee2-7f5e-4883-b66c-f9de69c5e70f,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-45550e51-14ac-4e2f-a88f-a631f9f4a365,DISK], DatanodeInfoWithStorage[127.0.0.1:33653,DS-0b231f9f-0725-485f-b2b3-950c35bec92c,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-4900ec8a-0481-4eb6-9d11-3ea3e3a9f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-7ba491e2-21fb-4844-a6a2-0494f03559ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44918,DS-89a33a29-bf45-4d9a-9478-d2799463db38,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-1840d660-131e-472e-9a79-2f0c87a6c163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258168116-172.17.0.6-1597045683842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40768,DS-a44ca597-a5d7-4774-ae21-5731786546d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-9a519e94-0165-4c8f-973c-53bf3e83cf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-b7af4443-f53a-43d9-b9a4-8ffa78ae384b,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-41fca8d6-083b-424e-8472-b0d87ac7011c,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-c1aa62d0-7f05-4b0e-8060-92da88790293,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-63d7c49a-9267-44f6-9f1b-d64a7aee381c,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-b53f8547-2fff-4a00-a15a-1e6ac22db317,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-800e367b-3874-4c7a-910e-4f8cad188219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-258168116-172.17.0.6-1597045683842:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40768,DS-a44ca597-a5d7-4774-ae21-5731786546d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-9a519e94-0165-4c8f-973c-53bf3e83cf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-b7af4443-f53a-43d9-b9a4-8ffa78ae384b,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-41fca8d6-083b-424e-8472-b0d87ac7011c,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-c1aa62d0-7f05-4b0e-8060-92da88790293,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-63d7c49a-9267-44f6-9f1b-d64a7aee381c,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-b53f8547-2fff-4a00-a15a-1e6ac22db317,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-800e367b-3874-4c7a-910e-4f8cad188219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980313388-172.17.0.6-1597046218007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40114,DS-51fc3831-102a-441f-bfb8-7505a22065ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-1a8b4f1f-27aa-4f4d-93fd-e26b7256ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-704fd530-e63f-4e12-8a9e-c9602c7396e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-0120b03a-e1d2-4bc3-bdb7-70b6d2b0483e,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-c8990d05-1c18-4f30-94d7-654c530b485f,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-29199c70-cf26-443e-80a5-06f3d772cac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-ca9de4e9-a4b9-45e1-8580-00d81fbb2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-1d10c9cc-8973-4fe9-ba28-40bd0095eec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980313388-172.17.0.6-1597046218007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40114,DS-51fc3831-102a-441f-bfb8-7505a22065ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-1a8b4f1f-27aa-4f4d-93fd-e26b7256ede2,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-704fd530-e63f-4e12-8a9e-c9602c7396e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-0120b03a-e1d2-4bc3-bdb7-70b6d2b0483e,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-c8990d05-1c18-4f30-94d7-654c530b485f,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-29199c70-cf26-443e-80a5-06f3d772cac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-ca9de4e9-a4b9-45e1-8580-00d81fbb2ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-1d10c9cc-8973-4fe9-ba28-40bd0095eec8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635409672-172.17.0.6-1597046292339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-cfa6a2cc-7775-4159-a30b-d53059a3b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-9b5705f7-6d13-4eb6-9463-a8835e7482ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-95c84e90-7083-47ed-af5d-23f68112a100,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-73d6405e-dd35-4e7d-b045-e7ff99ddc0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-76842e10-12be-4134-801b-3ecc7fd98b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-e0932684-cea0-4ea9-985f-11c0e0144d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-fbfefc68-da8c-462e-bfc7-ad3e87ce3013,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-395c090d-da94-4175-aaa9-bc2025e8aed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635409672-172.17.0.6-1597046292339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33715,DS-cfa6a2cc-7775-4159-a30b-d53059a3b69f,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-9b5705f7-6d13-4eb6-9463-a8835e7482ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-95c84e90-7083-47ed-af5d-23f68112a100,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-73d6405e-dd35-4e7d-b045-e7ff99ddc0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-76842e10-12be-4134-801b-3ecc7fd98b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-e0932684-cea0-4ea9-985f-11c0e0144d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-fbfefc68-da8c-462e-bfc7-ad3e87ce3013,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-395c090d-da94-4175-aaa9-bc2025e8aed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954171084-172.17.0.6-1597046746865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37467,DS-5acfd90b-b60e-4734-93d1-cc9c35655f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-282641ae-fc3b-4b67-b95f-a6aa56a50747,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-18d45f2f-3d13-448c-acaf-1514c39ef3db,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-07762223-338e-43b4-b23e-24f7847ec73a,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-816f1737-3726-4161-bfed-8b595d058526,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-476a04bf-aee3-4b62-8ad2-8a79f25dd8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-adcb3764-5b5d-4a18-a5a3-3c75a3988b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-6126e39d-9635-4d01-9124-47946b7cbbdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954171084-172.17.0.6-1597046746865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37467,DS-5acfd90b-b60e-4734-93d1-cc9c35655f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-282641ae-fc3b-4b67-b95f-a6aa56a50747,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-18d45f2f-3d13-448c-acaf-1514c39ef3db,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-07762223-338e-43b4-b23e-24f7847ec73a,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-816f1737-3726-4161-bfed-8b595d058526,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-476a04bf-aee3-4b62-8ad2-8a79f25dd8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-adcb3764-5b5d-4a18-a5a3-3c75a3988b81,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-6126e39d-9635-4d01-9124-47946b7cbbdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388091566-172.17.0.6-1597046888143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-4bdb3676-1125-461c-80de-fc8c591155a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-b031c712-e18a-4b55-ac0a-f64ccb45efdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-faa350b4-a5a3-4e31-9931-05bda7bf45b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-9baa2f49-9ca5-42b0-b2c4-48f2bebf7ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-67f8f23f-605e-42f8-8971-2a46396ef89d,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-4683c19d-ea0d-4c3f-a9f2-c7a7d0d31a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-9b68b674-0484-4653-8236-bc74c3c758ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-9b5ad15a-91cd-4694-8c00-6810ed325ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388091566-172.17.0.6-1597046888143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35897,DS-4bdb3676-1125-461c-80de-fc8c591155a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-b031c712-e18a-4b55-ac0a-f64ccb45efdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-faa350b4-a5a3-4e31-9931-05bda7bf45b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-9baa2f49-9ca5-42b0-b2c4-48f2bebf7ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-67f8f23f-605e-42f8-8971-2a46396ef89d,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-4683c19d-ea0d-4c3f-a9f2-c7a7d0d31a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-9b68b674-0484-4653-8236-bc74c3c758ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-9b5ad15a-91cd-4694-8c00-6810ed325ab5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553173827-172.17.0.6-1597047003020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-6216856d-322b-4001-9202-b319fe289dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-5b0d80b1-a481-4df9-90b8-d747eda54f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-f6511332-fba3-42c9-b11f-b686c75a3923,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-7f5b289b-9b3c-46f0-b7a4-55f5f0c7b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-9422719e-eaf3-4b00-87d6-23911760d16f,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-fafe1112-4b6a-465e-9682-f978102e8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-bdeb8c51-5ac2-497e-98e4-a7667c5c9f38,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-0dc0be81-2c5a-422e-9e6b-c01e761ca7fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553173827-172.17.0.6-1597047003020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-6216856d-322b-4001-9202-b319fe289dad,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-5b0d80b1-a481-4df9-90b8-d747eda54f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-f6511332-fba3-42c9-b11f-b686c75a3923,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-7f5b289b-9b3c-46f0-b7a4-55f5f0c7b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-9422719e-eaf3-4b00-87d6-23911760d16f,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-fafe1112-4b6a-465e-9682-f978102e8f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-bdeb8c51-5ac2-497e-98e4-a7667c5c9f38,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-0dc0be81-2c5a-422e-9e6b-c01e761ca7fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.max.request.header.size
component: hdfs:DataNode
v1: 65536
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642466848-172.17.0.6-1597047077772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40151,DS-8018a31d-e153-4f75-aec2-3dbd8c75e0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-57a874cd-f8de-40f6-b2e9-cc27162dbee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-9f70679c-4909-48ec-80ad-4d41e88058b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-9f0e25cc-5773-4519-af2b-7c1a5ba03e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-0b8a7a36-288a-4b7d-83e9-1067a45b8ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-c079161f-e706-47ec-9e86-7ad1ec25d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-9c3a96ef-53a2-49d9-8e66-9f4c1fb4fe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-46f9654f-f9d1-4a2e-8229-f32827520c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642466848-172.17.0.6-1597047077772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40151,DS-8018a31d-e153-4f75-aec2-3dbd8c75e0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-57a874cd-f8de-40f6-b2e9-cc27162dbee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44109,DS-9f70679c-4909-48ec-80ad-4d41e88058b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-9f0e25cc-5773-4519-af2b-7c1a5ba03e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41503,DS-0b8a7a36-288a-4b7d-83e9-1067a45b8ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-c079161f-e706-47ec-9e86-7ad1ec25d9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-9c3a96ef-53a2-49d9-8e66-9f4c1fb4fe0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-46f9654f-f9d1-4a2e-8229-f32827520c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5061
