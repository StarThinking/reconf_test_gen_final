reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990123886-172.17.0.11-1597197828695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42163,DS-921e170a-1186-4f78-9d8c-676cf8538365,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-9300fcf2-87fa-4b83-9ee1-3b93ca02151b,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-a030c3ed-45cd-4a34-9190-ed904b3f3057,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-9a57c35c-9dd9-4bea-92ef-f8672285cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-042672d3-bfcc-46ca-a9ad-d002c8b03fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-f6bd8eb3-5227-46eb-b08f-019f20c377ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-e59e6c06-52cb-484c-a92f-5987fa6e0025,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-2a67715b-be69-4b36-9ae2-67b07b8d0eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990123886-172.17.0.11-1597197828695:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42163,DS-921e170a-1186-4f78-9d8c-676cf8538365,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-9300fcf2-87fa-4b83-9ee1-3b93ca02151b,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-a030c3ed-45cd-4a34-9190-ed904b3f3057,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-9a57c35c-9dd9-4bea-92ef-f8672285cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-042672d3-bfcc-46ca-a9ad-d002c8b03fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-f6bd8eb3-5227-46eb-b08f-019f20c377ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-e59e6c06-52cb-484c-a92f-5987fa6e0025,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-2a67715b-be69-4b36-9ae2-67b07b8d0eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351627347-172.17.0.11-1597198142586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41490,DS-010cf531-8d0f-41fb-9fb4-084d1ee49a20,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-5f0d02f4-f01f-4850-9355-d87184520e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-e757a31e-e9b7-43ff-b753-ef21bf6f83c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-e1a0eae6-f9dc-40f1-bd2d-09b1c6823839,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-1a247df7-9c8f-4999-a4df-f4616b8b651d,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-d8c4fa95-47c6-4b7b-9768-fc0325ce1955,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-a58056c2-97a7-40e3-b906-aba30ca14682,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-717722bc-dd45-47b9-93a7-fb7a1712b03c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351627347-172.17.0.11-1597198142586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41490,DS-010cf531-8d0f-41fb-9fb4-084d1ee49a20,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-5f0d02f4-f01f-4850-9355-d87184520e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-e757a31e-e9b7-43ff-b753-ef21bf6f83c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-e1a0eae6-f9dc-40f1-bd2d-09b1c6823839,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-1a247df7-9c8f-4999-a4df-f4616b8b651d,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-d8c4fa95-47c6-4b7b-9768-fc0325ce1955,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-a58056c2-97a7-40e3-b906-aba30ca14682,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-717722bc-dd45-47b9-93a7-fb7a1712b03c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760848270-172.17.0.11-1597198382147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35835,DS-68f510a7-8ce7-48bb-b7cd-470f87660bde,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-0f0ed5ea-7deb-4c6d-a941-e86894dda873,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-07d662ab-255c-48ee-81cc-a38f9412a928,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-f036715d-cb16-443a-b323-f4bb78bfe0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-607bcd9e-7bfa-4193-a060-b9245ba801e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-8aed2388-73f7-4c45-9b9b-80600eb2dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-a9108326-f926-410a-aa3e-332ebebc8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-7cad8e70-f050-4eac-872f-43af836490f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-760848270-172.17.0.11-1597198382147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35835,DS-68f510a7-8ce7-48bb-b7cd-470f87660bde,DISK], DatanodeInfoWithStorage[127.0.0.1:37168,DS-0f0ed5ea-7deb-4c6d-a941-e86894dda873,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-07d662ab-255c-48ee-81cc-a38f9412a928,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-f036715d-cb16-443a-b323-f4bb78bfe0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-607bcd9e-7bfa-4193-a060-b9245ba801e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-8aed2388-73f7-4c45-9b9b-80600eb2dd0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-a9108326-f926-410a-aa3e-332ebebc8e17,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-7cad8e70-f050-4eac-872f-43af836490f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385648707-172.17.0.11-1597199065011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-dd7677f9-bdfe-424f-84bc-7cad2daee0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-d990db0e-4c96-4fe0-b1df-5eac9899baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-17d1a286-1eba-48df-a63a-fcdddfb92df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-96054881-7457-4f0e-8a93-ab73d56712ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-284b2c87-59d6-4c04-acb9-dac8c8271be5,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-410d5948-bda3-4f1e-8070-cf79a37bbf20,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-5bc92716-26b6-4134-aa5e-8b65e795cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-c217f7fb-ce20-48c6-a123-e8948caa6475,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385648707-172.17.0.11-1597199065011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44552,DS-dd7677f9-bdfe-424f-84bc-7cad2daee0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-d990db0e-4c96-4fe0-b1df-5eac9899baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-17d1a286-1eba-48df-a63a-fcdddfb92df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-96054881-7457-4f0e-8a93-ab73d56712ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-284b2c87-59d6-4c04-acb9-dac8c8271be5,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-410d5948-bda3-4f1e-8070-cf79a37bbf20,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-5bc92716-26b6-4134-aa5e-8b65e795cd49,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-c217f7fb-ce20-48c6-a123-e8948caa6475,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961806509-172.17.0.11-1597199196706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40205,DS-851c9925-e11e-4a51-93a0-be1c20347964,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-a963bc71-7db6-4f04-b06e-8c67e758dca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-93f31a2e-17d9-4524-af15-3c783151b7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-fbf44354-9e0a-4cf3-a3a6-658d9db9f1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-d339d5c3-b318-4869-8119-d5b396bf052b,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-333ecec7-544d-4c70-9ee7-204c76eecfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-8677a823-5558-4c08-93be-7e77381daf31,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-d82fb55c-d567-40a9-9ee1-7276e56b2474,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961806509-172.17.0.11-1597199196706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40205,DS-851c9925-e11e-4a51-93a0-be1c20347964,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-a963bc71-7db6-4f04-b06e-8c67e758dca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-93f31a2e-17d9-4524-af15-3c783151b7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45259,DS-fbf44354-9e0a-4cf3-a3a6-658d9db9f1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-d339d5c3-b318-4869-8119-d5b396bf052b,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-333ecec7-544d-4c70-9ee7-204c76eecfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-8677a823-5558-4c08-93be-7e77381daf31,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-d82fb55c-d567-40a9-9ee1-7276e56b2474,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261705070-172.17.0.11-1597199301080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44343,DS-d03df546-76a4-4e72-80a9-837f5f0ff901,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-4a2bdc83-0ef7-419f-bb70-778abeae9b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-b7b37311-b803-4af8-8214-69d9dd7826cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-ba2db3f3-5ed0-42ee-9416-1c959de5c465,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-a7c65163-6b9d-409f-b8e6-8c13b9e355ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-8b98a72b-77fe-4833-809a-d881e3b00c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-c33506a3-dccf-4995-b411-21302a0afc71,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-bcd0b90b-a274-4d8f-8cc5-36aeb588824e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-261705070-172.17.0.11-1597199301080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44343,DS-d03df546-76a4-4e72-80a9-837f5f0ff901,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-4a2bdc83-0ef7-419f-bb70-778abeae9b50,DISK], DatanodeInfoWithStorage[127.0.0.1:42978,DS-b7b37311-b803-4af8-8214-69d9dd7826cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-ba2db3f3-5ed0-42ee-9416-1c959de5c465,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-a7c65163-6b9d-409f-b8e6-8c13b9e355ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-8b98a72b-77fe-4833-809a-d881e3b00c81,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-c33506a3-dccf-4995-b411-21302a0afc71,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-bcd0b90b-a274-4d8f-8cc5-36aeb588824e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218865865-172.17.0.11-1597199333455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44347,DS-e4aa8bf4-05ba-4121-aec0-dcbb870db0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-9fc6ea55-6e7c-4143-a964-9409fdee6063,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-ecc293e2-087c-4ff2-bc1f-56ce368a21b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-7974f180-2796-44aa-ae18-dfc4ec78cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-47c1e20e-437a-4823-89d3-7dddb638b376,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-6cbe25ef-aeaa-4e19-bc78-144c2bc79f47,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-0c1cd0ea-b4c8-46d0-988d-397b637e05ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-220d65f8-9d1a-4991-8fc0-c6f0105e3643,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218865865-172.17.0.11-1597199333455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44347,DS-e4aa8bf4-05ba-4121-aec0-dcbb870db0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-9fc6ea55-6e7c-4143-a964-9409fdee6063,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-ecc293e2-087c-4ff2-bc1f-56ce368a21b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-7974f180-2796-44aa-ae18-dfc4ec78cfd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-47c1e20e-437a-4823-89d3-7dddb638b376,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-6cbe25ef-aeaa-4e19-bc78-144c2bc79f47,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-0c1cd0ea-b4c8-46d0-988d-397b637e05ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37681,DS-220d65f8-9d1a-4991-8fc0-c6f0105e3643,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758061186-172.17.0.11-1597199390887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-3e1265ca-a780-43ee-a32a-e1ffd4cf775e,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-e9e702fd-0a58-4d0d-a08a-2c2977d84e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-05c14e0e-d0a3-41b9-b32c-64e1d41b74bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-c29b5651-3880-4f20-90af-24846a3e9fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-eee90735-5307-45ee-8c88-eb56de22464a,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-b9ac2e9a-d519-435a-b307-d8f1c8f49c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-d5e3252f-94f9-494b-8098-5e713ea0f39f,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-e5b0edba-2dc0-4f7a-8ab3-6cbe9a080c84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758061186-172.17.0.11-1597199390887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33465,DS-3e1265ca-a780-43ee-a32a-e1ffd4cf775e,DISK], DatanodeInfoWithStorage[127.0.0.1:38718,DS-e9e702fd-0a58-4d0d-a08a-2c2977d84e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-05c14e0e-d0a3-41b9-b32c-64e1d41b74bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-c29b5651-3880-4f20-90af-24846a3e9fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44701,DS-eee90735-5307-45ee-8c88-eb56de22464a,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-b9ac2e9a-d519-435a-b307-d8f1c8f49c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-d5e3252f-94f9-494b-8098-5e713ea0f39f,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-e5b0edba-2dc0-4f7a-8ab3-6cbe9a080c84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012139081-172.17.0.11-1597199492266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-fcf1b8d0-0c5d-45fa-bfd5-d5932b2cbe97,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-65237cb9-55f2-48ac-a94a-f4137b311abf,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-99b5b0bd-81ef-4f6e-981d-f47da640fdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-50e31a2a-91b0-4e0b-a4cd-15ffb8ad2e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-0a40db98-f23a-4838-a0ea-0ee23d7ab59d,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-f8fb47b0-2b52-4db8-b53b-39fde400adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-93851646-e8e6-44f2-8eff-da06ca976f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-69d4bb27-760d-418f-a0ba-e06955cb0b4b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012139081-172.17.0.11-1597199492266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41364,DS-fcf1b8d0-0c5d-45fa-bfd5-d5932b2cbe97,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-65237cb9-55f2-48ac-a94a-f4137b311abf,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-99b5b0bd-81ef-4f6e-981d-f47da640fdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-50e31a2a-91b0-4e0b-a4cd-15ffb8ad2e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-0a40db98-f23a-4838-a0ea-0ee23d7ab59d,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-f8fb47b0-2b52-4db8-b53b-39fde400adf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-93851646-e8e6-44f2-8eff-da06ca976f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-69d4bb27-760d-418f-a0ba-e06955cb0b4b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114200932-172.17.0.11-1597199565034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38722,DS-ced0d96d-87d6-4859-b749-0ee24c53a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-7824f13c-b5ce-4e33-b993-f662ba121a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-d6da9c58-7ccb-46e1-8dc4-8332a2b7c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-8a62a8e0-37e0-4eb6-af53-a874706d9da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-61ba19f7-e257-4091-b86a-72e703fac946,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-d209fb59-6f8d-4cf9-9c44-52a541558451,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-937a26d9-1efc-4ad0-accf-cf57be7db973,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-1faa381b-100f-4381-bb14-62f34b0bb346,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114200932-172.17.0.11-1597199565034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38722,DS-ced0d96d-87d6-4859-b749-0ee24c53a5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-7824f13c-b5ce-4e33-b993-f662ba121a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-d6da9c58-7ccb-46e1-8dc4-8332a2b7c94f,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-8a62a8e0-37e0-4eb6-af53-a874706d9da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-61ba19f7-e257-4091-b86a-72e703fac946,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-d209fb59-6f8d-4cf9-9c44-52a541558451,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-937a26d9-1efc-4ad0-accf-cf57be7db973,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-1faa381b-100f-4381-bb14-62f34b0bb346,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904668334-172.17.0.11-1597199629326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38518,DS-bab8734b-b6e4-4e5e-8fde-bce8f5fe4a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-791d4e8d-1764-47a8-943a-b024385e8714,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-e287f089-fb74-4a6f-8cff-651a8f4ec7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-4b252189-e3c5-4d77-b8c2-8d9f56e159ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-38adb2b6-4ed4-4e38-a477-7193228325cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-0e98cdd5-7b6f-4ed8-968f-1fbe9e03acfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-52842d98-dfd0-4481-b3da-d5716592795c,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-06126635-ea60-48c1-9263-816309832acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904668334-172.17.0.11-1597199629326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38518,DS-bab8734b-b6e4-4e5e-8fde-bce8f5fe4a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-791d4e8d-1764-47a8-943a-b024385e8714,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-e287f089-fb74-4a6f-8cff-651a8f4ec7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-4b252189-e3c5-4d77-b8c2-8d9f56e159ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-38adb2b6-4ed4-4e38-a477-7193228325cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-0e98cdd5-7b6f-4ed8-968f-1fbe9e03acfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33414,DS-52842d98-dfd0-4481-b3da-d5716592795c,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-06126635-ea60-48c1-9263-816309832acf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751247176-172.17.0.11-1597199907637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-ed525b95-9e79-45a5-ba8f-32692814ed2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-f343d517-53f1-449c-8581-84de37855123,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-a0e65873-6a4a-495d-8fab-f12c6f1d1628,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-dd1f9348-9316-4095-9fb2-65962dae09bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-2e3a3482-38d8-4fe2-8991-79b1b1fe7898,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-80845265-6b71-462a-adae-2ce534c99738,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-91420a12-4018-4d36-b259-cd9ad2d25142,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-19403ba7-e09d-4f37-a92c-f998c7b3bc6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751247176-172.17.0.11-1597199907637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-ed525b95-9e79-45a5-ba8f-32692814ed2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-f343d517-53f1-449c-8581-84de37855123,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-a0e65873-6a4a-495d-8fab-f12c6f1d1628,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-dd1f9348-9316-4095-9fb2-65962dae09bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-2e3a3482-38d8-4fe2-8991-79b1b1fe7898,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-80845265-6b71-462a-adae-2ce534c99738,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-91420a12-4018-4d36-b259-cd9ad2d25142,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-19403ba7-e09d-4f37-a92c-f998c7b3bc6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647867904-172.17.0.11-1597200002303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46595,DS-e53f3a65-d064-4584-a8ea-9bc840dc5049,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-b6a13111-ecfb-4c3c-962e-ea98436714d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-65a616aa-92ff-488f-8632-45e1218e590a,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-bcba8662-1b22-4265-9517-0a57748677b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-f52918b6-e7f0-406c-8268-5d39c3a75b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-ad24795f-d70b-4a79-8ce6-f4714a349c97,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-45b13470-3aa9-4686-9370-29aea8a51f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-5728354c-51aa-4a87-a9f2-1877d43de30e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-647867904-172.17.0.11-1597200002303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46595,DS-e53f3a65-d064-4584-a8ea-9bc840dc5049,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-b6a13111-ecfb-4c3c-962e-ea98436714d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-65a616aa-92ff-488f-8632-45e1218e590a,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-bcba8662-1b22-4265-9517-0a57748677b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-f52918b6-e7f0-406c-8268-5d39c3a75b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-ad24795f-d70b-4a79-8ce6-f4714a349c97,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-45b13470-3aa9-4686-9370-29aea8a51f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-5728354c-51aa-4a87-a9f2-1877d43de30e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595183632-172.17.0.11-1597200037876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-b5028c6a-a6dd-4395-b50a-5c29fdaea848,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-68087149-a906-475b-8df2-6d9b551ac537,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-3cb6008b-8140-4d2f-8d88-c8068fcb2f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-b3a77d4d-ea93-424b-b205-77d3f18ffb45,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-7c6c5d72-9d0f-44f5-8fbe-85336796a172,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-b2b5b013-0c6a-446c-b393-21837bedf260,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-7ddc3304-5e4a-45f8-894c-d86619204bab,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-a8d21555-eecc-4f2f-8981-caf2a9b84ecd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595183632-172.17.0.11-1597200037876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46150,DS-b5028c6a-a6dd-4395-b50a-5c29fdaea848,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-68087149-a906-475b-8df2-6d9b551ac537,DISK], DatanodeInfoWithStorage[127.0.0.1:35275,DS-3cb6008b-8140-4d2f-8d88-c8068fcb2f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-b3a77d4d-ea93-424b-b205-77d3f18ffb45,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-7c6c5d72-9d0f-44f5-8fbe-85336796a172,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-b2b5b013-0c6a-446c-b393-21837bedf260,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-7ddc3304-5e4a-45f8-894c-d86619204bab,DISK], DatanodeInfoWithStorage[127.0.0.1:33189,DS-a8d21555-eecc-4f2f-8981-caf2a9b84ecd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954880668-172.17.0.11-1597200073041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-d770a2fb-edae-410f-b6b2-0966c8867a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-5a0aeb90-ebf3-4f18-ab5f-64c72c593036,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-eeb7678b-c22c-4c2c-8dbf-df06b92350b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-57ac7e7a-5a51-4114-a6b4-d35f7da09e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-d74ea710-daf5-4a49-82bf-1af9bebbbb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-56f643ff-4538-42c1-a6aa-2c50caa4fe85,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-f37dbfb5-3974-4092-97b1-942c3ba76e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-b9ef9e8a-6d5c-493b-ba2f-e3498c1fba82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954880668-172.17.0.11-1597200073041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-d770a2fb-edae-410f-b6b2-0966c8867a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-5a0aeb90-ebf3-4f18-ab5f-64c72c593036,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-eeb7678b-c22c-4c2c-8dbf-df06b92350b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-57ac7e7a-5a51-4114-a6b4-d35f7da09e60,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-d74ea710-daf5-4a49-82bf-1af9bebbbb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-56f643ff-4538-42c1-a6aa-2c50caa4fe85,DISK], DatanodeInfoWithStorage[127.0.0.1:42085,DS-f37dbfb5-3974-4092-97b1-942c3ba76e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33600,DS-b9ef9e8a-6d5c-493b-ba2f-e3498c1fba82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005943717-172.17.0.11-1597200170586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32905,DS-8f5fd59d-e971-42b9-ba36-06ea4ab2ba79,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-66f2b428-13c7-4ef7-8076-52aead0e06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-042be72a-d8cd-4fc2-a720-40fc322e387d,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-95bad590-c578-47fb-9e3b-9e50a5959799,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-8f201c3d-d77e-4939-a971-6a00e35433ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-43dc5c89-3916-4324-b0fa-ab4f490bec46,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-c99418f5-4899-46f5-9267-0f5f73e4e736,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-5a641463-f7f7-4bd4-988e-c0d7d0a1fdcf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005943717-172.17.0.11-1597200170586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32905,DS-8f5fd59d-e971-42b9-ba36-06ea4ab2ba79,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-66f2b428-13c7-4ef7-8076-52aead0e06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-042be72a-d8cd-4fc2-a720-40fc322e387d,DISK], DatanodeInfoWithStorage[127.0.0.1:45719,DS-95bad590-c578-47fb-9e3b-9e50a5959799,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-8f201c3d-d77e-4939-a971-6a00e35433ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-43dc5c89-3916-4324-b0fa-ab4f490bec46,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-c99418f5-4899-46f5-9267-0f5f73e4e736,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-5a641463-f7f7-4bd4-988e-c0d7d0a1fdcf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597020983-172.17.0.11-1597200335491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-cbb4dadc-df01-4eea-be0c-8b18c55abccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-24b86910-6b81-4298-9064-155a22c8d504,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-6e7a968d-d8e9-4a34-95bc-d5c6e56c5251,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-696ea82c-b916-4f1c-90b7-284b036fc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-e5b0edcc-dd3c-47e4-b384-38a3f8eafe41,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-5d429781-26db-423c-b636-0393879b9676,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-5a91a5b5-efb8-4e34-bce8-d09dd2e5adc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-b39fe212-631e-4639-9e90-f57abe76fcbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597020983-172.17.0.11-1597200335491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36116,DS-cbb4dadc-df01-4eea-be0c-8b18c55abccb,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-24b86910-6b81-4298-9064-155a22c8d504,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-6e7a968d-d8e9-4a34-95bc-d5c6e56c5251,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-696ea82c-b916-4f1c-90b7-284b036fc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:36476,DS-e5b0edcc-dd3c-47e4-b384-38a3f8eafe41,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-5d429781-26db-423c-b636-0393879b9676,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-5a91a5b5-efb8-4e34-bce8-d09dd2e5adc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-b39fe212-631e-4639-9e90-f57abe76fcbe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337838061-172.17.0.11-1597200465716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33943,DS-422f95bf-91db-485d-b064-f8b85651bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-2331469a-227f-45fe-9bca-c770ad4e9114,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-27656c49-391f-4e4f-8e8f-c1c29d179f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-cfe2635f-83ce-4145-86a0-b0d89ecfc9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-6a0cef3f-1e64-411a-b186-8b00c90cf1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-4b461034-7e62-4d71-a8cb-6da7cee0f994,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-6204da13-c054-453a-94be-a0bcd089b585,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-53d86d4c-5238-4895-b1a5-bc6ffad2c1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337838061-172.17.0.11-1597200465716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33943,DS-422f95bf-91db-485d-b064-f8b85651bc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-2331469a-227f-45fe-9bca-c770ad4e9114,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-27656c49-391f-4e4f-8e8f-c1c29d179f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-cfe2635f-83ce-4145-86a0-b0d89ecfc9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-6a0cef3f-1e64-411a-b186-8b00c90cf1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-4b461034-7e62-4d71-a8cb-6da7cee0f994,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-6204da13-c054-453a-94be-a0bcd089b585,DISK], DatanodeInfoWithStorage[127.0.0.1:39446,DS-53d86d4c-5238-4895-b1a5-bc6ffad2c1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042406554-172.17.0.11-1597200527080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35709,DS-076a9791-5fc1-4b27-a241-1cf0f0ca7c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-ef3c0a6e-f8b4-4b92-8257-d08c672809f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-1259dde1-df68-474f-9189-c78ae95a1298,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-4953ac97-ba67-4186-980c-bb2f1b490efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-47619686-6f41-4e66-a9c0-4cbf246a908d,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-b24d8b5f-bf6a-4139-9080-08f0ab93bf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-b30c6469-eb69-4425-9a4f-44660414ca53,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-fd88d4e0-0f4a-4d39-a541-0934eb0df1c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2042406554-172.17.0.11-1597200527080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35709,DS-076a9791-5fc1-4b27-a241-1cf0f0ca7c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-ef3c0a6e-f8b4-4b92-8257-d08c672809f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-1259dde1-df68-474f-9189-c78ae95a1298,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-4953ac97-ba67-4186-980c-bb2f1b490efb,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-47619686-6f41-4e66-a9c0-4cbf246a908d,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-b24d8b5f-bf6a-4139-9080-08f0ab93bf6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-b30c6469-eb69-4425-9a4f-44660414ca53,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-fd88d4e0-0f4a-4d39-a541-0934eb0df1c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045039837-172.17.0.11-1597200720014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37188,DS-76c31685-d099-4d64-beab-93c3d50710ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-af971c89-752d-46a9-9040-29d3f7849bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-7e1ea218-d6cd-4622-b8a6-1745354daf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-69e0335e-203e-403d-a296-df1e99412e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-73044bda-bc8a-4710-917d-61c942969e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-c9314561-a56d-4a8b-afa3-a7d919a30c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-e63e17da-7afe-4a13-a144-642254a4023d,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-639b8e53-c69c-4f58-ae8d-3a499ad26d5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045039837-172.17.0.11-1597200720014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37188,DS-76c31685-d099-4d64-beab-93c3d50710ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-af971c89-752d-46a9-9040-29d3f7849bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-7e1ea218-d6cd-4622-b8a6-1745354daf1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-69e0335e-203e-403d-a296-df1e99412e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-73044bda-bc8a-4710-917d-61c942969e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-c9314561-a56d-4a8b-afa3-a7d919a30c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-e63e17da-7afe-4a13-a144-642254a4023d,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-639b8e53-c69c-4f58-ae8d-3a499ad26d5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940762104-172.17.0.11-1597200756421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39729,DS-ebe9668e-990c-4af2-b31b-442fe4443135,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-4ede6148-c664-4bc2-83f8-4542dc654b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-744497e1-ec6d-4964-b7cf-3f43be60c500,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-e5924407-e760-4236-b1ec-43bba0f0348f,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-3e31cc66-31ac-4c10-9205-eacf38f5e225,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-7b123e88-d11c-49ae-8f4d-8dfc3fb33af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-2c004840-d5e5-4dc4-a429-8cddd03d09ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-c6369cbd-f580-4fe9-8541-47124751f1f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940762104-172.17.0.11-1597200756421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39729,DS-ebe9668e-990c-4af2-b31b-442fe4443135,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-4ede6148-c664-4bc2-83f8-4542dc654b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-744497e1-ec6d-4964-b7cf-3f43be60c500,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-e5924407-e760-4236-b1ec-43bba0f0348f,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-3e31cc66-31ac-4c10-9205-eacf38f5e225,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-7b123e88-d11c-49ae-8f4d-8dfc3fb33af7,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-2c004840-d5e5-4dc4-a429-8cddd03d09ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42366,DS-c6369cbd-f580-4fe9-8541-47124751f1f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279165228-172.17.0.11-1597201009981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40304,DS-f3696c67-dcce-4c60-b708-4eb3e435c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-3503a768-34e3-4163-9e18-0d630c34f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-9135bd57-a3bf-4dda-984f-db524a8c5a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-91d30562-61bf-4c76-a65c-d30eaf02f73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-97b6a583-9e9a-4a43-b0f1-97207fa1f89d,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-570f22cb-3244-4d94-babf-cb12ffd9740d,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-4aec8c61-ef68-4324-907e-eabc88b9feb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-aaf5bf5a-19ae-4b77-8498-2b4b4b3c5c95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279165228-172.17.0.11-1597201009981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40304,DS-f3696c67-dcce-4c60-b708-4eb3e435c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-3503a768-34e3-4163-9e18-0d630c34f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-9135bd57-a3bf-4dda-984f-db524a8c5a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-91d30562-61bf-4c76-a65c-d30eaf02f73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-97b6a583-9e9a-4a43-b0f1-97207fa1f89d,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-570f22cb-3244-4d94-babf-cb12ffd9740d,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-4aec8c61-ef68-4324-907e-eabc88b9feb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-aaf5bf5a-19ae-4b77-8498-2b4b4b3c5c95,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273376225-172.17.0.11-1597201085034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-a359afb6-c027-43e8-92ef-292fe318e508,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-154e968e-deb2-47f0-bada-f98ecdcca3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-fcfe2847-6439-4a8e-9fc5-129ffd5606de,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-b8de869a-840e-406b-a3e9-54a4b44811d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-f8408703-4e16-4dd9-ac7f-40a741150d99,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-026e3b2b-4abb-404e-8c64-923fb648a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-093a86cd-90d7-4b06-a1a7-814ae5cf066a,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-5f563de6-4dfe-4eed-b110-59c7d85cb358,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273376225-172.17.0.11-1597201085034:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37616,DS-a359afb6-c027-43e8-92ef-292fe318e508,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-154e968e-deb2-47f0-bada-f98ecdcca3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-fcfe2847-6439-4a8e-9fc5-129ffd5606de,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-b8de869a-840e-406b-a3e9-54a4b44811d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-f8408703-4e16-4dd9-ac7f-40a741150d99,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-026e3b2b-4abb-404e-8c64-923fb648a8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-093a86cd-90d7-4b06-a1a7-814ae5cf066a,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-5f563de6-4dfe-4eed-b110-59c7d85cb358,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929994572-172.17.0.11-1597201155903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46742,DS-c85eb0a1-9b65-4e5c-a31a-0d939eb7896c,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-00fd0553-608a-4771-9cb9-f67a29bd0fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-fb7c60eb-3170-4d86-8622-49070cf446d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-90d11ce5-f9a3-4a18-abad-98f9c1717ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-cc369239-7bae-4306-83cb-5127e05ef9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-5558f0bd-3fb0-49e3-a5c9-bca4c26445e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-d9887ae2-75f9-48ca-b4db-3e800a056185,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-baa4bec2-4250-4c88-b627-9cad31c3fe66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1929994572-172.17.0.11-1597201155903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46742,DS-c85eb0a1-9b65-4e5c-a31a-0d939eb7896c,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-00fd0553-608a-4771-9cb9-f67a29bd0fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-fb7c60eb-3170-4d86-8622-49070cf446d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-90d11ce5-f9a3-4a18-abad-98f9c1717ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-cc369239-7bae-4306-83cb-5127e05ef9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-5558f0bd-3fb0-49e3-a5c9-bca4c26445e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-d9887ae2-75f9-48ca-b4db-3e800a056185,DISK], DatanodeInfoWithStorage[127.0.0.1:44216,DS-baa4bec2-4250-4c88-b627-9cad31c3fe66,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980412191-172.17.0.11-1597201220709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-50667433-c845-4b60-ba74-05a66c7ea333,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-521005f3-def7-4f40-8680-0bc0fbd62d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-a152a002-a2c3-4a8d-81c2-619580fd9bba,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-db620441-9014-45a9-b205-166be1b2aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-ef9ac8ef-764c-40b9-9d3e-9f1c0f4dc3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-ffd9fd11-9c64-47dd-8e99-c37450041d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-61231084-f05d-4e78-b4a2-c4d30697eb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-5ace383a-c6a4-4d88-a1b2-e2e51a71dce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980412191-172.17.0.11-1597201220709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38115,DS-50667433-c845-4b60-ba74-05a66c7ea333,DISK], DatanodeInfoWithStorage[127.0.0.1:42879,DS-521005f3-def7-4f40-8680-0bc0fbd62d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-a152a002-a2c3-4a8d-81c2-619580fd9bba,DISK], DatanodeInfoWithStorage[127.0.0.1:35326,DS-db620441-9014-45a9-b205-166be1b2aba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-ef9ac8ef-764c-40b9-9d3e-9f1c0f4dc3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-ffd9fd11-9c64-47dd-8e99-c37450041d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-61231084-f05d-4e78-b4a2-c4d30697eb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-5ace383a-c6a4-4d88-a1b2-e2e51a71dce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218566981-172.17.0.11-1597201297418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37378,DS-f09921f6-93dd-4392-be91-955881385a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-de2110a1-5b3b-4f87-bb8f-799f23fbeaac,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-dcea00da-f5db-4e27-8a4b-940059324914,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-aff48c6c-2dca-40c7-9170-280611b8e02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-b55f09f3-42d4-4f21-bbb6-e0041ddea6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-b31e03f9-ffd4-42e3-8730-04656ef8f9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-d258615b-1b8d-4f0b-9800-a36948816201,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-4801824a-efb5-4ae7-aee5-f690f6ae8476,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218566981-172.17.0.11-1597201297418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37378,DS-f09921f6-93dd-4392-be91-955881385a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-de2110a1-5b3b-4f87-bb8f-799f23fbeaac,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-dcea00da-f5db-4e27-8a4b-940059324914,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-aff48c6c-2dca-40c7-9170-280611b8e02f,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-b55f09f3-42d4-4f21-bbb6-e0041ddea6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-b31e03f9-ffd4-42e3-8730-04656ef8f9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-d258615b-1b8d-4f0b-9800-a36948816201,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-4801824a-efb5-4ae7-aee5-f690f6ae8476,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422157863-172.17.0.11-1597201478259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38579,DS-456e4fac-062c-444d-b9fa-c016dec40f70,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-8a0032f0-acd3-49df-90ef-8be4c750c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-b1761110-0ba1-4032-b47b-eda654a3d6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-b04876ec-50d2-42ce-a783-6c66242aa866,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-348c0155-a4b5-4ab3-a309-447628e204d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-82161c5d-e9b6-450f-b323-27512b3fa432,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-3c85b9ed-5a7d-4404-a9e8-54eb808cea56,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-f7484a41-3c80-4edd-bff2-9c2764815581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1422157863-172.17.0.11-1597201478259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38579,DS-456e4fac-062c-444d-b9fa-c016dec40f70,DISK], DatanodeInfoWithStorage[127.0.0.1:45820,DS-8a0032f0-acd3-49df-90ef-8be4c750c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-b1761110-0ba1-4032-b47b-eda654a3d6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-b04876ec-50d2-42ce-a783-6c66242aa866,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-348c0155-a4b5-4ab3-a309-447628e204d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-82161c5d-e9b6-450f-b323-27512b3fa432,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-3c85b9ed-5a7d-4404-a9e8-54eb808cea56,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-f7484a41-3c80-4edd-bff2-9c2764815581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772320754-172.17.0.11-1597201592342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-29a5abe6-d1a0-4456-a77e-65b34391c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-510e7f74-475f-4e61-9c1d-6ae0723f680f,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-95aaa3a9-8947-47cb-bf59-ba97153791b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-5cf78b5b-d5ee-495f-82f1-9842ce584584,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-fac97213-47f1-499f-b8ab-e23746743bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-4358a92b-38cb-4476-8b7d-9344699a1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-b9eeae96-60b7-466c-bb27-bc4317adb92a,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-b49e7c83-c94a-475e-b4b9-f1993b45f2e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772320754-172.17.0.11-1597201592342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-29a5abe6-d1a0-4456-a77e-65b34391c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-510e7f74-475f-4e61-9c1d-6ae0723f680f,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-95aaa3a9-8947-47cb-bf59-ba97153791b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-5cf78b5b-d5ee-495f-82f1-9842ce584584,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-fac97213-47f1-499f-b8ab-e23746743bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-4358a92b-38cb-4476-8b7d-9344699a1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-b9eeae96-60b7-466c-bb27-bc4317adb92a,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-b49e7c83-c94a-475e-b4b9-f1993b45f2e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566931154-172.17.0.11-1597201688068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36310,DS-957066bf-43f2-49b2-82c3-b284c9752fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-d064cecd-9c37-47f0-bdbb-052f64d93d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-88d446b3-17b2-4bed-849c-6f54f42a1a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-2d335f23-1d15-4c52-8684-1ee05dac83ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-1fbdcc42-c968-4413-97bc-d427ab6f49d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-6207e5ae-3692-4eeb-a44c-3bd526286c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-beddbe35-e774-48f9-ad7e-9479b6722c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-ae4ca2cd-2f27-423d-aea4-e789f6fafecf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1566931154-172.17.0.11-1597201688068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36310,DS-957066bf-43f2-49b2-82c3-b284c9752fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-d064cecd-9c37-47f0-bdbb-052f64d93d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-88d446b3-17b2-4bed-849c-6f54f42a1a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-2d335f23-1d15-4c52-8684-1ee05dac83ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-1fbdcc42-c968-4413-97bc-d427ab6f49d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-6207e5ae-3692-4eeb-a44c-3bd526286c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41471,DS-beddbe35-e774-48f9-ad7e-9479b6722c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-ae4ca2cd-2f27-423d-aea4-e789f6fafecf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669845505-172.17.0.11-1597202161015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-18a8fdcd-53af-462e-98c1-98954aa29186,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-114a61d5-cd24-4c2b-9583-99fb7a3f17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-b0ab29be-6c44-4262-b63c-3af36b28dcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-fddca62c-2183-44df-9d91-2fbe87c47ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-5a32e2c4-0dc1-4248-8e21-b6ddaf695a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-2803ac7e-42de-4442-a436-1c2cb0c5fd05,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-54e5a111-fc5c-447e-8f3b-b00d47c680dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-15ec8281-b295-4b7d-9b1e-04fdf4232c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669845505-172.17.0.11-1597202161015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45883,DS-18a8fdcd-53af-462e-98c1-98954aa29186,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-114a61d5-cd24-4c2b-9583-99fb7a3f17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-b0ab29be-6c44-4262-b63c-3af36b28dcd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34956,DS-fddca62c-2183-44df-9d91-2fbe87c47ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-5a32e2c4-0dc1-4248-8e21-b6ddaf695a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-2803ac7e-42de-4442-a436-1c2cb0c5fd05,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-54e5a111-fc5c-447e-8f3b-b00d47c680dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-15ec8281-b295-4b7d-9b1e-04fdf4232c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962694730-172.17.0.11-1597202304303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-ee36b074-8997-4203-b058-342d5a92ebdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-a7b45dea-7c19-4d49-954d-cb0abffe73bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-64c5fd4b-a3ce-4f5f-95dc-7ff21d112f02,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-c12c29aa-e934-4121-8c28-31d66af6d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-bde3578f-7e49-4a20-be26-f2f8a6178497,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-bb95702e-4991-42b2-8f5d-13eb264bc75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-863e4a3b-725d-4b41-ad17-09bb3667a9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-ac437c29-6236-4d78-8374-6481e50327b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962694730-172.17.0.11-1597202304303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42646,DS-ee36b074-8997-4203-b058-342d5a92ebdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-a7b45dea-7c19-4d49-954d-cb0abffe73bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-64c5fd4b-a3ce-4f5f-95dc-7ff21d112f02,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-c12c29aa-e934-4121-8c28-31d66af6d4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39185,DS-bde3578f-7e49-4a20-be26-f2f8a6178497,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-bb95702e-4991-42b2-8f5d-13eb264bc75f,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-863e4a3b-725d-4b41-ad17-09bb3667a9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-ac437c29-6236-4d78-8374-6481e50327b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048804850-172.17.0.11-1597202482692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-714aece6-b24b-47e0-99a2-64010e786eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-eae8e45b-712f-4dcd-a4e0-c15841539ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-746ba28d-fa88-451a-8fd5-5466a3c1b335,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-4b119407-64e9-44c4-a6a3-7fa66f4217e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-af8f5058-d3f7-44db-a2bb-69f374c3c243,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-2ffbc5e6-e09c-4063-a841-cf53009d1ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-e12a6657-1b2b-4906-bdc4-ba2c4bd1f953,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-f9736958-91e8-4e1e-8aef-855fe80ed377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048804850-172.17.0.11-1597202482692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37107,DS-714aece6-b24b-47e0-99a2-64010e786eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-eae8e45b-712f-4dcd-a4e0-c15841539ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-746ba28d-fa88-451a-8fd5-5466a3c1b335,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-4b119407-64e9-44c4-a6a3-7fa66f4217e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-af8f5058-d3f7-44db-a2bb-69f374c3c243,DISK], DatanodeInfoWithStorage[127.0.0.1:36533,DS-2ffbc5e6-e09c-4063-a841-cf53009d1ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-e12a6657-1b2b-4906-bdc4-ba2c4bd1f953,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-f9736958-91e8-4e1e-8aef-855fe80ed377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-xattrs-per-inode
component: hdfs:NameNode
v1: 1024
v2: 32
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348534536-172.17.0.11-1597202615891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33130,DS-fcd6a89e-97fb-462f-b310-23f8f52dac00,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-5ec774e2-91ea-4956-aeba-861d7c45dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-9a11878e-074d-4fa3-8408-7e7e90279768,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-47eda6d5-6f94-4e10-b3f9-99e26125100f,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-e11430ff-4d24-484d-9121-ad8f2e8cc557,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-f0f3a585-92c2-4fbf-be00-ca6f95972317,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-e80ccae9-54e1-4b7a-90b8-1e417cfe43af,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-e13befdd-768a-46dc-9524-d248c05626c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348534536-172.17.0.11-1597202615891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33130,DS-fcd6a89e-97fb-462f-b310-23f8f52dac00,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-5ec774e2-91ea-4956-aeba-861d7c45dd44,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-9a11878e-074d-4fa3-8408-7e7e90279768,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-47eda6d5-6f94-4e10-b3f9-99e26125100f,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-e11430ff-4d24-484d-9121-ad8f2e8cc557,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-f0f3a585-92c2-4fbf-be00-ca6f95972317,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-e80ccae9-54e1-4b7a-90b8-1e417cfe43af,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-e13befdd-768a-46dc-9524-d248c05626c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 23 out of 50
result: false positive !!!
Total execution time in seconds : 4984
