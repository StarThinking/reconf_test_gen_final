reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129736893-172.17.0.21-1597183346480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35291,DS-35da5f83-2095-4703-b5ae-1d8c1205df70,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-669daab2-2af3-481a-91f4-a6755d70da7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-6b19cfbf-d563-4cc4-a64a-b8f47a6dac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-7f2d7eef-afe6-489a-8b97-956c4c994a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-1da998c4-144e-45cb-ab6e-0e0415fc817e,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-97d5a286-c5ca-46ce-9d8d-407850d365a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-68f702af-045f-4d26-b78b-f6cc13bf5b91,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-488ed5c7-9a7f-402e-94ea-3eced085b6b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129736893-172.17.0.21-1597183346480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35291,DS-35da5f83-2095-4703-b5ae-1d8c1205df70,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-669daab2-2af3-481a-91f4-a6755d70da7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-6b19cfbf-d563-4cc4-a64a-b8f47a6dac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-7f2d7eef-afe6-489a-8b97-956c4c994a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-1da998c4-144e-45cb-ab6e-0e0415fc817e,DISK], DatanodeInfoWithStorage[127.0.0.1:43725,DS-97d5a286-c5ca-46ce-9d8d-407850d365a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-68f702af-045f-4d26-b78b-f6cc13bf5b91,DISK], DatanodeInfoWithStorage[127.0.0.1:36455,DS-488ed5c7-9a7f-402e-94ea-3eced085b6b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109412229-172.17.0.21-1597183378393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-1df9d859-1e83-47c6-b295-4201ec317e71,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-3a137b92-56b2-4f4e-b08e-91e930e1d057,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-7d1fde65-ee33-403d-a8fb-5b46e759c064,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-698ec44f-4912-424b-9e9e-e54215d5f144,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-a55b773e-8ef2-485f-a092-9c6274f01374,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-874e37b1-e3ea-4b71-88e0-2a4afeaa46b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-fa1204b4-88b4-459a-87de-213f320ae344,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-51b6e761-34df-4c69-82f8-42b39fe19997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109412229-172.17.0.21-1597183378393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-1df9d859-1e83-47c6-b295-4201ec317e71,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-3a137b92-56b2-4f4e-b08e-91e930e1d057,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-7d1fde65-ee33-403d-a8fb-5b46e759c064,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-698ec44f-4912-424b-9e9e-e54215d5f144,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-a55b773e-8ef2-485f-a092-9c6274f01374,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-874e37b1-e3ea-4b71-88e0-2a4afeaa46b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-fa1204b4-88b4-459a-87de-213f320ae344,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-51b6e761-34df-4c69-82f8-42b39fe19997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705314438-172.17.0.21-1597183450853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-6bca8b99-4b77-4a78-943c-446c1f3ec6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-dbff7caa-029c-44df-baa3-7dd4d650a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-bdfa8d50-268c-4e68-9dd5-e79e722887e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-b3e38e57-a586-4e09-9959-0121b5671264,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-d6104255-87a6-443d-a9b7-eef02be80f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-6f282612-9d1b-4a22-b296-6d4a33cdbc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-9aa317ad-a55e-4572-84e6-1ea4adc4df51,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-1d79d022-6fd7-4a64-ad7b-651e4939d038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705314438-172.17.0.21-1597183450853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36820,DS-6bca8b99-4b77-4a78-943c-446c1f3ec6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-dbff7caa-029c-44df-baa3-7dd4d650a9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42379,DS-bdfa8d50-268c-4e68-9dd5-e79e722887e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-b3e38e57-a586-4e09-9959-0121b5671264,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-d6104255-87a6-443d-a9b7-eef02be80f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-6f282612-9d1b-4a22-b296-6d4a33cdbc00,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-9aa317ad-a55e-4572-84e6-1ea4adc4df51,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-1d79d022-6fd7-4a64-ad7b-651e4939d038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082975647-172.17.0.21-1597183859930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43085,DS-16417cd1-22f0-4aa0-a41f-8d3a443a3049,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-b0c7e882-6375-4dc3-bff0-91049a707b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-dd2ebc01-3486-44f8-aed2-8c3234a9a5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-acdcf3cc-5780-437f-a4d9-d9b416f5331d,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-d9df1245-87c4-4388-8398-8ad38d82dcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-d6cb5f8b-c7a5-4720-b232-9738c486e22a,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-03d3f86b-5e80-4bfa-85d6-bd0e08924d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-53ae3090-e7b8-4b3d-9101-fd1e4140083a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2082975647-172.17.0.21-1597183859930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43085,DS-16417cd1-22f0-4aa0-a41f-8d3a443a3049,DISK], DatanodeInfoWithStorage[127.0.0.1:40025,DS-b0c7e882-6375-4dc3-bff0-91049a707b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-dd2ebc01-3486-44f8-aed2-8c3234a9a5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-acdcf3cc-5780-437f-a4d9-d9b416f5331d,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-d9df1245-87c4-4388-8398-8ad38d82dcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-d6cb5f8b-c7a5-4720-b232-9738c486e22a,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-03d3f86b-5e80-4bfa-85d6-bd0e08924d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-53ae3090-e7b8-4b3d-9101-fd1e4140083a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204152373-172.17.0.21-1597184141103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-84ee0555-5425-47ae-8143-e0364c5b9212,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-52b7dc54-9c5b-42de-abd7-c88c026e8a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-851f0654-6a19-466d-8751-628fd5d0b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-5b5b36ec-1f1c-4137-a5b1-7362081b3007,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-0a44ba19-6d21-4ad9-b93c-ef2de9ec121e,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-bc2c628e-1201-44fa-b123-ab6f7253633e,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-43acdb4a-553c-478e-b71b-e0f51ea84d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-4972dcfc-5f21-4e28-ad85-7b47401789c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204152373-172.17.0.21-1597184141103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43748,DS-84ee0555-5425-47ae-8143-e0364c5b9212,DISK], DatanodeInfoWithStorage[127.0.0.1:45548,DS-52b7dc54-9c5b-42de-abd7-c88c026e8a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-851f0654-6a19-466d-8751-628fd5d0b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-5b5b36ec-1f1c-4137-a5b1-7362081b3007,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-0a44ba19-6d21-4ad9-b93c-ef2de9ec121e,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-bc2c628e-1201-44fa-b123-ab6f7253633e,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-43acdb4a-553c-478e-b71b-e0f51ea84d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-4972dcfc-5f21-4e28-ad85-7b47401789c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683216168-172.17.0.21-1597184244866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-fc2954db-ad1e-4de0-bb4a-b2c851087950,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-ce7c5e15-6e51-4f7f-b085-282417d24ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-310e4672-cafe-4b6f-b41f-8f001c57b956,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-9c7dc52d-d53a-4d40-a1e9-a09f21536540,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-3754b2f2-d043-4e47-900f-b66076d44ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-42dabe4c-b191-49ab-b166-13dc7be37eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-bb8b4122-d842-4459-a02a-6e0edb3be08e,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-8ef1f793-7958-4174-ab29-58fcf588482e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683216168-172.17.0.21-1597184244866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43110,DS-fc2954db-ad1e-4de0-bb4a-b2c851087950,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-ce7c5e15-6e51-4f7f-b085-282417d24ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-310e4672-cafe-4b6f-b41f-8f001c57b956,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-9c7dc52d-d53a-4d40-a1e9-a09f21536540,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-3754b2f2-d043-4e47-900f-b66076d44ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-42dabe4c-b191-49ab-b166-13dc7be37eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-bb8b4122-d842-4459-a02a-6e0edb3be08e,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-8ef1f793-7958-4174-ab29-58fcf588482e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924861508-172.17.0.21-1597184299473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40734,DS-4d9895bc-1740-45f2-a739-ac975452bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-254d934c-5019-469d-b123-82ef3c2f2f77,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-3f8d99c3-22e4-4816-afb7-214ea10fd00e,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-a23ead1a-b4cd-4469-ad88-cae637bf95b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-1b53d452-9f58-441d-b02a-e0fbf6842585,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-b2a7d2fd-1e4f-44c6-86bf-6522fc6129bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-7124f0b4-6c5f-40f6-a3d7-dc649f0f4248,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-3b0e36c0-2c6f-4032-8711-459648445e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924861508-172.17.0.21-1597184299473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40734,DS-4d9895bc-1740-45f2-a739-ac975452bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-254d934c-5019-469d-b123-82ef3c2f2f77,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-3f8d99c3-22e4-4816-afb7-214ea10fd00e,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-a23ead1a-b4cd-4469-ad88-cae637bf95b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-1b53d452-9f58-441d-b02a-e0fbf6842585,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-b2a7d2fd-1e4f-44c6-86bf-6522fc6129bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-7124f0b4-6c5f-40f6-a3d7-dc649f0f4248,DISK], DatanodeInfoWithStorage[127.0.0.1:33722,DS-3b0e36c0-2c6f-4032-8711-459648445e50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758609202-172.17.0.21-1597184574760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41354,DS-6f67ebcc-f1a7-44c7-87b7-8d6d1bac71f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-b8ba83b2-694c-4ec4-a70f-90a3071e716f,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-c5be30c8-8c0c-478c-9bed-ed555e7382bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-f1f3b290-6a86-432a-b9dd-2630b5909c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-8fee98af-edc5-44a6-af25-4ceb8425b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-c09678cf-81e5-4435-896a-fbe50686f0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-8e19f706-a502-4531-8b23-e44dcf1b30bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-bf34248b-fd41-4843-885d-3006a1c70d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758609202-172.17.0.21-1597184574760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41354,DS-6f67ebcc-f1a7-44c7-87b7-8d6d1bac71f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44267,DS-b8ba83b2-694c-4ec4-a70f-90a3071e716f,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-c5be30c8-8c0c-478c-9bed-ed555e7382bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-f1f3b290-6a86-432a-b9dd-2630b5909c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-8fee98af-edc5-44a6-af25-4ceb8425b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-c09678cf-81e5-4435-896a-fbe50686f0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-8e19f706-a502-4531-8b23-e44dcf1b30bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-bf34248b-fd41-4843-885d-3006a1c70d45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381012238-172.17.0.21-1597185012792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45742,DS-260100dd-10e4-4013-9548-db6d93245edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-7cb24954-cec2-471b-a14d-884d8842c427,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-5edb608f-2750-4f9c-bac5-3910ae5243f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-449ffdbc-f6e0-4577-b6ec-90aaaae5eabd,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-acb2b9d7-89b6-44a2-95f6-5305825442cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-d3589f0b-03fa-4270-ac3b-6482ddf342f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-ff14481b-ef43-4e70-82a7-9624d0e59187,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-1c31b928-dc38-4cef-85a2-8460e1c7443e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-381012238-172.17.0.21-1597185012792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45742,DS-260100dd-10e4-4013-9548-db6d93245edf,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-7cb24954-cec2-471b-a14d-884d8842c427,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-5edb608f-2750-4f9c-bac5-3910ae5243f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-449ffdbc-f6e0-4577-b6ec-90aaaae5eabd,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-acb2b9d7-89b6-44a2-95f6-5305825442cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-d3589f0b-03fa-4270-ac3b-6482ddf342f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-ff14481b-ef43-4e70-82a7-9624d0e59187,DISK], DatanodeInfoWithStorage[127.0.0.1:32792,DS-1c31b928-dc38-4cef-85a2-8460e1c7443e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665006499-172.17.0.21-1597185487066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42801,DS-93fc29d8-c952-43ae-b683-8cf1c5a0a137,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-0c34c73e-2e3e-4e4a-aa9b-7a84f1b68c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-e19cffe4-f6d3-4799-8cbf-8e9c1fbccba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-1f6adc8e-8949-4d7b-a1e1-f4c532318697,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-b7e9397c-96df-450f-82d3-76e8c54eeb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-3020b4a8-b3cd-4a2f-8ae3-cf676bc3d786,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-5a57e642-7cc1-43f0-a50a-f220d901e322,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-ced1f7e4-ea9a-44d0-bff1-14e27a41c5f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665006499-172.17.0.21-1597185487066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42801,DS-93fc29d8-c952-43ae-b683-8cf1c5a0a137,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-0c34c73e-2e3e-4e4a-aa9b-7a84f1b68c86,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-e19cffe4-f6d3-4799-8cbf-8e9c1fbccba5,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-1f6adc8e-8949-4d7b-a1e1-f4c532318697,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-b7e9397c-96df-450f-82d3-76e8c54eeb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-3020b4a8-b3cd-4a2f-8ae3-cf676bc3d786,DISK], DatanodeInfoWithStorage[127.0.0.1:35626,DS-5a57e642-7cc1-43f0-a50a-f220d901e322,DISK], DatanodeInfoWithStorage[127.0.0.1:43431,DS-ced1f7e4-ea9a-44d0-bff1-14e27a41c5f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170496114-172.17.0.21-1597185920070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-cb3da5e8-8012-42fb-b7ef-206a1d68c761,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-85461f04-5d9f-4644-92a2-d667099146d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-0c1b96da-25bb-4618-a365-96f2018c37cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-5814b73c-5dcb-4f44-9a44-7136e5eb93ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-e50fd633-a366-4653-baf3-e6eadaff5885,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-f5d390db-d9ca-4ad0-b7c1-755d33d8321f,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-46defe0f-ee91-4f89-a4bb-e114655dfc41,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-83910a7d-4cad-4cac-bee0-56901c17f592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170496114-172.17.0.21-1597185920070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-cb3da5e8-8012-42fb-b7ef-206a1d68c761,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-85461f04-5d9f-4644-92a2-d667099146d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-0c1b96da-25bb-4618-a365-96f2018c37cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39875,DS-5814b73c-5dcb-4f44-9a44-7136e5eb93ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-e50fd633-a366-4653-baf3-e6eadaff5885,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-f5d390db-d9ca-4ad0-b7c1-755d33d8321f,DISK], DatanodeInfoWithStorage[127.0.0.1:37700,DS-46defe0f-ee91-4f89-a4bb-e114655dfc41,DISK], DatanodeInfoWithStorage[127.0.0.1:40623,DS-83910a7d-4cad-4cac-bee0-56901c17f592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012047293-172.17.0.21-1597186058036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-11bd949f-1e3a-4abc-9216-d5a6d0a061ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-a3ee3cf6-bbda-4552-9fd6-3f716069573e,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-ea062cda-0d4c-4cc7-9641-40e4f52d0b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-b662aab8-0489-4071-ae25-97b443219b00,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-25b126f0-8544-48b3-b5a2-866d22372939,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-64ede5c0-a292-4b40-bd6f-e8629957e4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-8024c53b-6b19-4490-b115-6c5ac81ba011,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-460a3ff2-1c55-48fd-878f-2d003f40b338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1012047293-172.17.0.21-1597186058036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33527,DS-11bd949f-1e3a-4abc-9216-d5a6d0a061ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-a3ee3cf6-bbda-4552-9fd6-3f716069573e,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-ea062cda-0d4c-4cc7-9641-40e4f52d0b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-b662aab8-0489-4071-ae25-97b443219b00,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-25b126f0-8544-48b3-b5a2-866d22372939,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-64ede5c0-a292-4b40-bd6f-e8629957e4a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40830,DS-8024c53b-6b19-4490-b115-6c5ac81ba011,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-460a3ff2-1c55-48fd-878f-2d003f40b338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486975116-172.17.0.21-1597186095426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-f2184824-fc11-4404-bf77-9ba055b7dd58,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-dc4d0d12-ecc4-477d-83a6-8f7d76f8be65,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-65bb33a0-9d12-40fe-8aa4-8abcfd846282,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-64cf8ac8-4112-4e73-9bc7-00a8cbcbe87b,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-4227803b-c519-42fd-a7e8-bf9a690fe15d,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-ce60a3b6-d407-45ea-82ea-03c26426f2da,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-58bcab55-e546-41fa-9c38-61a16247df7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-4630c817-cf92-4101-bf69-5fc562d990de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486975116-172.17.0.21-1597186095426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39789,DS-f2184824-fc11-4404-bf77-9ba055b7dd58,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-dc4d0d12-ecc4-477d-83a6-8f7d76f8be65,DISK], DatanodeInfoWithStorage[127.0.0.1:44685,DS-65bb33a0-9d12-40fe-8aa4-8abcfd846282,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-64cf8ac8-4112-4e73-9bc7-00a8cbcbe87b,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-4227803b-c519-42fd-a7e8-bf9a690fe15d,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-ce60a3b6-d407-45ea-82ea-03c26426f2da,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-58bcab55-e546-41fa-9c38-61a16247df7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-4630c817-cf92-4101-bf69-5fc562d990de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751140166-172.17.0.21-1597186441722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-ebdb8276-7fa3-426f-9be0-a459b52ae339,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-53906bd4-d1f0-4b82-9932-3d10dc6ba0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7776f7d1-dfaf-4a03-9a6c-41bb5f5e367b,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-aea0542b-e91c-4479-91ee-51ffb1aa1395,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-5850fd8f-6b3e-441c-9088-98a94be69a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-48e89554-26be-4859-b3f0-709300a7ef01,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-fcd2185d-efd6-4714-ae4a-0d138b00d35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-4406417d-eb3d-467a-8e6c-382e6d37cfa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751140166-172.17.0.21-1597186441722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40944,DS-ebdb8276-7fa3-426f-9be0-a459b52ae339,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-53906bd4-d1f0-4b82-9932-3d10dc6ba0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7776f7d1-dfaf-4a03-9a6c-41bb5f5e367b,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-aea0542b-e91c-4479-91ee-51ffb1aa1395,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-5850fd8f-6b3e-441c-9088-98a94be69a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-48e89554-26be-4859-b3f0-709300a7ef01,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-fcd2185d-efd6-4714-ae4a-0d138b00d35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-4406417d-eb3d-467a-8e6c-382e6d37cfa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151765015-172.17.0.21-1597186674989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43244,DS-6e3ad27d-d8b7-43c9-862e-f47e17c5b1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-4244df89-139c-436f-9be6-d1bbb88b0a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-efead90c-7796-4464-82a3-3e26196b4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-b820007f-75a2-4908-88d9-7fc23e05d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-33774d50-13d7-4265-a0b9-76a4fc8d1070,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-874dcb39-c16a-4f9d-acdc-d36d304ad763,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-d73b4c18-75f5-42de-8c9f-f6783ce41354,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-a84d138f-85c8-4238-b52b-b84dac9b1a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151765015-172.17.0.21-1597186674989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43244,DS-6e3ad27d-d8b7-43c9-862e-f47e17c5b1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-4244df89-139c-436f-9be6-d1bbb88b0a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41454,DS-efead90c-7796-4464-82a3-3e26196b4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-b820007f-75a2-4908-88d9-7fc23e05d04f,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-33774d50-13d7-4265-a0b9-76a4fc8d1070,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-874dcb39-c16a-4f9d-acdc-d36d304ad763,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-d73b4c18-75f5-42de-8c9f-f6783ce41354,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-a84d138f-85c8-4238-b52b-b84dac9b1a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680555853-172.17.0.21-1597186753621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-26307758-86ad-495f-b25c-56592bdabe12,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-5f04019c-7b02-48a2-ab46-861bfa864617,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-14c3eb36-1ee0-4c1a-9f81-929fab196b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-7119a904-5404-4b6b-853c-732316a96acb,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-7fa528b8-18e8-4944-baaa-c7979f4aac97,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-31c3fde6-29b2-4852-8a78-16419e2fc8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-4ebdc817-b008-4bbc-a213-8480f5a653b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-5dddfde8-fbf1-47dd-b18a-f376729cefcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1680555853-172.17.0.21-1597186753621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46832,DS-26307758-86ad-495f-b25c-56592bdabe12,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-5f04019c-7b02-48a2-ab46-861bfa864617,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-14c3eb36-1ee0-4c1a-9f81-929fab196b69,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-7119a904-5404-4b6b-853c-732316a96acb,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-7fa528b8-18e8-4944-baaa-c7979f4aac97,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-31c3fde6-29b2-4852-8a78-16419e2fc8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42089,DS-4ebdc817-b008-4bbc-a213-8480f5a653b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-5dddfde8-fbf1-47dd-b18a-f376729cefcc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346036138-172.17.0.21-1597186934793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-44e7c4ad-d80e-491a-89a0-4c23f9ef6b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-bf4adc0e-7cc7-46db-aafb-5440d104acc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-1b5e8dc1-731e-4a51-945c-41d15346b980,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-e2851b1b-aef2-48c0-a2ea-4bb5c1fa9c49,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-9a8ae06d-8339-4c0e-8c4a-823c4f060941,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-a2182941-0886-4170-89ee-8acfc69b3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-7a627916-05b1-4726-987c-dc3d3d03fb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-f530d14f-8371-4393-b611-15b2b6bad614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346036138-172.17.0.21-1597186934793:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37242,DS-44e7c4ad-d80e-491a-89a0-4c23f9ef6b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-bf4adc0e-7cc7-46db-aafb-5440d104acc5,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-1b5e8dc1-731e-4a51-945c-41d15346b980,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-e2851b1b-aef2-48c0-a2ea-4bb5c1fa9c49,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-9a8ae06d-8339-4c0e-8c4a-823c4f060941,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-a2182941-0886-4170-89ee-8acfc69b3da6,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-7a627916-05b1-4726-987c-dc3d3d03fb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-f530d14f-8371-4393-b611-15b2b6bad614,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389567313-172.17.0.21-1597187203724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40415,DS-d2c57fda-2501-463f-aa20-4f4253bff01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-ac8526d0-1dc7-4d35-9181-61d125f765ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-593c1d38-ec7f-40ab-8eaf-0fe39d85761b,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-08e48170-20d9-4799-8e68-9f4972cb15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-0caa3c1c-408b-4d96-8460-98ac3153bc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-851b331a-5511-4939-8aa1-4d8b9e69e270,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-41824263-1a7f-4044-8442-0fdea0218172,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-83b3be44-1a33-4600-8304-1ec8191f76fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1389567313-172.17.0.21-1597187203724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40415,DS-d2c57fda-2501-463f-aa20-4f4253bff01c,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-ac8526d0-1dc7-4d35-9181-61d125f765ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-593c1d38-ec7f-40ab-8eaf-0fe39d85761b,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-08e48170-20d9-4799-8e68-9f4972cb15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-0caa3c1c-408b-4d96-8460-98ac3153bc1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-851b331a-5511-4939-8aa1-4d8b9e69e270,DISK], DatanodeInfoWithStorage[127.0.0.1:35548,DS-41824263-1a7f-4044-8442-0fdea0218172,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-83b3be44-1a33-4600-8304-1ec8191f76fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559116449-172.17.0.21-1597187504879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-706b8dd0-e600-4dcf-803c-3b1556be6126,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-f399bd2b-8536-41fa-a72e-a3a83ea33d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-7a584578-6868-4be1-b589-fb71f0cec86a,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-477e3566-67d1-4781-a64f-663c3fc4f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-24368498-0d84-488a-8139-a4efba680d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-b043a04e-938a-4903-b262-9c6066ae41ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-bc7c1ea6-d561-4924-a9ec-ea9cd7a49209,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-601bc1d3-00ce-4bb3-9a1f-c9e8d1953df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-559116449-172.17.0.21-1597187504879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-706b8dd0-e600-4dcf-803c-3b1556be6126,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-f399bd2b-8536-41fa-a72e-a3a83ea33d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34999,DS-7a584578-6868-4be1-b589-fb71f0cec86a,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-477e3566-67d1-4781-a64f-663c3fc4f0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-24368498-0d84-488a-8139-a4efba680d82,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-b043a04e-938a-4903-b262-9c6066ae41ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39270,DS-bc7c1ea6-d561-4924-a9ec-ea9cd7a49209,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-601bc1d3-00ce-4bb3-9a1f-c9e8d1953df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transfer.socket.send.buffer.size
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924291945-172.17.0.21-1597188109160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-fdd5d564-affe-466d-9d1a-2904e8503e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-0993a881-0fed-4d52-93da-e79709a05ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-ce17be3e-bed5-4bd1-86b7-6fb46a67797d,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-ea8d532e-1f8a-43e3-831d-4e8c11dd0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-f807e616-d422-474f-adec-e71156f16304,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-98cd32ec-c4e2-4a75-bf53-a6a4d60b4cde,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-28153ed2-6971-4d85-9b49-ea28dc06f1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-e2ab0b9e-67e4-4e1d-8e01-eaaa2a112439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924291945-172.17.0.21-1597188109160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-fdd5d564-affe-466d-9d1a-2904e8503e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40685,DS-0993a881-0fed-4d52-93da-e79709a05ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-ce17be3e-bed5-4bd1-86b7-6fb46a67797d,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-ea8d532e-1f8a-43e3-831d-4e8c11dd0e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-f807e616-d422-474f-adec-e71156f16304,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-98cd32ec-c4e2-4a75-bf53-a6a4d60b4cde,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-28153ed2-6971-4d85-9b49-ea28dc06f1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-e2ab0b9e-67e4-4e1d-8e01-eaaa2a112439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5387
