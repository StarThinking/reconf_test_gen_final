reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168384258-172.17.0.17-1597124865617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36589,DS-62d5ddc5-f77d-4e41-9343-c4e297ee0acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-a8f8593a-a326-4339-8c60-1e9573e1731d,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-688df792-ae3f-495b-a8b3-164a25cf55c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-a732e62e-415e-4d95-b4c2-e7b04c5b00f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-ff602270-39ca-49c0-a4c9-e68812a3a398,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-fe354a2e-5274-496c-bf7d-97273f260295,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-1288d96a-60db-40d7-b3ff-03ef73c1a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-0e22ce1b-3822-4640-85e4-359e61c7d85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168384258-172.17.0.17-1597124865617:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36589,DS-62d5ddc5-f77d-4e41-9343-c4e297ee0acd,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-a8f8593a-a326-4339-8c60-1e9573e1731d,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-688df792-ae3f-495b-a8b3-164a25cf55c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-a732e62e-415e-4d95-b4c2-e7b04c5b00f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45730,DS-ff602270-39ca-49c0-a4c9-e68812a3a398,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-fe354a2e-5274-496c-bf7d-97273f260295,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-1288d96a-60db-40d7-b3ff-03ef73c1a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-0e22ce1b-3822-4640-85e4-359e61c7d85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992158378-172.17.0.17-1597125465689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-c509ffa2-fb46-44bc-b467-9ab68af60586,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-8db7eaf8-cc86-44d6-aad0-d27935d51b75,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-3955b018-522a-4a56-9946-ad9ceab241a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-3c92fce0-db12-4414-9c6a-da6b6ed72b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-7e0e31f2-9ff2-49fc-bd16-70d29aef709b,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-ccb041c4-3496-45c6-ba67-bacd9ebe87b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-05109705-7194-49eb-8534-aea70e655028,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-ed5e6831-ee67-4a93-bb70-a3a66d9990fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992158378-172.17.0.17-1597125465689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-c509ffa2-fb46-44bc-b467-9ab68af60586,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-8db7eaf8-cc86-44d6-aad0-d27935d51b75,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-3955b018-522a-4a56-9946-ad9ceab241a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-3c92fce0-db12-4414-9c6a-da6b6ed72b14,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-7e0e31f2-9ff2-49fc-bd16-70d29aef709b,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-ccb041c4-3496-45c6-ba67-bacd9ebe87b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40303,DS-05109705-7194-49eb-8534-aea70e655028,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-ed5e6831-ee67-4a93-bb70-a3a66d9990fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862462767-172.17.0.17-1597125503543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-0f6add64-ae9e-4090-ad36-2132b81eb67d,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-edf10bcc-23ef-4255-8812-78d7e2806113,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-ba03f0b1-a37f-45a7-9a1c-4213d65275c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-fa28a671-f2b9-4a4a-8bef-9167faa6a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-6b79e1f2-ca33-4a51-a62a-a0f1106df3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-73f5be62-cd34-4387-9802-b4846db1f2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-ac22622d-3a3f-437d-8013-73217d6982fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-51884b44-335e-48ec-8011-d0177059c3e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1862462767-172.17.0.17-1597125503543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-0f6add64-ae9e-4090-ad36-2132b81eb67d,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-edf10bcc-23ef-4255-8812-78d7e2806113,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-ba03f0b1-a37f-45a7-9a1c-4213d65275c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-fa28a671-f2b9-4a4a-8bef-9167faa6a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-6b79e1f2-ca33-4a51-a62a-a0f1106df3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-73f5be62-cd34-4387-9802-b4846db1f2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-ac22622d-3a3f-437d-8013-73217d6982fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-51884b44-335e-48ec-8011-d0177059c3e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498006747-172.17.0.17-1597126080520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-fb6b17d0-9482-4a01-afc1-3d47ec37a478,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-b5ec1d35-567a-4c20-92b9-6f2293b929bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-3415aba0-dc4d-46b7-9348-f80f00865c16,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-58e44917-fd88-41cf-9316-bf3e9bcbeca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-d9fa9083-0a92-4fb4-b532-50fe793a7347,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-6e56efb1-4d27-4d3b-8d0d-90ef1d722c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-6b0788c7-3f6d-4430-9f71-34ccbba717ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-d7e2054b-fa2b-4177-ba6b-acf8cf642311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498006747-172.17.0.17-1597126080520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-fb6b17d0-9482-4a01-afc1-3d47ec37a478,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-b5ec1d35-567a-4c20-92b9-6f2293b929bf,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-3415aba0-dc4d-46b7-9348-f80f00865c16,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-58e44917-fd88-41cf-9316-bf3e9bcbeca4,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-d9fa9083-0a92-4fb4-b532-50fe793a7347,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-6e56efb1-4d27-4d3b-8d0d-90ef1d722c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-6b0788c7-3f6d-4430-9f71-34ccbba717ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40242,DS-d7e2054b-fa2b-4177-ba6b-acf8cf642311,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503824459-172.17.0.17-1597126233941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39419,DS-edc9e100-2318-44cd-be3c-d55ceffaab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-cb796401-b409-4f32-b59a-1604e9ca1cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-786f184c-954c-4b6c-9493-140fe8b0882c,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-7d2f833d-a053-4491-87d7-847a5821daf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-8fd635d3-51f3-46c2-b1ab-483d3a4e63a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-c3352d51-295f-4b00-b635-eaa78c80666b,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-01d03eba-f8b8-41ad-953e-233b278292fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-2d012b84-d3de-46db-8ed3-9b596cd1b3e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503824459-172.17.0.17-1597126233941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39419,DS-edc9e100-2318-44cd-be3c-d55ceffaab7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-cb796401-b409-4f32-b59a-1604e9ca1cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-786f184c-954c-4b6c-9493-140fe8b0882c,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-7d2f833d-a053-4491-87d7-847a5821daf0,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-8fd635d3-51f3-46c2-b1ab-483d3a4e63a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-c3352d51-295f-4b00-b635-eaa78c80666b,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-01d03eba-f8b8-41ad-953e-233b278292fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-2d012b84-d3de-46db-8ed3-9b596cd1b3e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278526982-172.17.0.17-1597126829866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-39ed50b2-7b36-4443-9eb9-025beeccfc61,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-dd3adb0d-3735-41fc-a9d1-c887a52b7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-9b41e64f-5faa-4f53-83b3-ee3b177fda38,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-a4f735cf-dbe5-4916-9039-6996077f793f,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-66b229c0-cd4d-4971-8195-4b144c6a3df3,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-af905b9d-f1e5-4f7f-958b-fdbea6705116,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-c8e68045-5926-40dd-ab8b-e9b36166e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-83213614-2c9d-4f31-b179-3f32bd0deefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278526982-172.17.0.17-1597126829866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-39ed50b2-7b36-4443-9eb9-025beeccfc61,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-dd3adb0d-3735-41fc-a9d1-c887a52b7e57,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-9b41e64f-5faa-4f53-83b3-ee3b177fda38,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-a4f735cf-dbe5-4916-9039-6996077f793f,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-66b229c0-cd4d-4971-8195-4b144c6a3df3,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-af905b9d-f1e5-4f7f-958b-fdbea6705116,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-c8e68045-5926-40dd-ab8b-e9b36166e6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-83213614-2c9d-4f31-b179-3f32bd0deefd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812316287-172.17.0.17-1597126989987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38692,DS-837aef6d-f320-4230-ae0a-765dd7d10711,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-b5c08033-c384-40aa-a36f-ca8b5a606efa,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-f430d829-9c9e-4f5b-890f-e5987e36e6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-4d857527-78e4-411d-a9cc-b84a9ffd363d,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-b6afb95e-a323-4dd6-8109-a6797502e373,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-75256aa7-add6-4a83-a85e-05cc593f4fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-ad6b9e69-c32a-4ac1-af05-acb7019f617f,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-c98ce033-d58d-45bd-afa4-672fbcc40353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812316287-172.17.0.17-1597126989987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38692,DS-837aef6d-f320-4230-ae0a-765dd7d10711,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-b5c08033-c384-40aa-a36f-ca8b5a606efa,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-f430d829-9c9e-4f5b-890f-e5987e36e6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-4d857527-78e4-411d-a9cc-b84a9ffd363d,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-b6afb95e-a323-4dd6-8109-a6797502e373,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-75256aa7-add6-4a83-a85e-05cc593f4fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-ad6b9e69-c32a-4ac1-af05-acb7019f617f,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-c98ce033-d58d-45bd-afa4-672fbcc40353,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693932390-172.17.0.17-1597127618967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-b9af6b2c-32d8-4cfd-9e71-c83de15dd482,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-9b85a6ba-e847-4c3c-bdab-94586d20ac10,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-7cf7e8b7-0469-4a7f-8499-9dc3a84579b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-492f19f8-0b02-49c8-a06a-97dff235b569,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-a6c73786-b4e1-4a64-8065-765df8465c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-b9da56f4-67b1-4154-9eaa-9d6bbc37156f,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-01bafe92-7911-4390-8a07-2d0f99eba737,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-b52bb650-731e-436a-be2d-bbd1227bb01f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693932390-172.17.0.17-1597127618967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-b9af6b2c-32d8-4cfd-9e71-c83de15dd482,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-9b85a6ba-e847-4c3c-bdab-94586d20ac10,DISK], DatanodeInfoWithStorage[127.0.0.1:42350,DS-7cf7e8b7-0469-4a7f-8499-9dc3a84579b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-492f19f8-0b02-49c8-a06a-97dff235b569,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-a6c73786-b4e1-4a64-8065-765df8465c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-b9da56f4-67b1-4154-9eaa-9d6bbc37156f,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-01bafe92-7911-4390-8a07-2d0f99eba737,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-b52bb650-731e-436a-be2d-bbd1227bb01f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913461855-172.17.0.17-1597128639881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-2a947015-e699-40a8-b7d9-bea3f76eb9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-4f16807f-97ee-464e-b32a-25f58c44f1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-d4ef65f1-ccbb-4445-8b0c-674f3523fd24,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-2c6beb76-f398-4cea-adf8-02e24ce93405,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-e859eeaa-9269-49b4-acfa-17abd729b068,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-866faabb-a2d9-4d0e-9990-268b88876988,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-0b474b92-5d9d-4080-88e5-066abd3dc924,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-c371a283-6b43-407b-9ad7-955cd59866d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1913461855-172.17.0.17-1597128639881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45934,DS-2a947015-e699-40a8-b7d9-bea3f76eb9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35069,DS-4f16807f-97ee-464e-b32a-25f58c44f1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-d4ef65f1-ccbb-4445-8b0c-674f3523fd24,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-2c6beb76-f398-4cea-adf8-02e24ce93405,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-e859eeaa-9269-49b4-acfa-17abd729b068,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-866faabb-a2d9-4d0e-9990-268b88876988,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-0b474b92-5d9d-4080-88e5-066abd3dc924,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-c371a283-6b43-407b-9ad7-955cd59866d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45107189-172.17.0.17-1597129193354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-f37fd83c-f7e8-42a4-a576-178d8dec3512,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-a9a620a1-b932-46b3-b546-ff006dc21a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-09af589e-72fc-4f79-853c-0329485dc66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-8a131560-809c-4de3-9ccb-f6939272348d,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-009e9716-0fc1-4ead-818f-e3e5032a32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-fae65565-5a63-48c5-80c7-a316048b713b,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-5aa16edf-5824-47d7-a53f-ca85c2e2652b,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-e069ee2c-7e0c-40e5-a1c8-0d4b926eb55e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-45107189-172.17.0.17-1597129193354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-f37fd83c-f7e8-42a4-a576-178d8dec3512,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-a9a620a1-b932-46b3-b546-ff006dc21a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-09af589e-72fc-4f79-853c-0329485dc66e,DISK], DatanodeInfoWithStorage[127.0.0.1:37728,DS-8a131560-809c-4de3-9ccb-f6939272348d,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-009e9716-0fc1-4ead-818f-e3e5032a32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-fae65565-5a63-48c5-80c7-a316048b713b,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-5aa16edf-5824-47d7-a53f-ca85c2e2652b,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-e069ee2c-7e0c-40e5-a1c8-0d4b926eb55e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-130568132-172.17.0.17-1597129692639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-75980abb-d236-42a9-91d2-9f21b05fe28b,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-48190b0b-f53d-4fe9-8450-596602ab2c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-e2657274-6da8-42b4-b53c-a64f20a6fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-17922c38-4c88-4d05-91dc-e531c78a0b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-c516904f-d896-4171-8e26-56b1e5703dae,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-11b112d9-a246-4c9c-b0e7-2d15bf62473d,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-0d21f94c-8a28-41da-94fc-641ff5c59383,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-14cce378-1e60-4b7e-8718-6b5d777ab246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-130568132-172.17.0.17-1597129692639:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-75980abb-d236-42a9-91d2-9f21b05fe28b,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-48190b0b-f53d-4fe9-8450-596602ab2c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-e2657274-6da8-42b4-b53c-a64f20a6fa04,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-17922c38-4c88-4d05-91dc-e531c78a0b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-c516904f-d896-4171-8e26-56b1e5703dae,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-11b112d9-a246-4c9c-b0e7-2d15bf62473d,DISK], DatanodeInfoWithStorage[127.0.0.1:40321,DS-0d21f94c-8a28-41da-94fc-641ff5c59383,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-14cce378-1e60-4b7e-8718-6b5d777ab246,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128745942-172.17.0.17-1597129818841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46417,DS-1839fd62-f871-4b50-94c7-a9545e44961c,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-2b93512f-14ab-423e-8b7f-bb5b696b2045,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-35c4b67c-eff7-4785-acd8-6a6a7eae11ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-7fae6c70-3067-4bb4-98d4-c68692168252,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-ff93193e-74d1-4381-9b1c-49d9dfebfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-66499d14-a222-4038-85e7-fd9cec2901f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-83aa7510-76a4-4991-acf2-a00f381c7327,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-78797a22-f14c-4a82-b48c-c5defde347e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128745942-172.17.0.17-1597129818841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46417,DS-1839fd62-f871-4b50-94c7-a9545e44961c,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-2b93512f-14ab-423e-8b7f-bb5b696b2045,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-35c4b67c-eff7-4785-acd8-6a6a7eae11ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-7fae6c70-3067-4bb4-98d4-c68692168252,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-ff93193e-74d1-4381-9b1c-49d9dfebfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-66499d14-a222-4038-85e7-fd9cec2901f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-83aa7510-76a4-4991-acf2-a00f381c7327,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-78797a22-f14c-4a82-b48c-c5defde347e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.parallel.volumes.load.threads.num
component: hdfs:DataNode
v1: 1000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14914902-172.17.0.17-1597129983859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-f48d524e-eea8-4c8f-8c13-91ca74155079,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-551ffce4-95fc-4104-8cbe-877c6423911b,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-7b50306d-9581-4592-99cc-3ff73daa4ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-3e302b77-081e-4d15-8343-a78be4b5179d,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-9626b39f-d11d-434c-85b1-05530496c0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-47e9a951-2125-4445-808d-9dea5ed07332,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-fc681b33-9dda-4826-aa9c-b4a72801e227,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-32330890-5c61-48e7-aea7-f613adb3d247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14914902-172.17.0.17-1597129983859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-f48d524e-eea8-4c8f-8c13-91ca74155079,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-551ffce4-95fc-4104-8cbe-877c6423911b,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-7b50306d-9581-4592-99cc-3ff73daa4ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-3e302b77-081e-4d15-8343-a78be4b5179d,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-9626b39f-d11d-434c-85b1-05530496c0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37314,DS-47e9a951-2125-4445-808d-9dea5ed07332,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-fc681b33-9dda-4826-aa9c-b4a72801e227,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-32330890-5c61-48e7-aea7-f613adb3d247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5233
