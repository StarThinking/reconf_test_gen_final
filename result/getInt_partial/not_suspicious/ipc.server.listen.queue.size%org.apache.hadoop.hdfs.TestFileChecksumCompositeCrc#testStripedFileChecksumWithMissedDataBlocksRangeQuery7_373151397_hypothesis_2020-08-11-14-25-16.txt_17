reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947998797-172.17.0.3-1597156033871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-3a9b5116-ffd7-4800-813d-4289314ae165,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-44d6844c-51b6-4ba3-8409-30cce2b60a26,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-641f44e3-b268-4863-af7b-fab1e4ee5616,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-b8369f5a-68f2-4a60-999a-ea8eadc7a93c,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-f8bf93e4-a7eb-4371-9b6d-7cfba59a3268,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-1a9b5a40-0932-4601-bc52-76e17f2cdb00,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-d0da964b-a122-4484-9544-0f44d55cb57e,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-3139a99d-c61d-4d09-8494-77225f386528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947998797-172.17.0.3-1597156033871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42384,DS-3a9b5116-ffd7-4800-813d-4289314ae165,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-44d6844c-51b6-4ba3-8409-30cce2b60a26,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-641f44e3-b268-4863-af7b-fab1e4ee5616,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-b8369f5a-68f2-4a60-999a-ea8eadc7a93c,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-f8bf93e4-a7eb-4371-9b6d-7cfba59a3268,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-1a9b5a40-0932-4601-bc52-76e17f2cdb00,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-d0da964b-a122-4484-9544-0f44d55cb57e,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-3139a99d-c61d-4d09-8494-77225f386528,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785074529-172.17.0.3-1597156218425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-8b60f204-eca8-4309-b4e8-43a695193ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-0e9550a6-9c3c-4f07-822e-9e3d83181222,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-bee64636-039c-4ecb-951e-4cf7d6727abe,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-fbc5dc91-dd73-4eee-9dad-04762005868d,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-fa00a43a-2be5-4fd9-901d-45996988def4,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-f789d443-88fa-4694-95ea-e4b19c734f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-573d9727-eb0b-468b-a465-d412d7d04667,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-0f98f494-04c8-4d02-8f40-964fd5b311b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785074529-172.17.0.3-1597156218425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-8b60f204-eca8-4309-b4e8-43a695193ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-0e9550a6-9c3c-4f07-822e-9e3d83181222,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-bee64636-039c-4ecb-951e-4cf7d6727abe,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-fbc5dc91-dd73-4eee-9dad-04762005868d,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-fa00a43a-2be5-4fd9-901d-45996988def4,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-f789d443-88fa-4694-95ea-e4b19c734f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-573d9727-eb0b-468b-a465-d412d7d04667,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-0f98f494-04c8-4d02-8f40-964fd5b311b4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182117144-172.17.0.3-1597156287646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35349,DS-a2f3988b-c4f1-4d5b-a143-41fff33dfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-0fe7580b-7bd0-4f5e-99eb-c5f1399a0273,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-5cc0893a-e5ae-4737-9249-ef1afe79bcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-46cb17c7-4685-4c03-9c24-314fbacebf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-4eea0168-3e55-4594-87c6-32258389b103,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-6654e599-e166-467e-967c-6c9bcbed20f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-4dce74d0-1231-4bc2-9cd4-42b6a482236d,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-883f7a2d-5b00-4c8b-aa70-51b535b83198,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182117144-172.17.0.3-1597156287646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35349,DS-a2f3988b-c4f1-4d5b-a143-41fff33dfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-0fe7580b-7bd0-4f5e-99eb-c5f1399a0273,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-5cc0893a-e5ae-4737-9249-ef1afe79bcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-46cb17c7-4685-4c03-9c24-314fbacebf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-4eea0168-3e55-4594-87c6-32258389b103,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-6654e599-e166-467e-967c-6c9bcbed20f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-4dce74d0-1231-4bc2-9cd4-42b6a482236d,DISK], DatanodeInfoWithStorage[127.0.0.1:43320,DS-883f7a2d-5b00-4c8b-aa70-51b535b83198,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512519726-172.17.0.3-1597156369953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44209,DS-e72a611d-935b-46b2-8005-db7cebf8f226,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-9bbbe762-e0bc-4f87-afe5-5ae8a4026b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-08254a7d-7a73-4ac9-ae4a-714540d2a6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-19e4a7f6-5673-468b-ba34-e94e65eb3b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-e335f822-bcd0-4af0-9cda-bb476ee14562,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-23f4c85c-605a-4380-a855-e6b6aac5c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-4e741a31-cff8-4897-ba1e-267cdb098b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-67359cda-48e3-4bdc-ba83-4d4926f4ddaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512519726-172.17.0.3-1597156369953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44209,DS-e72a611d-935b-46b2-8005-db7cebf8f226,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-9bbbe762-e0bc-4f87-afe5-5ae8a4026b19,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-08254a7d-7a73-4ac9-ae4a-714540d2a6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-19e4a7f6-5673-468b-ba34-e94e65eb3b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-e335f822-bcd0-4af0-9cda-bb476ee14562,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-23f4c85c-605a-4380-a855-e6b6aac5c5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-4e741a31-cff8-4897-ba1e-267cdb098b34,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-67359cda-48e3-4bdc-ba83-4d4926f4ddaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7580304-172.17.0.3-1597156791719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42410,DS-3fdc7272-68b4-4d50-9fb4-0ce67f34a01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-2fc9f48d-7adc-4016-b7fd-854cae8b1ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-d2f9d1dd-5445-4ec7-ad1f-c94eee3e392d,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-4b607d3a-513d-4c7f-80ee-e7269c33793e,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-636a90d7-04cc-430b-bd88-686a7a2b37ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-c6d59863-bc6a-4d56-9667-6410d16a5837,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-71a4ef1f-0974-46a8-929c-de8e085ec60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-c4f899dd-9948-4910-9565-f6e560248789,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7580304-172.17.0.3-1597156791719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42410,DS-3fdc7272-68b4-4d50-9fb4-0ce67f34a01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39514,DS-2fc9f48d-7adc-4016-b7fd-854cae8b1ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-d2f9d1dd-5445-4ec7-ad1f-c94eee3e392d,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-4b607d3a-513d-4c7f-80ee-e7269c33793e,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-636a90d7-04cc-430b-bd88-686a7a2b37ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-c6d59863-bc6a-4d56-9667-6410d16a5837,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-71a4ef1f-0974-46a8-929c-de8e085ec60a,DISK], DatanodeInfoWithStorage[127.0.0.1:37181,DS-c4f899dd-9948-4910-9565-f6e560248789,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017124916-172.17.0.3-1597156966612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-9291c810-66b1-4933-8b3e-5167712c7466,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-e3018aa8-1aed-4665-8a8a-602d12cda8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-87a57596-c993-4e3a-8c80-59894a09271d,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-3aea386f-43a5-492c-89a5-67fee40df9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-1cfde14c-a7bf-47c2-b50a-2650b9eb986c,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-467c7a8c-734d-4414-8252-d597d0abe36f,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-a4c472ac-cbda-4314-8d10-51e51bd905b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-299fa6e4-43d6-4f3c-9ecc-1809f307de21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1017124916-172.17.0.3-1597156966612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42127,DS-9291c810-66b1-4933-8b3e-5167712c7466,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-e3018aa8-1aed-4665-8a8a-602d12cda8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-87a57596-c993-4e3a-8c80-59894a09271d,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-3aea386f-43a5-492c-89a5-67fee40df9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-1cfde14c-a7bf-47c2-b50a-2650b9eb986c,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-467c7a8c-734d-4414-8252-d597d0abe36f,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-a4c472ac-cbda-4314-8d10-51e51bd905b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-299fa6e4-43d6-4f3c-9ecc-1809f307de21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029901439-172.17.0.3-1597157259628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35948,DS-bc6b5e94-ae9d-4ebc-ac86-fddff1b0f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-1a74643b-8dca-4d84-a344-eb1da3949d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-d006a907-bcdc-40ee-b489-6a177ebc97fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-2a3fd59e-e75d-492b-b16b-c15c2d774eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-1b1cfe9c-6955-42d8-a183-5bf9236f135d,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-6d1a6b05-a181-435c-abb3-7fdec984da75,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-74ef9f1d-686d-47da-a11e-03a3774cd23d,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0cf37c77-f42a-46ff-a073-70a98a985e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029901439-172.17.0.3-1597157259628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35948,DS-bc6b5e94-ae9d-4ebc-ac86-fddff1b0f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-1a74643b-8dca-4d84-a344-eb1da3949d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-d006a907-bcdc-40ee-b489-6a177ebc97fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-2a3fd59e-e75d-492b-b16b-c15c2d774eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-1b1cfe9c-6955-42d8-a183-5bf9236f135d,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-6d1a6b05-a181-435c-abb3-7fdec984da75,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-74ef9f1d-686d-47da-a11e-03a3774cd23d,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-0cf37c77-f42a-46ff-a073-70a98a985e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032689764-172.17.0.3-1597157327069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46005,DS-9aa7f897-296c-47ce-84c6-0db68be70ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-eb5651be-5b37-4a95-87bc-40fb903be824,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-59d46b72-c390-484f-a6aa-e6a8c54aa8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-b31d1362-3e9f-418f-a569-f94592dfecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-79d55952-590d-4d4a-8532-4976ca726b63,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-bd8b5dfe-7e40-4bf1-966a-8ee4513bcab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-c1ec960e-c397-429f-9b45-9978c1f2cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-2cd7a52a-22c9-41ee-8c8f-c7f0f752e5b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032689764-172.17.0.3-1597157327069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46005,DS-9aa7f897-296c-47ce-84c6-0db68be70ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-eb5651be-5b37-4a95-87bc-40fb903be824,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-59d46b72-c390-484f-a6aa-e6a8c54aa8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-b31d1362-3e9f-418f-a569-f94592dfecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44982,DS-79d55952-590d-4d4a-8532-4976ca726b63,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-bd8b5dfe-7e40-4bf1-966a-8ee4513bcab1,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-c1ec960e-c397-429f-9b45-9978c1f2cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-2cd7a52a-22c9-41ee-8c8f-c7f0f752e5b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606333381-172.17.0.3-1597157428843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40583,DS-fddbb367-7a62-44ee-b13d-c79cf76b4f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-fb31b4fe-12f0-4d8d-9ceb-10358f0ae97f,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-9da05784-4ca6-43d5-ae56-8c8099f781c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-d1ac413e-ddb4-474a-9906-2fdb0acce631,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-9802eb01-9c5b-4f47-bc93-679ec906bd14,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-764785c1-e95b-4a5c-a90a-2c02be5fefed,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-44a80412-975a-42d5-938a-bf1cdfa06932,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-55c59f5a-531d-4d4c-9a5a-cb4280851074,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606333381-172.17.0.3-1597157428843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40583,DS-fddbb367-7a62-44ee-b13d-c79cf76b4f23,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-fb31b4fe-12f0-4d8d-9ceb-10358f0ae97f,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-9da05784-4ca6-43d5-ae56-8c8099f781c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-d1ac413e-ddb4-474a-9906-2fdb0acce631,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-9802eb01-9c5b-4f47-bc93-679ec906bd14,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-764785c1-e95b-4a5c-a90a-2c02be5fefed,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-44a80412-975a-42d5-938a-bf1cdfa06932,DISK], DatanodeInfoWithStorage[127.0.0.1:42753,DS-55c59f5a-531d-4d4c-9a5a-cb4280851074,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867469043-172.17.0.3-1597157536578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-ced2f32a-f7a7-4aa2-bb83-9a1deb3addee,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-70ecd366-6820-47b0-a553-b1e3a58c4be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-5fa9b8a7-3947-4e60-8605-f5ff1f5e4dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-6c2d1ba6-bafa-4867-8dac-a3d2c0b5ed00,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-85cbe1a4-63ec-4d65-bb99-6c68c9a0d261,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-a4f1e9cc-66ae-44a1-8532-055802942506,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-39a57af8-ad63-45fa-87de-dd91f34c4aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-5be2f4c3-dd6b-427c-9f79-1f802b1fa33d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867469043-172.17.0.3-1597157536578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-ced2f32a-f7a7-4aa2-bb83-9a1deb3addee,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-70ecd366-6820-47b0-a553-b1e3a58c4be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-5fa9b8a7-3947-4e60-8605-f5ff1f5e4dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-6c2d1ba6-bafa-4867-8dac-a3d2c0b5ed00,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-85cbe1a4-63ec-4d65-bb99-6c68c9a0d261,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-a4f1e9cc-66ae-44a1-8532-055802942506,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-39a57af8-ad63-45fa-87de-dd91f34c4aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-5be2f4c3-dd6b-427c-9f79-1f802b1fa33d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509993431-172.17.0.3-1597158004747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40994,DS-1fefeb82-c389-4b68-b06d-d2444ec87625,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-d0682b34-37ed-42b7-9284-0f31c36b2c99,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-d0536a20-02de-46e5-89d6-39b9b0b50a40,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-2788f71f-1ebc-4dfa-a7d4-63c5d100d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-c9a4a3cc-4efc-4b1d-9f74-66567a7b7a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-09e42301-55de-493e-a66c-66b32b9e0fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-1e1775b3-aa6d-4fb5-93a7-51b9c1472f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-792fda89-5eac-466d-a3d8-23f2af5c77c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509993431-172.17.0.3-1597158004747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40994,DS-1fefeb82-c389-4b68-b06d-d2444ec87625,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-d0682b34-37ed-42b7-9284-0f31c36b2c99,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-d0536a20-02de-46e5-89d6-39b9b0b50a40,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-2788f71f-1ebc-4dfa-a7d4-63c5d100d63d,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-c9a4a3cc-4efc-4b1d-9f74-66567a7b7a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:45786,DS-09e42301-55de-493e-a66c-66b32b9e0fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-1e1775b3-aa6d-4fb5-93a7-51b9c1472f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-792fda89-5eac-466d-a3d8-23f2af5c77c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003555413-172.17.0.3-1597158282499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37943,DS-ce04cc59-8211-4616-b9cc-a5c252f20d60,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-de784593-9225-4263-a094-5547ef2f62f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-93e46215-34e7-4775-ae80-4350822f9143,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-e4781604-2448-43fa-ba44-c2a5bb6add26,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-5a29099e-7441-41df-ac24-ee51c3a0c5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-a8044a88-8625-4286-bda8-c875c9b8e907,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-947b46f8-fe38-4b1f-bde7-6d66ff353b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-312ba85e-bf2a-45ff-9a5f-f3ecbcf93b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003555413-172.17.0.3-1597158282499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37943,DS-ce04cc59-8211-4616-b9cc-a5c252f20d60,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-de784593-9225-4263-a094-5547ef2f62f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-93e46215-34e7-4775-ae80-4350822f9143,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-e4781604-2448-43fa-ba44-c2a5bb6add26,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-5a29099e-7441-41df-ac24-ee51c3a0c5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-a8044a88-8625-4286-bda8-c875c9b8e907,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-947b46f8-fe38-4b1f-bde7-6d66ff353b14,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-312ba85e-bf2a-45ff-9a5f-f3ecbcf93b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430393448-172.17.0.3-1597158629540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-f0d9dc63-ea27-4d1f-a982-3c5e50d818f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-7ec9bf7b-f7c2-4ffa-b8b3-c6f4953cb5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-533eee27-797c-4749-bea5-83914e7a6461,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-994e245d-3fc3-4ab7-b325-7afafc876b66,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-0509bb8c-188d-424d-abd8-7b2cc4a43b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-7ecba216-bab5-4329-8213-92a0337d0bae,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-dad7c3ef-1663-4e83-afec-3ec818293571,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-206db440-195e-4ad8-9553-d75ec765b060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430393448-172.17.0.3-1597158629540:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-f0d9dc63-ea27-4d1f-a982-3c5e50d818f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-7ec9bf7b-f7c2-4ffa-b8b3-c6f4953cb5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-533eee27-797c-4749-bea5-83914e7a6461,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-994e245d-3fc3-4ab7-b325-7afafc876b66,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-0509bb8c-188d-424d-abd8-7b2cc4a43b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-7ecba216-bab5-4329-8213-92a0337d0bae,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-dad7c3ef-1663-4e83-afec-3ec818293571,DISK], DatanodeInfoWithStorage[127.0.0.1:43495,DS-206db440-195e-4ad8-9553-d75ec765b060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022754782-172.17.0.3-1597158922564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37402,DS-96ee7c99-ecd4-4fce-9759-4294b57baca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-a1d87786-d2b0-45d8-94ce-083ef77f44da,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-8f54d668-5491-4a5a-8bc0-fb8ba245ec8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-7bb9a8fc-0763-4000-a1ea-7f1fd96e0647,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-08f334e7-28ab-4247-9179-4ab661a51d92,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-041be83a-a36a-4250-aa63-ccb90f2edcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-ed368761-5d86-4f3f-9315-39c7d03bf5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-8420f88e-1060-477b-85b3-1838b63d2997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022754782-172.17.0.3-1597158922564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37402,DS-96ee7c99-ecd4-4fce-9759-4294b57baca5,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-a1d87786-d2b0-45d8-94ce-083ef77f44da,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-8f54d668-5491-4a5a-8bc0-fb8ba245ec8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-7bb9a8fc-0763-4000-a1ea-7f1fd96e0647,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-08f334e7-28ab-4247-9179-4ab661a51d92,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-041be83a-a36a-4250-aa63-ccb90f2edcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-ed368761-5d86-4f3f-9315-39c7d03bf5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-8420f88e-1060-477b-85b3-1838b63d2997,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152266646-172.17.0.3-1597159131008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44363,DS-c5b50a55-5f28-4318-843f-b843ecc7765b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-430fe27b-0322-4a83-9b61-5053d8f0c342,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-30612799-7d9b-4b9f-b4a5-a8dcbd26511f,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-01d9b289-c041-41f4-b3cd-12a6d8a11567,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-ef210753-02b0-46a6-b451-bcdcaf01d766,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-15822542-88d7-41e5-9e12-169a17fdf38f,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-c1a52b0d-a533-4fec-b28f-dc56a3302858,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-c2a82949-3bd2-4fdb-9028-6015c41c7220,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152266646-172.17.0.3-1597159131008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44363,DS-c5b50a55-5f28-4318-843f-b843ecc7765b,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-430fe27b-0322-4a83-9b61-5053d8f0c342,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-30612799-7d9b-4b9f-b4a5-a8dcbd26511f,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-01d9b289-c041-41f4-b3cd-12a6d8a11567,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-ef210753-02b0-46a6-b451-bcdcaf01d766,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-15822542-88d7-41e5-9e12-169a17fdf38f,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-c1a52b0d-a533-4fec-b28f-dc56a3302858,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-c2a82949-3bd2-4fdb-9028-6015c41c7220,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571266784-172.17.0.3-1597159313854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-cbcfd5bd-eb7f-40c6-83e4-8084063b032e,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-9076b1e5-240d-4ea2-b2f1-8e77cbf58ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-e89bc304-8a62-4fb5-99a7-b3beb73daee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-3e1267a5-368a-4523-9afc-33068f05c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-e2a81090-0b03-4802-b799-59a064bafe40,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-cc2c922c-43df-4827-b193-c45a8cd83a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-4608f106-9578-44dc-934e-805f3eb31563,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-bdbd6295-dcee-4eb0-9d99-67f1da839f11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571266784-172.17.0.3-1597159313854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-cbcfd5bd-eb7f-40c6-83e4-8084063b032e,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-9076b1e5-240d-4ea2-b2f1-8e77cbf58ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-e89bc304-8a62-4fb5-99a7-b3beb73daee9,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-3e1267a5-368a-4523-9afc-33068f05c6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-e2a81090-0b03-4802-b799-59a064bafe40,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-cc2c922c-43df-4827-b193-c45a8cd83a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-4608f106-9578-44dc-934e-805f3eb31563,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-bdbd6295-dcee-4eb0-9d99-67f1da839f11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957950952-172.17.0.3-1597159350257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-f949b2ee-d4b7-42c0-8eff-a2c5028e9514,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-2d628118-e294-406b-b692-45094f58d546,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-a9abbb50-d61a-4186-8fdb-5648fc0005b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-4c3a1a70-a8d7-4d0a-9a87-04155c6e8935,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-ab9ffd1d-a7f6-490a-bdcd-e86ec157a34c,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-b403d355-1983-408d-af3b-6d0e5f3621fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-e626f24b-3f2f-4111-b4bf-a8ffba7bbb37,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-81b090cd-9b41-4244-8b0b-3bd8d39bb057,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957950952-172.17.0.3-1597159350257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33315,DS-f949b2ee-d4b7-42c0-8eff-a2c5028e9514,DISK], DatanodeInfoWithStorage[127.0.0.1:33496,DS-2d628118-e294-406b-b692-45094f58d546,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-a9abbb50-d61a-4186-8fdb-5648fc0005b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44675,DS-4c3a1a70-a8d7-4d0a-9a87-04155c6e8935,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-ab9ffd1d-a7f6-490a-bdcd-e86ec157a34c,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-b403d355-1983-408d-af3b-6d0e5f3621fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-e626f24b-3f2f-4111-b4bf-a8ffba7bbb37,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-81b090cd-9b41-4244-8b0b-3bd8d39bb057,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833489014-172.17.0.3-1597159415829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42012,DS-b16599c5-1a1b-4e0b-abde-65cf410ae2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-a9240bc5-4b3a-4a26-8a1b-cde50eb4e80f,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-a0feb90f-c28e-4821-b413-eaa251ae2d94,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-0f4b139d-51c2-4312-8547-71bc963fec9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-4bb72e19-7148-41ba-9e5e-d8e30d68b7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-4032fa60-d793-4d08-a873-056f33e84a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-7fb3c7ec-2bcf-424b-a65f-b6cd4894de97,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-1d392417-15b3-49af-983b-c8f8be570992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1833489014-172.17.0.3-1597159415829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42012,DS-b16599c5-1a1b-4e0b-abde-65cf410ae2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-a9240bc5-4b3a-4a26-8a1b-cde50eb4e80f,DISK], DatanodeInfoWithStorage[127.0.0.1:35659,DS-a0feb90f-c28e-4821-b413-eaa251ae2d94,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-0f4b139d-51c2-4312-8547-71bc963fec9c,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-4bb72e19-7148-41ba-9e5e-d8e30d68b7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-4032fa60-d793-4d08-a873-056f33e84a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-7fb3c7ec-2bcf-424b-a65f-b6cd4894de97,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-1d392417-15b3-49af-983b-c8f8be570992,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328130208-172.17.0.3-1597159449350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-25a79334-e568-49a4-b7fd-a0fe3976de50,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-bee2faac-79ec-4ed8-bcf2-890851e1f501,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-8bf0191b-7064-4897-b5b6-77d558740bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-f1d889e0-9250-4526-90b0-d40bfcb138f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-dfb581b6-3365-464c-926f-223027332474,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-364c4a4f-99e2-467b-84ad-1b5a75db1774,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-7bd31a3d-0cac-4594-8c48-0c8836ebeec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-43efb53d-6f13-4b2d-a0ab-5d0b38867033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328130208-172.17.0.3-1597159449350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-25a79334-e568-49a4-b7fd-a0fe3976de50,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-bee2faac-79ec-4ed8-bcf2-890851e1f501,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-8bf0191b-7064-4897-b5b6-77d558740bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42451,DS-f1d889e0-9250-4526-90b0-d40bfcb138f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-dfb581b6-3365-464c-926f-223027332474,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-364c4a4f-99e2-467b-84ad-1b5a75db1774,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-7bd31a3d-0cac-4594-8c48-0c8836ebeec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-43efb53d-6f13-4b2d-a0ab-5d0b38867033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077647064-172.17.0.3-1597159595696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-114df28f-4b70-4614-9885-7e9741cbf51e,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-1c39bfb4-6444-460e-9e32-813928bbab47,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-36c7ce7d-ab9c-41fb-9ba5-8db962aa72d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-b8b8bab7-867b-460d-823a-76531bf6bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-db5a5c40-9db6-4756-8212-3b756bba4677,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-88a93241-41fc-46c0-af52-694ce7bd6a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-c04fc8ea-c449-4cfb-b74c-ec2e372089ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-cfb97187-59b8-4519-9c8b-952881b05e11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077647064-172.17.0.3-1597159595696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35072,DS-114df28f-4b70-4614-9885-7e9741cbf51e,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-1c39bfb4-6444-460e-9e32-813928bbab47,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-36c7ce7d-ab9c-41fb-9ba5-8db962aa72d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-b8b8bab7-867b-460d-823a-76531bf6bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-db5a5c40-9db6-4756-8212-3b756bba4677,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-88a93241-41fc-46c0-af52-694ce7bd6a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-c04fc8ea-c449-4cfb-b74c-ec2e372089ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-cfb97187-59b8-4519-9c8b-952881b05e11,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693127217-172.17.0.3-1597159627296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-3d53e0a9-082e-44a8-b4e8-b9afca0b9b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-3028708f-c5e4-4b30-9c3a-72a64f1e3c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-5c3fba31-473a-403d-8ebd-665ecce06b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-afa36246-5b8a-4efb-979c-55d07d0304d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-c756a472-bd87-4bab-ab69-6f56ed3ca4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-5795d23d-3e2d-41f6-abfe-7f33b1ece0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-a2815552-210a-4e0d-8e91-ed780370af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-8b7e6c70-697f-4d6f-a12c-10d00b8c05e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1693127217-172.17.0.3-1597159627296:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35417,DS-3d53e0a9-082e-44a8-b4e8-b9afca0b9b52,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-3028708f-c5e4-4b30-9c3a-72a64f1e3c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-5c3fba31-473a-403d-8ebd-665ecce06b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-afa36246-5b8a-4efb-979c-55d07d0304d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-c756a472-bd87-4bab-ab69-6f56ed3ca4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-5795d23d-3e2d-41f6-abfe-7f33b1ece0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-a2815552-210a-4e0d-8e91-ed780370af5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-8b7e6c70-697f-4d6f-a12c-10d00b8c05e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621285330-172.17.0.3-1597159666952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38182,DS-500f6257-7f8b-4dd0-a75e-5722d5aa6982,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-f10205f7-9cb4-4d1a-a4ce-fb550d8d79b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-190df0f9-1328-428d-b3be-671dcdb6f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-ed0c5b80-4943-42fb-9769-e3e09537ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-f6228d62-3da6-45a6-bcc1-f6f4e08fcb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-afb13fe9-51c3-462b-a023-b767a3edf1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-daf4575e-3f72-4b7c-b7c3-3bfee8097a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-3671c78c-3c7e-4b5e-82d1-7aec585e48ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621285330-172.17.0.3-1597159666952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38182,DS-500f6257-7f8b-4dd0-a75e-5722d5aa6982,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-f10205f7-9cb4-4d1a-a4ce-fb550d8d79b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-190df0f9-1328-428d-b3be-671dcdb6f4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-ed0c5b80-4943-42fb-9769-e3e09537ca1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-f6228d62-3da6-45a6-bcc1-f6f4e08fcb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-afb13fe9-51c3-462b-a023-b767a3edf1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-daf4575e-3f72-4b7c-b7c3-3bfee8097a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-3671c78c-3c7e-4b5e-82d1-7aec585e48ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494154914-172.17.0.3-1597159773070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-5f56c190-285a-4953-b9c0-54c386dc0b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-e527e288-adb6-429d-8d09-9c73b5d5e745,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-278ec3b7-6897-4db1-8638-b01df1003b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-a305bdb2-903d-4ea0-908e-217b06023281,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-53f8f229-bb0b-4eb2-96a5-2c7fe658b448,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-b3e7318c-c7ca-467e-8f20-eaa9b3d435da,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-e7c6fd69-322e-4753-8bbd-de268f82f634,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-b392845d-35d4-45bc-a10a-1885f4b8e3f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494154914-172.17.0.3-1597159773070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37495,DS-5f56c190-285a-4953-b9c0-54c386dc0b17,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-e527e288-adb6-429d-8d09-9c73b5d5e745,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-278ec3b7-6897-4db1-8638-b01df1003b61,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-a305bdb2-903d-4ea0-908e-217b06023281,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-53f8f229-bb0b-4eb2-96a5-2c7fe658b448,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-b3e7318c-c7ca-467e-8f20-eaa9b3d435da,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-e7c6fd69-322e-4753-8bbd-de268f82f634,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-b392845d-35d4-45bc-a10a-1885f4b8e3f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736323766-172.17.0.3-1597159838963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-ccfc5795-ee10-4ea7-939e-142105ff47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-31a813bb-29c2-4eb7-a1aa-97f9e172ee9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-6f44a19b-ad71-4304-94bc-fe2c8b156948,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-8cd32372-d8e1-49e4-93bb-9bc8149fb3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-70a402b1-690e-4bf7-81f4-32252be3013e,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-ac5ff31e-cff4-4ec4-ba87-b78554a8797e,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-432c3e31-9826-4a9c-8314-4f78000ebab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-ffcd15d1-2286-4c04-ac4d-074f806bca1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736323766-172.17.0.3-1597159838963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36149,DS-ccfc5795-ee10-4ea7-939e-142105ff47bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-31a813bb-29c2-4eb7-a1aa-97f9e172ee9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-6f44a19b-ad71-4304-94bc-fe2c8b156948,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-8cd32372-d8e1-49e4-93bb-9bc8149fb3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-70a402b1-690e-4bf7-81f4-32252be3013e,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-ac5ff31e-cff4-4ec4-ba87-b78554a8797e,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-432c3e31-9826-4a9c-8314-4f78000ebab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-ffcd15d1-2286-4c04-ac4d-074f806bca1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032371133-172.17.0.3-1597160346508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33198,DS-4c1ad1dc-18e2-4187-8082-0dc8e29f7648,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-939fa62d-dbe4-4b75-9290-aecec5d65f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-1f137c0c-59ee-4406-adbb-1580ee19a59a,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-fb0eefe6-8c28-4190-92fe-5720d18a3cff,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-4907f7cd-c446-4095-b912-fa6a31a7c8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-f97f9de1-5de4-4921-86b6-37591e22e195,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-2ce778cc-f36d-46d9-bfd7-d578068eee74,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-11e622ff-4bdf-4ab8-9232-b914e1a0111f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2032371133-172.17.0.3-1597160346508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33198,DS-4c1ad1dc-18e2-4187-8082-0dc8e29f7648,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-939fa62d-dbe4-4b75-9290-aecec5d65f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-1f137c0c-59ee-4406-adbb-1580ee19a59a,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-fb0eefe6-8c28-4190-92fe-5720d18a3cff,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-4907f7cd-c446-4095-b912-fa6a31a7c8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-f97f9de1-5de4-4921-86b6-37591e22e195,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-2ce778cc-f36d-46d9-bfd7-d578068eee74,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-11e622ff-4bdf-4ab8-9232-b914e1a0111f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182958844-172.17.0.3-1597160458489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-3a23a551-8ec9-423a-b9f1-c0cbf60b0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-d1f5e502-cc1b-458a-b4eb-0853aee7daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-3617703c-7b1b-49d5-9a72-4d5ba0876f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-cc7da7bc-81d0-424c-a4a8-d75187727da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-e927a380-105a-4ada-83a7-5725c31765a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-85ffe86d-fe3d-4437-9034-9b6fc5f2d9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-5db41d0c-9d1d-4cc6-bac4-b5151c5e7a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-a30256e6-0c15-49a4-9ae6-f5d65de76f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182958844-172.17.0.3-1597160458489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40597,DS-3a23a551-8ec9-423a-b9f1-c0cbf60b0ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-d1f5e502-cc1b-458a-b4eb-0853aee7daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-3617703c-7b1b-49d5-9a72-4d5ba0876f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-cc7da7bc-81d0-424c-a4a8-d75187727da0,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-e927a380-105a-4ada-83a7-5725c31765a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-85ffe86d-fe3d-4437-9034-9b6fc5f2d9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-5db41d0c-9d1d-4cc6-bac4-b5151c5e7a72,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-a30256e6-0c15-49a4-9ae6-f5d65de76f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436070813-172.17.0.3-1597160677146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-41b26ebd-2104-4045-b483-d52f859da8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-1c97c88c-9cfa-4f5e-846e-f00348dbfc20,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e8540733-facd-42b2-bcd9-e5a4fed1da80,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-e2931037-cb00-4dea-a2ad-9473b154c3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-3778379d-a94d-4702-881b-445ebe197445,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-5d6dee78-06b3-41db-8e73-bb59dfa6acf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-56a615e4-ad31-4f8f-835e-68dbd44b804f,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-fa82ec12-1ea2-486b-831a-75e24382885d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436070813-172.17.0.3-1597160677146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36233,DS-41b26ebd-2104-4045-b483-d52f859da8d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-1c97c88c-9cfa-4f5e-846e-f00348dbfc20,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-e8540733-facd-42b2-bcd9-e5a4fed1da80,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-e2931037-cb00-4dea-a2ad-9473b154c3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34697,DS-3778379d-a94d-4702-881b-445ebe197445,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-5d6dee78-06b3-41db-8e73-bb59dfa6acf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-56a615e4-ad31-4f8f-835e-68dbd44b804f,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-fa82ec12-1ea2-486b-831a-75e24382885d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50816188-172.17.0.3-1597160711363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44023,DS-10976dbe-941b-44fd-8b43-bb63d9c98747,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-485b193c-f958-4d0e-81ef-511c75318628,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-ed6a94cc-aa69-4454-9d6e-36a6d773bc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-1b790f3f-1227-4296-881d-c450c1343035,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-1f8d184e-9afa-4788-aa43-a34345a01fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-42f6bbaf-f9f8-4b66-8364-fe265ce53cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-a3b46327-766a-43b1-91d8-e27309659753,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-54af1c32-4840-4a24-91f4-c5dc643d7905,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50816188-172.17.0.3-1597160711363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44023,DS-10976dbe-941b-44fd-8b43-bb63d9c98747,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-485b193c-f958-4d0e-81ef-511c75318628,DISK], DatanodeInfoWithStorage[127.0.0.1:45768,DS-ed6a94cc-aa69-4454-9d6e-36a6d773bc4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-1b790f3f-1227-4296-881d-c450c1343035,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-1f8d184e-9afa-4788-aa43-a34345a01fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-42f6bbaf-f9f8-4b66-8364-fe265ce53cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-a3b46327-766a-43b1-91d8-e27309659753,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-54af1c32-4840-4a24-91f4-c5dc643d7905,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251527287-172.17.0.3-1597160748768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-bf8b8b5d-fcc7-4035-91ca-087fc046af22,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-4e690231-9f6c-4e0c-a583-df09c85c5679,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-db6515d5-6942-4fb3-b01b-3018e3c00167,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-b9a74e27-2913-490c-bf4e-d3d4588c42ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-2cff6f1a-ada2-47a5-80eb-a2f7d310aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-1c073d84-a7df-47e9-a01b-0311c63448ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-45d7aa1b-c135-40a2-9727-c08ea698e173,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-1e96ef21-b443-4bd5-b6a7-6e2513da141b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-251527287-172.17.0.3-1597160748768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33401,DS-bf8b8b5d-fcc7-4035-91ca-087fc046af22,DISK], DatanodeInfoWithStorage[127.0.0.1:37861,DS-4e690231-9f6c-4e0c-a583-df09c85c5679,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-db6515d5-6942-4fb3-b01b-3018e3c00167,DISK], DatanodeInfoWithStorage[127.0.0.1:43878,DS-b9a74e27-2913-490c-bf4e-d3d4588c42ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-2cff6f1a-ada2-47a5-80eb-a2f7d310aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-1c073d84-a7df-47e9-a01b-0311c63448ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-45d7aa1b-c135-40a2-9727-c08ea698e173,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-1e96ef21-b443-4bd5-b6a7-6e2513da141b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257400517-172.17.0.3-1597160796487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43232,DS-ab2ec961-0d86-4bda-b51d-5fc6d87f9671,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-9991a1c1-cc21-4d14-8081-7a58b5fa7e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-8d080835-c160-452c-b2f0-5f80a794e205,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-46938bbe-f556-48a5-a37f-75a8fbbe7429,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-91cd5f12-3d8b-4184-b221-1b5c8be7b430,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-17ba87aa-ec5a-4c68-8931-ce97c07b552d,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-ea525d93-5eaf-4107-a3f9-492382927888,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-32348ff8-47e9-4660-bdad-9b1c2d22ddd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257400517-172.17.0.3-1597160796487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43232,DS-ab2ec961-0d86-4bda-b51d-5fc6d87f9671,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-9991a1c1-cc21-4d14-8081-7a58b5fa7e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-8d080835-c160-452c-b2f0-5f80a794e205,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-46938bbe-f556-48a5-a37f-75a8fbbe7429,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-91cd5f12-3d8b-4184-b221-1b5c8be7b430,DISK], DatanodeInfoWithStorage[127.0.0.1:44878,DS-17ba87aa-ec5a-4c68-8931-ce97c07b552d,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-ea525d93-5eaf-4107-a3f9-492382927888,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-32348ff8-47e9-4660-bdad-9b1c2d22ddd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966298963-172.17.0.3-1597160856363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33434,DS-f18e57e9-1691-4d30-ab57-fe0e28ad6616,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-33415fd8-e16d-4375-af23-f88686cabab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-bb3632f5-995c-476a-bde2-7f527c539465,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-65d562da-769d-44f2-8254-f6f109a60c21,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-2e72d5b3-1c96-4c14-8486-01a28e5e7769,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-f4c61d82-6064-4ec2-a770-de86c50ae6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-57614e84-2db6-435a-a0dd-8ea5f1b6f3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-d87b7386-94b7-4d54-ab22-586931828f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966298963-172.17.0.3-1597160856363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33434,DS-f18e57e9-1691-4d30-ab57-fe0e28ad6616,DISK], DatanodeInfoWithStorage[127.0.0.1:37229,DS-33415fd8-e16d-4375-af23-f88686cabab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-bb3632f5-995c-476a-bde2-7f527c539465,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-65d562da-769d-44f2-8254-f6f109a60c21,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-2e72d5b3-1c96-4c14-8486-01a28e5e7769,DISK], DatanodeInfoWithStorage[127.0.0.1:38647,DS-f4c61d82-6064-4ec2-a770-de86c50ae6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-57614e84-2db6-435a-a0dd-8ea5f1b6f3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-d87b7386-94b7-4d54-ab22-586931828f8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999829433-172.17.0.3-1597160890597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-f0f47e23-1ac6-443a-8e71-2db40b10830d,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-d4769a9d-ad4a-4bb8-a7b6-a0a7fca30746,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-1aee1054-fe02-4d17-a58a-2301dedb2d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-469c69e9-4b09-43ec-acba-e284e1d4f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-5ae9ab96-c966-4623-98b3-890c2e2aa218,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-7785fe57-9ad3-40fa-8c98-960a1ecab3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-d713f639-e6cf-47ba-b9d9-7fcaa3c156c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-0b20a659-c3ef-4578-bb65-9da163d0acda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1999829433-172.17.0.3-1597160890597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-f0f47e23-1ac6-443a-8e71-2db40b10830d,DISK], DatanodeInfoWithStorage[127.0.0.1:35624,DS-d4769a9d-ad4a-4bb8-a7b6-a0a7fca30746,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-1aee1054-fe02-4d17-a58a-2301dedb2d74,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-469c69e9-4b09-43ec-acba-e284e1d4f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-5ae9ab96-c966-4623-98b3-890c2e2aa218,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-7785fe57-9ad3-40fa-8c98-960a1ecab3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44804,DS-d713f639-e6cf-47ba-b9d9-7fcaa3c156c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37792,DS-0b20a659-c3ef-4578-bb65-9da163d0acda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533668712-172.17.0.3-1597161021908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-058c8877-91f3-49d9-8244-bced2e52a4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-b2375c93-045d-4482-aca2-c7e584ac9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-12dec168-7f5a-4911-8009-1130c4568c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-71c7c7b4-57ce-49f3-bb56-34b69aa95d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-f2c3c40a-85b5-4ea0-8cea-da59e74db2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-a0e25199-a577-4400-943c-14f1ef1f10f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-44354771-9cbf-4adf-9a30-32b5bc7d77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-16c08318-9c51-45c5-9b93-844641c1a62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1533668712-172.17.0.3-1597161021908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41741,DS-058c8877-91f3-49d9-8244-bced2e52a4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-b2375c93-045d-4482-aca2-c7e584ac9acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-12dec168-7f5a-4911-8009-1130c4568c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-71c7c7b4-57ce-49f3-bb56-34b69aa95d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-f2c3c40a-85b5-4ea0-8cea-da59e74db2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-a0e25199-a577-4400-943c-14f1ef1f10f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-44354771-9cbf-4adf-9a30-32b5bc7d77fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-16c08318-9c51-45c5-9b93-844641c1a62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152379613-172.17.0.3-1597161193284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43036,DS-a0f5dcf8-a84c-4ba3-9dc0-2fac6c174a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-0d615531-d20d-41ef-9fa0-b221f0b91d40,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-d078f97c-8e8a-4b02-a215-c914884a2ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-ad6ddd39-5be5-4664-9549-27f9575c5adc,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-a297387a-5ba3-4097-adf3-f03e5a8c5935,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-7d8ad53f-e87d-4249-80a2-c845f88afd17,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-c26a92ec-4f5d-4234-b149-9729b72c2357,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-a2111281-5105-4528-8ebd-0540f5c133d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-152379613-172.17.0.3-1597161193284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43036,DS-a0f5dcf8-a84c-4ba3-9dc0-2fac6c174a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-0d615531-d20d-41ef-9fa0-b221f0b91d40,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-d078f97c-8e8a-4b02-a215-c914884a2ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-ad6ddd39-5be5-4664-9549-27f9575c5adc,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-a297387a-5ba3-4097-adf3-f03e5a8c5935,DISK], DatanodeInfoWithStorage[127.0.0.1:35090,DS-7d8ad53f-e87d-4249-80a2-c845f88afd17,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-c26a92ec-4f5d-4234-b149-9729b72c2357,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-a2111281-5105-4528-8ebd-0540f5c133d2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.listen.queue.size
component: hdfs:DataNode
v1: 256
v2: 128
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877552841-172.17.0.3-1597161294659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42003,DS-c124a17c-3376-4797-86b0-ddd6c5de05e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-7b6ca480-4e1d-4428-87a0-fde799fdd51a,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-0cdcddcf-6b7d-4695-b673-0602e18a521f,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-a2730735-3c3e-4349-8bf6-09f4982745e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-11479cf1-24f4-4a1f-9210-9dc6a63c266c,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-246cc2db-343f-46a0-b358-d20ab57cebff,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-5638ce69-da20-40c4-b59d-197b8f33415e,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-b305612e-7a73-418c-a31c-16f91fd5c6fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877552841-172.17.0.3-1597161294659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42003,DS-c124a17c-3376-4797-86b0-ddd6c5de05e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-7b6ca480-4e1d-4428-87a0-fde799fdd51a,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-0cdcddcf-6b7d-4695-b673-0602e18a521f,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-a2730735-3c3e-4349-8bf6-09f4982745e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-11479cf1-24f4-4a1f-9210-9dc6a63c266c,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-246cc2db-343f-46a0-b358-d20ab57cebff,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-5638ce69-da20-40c4-b59d-197b8f33415e,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-b305612e-7a73-418c-a31c-16f91fd5c6fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5396
