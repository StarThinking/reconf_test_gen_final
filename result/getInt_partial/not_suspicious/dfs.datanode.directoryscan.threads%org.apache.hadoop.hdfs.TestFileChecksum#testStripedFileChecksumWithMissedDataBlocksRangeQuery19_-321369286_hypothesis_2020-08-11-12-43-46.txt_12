reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330052739-172.17.0.2-1597149913214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-e9b11289-5ba5-4655-b3f0-a3e00adade5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-dc7a5ea8-4cc4-459b-89fc-4ce510a991f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-76c08ca1-41bf-4141-af6b-b99678af018a,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-cb615af9-7d65-4b0c-853a-1a9db70bfe64,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-2eccf04c-f4fe-4677-866d-5858b19637eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-69b5637e-1b0b-4bd7-9544-5f7e392150f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-d04ca93b-f141-4cce-87fb-24cc443807c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-bdc898db-96ce-4488-a844-e785cbb80870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330052739-172.17.0.2-1597149913214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-e9b11289-5ba5-4655-b3f0-a3e00adade5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-dc7a5ea8-4cc4-459b-89fc-4ce510a991f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-76c08ca1-41bf-4141-af6b-b99678af018a,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-cb615af9-7d65-4b0c-853a-1a9db70bfe64,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-2eccf04c-f4fe-4677-866d-5858b19637eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35429,DS-69b5637e-1b0b-4bd7-9544-5f7e392150f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-d04ca93b-f141-4cce-87fb-24cc443807c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-bdc898db-96ce-4488-a844-e785cbb80870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006247139-172.17.0.2-1597150591494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45725,DS-5cf183cd-aa86-491b-9980-30f2cd36f944,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-cda57d5b-4344-40d8-a15d-dedb6cd2a489,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-171fe95d-732d-45dd-bbc6-9c0db4615776,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-baed5748-e8fe-4457-b8a7-10cf0978a387,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-8e39da6d-c87d-4d04-b9d9-dac543351a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-35705cdb-212d-4c91-8188-90702c518849,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-fdac03c3-878b-4350-a629-5828a49a9c50,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-12ed5f8f-3e53-4a37-9455-d6387694bce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006247139-172.17.0.2-1597150591494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45725,DS-5cf183cd-aa86-491b-9980-30f2cd36f944,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-cda57d5b-4344-40d8-a15d-dedb6cd2a489,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-171fe95d-732d-45dd-bbc6-9c0db4615776,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-baed5748-e8fe-4457-b8a7-10cf0978a387,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-8e39da6d-c87d-4d04-b9d9-dac543351a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-35705cdb-212d-4c91-8188-90702c518849,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-fdac03c3-878b-4350-a629-5828a49a9c50,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-12ed5f8f-3e53-4a37-9455-d6387694bce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982847087-172.17.0.2-1597150623338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36479,DS-56dc137d-e2d4-499d-a8ae-115510430bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-67a399be-02e0-4dbf-a335-00bd4f92dd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-4706a54b-33c3-4839-aee0-0a3988187815,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-06a8a674-1383-418f-a999-043228c21772,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-3fad8874-c0f3-4dee-8fe9-c5b280aafa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-c812c970-b32e-4298-9c6b-cd2349691a83,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-2ef84ce5-a90f-4bb0-ad21-7c2a544b68af,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-90f75bff-c392-4520-ae28-3295e98cb05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982847087-172.17.0.2-1597150623338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36479,DS-56dc137d-e2d4-499d-a8ae-115510430bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-67a399be-02e0-4dbf-a335-00bd4f92dd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-4706a54b-33c3-4839-aee0-0a3988187815,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-06a8a674-1383-418f-a999-043228c21772,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-3fad8874-c0f3-4dee-8fe9-c5b280aafa7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-c812c970-b32e-4298-9c6b-cd2349691a83,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-2ef84ce5-a90f-4bb0-ad21-7c2a544b68af,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-90f75bff-c392-4520-ae28-3295e98cb05e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617612321-172.17.0.2-1597150760195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36642,DS-87a48750-1b03-4432-9e60-21ce1d8e9f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-53ee8d75-3a9f-4da9-8b1d-8152a8b0c8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-b2644440-355f-4cd3-8d4e-88dc2f2d4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-d15e0da2-6b0d-4e0b-bde9-d627fae6f145,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-999ea01d-cfd9-4975-b1bb-54c97c8cb390,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-81b0a582-6110-4259-8e5a-0c070fa45639,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-973aabd9-d2f3-4d20-8708-07116c3cd5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-8e1e136d-cec4-456a-a900-00c52b14ac3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-617612321-172.17.0.2-1597150760195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36642,DS-87a48750-1b03-4432-9e60-21ce1d8e9f70,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-53ee8d75-3a9f-4da9-8b1d-8152a8b0c8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-b2644440-355f-4cd3-8d4e-88dc2f2d4cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-d15e0da2-6b0d-4e0b-bde9-d627fae6f145,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-999ea01d-cfd9-4975-b1bb-54c97c8cb390,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-81b0a582-6110-4259-8e5a-0c070fa45639,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-973aabd9-d2f3-4d20-8708-07116c3cd5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-8e1e136d-cec4-456a-a900-00c52b14ac3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581553141-172.17.0.2-1597150995947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38137,DS-8c231635-17ae-447a-89c8-4809e86dfd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-3f0f90bb-8dba-4481-91f6-7ccde534ddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-4a90d04d-4a04-4014-9bb7-17046043095d,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-a7e2b92b-5141-4aa0-8518-0e4cace0f8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-15ab0241-1e1b-4f40-b6cf-2605311c03e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-fa078f23-0489-40fc-bda5-04a47ee5188e,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-8fbfbda9-2485-4e0d-875d-9171a6ef5b66,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-0406dce0-595a-419d-85ba-03f28bde7856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581553141-172.17.0.2-1597150995947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38137,DS-8c231635-17ae-447a-89c8-4809e86dfd3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45367,DS-3f0f90bb-8dba-4481-91f6-7ccde534ddb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-4a90d04d-4a04-4014-9bb7-17046043095d,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-a7e2b92b-5141-4aa0-8518-0e4cace0f8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-15ab0241-1e1b-4f40-b6cf-2605311c03e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-fa078f23-0489-40fc-bda5-04a47ee5188e,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-8fbfbda9-2485-4e0d-875d-9171a6ef5b66,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-0406dce0-595a-419d-85ba-03f28bde7856,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901306362-172.17.0.2-1597151174269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-a94bdb3a-fe7c-4832-8fbf-fa431bd081c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-fe0624aa-8920-4996-82f0-e7b26fce54f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-8a6d8a4f-ed3b-4555-a125-8d742c9fb5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-6431d067-7794-4666-a68b-1454668d47df,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-4cbdedac-9a87-4540-a1ff-4e93d9050430,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-74f94260-a89c-4e46-b540-7aa4d54da411,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-4d9a3a44-51fb-4341-a578-0fe699953e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-192b4916-c21e-456a-a9de-c72dcb2c2e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901306362-172.17.0.2-1597151174269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42075,DS-a94bdb3a-fe7c-4832-8fbf-fa431bd081c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-fe0624aa-8920-4996-82f0-e7b26fce54f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-8a6d8a4f-ed3b-4555-a125-8d742c9fb5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-6431d067-7794-4666-a68b-1454668d47df,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-4cbdedac-9a87-4540-a1ff-4e93d9050430,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-74f94260-a89c-4e46-b540-7aa4d54da411,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-4d9a3a44-51fb-4341-a578-0fe699953e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-192b4916-c21e-456a-a9de-c72dcb2c2e4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864470203-172.17.0.2-1597151339678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45058,DS-01e6e63d-0264-4d33-9c36-433aa369c027,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-15ee222e-0aeb-40f2-835b-778a17cdb379,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-30bdfc9a-c086-482d-af3d-6c30ae3daea2,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-86360da9-f57c-43e7-a3af-08a39729b5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-7db49c15-afee-4dba-8ca3-fdfc4132d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-6b24c8f1-4ead-45a1-bc5a-b6e6a3054aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-b0ffbef0-6966-4497-8163-fd8f90d7497e,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-8bb49c21-fe0e-45c5-948e-c97fdee02c82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864470203-172.17.0.2-1597151339678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45058,DS-01e6e63d-0264-4d33-9c36-433aa369c027,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-15ee222e-0aeb-40f2-835b-778a17cdb379,DISK], DatanodeInfoWithStorage[127.0.0.1:34511,DS-30bdfc9a-c086-482d-af3d-6c30ae3daea2,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-86360da9-f57c-43e7-a3af-08a39729b5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-7db49c15-afee-4dba-8ca3-fdfc4132d99c,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-6b24c8f1-4ead-45a1-bc5a-b6e6a3054aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-b0ffbef0-6966-4497-8163-fd8f90d7497e,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-8bb49c21-fe0e-45c5-948e-c97fdee02c82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27413569-172.17.0.2-1597151579032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35878,DS-7dead717-89b5-47ab-9bf4-e7eb6a084f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-20ba9e0a-3d17-44c6-95bf-36418804d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-dbbc2432-eb57-4e45-8318-c4e5884034c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-953082dd-4f3c-4ea7-bb64-79880013107c,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-f3d2cc87-c516-4043-bfbb-912a7f1d8ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-9f81cbe7-62a1-4a4f-8a9f-227ec6e5ef0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-73531069-0e43-4a54-b1e4-08781dc02197,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-4324f565-ada9-4a14-9556-b39c4fe8a96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27413569-172.17.0.2-1597151579032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35878,DS-7dead717-89b5-47ab-9bf4-e7eb6a084f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-20ba9e0a-3d17-44c6-95bf-36418804d9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-dbbc2432-eb57-4e45-8318-c4e5884034c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-953082dd-4f3c-4ea7-bb64-79880013107c,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-f3d2cc87-c516-4043-bfbb-912a7f1d8ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-9f81cbe7-62a1-4a4f-8a9f-227ec6e5ef0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32787,DS-73531069-0e43-4a54-b1e4-08781dc02197,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-4324f565-ada9-4a14-9556-b39c4fe8a96e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131089961-172.17.0.2-1597151707453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42830,DS-03ba0301-5c98-4131-be7e-ae93dd92922f,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-8739e911-ff12-454b-855c-1fe06d89a659,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-5f25e0c8-310e-4c3c-b71e-dade915bc6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-bf2b9124-5449-43b8-b62d-d2bd9ed0a3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-88dbb237-61c7-4a75-8e63-b7fb1e034be2,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-6b21a25a-4f4f-46b9-8700-46a8ff9ebe49,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-99c2a876-4bc9-4948-a315-bf658a5c0299,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-b664f8a7-a647-4088-91b4-1be539ba3381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2131089961-172.17.0.2-1597151707453:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42830,DS-03ba0301-5c98-4131-be7e-ae93dd92922f,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-8739e911-ff12-454b-855c-1fe06d89a659,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-5f25e0c8-310e-4c3c-b71e-dade915bc6c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-bf2b9124-5449-43b8-b62d-d2bd9ed0a3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-88dbb237-61c7-4a75-8e63-b7fb1e034be2,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-6b21a25a-4f4f-46b9-8700-46a8ff9ebe49,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-99c2a876-4bc9-4948-a315-bf658a5c0299,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-b664f8a7-a647-4088-91b4-1be539ba3381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128782292-172.17.0.2-1597151808992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34020,DS-c22c0ea8-3856-4a29-a800-57bc36b429e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-60af5bf3-4ab5-4fc5-b47f-6f19b8f3d95d,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-c0f349a6-82f9-4958-8e99-8e0df065191c,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-920a3af7-ec27-4564-b690-50890cae9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-002bc635-bf73-4a46-8740-f7842b74961e,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-4d668126-ab3c-44aa-ba4f-65650ef988a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-3f814f91-f0ef-4b8b-94bd-d1244f1af273,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-2e859e1f-13ef-4948-801f-cb3b12baee50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128782292-172.17.0.2-1597151808992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34020,DS-c22c0ea8-3856-4a29-a800-57bc36b429e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-60af5bf3-4ab5-4fc5-b47f-6f19b8f3d95d,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-c0f349a6-82f9-4958-8e99-8e0df065191c,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-920a3af7-ec27-4564-b690-50890cae9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-002bc635-bf73-4a46-8740-f7842b74961e,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-4d668126-ab3c-44aa-ba4f-65650ef988a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-3f814f91-f0ef-4b8b-94bd-d1244f1af273,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-2e859e1f-13ef-4948-801f-cb3b12baee50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414623866-172.17.0.2-1597152168244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-7e26bbc0-bcec-4423-abd8-7e9292304d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-1584f54e-2f70-46c1-b0ab-7795fa2a2937,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-4dbe8a63-3527-4e75-986b-2d7a9364b857,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-c5355386-8159-48a1-b88c-c5a2be176879,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-49725d69-0e56-4463-9743-3faea1bc9747,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-7ee6746e-64e0-4698-a049-eb5bafb7d857,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-2d5dac0d-4606-47ab-9d47-8dcb3a4eac70,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-2a7bc433-4940-4ff3-8f58-e9ea16190950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-414623866-172.17.0.2-1597152168244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-7e26bbc0-bcec-4423-abd8-7e9292304d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-1584f54e-2f70-46c1-b0ab-7795fa2a2937,DISK], DatanodeInfoWithStorage[127.0.0.1:35486,DS-4dbe8a63-3527-4e75-986b-2d7a9364b857,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-c5355386-8159-48a1-b88c-c5a2be176879,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-49725d69-0e56-4463-9743-3faea1bc9747,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-7ee6746e-64e0-4698-a049-eb5bafb7d857,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-2d5dac0d-4606-47ab-9d47-8dcb3a4eac70,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-2a7bc433-4940-4ff3-8f58-e9ea16190950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229791934-172.17.0.2-1597152545335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33427,DS-7824d2bb-e806-4bd3-9137-31f0ca14edf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-c3c62f60-9b47-4fd7-9c32-4b69c7c6510c,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-a10e552f-c6c6-4a70-a66b-f7e6f482e15a,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-c061bc1e-a55a-43db-8233-1215afd89d72,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-e6fbbd0f-55fb-4930-ab8e-ed58ea977705,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-a0577ef8-fb09-449d-805f-618b391f19a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-ce1bb377-04ee-42cd-8be3-7f8ba1a7866e,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-a7634d94-f9fb-422a-92fb-a296041f0e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-229791934-172.17.0.2-1597152545335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33427,DS-7824d2bb-e806-4bd3-9137-31f0ca14edf2,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-c3c62f60-9b47-4fd7-9c32-4b69c7c6510c,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-a10e552f-c6c6-4a70-a66b-f7e6f482e15a,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-c061bc1e-a55a-43db-8233-1215afd89d72,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-e6fbbd0f-55fb-4930-ab8e-ed58ea977705,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-a0577ef8-fb09-449d-805f-618b391f19a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-ce1bb377-04ee-42cd-8be3-7f8ba1a7866e,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-a7634d94-f9fb-422a-92fb-a296041f0e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775370106-172.17.0.2-1597153546224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-e9ab68e2-1e57-4f1a-bf2d-300bb097109b,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-343e1629-47d0-44a1-9f9c-9112739fa64c,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-61c347af-ebab-45bb-897b-8d73de5af811,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-20cf2c61-788b-476b-b38f-81a960141366,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-4c0bc5c3-1ba4-48f2-8ecb-3f86e862d79c,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-0bf553a0-4b2b-4218-873c-c68e3f1ebfad,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-06000a13-a763-4e0d-98eb-f50359d9b015,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-c18301c0-014a-4e5b-9252-6537c0952be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775370106-172.17.0.2-1597153546224:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45622,DS-e9ab68e2-1e57-4f1a-bf2d-300bb097109b,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-343e1629-47d0-44a1-9f9c-9112739fa64c,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-61c347af-ebab-45bb-897b-8d73de5af811,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-20cf2c61-788b-476b-b38f-81a960141366,DISK], DatanodeInfoWithStorage[127.0.0.1:43307,DS-4c0bc5c3-1ba4-48f2-8ecb-3f86e862d79c,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-0bf553a0-4b2b-4218-873c-c68e3f1ebfad,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-06000a13-a763-4e0d-98eb-f50359d9b015,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-c18301c0-014a-4e5b-9252-6537c0952be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017169270-172.17.0.2-1597153783700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44239,DS-d2b7c7e2-ec31-4a22-a3a1-4b669fc02961,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-90ba7a8a-c966-4e28-ba66-06fe5e21473d,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-d355bb66-e029-4499-bace-107c04dd9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-1f7ceb18-dc8d-42de-a225-6affcd33423c,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-36305124-23c9-4098-9835-48a517250551,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-025fd94a-c63b-437a-8289-a74ff2d907f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-e98a8926-7200-401f-9d2e-ed3c299d293a,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-dff9df8d-a90e-436f-a49d-ef6c1fcb7db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017169270-172.17.0.2-1597153783700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44239,DS-d2b7c7e2-ec31-4a22-a3a1-4b669fc02961,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-90ba7a8a-c966-4e28-ba66-06fe5e21473d,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-d355bb66-e029-4499-bace-107c04dd9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-1f7ceb18-dc8d-42de-a225-6affcd33423c,DISK], DatanodeInfoWithStorage[127.0.0.1:46702,DS-36305124-23c9-4098-9835-48a517250551,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-025fd94a-c63b-437a-8289-a74ff2d907f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-e98a8926-7200-401f-9d2e-ed3c299d293a,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-dff9df8d-a90e-436f-a49d-ef6c1fcb7db6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996018769-172.17.0.2-1597154026283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-4c958079-3412-49f1-b16c-ed3eff1e4ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-ce41e379-205e-46fc-ab41-a2c762174565,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-30d31fa2-78b0-4f87-b309-4bb44add086b,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-3aab80d5-ac5b-4645-a0b3-c91d48db2b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-f1545db5-e133-4c02-8727-514e88ca8044,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-6b8caf14-b4b0-4a55-95a4-8ab58bec8ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-b9b7ba45-7042-4940-bd5b-1bf3262b1e01,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-517dc46f-a38f-4c6c-b46c-75363e47916d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996018769-172.17.0.2-1597154026283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-4c958079-3412-49f1-b16c-ed3eff1e4ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-ce41e379-205e-46fc-ab41-a2c762174565,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-30d31fa2-78b0-4f87-b309-4bb44add086b,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-3aab80d5-ac5b-4645-a0b3-c91d48db2b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-f1545db5-e133-4c02-8727-514e88ca8044,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-6b8caf14-b4b0-4a55-95a4-8ab58bec8ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-b9b7ba45-7042-4940-bd5b-1bf3262b1e01,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-517dc46f-a38f-4c6c-b46c-75363e47916d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447910300-172.17.0.2-1597154161715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41276,DS-6ed3b75e-4f7b-4078-8ff2-4e4b057e48b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-10b295d2-567e-4f68-9f7b-b36f054704f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-a4fd8220-7449-4dae-9814-9f2c6950a37e,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-3c7db359-91cd-4a65-848b-74fa743fc8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-8a6b5f7b-34a5-43d7-97f2-7b5843502630,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-0e6fb3c5-bb6a-461a-af81-a1c27a9ac976,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-ae1eab49-7d5b-4c0b-a65d-8f87754adf51,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-82a32603-1d0f-40ba-862d-7c1dc98bb21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-447910300-172.17.0.2-1597154161715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41276,DS-6ed3b75e-4f7b-4078-8ff2-4e4b057e48b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-10b295d2-567e-4f68-9f7b-b36f054704f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-a4fd8220-7449-4dae-9814-9f2c6950a37e,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-3c7db359-91cd-4a65-848b-74fa743fc8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36719,DS-8a6b5f7b-34a5-43d7-97f2-7b5843502630,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-0e6fb3c5-bb6a-461a-af81-a1c27a9ac976,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-ae1eab49-7d5b-4c0b-a65d-8f87754adf51,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-82a32603-1d0f-40ba-862d-7c1dc98bb21b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55261258-172.17.0.2-1597154235626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41410,DS-a825be98-a367-4145-ae72-913feefc912e,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-b5b0b5fd-8ee8-467c-a810-4c9c0d42d58f,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-9cf053cb-2ace-4810-9661-3dca0f7be589,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-0f62d8ab-dd41-4db4-a395-7bd197d22c82,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-d2eb9c65-ddc1-4ef6-8f56-ff8b11c14467,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-bc5ba295-a896-4fc8-97d8-1dab201ca407,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-29b897ef-b4a3-4ec9-8faf-212f366bb8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-4a0e5f6e-4a72-46bf-946a-1373e7bc3e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-55261258-172.17.0.2-1597154235626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41410,DS-a825be98-a367-4145-ae72-913feefc912e,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-b5b0b5fd-8ee8-467c-a810-4c9c0d42d58f,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-9cf053cb-2ace-4810-9661-3dca0f7be589,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-0f62d8ab-dd41-4db4-a395-7bd197d22c82,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-d2eb9c65-ddc1-4ef6-8f56-ff8b11c14467,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-bc5ba295-a896-4fc8-97d8-1dab201ca407,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-29b897ef-b4a3-4ec9-8faf-212f366bb8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46809,DS-4a0e5f6e-4a72-46bf-946a-1373e7bc3e52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039611946-172.17.0.2-1597154378078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-8f05d717-4f08-4338-99a7-4e8e804aab37,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-ab38f738-1cd1-4624-a1d9-ed69a8522712,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-8ff6754d-1f55-4a1a-b103-90e233050100,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-a871abfb-06e1-4534-9b9d-c0f846531d01,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-49db70e9-9cb2-4cc6-b468-d3c73a1caa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-1e607036-d195-4067-aeab-2fbfe86b69f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-f33005ce-33a3-4963-8285-aa55e0c6e6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-1f789843-0ea4-4dff-8c26-2526e0b7f101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039611946-172.17.0.2-1597154378078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39835,DS-8f05d717-4f08-4338-99a7-4e8e804aab37,DISK], DatanodeInfoWithStorage[127.0.0.1:44853,DS-ab38f738-1cd1-4624-a1d9-ed69a8522712,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-8ff6754d-1f55-4a1a-b103-90e233050100,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-a871abfb-06e1-4534-9b9d-c0f846531d01,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-49db70e9-9cb2-4cc6-b468-d3c73a1caa0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-1e607036-d195-4067-aeab-2fbfe86b69f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-f33005ce-33a3-4963-8285-aa55e0c6e6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-1f789843-0ea4-4dff-8c26-2526e0b7f101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.directoryscan.threads
component: hdfs:DataNode
v1: 3
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982120834-172.17.0.2-1597154952107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44925,DS-813bd63b-c1c3-422f-875f-06b54a4ffbca,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-68606a0d-f859-482b-bd1c-ac96c230a379,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-5e592ac3-8d31-42aa-9b07-0fec23ba2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-7dbc77f2-b514-4a44-b36b-3e671360a75a,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-25af4518-a5e3-47b5-bc23-a1b5d4f1de59,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-ef4fc9b0-b1fe-40a6-b77d-14438989c485,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-d2a41bdb-9684-4601-87b9-31b8421e666a,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-a4171a4e-fd23-4c85-ad93-d5ed914d72e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1982120834-172.17.0.2-1597154952107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44925,DS-813bd63b-c1c3-422f-875f-06b54a4ffbca,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-68606a0d-f859-482b-bd1c-ac96c230a379,DISK], DatanodeInfoWithStorage[127.0.0.1:46656,DS-5e592ac3-8d31-42aa-9b07-0fec23ba2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-7dbc77f2-b514-4a44-b36b-3e671360a75a,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-25af4518-a5e3-47b5-bc23-a1b5d4f1de59,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-ef4fc9b0-b1fe-40a6-b77d-14438989c485,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-d2a41bdb-9684-4601-87b9-31b8421e666a,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-a4171a4e-fd23-4c85-ad93-d5ed914d72e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5150
