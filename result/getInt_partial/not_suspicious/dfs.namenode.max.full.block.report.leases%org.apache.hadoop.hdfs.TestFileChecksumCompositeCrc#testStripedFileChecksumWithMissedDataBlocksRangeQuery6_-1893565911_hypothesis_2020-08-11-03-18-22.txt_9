reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006368926-172.17.0.12-1597115916982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39721,DS-f693deea-3296-4f5b-8ca2-1e8d08185118,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-e0dd5716-fd77-49cb-a9e2-1abb3fa4b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-945ba970-abf9-499c-a62c-414920ab4b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-6e698f5f-f1ba-4211-9299-28156e7406f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-a3d055a0-cf84-4837-8e98-f5a0af604b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-72862550-06a7-4f7a-b51e-0b3bb9f6f4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-a79ff7d8-94d7-456a-a3de-5286686efe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-21c65c16-0681-476d-8840-b798a45709d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006368926-172.17.0.12-1597115916982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39721,DS-f693deea-3296-4f5b-8ca2-1e8d08185118,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-e0dd5716-fd77-49cb-a9e2-1abb3fa4b5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-945ba970-abf9-499c-a62c-414920ab4b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-6e698f5f-f1ba-4211-9299-28156e7406f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-a3d055a0-cf84-4837-8e98-f5a0af604b37,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-72862550-06a7-4f7a-b51e-0b3bb9f6f4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-a79ff7d8-94d7-456a-a3de-5286686efe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-21c65c16-0681-476d-8840-b798a45709d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751989824-172.17.0.12-1597116071177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-109d27c4-49f3-46ea-9765-4ea51e5e2fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-94c78c04-d3ab-4d84-a905-12bc63a14085,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-c1654260-a184-4b99-bfeb-a0eb62b35808,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-9da836c8-7428-467d-83d3-05c00a535276,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-88101f8e-0b2a-4f47-b08f-28f81b347a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-a296ee34-f104-4c06-b5e4-a2259be32e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-99bda010-d363-4153-80e3-619a5366ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-bc5a3262-d3cf-4a5a-97c9-3a19f4ca8892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751989824-172.17.0.12-1597116071177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-109d27c4-49f3-46ea-9765-4ea51e5e2fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-94c78c04-d3ab-4d84-a905-12bc63a14085,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-c1654260-a184-4b99-bfeb-a0eb62b35808,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-9da836c8-7428-467d-83d3-05c00a535276,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-88101f8e-0b2a-4f47-b08f-28f81b347a68,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-a296ee34-f104-4c06-b5e4-a2259be32e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-99bda010-d363-4153-80e3-619a5366ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-bc5a3262-d3cf-4a5a-97c9-3a19f4ca8892,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299946520-172.17.0.12-1597116234337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36849,DS-e0cad15e-03f8-4cff-888f-27acc6e89893,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-177bbec7-e793-4c7b-8b80-bc96fae51f89,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-8fca105d-08ac-49e4-8b14-a143a3752b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-d6dc552e-b53f-413e-8d4c-1db20eabe2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-3e345103-afd5-4131-9ac2-86b732963aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-17ccf34d-5515-4319-9c6a-ad33e48f3c31,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-b95964b9-fba1-4052-9ad9-61972bb254cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-ea06feb9-bb2a-4dc8-b752-a5fb7ef0bf99,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299946520-172.17.0.12-1597116234337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36849,DS-e0cad15e-03f8-4cff-888f-27acc6e89893,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-177bbec7-e793-4c7b-8b80-bc96fae51f89,DISK], DatanodeInfoWithStorage[127.0.0.1:42503,DS-8fca105d-08ac-49e4-8b14-a143a3752b26,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-d6dc552e-b53f-413e-8d4c-1db20eabe2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-3e345103-afd5-4131-9ac2-86b732963aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-17ccf34d-5515-4319-9c6a-ad33e48f3c31,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-b95964b9-fba1-4052-9ad9-61972bb254cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-ea06feb9-bb2a-4dc8-b752-a5fb7ef0bf99,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448893417-172.17.0.12-1597116569007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43155,DS-bc1f082e-0839-42e3-a570-fd3748794c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-cb273de4-6777-43b6-b31b-d204a9208ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-a215570c-777c-4029-8282-b329a716f286,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-a5e4b399-e12a-41e9-8c31-393a91d285fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-d0b7fbbe-fc68-4669-b98b-a70b26b9a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d578cff5-188e-4de8-8ae2-c8648a49e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-ff46e29f-60b3-4057-8685-ccb5062ae00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-85fe85b7-6b5a-44cb-860d-d75e8d98cda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448893417-172.17.0.12-1597116569007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43155,DS-bc1f082e-0839-42e3-a570-fd3748794c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-cb273de4-6777-43b6-b31b-d204a9208ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-a215570c-777c-4029-8282-b329a716f286,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-a5e4b399-e12a-41e9-8c31-393a91d285fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-d0b7fbbe-fc68-4669-b98b-a70b26b9a65b,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-d578cff5-188e-4de8-8ae2-c8648a49e2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-ff46e29f-60b3-4057-8685-ccb5062ae00c,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-85fe85b7-6b5a-44cb-860d-d75e8d98cda6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692664185-172.17.0.12-1597116782990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32944,DS-d238f5b3-c598-41a2-9aa0-6eb5a3f1ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-e6b87eb7-140a-4353-8fc4-790ebded7aee,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-a854dfdd-1525-41d8-8128-a78ef656f6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-9644f683-ffd6-4a8e-ac86-777001dacccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-30988415-9139-4469-86cc-649deb46accf,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-36136e9c-6634-4b59-9c3a-e21db3555820,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-4ecc0262-3f08-4193-bcb5-7985e887bc77,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-d7449fff-581e-479b-9a69-3781991788b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692664185-172.17.0.12-1597116782990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32944,DS-d238f5b3-c598-41a2-9aa0-6eb5a3f1ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-e6b87eb7-140a-4353-8fc4-790ebded7aee,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-a854dfdd-1525-41d8-8128-a78ef656f6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-9644f683-ffd6-4a8e-ac86-777001dacccc,DISK], DatanodeInfoWithStorage[127.0.0.1:41561,DS-30988415-9139-4469-86cc-649deb46accf,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-36136e9c-6634-4b59-9c3a-e21db3555820,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-4ecc0262-3f08-4193-bcb5-7985e887bc77,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-d7449fff-581e-479b-9a69-3781991788b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54651248-172.17.0.12-1597117118661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42263,DS-f3d015aa-fffa-4638-9ec7-81b0eab89d54,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-6f7556cd-30e7-45d8-9c6e-d8389c03f3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-03efc1a9-fe34-44a3-ae70-20bcea9e9dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-35af0af1-8f24-4570-afae-6dfe9e511f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-5e4aa1d1-1080-4a2f-bb06-fecd7ebd9d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-29ff7dc5-a430-49e6-bde5-15461670da47,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-6463f291-8597-4ffd-9763-8f7e1ff112a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-5563815a-5c25-44b5-845b-0dd3db111d6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54651248-172.17.0.12-1597117118661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42263,DS-f3d015aa-fffa-4638-9ec7-81b0eab89d54,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-6f7556cd-30e7-45d8-9c6e-d8389c03f3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-03efc1a9-fe34-44a3-ae70-20bcea9e9dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-35af0af1-8f24-4570-afae-6dfe9e511f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-5e4aa1d1-1080-4a2f-bb06-fecd7ebd9d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-29ff7dc5-a430-49e6-bde5-15461670da47,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-6463f291-8597-4ffd-9763-8f7e1ff112a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-5563815a-5c25-44b5-845b-0dd3db111d6b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500275343-172.17.0.12-1597117327818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40960,DS-7141fe3a-92b0-40c5-bd79-ee8861249d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-8f6c4888-6865-44fd-9ebe-923062d0b3be,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-47b4517d-5104-460d-8c68-2350d27f6155,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-b24666eb-7ec7-49d5-b832-f08f53f6ed78,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-7b8918b8-b04c-49ff-b28c-ee591619185c,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-2cb39e67-0664-49d7-a46f-4b68b5f19356,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-126c3e83-9c3d-460a-983a-9753610d85b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-18995282-f845-4bdc-a826-fe86f0050d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-500275343-172.17.0.12-1597117327818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40960,DS-7141fe3a-92b0-40c5-bd79-ee8861249d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-8f6c4888-6865-44fd-9ebe-923062d0b3be,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-47b4517d-5104-460d-8c68-2350d27f6155,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-b24666eb-7ec7-49d5-b832-f08f53f6ed78,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-7b8918b8-b04c-49ff-b28c-ee591619185c,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-2cb39e67-0664-49d7-a46f-4b68b5f19356,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-126c3e83-9c3d-460a-983a-9753610d85b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-18995282-f845-4bdc-a826-fe86f0050d77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369105876-172.17.0.12-1597117401367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34771,DS-2038f648-d67e-4007-a7e6-e8959f981445,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-a9b724d5-b99a-4f23-a228-ac84cac679b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-40c8dbdd-6429-4420-b8e1-7da0e6f2e478,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-0428d603-9252-4c3b-b802-823d84ec869b,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-6217a366-5e17-40dc-ae27-2c09d36bcf16,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-2fe9975b-0898-49f8-b688-b60e520287e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-b12f2eda-2950-40f7-82bf-66dcc73c2afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-1f4e80d3-f630-4fd8-890c-6886a6ac2a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369105876-172.17.0.12-1597117401367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34771,DS-2038f648-d67e-4007-a7e6-e8959f981445,DISK], DatanodeInfoWithStorage[127.0.0.1:43035,DS-a9b724d5-b99a-4f23-a228-ac84cac679b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-40c8dbdd-6429-4420-b8e1-7da0e6f2e478,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-0428d603-9252-4c3b-b802-823d84ec869b,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-6217a366-5e17-40dc-ae27-2c09d36bcf16,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-2fe9975b-0898-49f8-b688-b60e520287e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43737,DS-b12f2eda-2950-40f7-82bf-66dcc73c2afe,DISK], DatanodeInfoWithStorage[127.0.0.1:37719,DS-1f4e80d3-f630-4fd8-890c-6886a6ac2a1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514827952-172.17.0.12-1597117462230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-ec03a1e0-4f1f-493a-a328-0f9b01250c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-44649fb3-fc43-4e05-8db0-3c8381554654,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-313ede8a-cd4b-453b-82fb-83733f966f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-73ebb7c8-ad0f-4155-b516-2e93676451df,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-92b4ef7e-1037-44e2-a7a1-6f2dc8e93fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-8769f281-f9bb-440d-8074-a042eff8ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-259aa285-9e73-470d-aec7-8434a99bfb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-52834453-53a2-4ffd-b200-99b1bf03fa7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514827952-172.17.0.12-1597117462230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35484,DS-ec03a1e0-4f1f-493a-a328-0f9b01250c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-44649fb3-fc43-4e05-8db0-3c8381554654,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-313ede8a-cd4b-453b-82fb-83733f966f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-73ebb7c8-ad0f-4155-b516-2e93676451df,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-92b4ef7e-1037-44e2-a7a1-6f2dc8e93fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-8769f281-f9bb-440d-8074-a042eff8ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-259aa285-9e73-470d-aec7-8434a99bfb91,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-52834453-53a2-4ffd-b200-99b1bf03fa7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113267888-172.17.0.12-1597117706391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46852,DS-0d14db3a-ee73-4cb6-84cc-16fd84f89881,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-a0579352-cf13-4e4b-b649-6ff4b135a4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-bbece7f5-674e-4c5b-b471-ec76a8ada8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-62688288-13b6-4152-b912-95dc5945842a,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-cc9c54d8-a246-48b7-92eb-410ca343a2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-1dec12a0-9279-468a-9312-a6c32cd302de,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-e997da9e-6998-48e4-8783-c71b0a33324d,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-e57c5ac6-82f8-41c6-bea5-1c1a87a97e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-113267888-172.17.0.12-1597117706391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46852,DS-0d14db3a-ee73-4cb6-84cc-16fd84f89881,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-a0579352-cf13-4e4b-b649-6ff4b135a4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-bbece7f5-674e-4c5b-b471-ec76a8ada8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-62688288-13b6-4152-b912-95dc5945842a,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-cc9c54d8-a246-48b7-92eb-410ca343a2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-1dec12a0-9279-468a-9312-a6c32cd302de,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-e997da9e-6998-48e4-8783-c71b0a33324d,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-e57c5ac6-82f8-41c6-bea5-1c1a87a97e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798311676-172.17.0.12-1597117921751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-9ac1a8be-8d41-4a13-90b8-fe27af13e148,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-efcf8672-47b6-498e-bc3e-ff5bce7e1cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-2aa6509a-7464-4c80-86db-e9b73c06c991,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-0eeec083-2980-4c14-9d13-ad7bb60223e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-7fc8b0de-ad45-4d51-9aa8-bc6f6365b013,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-c01d6f63-f019-4668-9d0a-902cea0ce952,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-f4cd50b7-2462-4839-bebd-b2979ba6671b,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-93876371-dbbf-4e54-9a49-d6f1b7b1acdf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798311676-172.17.0.12-1597117921751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36326,DS-9ac1a8be-8d41-4a13-90b8-fe27af13e148,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-efcf8672-47b6-498e-bc3e-ff5bce7e1cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35535,DS-2aa6509a-7464-4c80-86db-e9b73c06c991,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-0eeec083-2980-4c14-9d13-ad7bb60223e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-7fc8b0de-ad45-4d51-9aa8-bc6f6365b013,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-c01d6f63-f019-4668-9d0a-902cea0ce952,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-f4cd50b7-2462-4839-bebd-b2979ba6671b,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-93876371-dbbf-4e54-9a49-d6f1b7b1acdf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407861438-172.17.0.12-1597117988519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36694,DS-1e4ed034-a070-4d26-b3e8-d2f9447842c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-fdb42994-2dd6-4163-9025-5c9393300cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-b1af3b9a-8f59-459c-a58a-80f393dfc43a,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-d547144f-3bc1-476c-a57f-a5d188b6d821,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-e98e06ac-1744-49d1-92fe-aedc3b510389,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-9cace0fa-bcbc-4166-8dca-a822528bfeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-3e8e85cf-6962-45f7-a0b4-a5796ba0e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-a90d8e4e-6347-47d3-99aa-1e5c571e1a10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407861438-172.17.0.12-1597117988519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36694,DS-1e4ed034-a070-4d26-b3e8-d2f9447842c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-fdb42994-2dd6-4163-9025-5c9393300cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-b1af3b9a-8f59-459c-a58a-80f393dfc43a,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-d547144f-3bc1-476c-a57f-a5d188b6d821,DISK], DatanodeInfoWithStorage[127.0.0.1:33445,DS-e98e06ac-1744-49d1-92fe-aedc3b510389,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-9cace0fa-bcbc-4166-8dca-a822528bfeb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-3e8e85cf-6962-45f7-a0b4-a5796ba0e4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-a90d8e4e-6347-47d3-99aa-1e5c571e1a10,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475215646-172.17.0.12-1597118198102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-c259e46b-f782-4ab2-abb1-947f83eeabb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-320812f0-f2ad-45df-8dba-d988065674b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-1a342052-19a9-4431-87f6-54bf9eca7c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-dce62db6-78cb-4afc-a64b-ea07bb0bae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-2ab5dd88-ce01-4412-9cdd-3465f7392453,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-377d88e0-3d35-4925-8edb-255ee0481cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-2b64b0ea-c174-4412-abbf-815197db8452,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-add0c52e-4ff8-4d01-8261-10f256329e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475215646-172.17.0.12-1597118198102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37436,DS-c259e46b-f782-4ab2-abb1-947f83eeabb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39520,DS-320812f0-f2ad-45df-8dba-d988065674b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-1a342052-19a9-4431-87f6-54bf9eca7c65,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-dce62db6-78cb-4afc-a64b-ea07bb0bae3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-2ab5dd88-ce01-4412-9cdd-3465f7392453,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-377d88e0-3d35-4925-8edb-255ee0481cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-2b64b0ea-c174-4412-abbf-815197db8452,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-add0c52e-4ff8-4d01-8261-10f256329e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195318032-172.17.0.12-1597118345189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39306,DS-d6cfd1a3-20e9-464a-939f-04f0b85ebf96,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-98c42cea-6acf-44d4-9c1b-f40939247c04,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-bdafc887-56a1-4994-ad6e-8e57abc17b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-14424c8f-86b5-4458-aa98-28777f5b8c04,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-5f31958b-bcb5-40a8-ac86-32d3f55bfe47,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-f7d2cad0-3635-439c-a224-41194e50327e,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-4a505e3d-642c-4421-8f54-243ec2e540e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-8d1dae11-b351-4fd3-a85a-7bbd78e63bd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195318032-172.17.0.12-1597118345189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39306,DS-d6cfd1a3-20e9-464a-939f-04f0b85ebf96,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-98c42cea-6acf-44d4-9c1b-f40939247c04,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-bdafc887-56a1-4994-ad6e-8e57abc17b35,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-14424c8f-86b5-4458-aa98-28777f5b8c04,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-5f31958b-bcb5-40a8-ac86-32d3f55bfe47,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-f7d2cad0-3635-439c-a224-41194e50327e,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-4a505e3d-642c-4421-8f54-243ec2e540e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-8d1dae11-b351-4fd3-a85a-7bbd78e63bd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460444331-172.17.0.12-1597118383874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-5bda12e5-b2c7-41df-b6c5-db9ff73929c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-4ff2c271-5326-4ce4-96f3-0cf367266ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-b9541e80-e713-42f0-8fff-28c542b7f84b,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-9f03485c-e4d6-4620-88d9-2a31a5a3ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-63cb5920-7659-4033-97ca-9a26d060df93,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-7dc4c678-2125-4540-b984-30db15898f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-1ef14881-26dd-4d87-99b4-e77ec7df9caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-abe1753c-248c-4c26-bc31-03331c748731,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460444331-172.17.0.12-1597118383874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-5bda12e5-b2c7-41df-b6c5-db9ff73929c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-4ff2c271-5326-4ce4-96f3-0cf367266ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-b9541e80-e713-42f0-8fff-28c542b7f84b,DISK], DatanodeInfoWithStorage[127.0.0.1:37078,DS-9f03485c-e4d6-4620-88d9-2a31a5a3ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-63cb5920-7659-4033-97ca-9a26d060df93,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-7dc4c678-2125-4540-b984-30db15898f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-1ef14881-26dd-4d87-99b4-e77ec7df9caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40518,DS-abe1753c-248c-4c26-bc31-03331c748731,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116346076-172.17.0.12-1597118482986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-6ef7c6b9-dc69-4d2d-be40-36591ab2d068,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-4b876646-7a05-41eb-b843-7bc36c6406fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-3752f7db-1949-49ea-8012-651ebd14d4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-a50b433f-d9a4-45f8-b9ed-165994f2909d,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-5dca50d0-2213-4551-b63e-2ed791580eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-0afb1d51-d808-4711-b4f2-e124fa98a031,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-be6bf985-a1c7-400c-a62e-fdee12dff9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-43c7fe98-bb49-4666-925f-3ac74f1a7094,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116346076-172.17.0.12-1597118482986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-6ef7c6b9-dc69-4d2d-be40-36591ab2d068,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-4b876646-7a05-41eb-b843-7bc36c6406fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-3752f7db-1949-49ea-8012-651ebd14d4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-a50b433f-d9a4-45f8-b9ed-165994f2909d,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-5dca50d0-2213-4551-b63e-2ed791580eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-0afb1d51-d808-4711-b4f2-e124fa98a031,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-be6bf985-a1c7-400c-a62e-fdee12dff9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-43c7fe98-bb49-4666-925f-3ac74f1a7094,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945110624-172.17.0.12-1597118576562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35878,DS-3c90589d-ff14-4e09-81c3-2a2a48859e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-e8c9b57c-adf9-4563-98a6-b5a1f5c50f33,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-a0f3350b-7efb-48b5-8046-01d6c6a8c455,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-f08830c3-ba7a-4d3b-a91a-e1b18bb51bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-d8a572ed-c768-46ac-bcaa-7665804ef6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-0e737f8f-5ed4-4490-948b-a3517d8fdfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-01bb25f2-c613-47c8-9569-d0ea40edad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-e9ec19e2-c5bc-4f18-bf5d-bd13c9e3f2e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1945110624-172.17.0.12-1597118576562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35878,DS-3c90589d-ff14-4e09-81c3-2a2a48859e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42494,DS-e8c9b57c-adf9-4563-98a6-b5a1f5c50f33,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-a0f3350b-7efb-48b5-8046-01d6c6a8c455,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-f08830c3-ba7a-4d3b-a91a-e1b18bb51bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-d8a572ed-c768-46ac-bcaa-7665804ef6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-0e737f8f-5ed4-4490-948b-a3517d8fdfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39523,DS-01bb25f2-c613-47c8-9569-d0ea40edad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-e9ec19e2-c5bc-4f18-bf5d-bd13c9e3f2e6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577514103-172.17.0.12-1597118792608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32838,DS-5c38ec08-494c-4c23-be02-bc5bfc5716ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-b7d90f16-ad51-4b04-b4d0-133b880bb931,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-16760cc3-5c28-4896-8d68-220f519e2535,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-4bd3cb1e-6f5c-48ef-8741-e3781e7b7dca,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-9abde9bd-ca02-42e0-b782-eefb65cba4be,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-97f278c8-9142-432c-9b52-d378a45d387b,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-10c1a21c-0685-4cd4-a1e8-6f6b2aef8c53,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-6bba9849-0c4b-48b5-a046-5e99ab0c7ba3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577514103-172.17.0.12-1597118792608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32838,DS-5c38ec08-494c-4c23-be02-bc5bfc5716ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-b7d90f16-ad51-4b04-b4d0-133b880bb931,DISK], DatanodeInfoWithStorage[127.0.0.1:41812,DS-16760cc3-5c28-4896-8d68-220f519e2535,DISK], DatanodeInfoWithStorage[127.0.0.1:32836,DS-4bd3cb1e-6f5c-48ef-8741-e3781e7b7dca,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-9abde9bd-ca02-42e0-b782-eefb65cba4be,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-97f278c8-9142-432c-9b52-d378a45d387b,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-10c1a21c-0685-4cd4-a1e8-6f6b2aef8c53,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-6bba9849-0c4b-48b5-a046-5e99ab0c7ba3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808311030-172.17.0.12-1597118967496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-47ed1f07-bbcf-4a8d-b827-77e152103af0,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-223f3cc1-9637-462b-aa27-407e4c4adb39,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-6427378f-f313-4253-b0c2-f8e5237af764,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-0a64e3c3-cb50-4f38-83d2-735e99710b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-edd0105c-6230-44e5-a285-2dba066b3d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-7f7021b9-5021-4cfa-a13e-d7e42fc04c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-8ec02f7e-19ea-4fac-996f-a65e218ffee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-8d9c2951-6382-497b-aa17-516cfa012c57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808311030-172.17.0.12-1597118967496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33874,DS-47ed1f07-bbcf-4a8d-b827-77e152103af0,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-223f3cc1-9637-462b-aa27-407e4c4adb39,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-6427378f-f313-4253-b0c2-f8e5237af764,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-0a64e3c3-cb50-4f38-83d2-735e99710b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-edd0105c-6230-44e5-a285-2dba066b3d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41473,DS-7f7021b9-5021-4cfa-a13e-d7e42fc04c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-8ec02f7e-19ea-4fac-996f-a65e218ffee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-8d9c2951-6382-497b-aa17-516cfa012c57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584914644-172.17.0.12-1597119107384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-8af633b9-64af-453e-80a1-3bab392f1ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-4bf6cadc-8afd-4e44-aa9b-2d7d88fe6bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-233a81d8-605a-4ead-97cb-5ad56e04604f,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-eceb137f-b2ae-4b3c-b508-89857a30622b,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-954d93b0-a117-4aac-a58a-05d64b6a6aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-cb0c5a39-7556-4ba5-8126-14559e51fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-15cb80b3-6ca4-479e-9d1b-87648c3ec2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-0ff8829f-982d-42c8-870f-fc16626992b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584914644-172.17.0.12-1597119107384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41505,DS-8af633b9-64af-453e-80a1-3bab392f1ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-4bf6cadc-8afd-4e44-aa9b-2d7d88fe6bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-233a81d8-605a-4ead-97cb-5ad56e04604f,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-eceb137f-b2ae-4b3c-b508-89857a30622b,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-954d93b0-a117-4aac-a58a-05d64b6a6aba,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-cb0c5a39-7556-4ba5-8126-14559e51fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-15cb80b3-6ca4-479e-9d1b-87648c3ec2fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-0ff8829f-982d-42c8-870f-fc16626992b1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096711546-172.17.0.12-1597119179082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-9b81254a-476b-432c-a04a-4e76ae091a83,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-75ebb13c-d1c6-406a-b49a-469989f0a429,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-2c28c22d-7f6b-4ea4-ae0b-beefc021ae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-02c34f36-fa5b-48f1-a641-9359e06ff8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-bcaa99ed-dfa3-4dee-aec0-729b66980e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-1695556f-6b45-4256-bf3e-a529fdab789b,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-26cf4961-53f0-405e-96cb-b4e83a71c671,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-50b682ab-8246-4047-884f-57e44b22c2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096711546-172.17.0.12-1597119179082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44916,DS-9b81254a-476b-432c-a04a-4e76ae091a83,DISK], DatanodeInfoWithStorage[127.0.0.1:36289,DS-75ebb13c-d1c6-406a-b49a-469989f0a429,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-2c28c22d-7f6b-4ea4-ae0b-beefc021ae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-02c34f36-fa5b-48f1-a641-9359e06ff8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-bcaa99ed-dfa3-4dee-aec0-729b66980e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-1695556f-6b45-4256-bf3e-a529fdab789b,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-26cf4961-53f0-405e-96cb-b4e83a71c671,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-50b682ab-8246-4047-884f-57e44b22c2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096935127-172.17.0.12-1597119453972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40224,DS-cca742ab-a1c5-4366-9c61-9d233e605f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-b7f36060-1857-4a98-a8ce-fa3fc1e9d1af,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-3e1262ba-2f06-4fde-8fe1-033ec86e2102,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-35f79303-6fb9-4121-b98f-50b50ec0f51f,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-b3513cea-9bb2-4314-9edf-f688b14e39bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-bb9eac38-59b8-4034-ad09-618a0b092057,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-fbfa3076-0599-487a-8e4a-f78374861033,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-2a262730-b5e0-45f0-a091-f4b86e54f2c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096935127-172.17.0.12-1597119453972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40224,DS-cca742ab-a1c5-4366-9c61-9d233e605f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-b7f36060-1857-4a98-a8ce-fa3fc1e9d1af,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-3e1262ba-2f06-4fde-8fe1-033ec86e2102,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-35f79303-6fb9-4121-b98f-50b50ec0f51f,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-b3513cea-9bb2-4314-9edf-f688b14e39bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-bb9eac38-59b8-4034-ad09-618a0b092057,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-fbfa3076-0599-487a-8e4a-f78374861033,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-2a262730-b5e0-45f0-a091-f4b86e54f2c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688510623-172.17.0.12-1597119558869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-c247fa9b-46d6-4391-9c8e-639abe9de2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-35b142c8-484d-4da8-9ad6-378d76067694,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-ef1be193-75c9-408f-9a41-85db67e13eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-64399dbf-6212-469d-98c1-bda91b41f5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-048eea49-41f3-44ed-86c1-74d759b6840a,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-ca89f170-cb9b-4ca5-b004-4271f0e6e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-705055c7-7d56-40b4-b359-400415f7d951,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-2b709e28-d20b-4ad6-b16e-e6dc9901ba22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688510623-172.17.0.12-1597119558869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-c247fa9b-46d6-4391-9c8e-639abe9de2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-35b142c8-484d-4da8-9ad6-378d76067694,DISK], DatanodeInfoWithStorage[127.0.0.1:36855,DS-ef1be193-75c9-408f-9a41-85db67e13eef,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-64399dbf-6212-469d-98c1-bda91b41f5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-048eea49-41f3-44ed-86c1-74d759b6840a,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-ca89f170-cb9b-4ca5-b004-4271f0e6e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-705055c7-7d56-40b4-b359-400415f7d951,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-2b709e28-d20b-4ad6-b16e-e6dc9901ba22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149030190-172.17.0.12-1597119833686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-b498cace-adca-4ba3-85e5-b9656adf32ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-70381297-df4f-4e09-9c6f-1b5a2445a21d,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-78ca1a39-1408-40a6-ab0e-5acd0f53b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-00d86e14-e02b-4841-9e95-73f5934c1134,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-08abf073-71c0-476f-9ceb-3428f519117e,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-ce7e3202-a323-4139-ab66-0b6059cf1394,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-7dc6ecc3-26cf-4f39-a3aa-c583c52b9039,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-0ef6973f-20a6-4c85-96aa-51d73e344d90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-149030190-172.17.0.12-1597119833686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43108,DS-b498cace-adca-4ba3-85e5-b9656adf32ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-70381297-df4f-4e09-9c6f-1b5a2445a21d,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-78ca1a39-1408-40a6-ab0e-5acd0f53b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-00d86e14-e02b-4841-9e95-73f5934c1134,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-08abf073-71c0-476f-9ceb-3428f519117e,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-ce7e3202-a323-4139-ab66-0b6059cf1394,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-7dc6ecc3-26cf-4f39-a3aa-c583c52b9039,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-0ef6973f-20a6-4c85-96aa-51d73e344d90,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896623378-172.17.0.12-1597119975526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39281,DS-d940a9a9-296a-4457-a069-6823db72aace,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-5e86f6a3-1494-44db-95e1-acbdcab84074,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-897a95a5-1674-40cc-aee3-042d48a98314,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-f14784d0-439c-4654-9757-602f1b8e5436,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-7fec10b3-1334-499c-9e97-4bab7fe3b641,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-27fc867a-5e28-4703-90d4-a86960560b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-10180322-f9df-464f-a65d-f2d8d672e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-d1e3af79-0b21-41b6-ad6f-47b5edb7eca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896623378-172.17.0.12-1597119975526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39281,DS-d940a9a9-296a-4457-a069-6823db72aace,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-5e86f6a3-1494-44db-95e1-acbdcab84074,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-897a95a5-1674-40cc-aee3-042d48a98314,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-f14784d0-439c-4654-9757-602f1b8e5436,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-7fec10b3-1334-499c-9e97-4bab7fe3b641,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-27fc867a-5e28-4703-90d4-a86960560b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-10180322-f9df-464f-a65d-f2d8d672e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-d1e3af79-0b21-41b6-ad6f-47b5edb7eca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492906598-172.17.0.12-1597120071484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44642,DS-b99e5fed-e904-4b6e-ad42-10fd4e232946,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-458e2035-09ee-4df2-b560-15e0f11c239b,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-92aecd7a-c83c-450e-be6a-233e5123fb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-4969a94e-0076-4596-aa2a-37e0379c9eda,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-99cbe88f-2fec-42ad-9c59-51bcedcf6cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-2f9fd521-eb4b-4483-bd9d-b74bd6119f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-e752758a-cc35-4151-8dd3-495ed1a35056,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-31618524-9da6-4a71-95b3-ad580d677525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492906598-172.17.0.12-1597120071484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44642,DS-b99e5fed-e904-4b6e-ad42-10fd4e232946,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-458e2035-09ee-4df2-b560-15e0f11c239b,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-92aecd7a-c83c-450e-be6a-233e5123fb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-4969a94e-0076-4596-aa2a-37e0379c9eda,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-99cbe88f-2fec-42ad-9c59-51bcedcf6cff,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-2f9fd521-eb4b-4483-bd9d-b74bd6119f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-e752758a-cc35-4151-8dd3-495ed1a35056,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-31618524-9da6-4a71-95b3-ad580d677525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70552432-172.17.0.12-1597120196803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-2f09f352-f70c-472b-b5a6-bd43b17300f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-12468f6f-cf70-463d-9722-b3bb107b1f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-582460f9-1b19-4b0c-be7c-21294bb1f097,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-ee0a14f5-1434-4fb2-a113-762efe363bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-08b4b2e9-52b7-4cc9-8476-b0aee63a5b95,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-3d779516-36cb-4b71-b8a9-43551d47a2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-bcf85b0b-e1af-4993-9569-58f86f877b57,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-2f081162-c0e6-4be7-988a-315bcd6e230d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70552432-172.17.0.12-1597120196803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-2f09f352-f70c-472b-b5a6-bd43b17300f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-12468f6f-cf70-463d-9722-b3bb107b1f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-582460f9-1b19-4b0c-be7c-21294bb1f097,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-ee0a14f5-1434-4fb2-a113-762efe363bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-08b4b2e9-52b7-4cc9-8476-b0aee63a5b95,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-3d779516-36cb-4b71-b8a9-43551d47a2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-bcf85b0b-e1af-4993-9569-58f86f877b57,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-2f081162-c0e6-4be7-988a-315bcd6e230d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071874541-172.17.0.12-1597120272794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37317,DS-7e5f6746-0b03-44e8-9894-25420f462357,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-7ff33e6a-6906-41d0-97dd-2f7c82858235,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-11d0e4cf-481e-4cd6-a05e-1c5012726997,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-2fe7d6c2-792b-4d8f-8d85-36522d5e0ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-1614ed69-4126-48ce-8629-f4b206078f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-90519c22-d1f2-46ff-bcf1-079351713872,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-b77160bf-559b-4e3e-8f6e-0501df04d727,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-39995de1-497a-4aa3-b64e-05fa829a4d80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071874541-172.17.0.12-1597120272794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37317,DS-7e5f6746-0b03-44e8-9894-25420f462357,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-7ff33e6a-6906-41d0-97dd-2f7c82858235,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-11d0e4cf-481e-4cd6-a05e-1c5012726997,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-2fe7d6c2-792b-4d8f-8d85-36522d5e0ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-1614ed69-4126-48ce-8629-f4b206078f28,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-90519c22-d1f2-46ff-bcf1-079351713872,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-b77160bf-559b-4e3e-8f6e-0501df04d727,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-39995de1-497a-4aa3-b64e-05fa829a4d80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977500491-172.17.0.12-1597120305040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43420,DS-d8227285-8878-4b43-a72a-f0662c292030,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-5390b180-f0a4-43ff-b4fa-51016b151871,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-b3196789-188a-49bf-a8ab-e301cfad86a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-51b9c296-37a1-4719-a3d2-cf25f0c0104f,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-ce9122b6-f54b-47c4-94e8-9996469582ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-ccb87176-1766-4a0f-a869-6a8aebd30b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-aeb1d8ea-7123-4a67-ad88-3202bd271da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-bc27f059-0992-4c9a-b14b-7af3d878a798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977500491-172.17.0.12-1597120305040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43420,DS-d8227285-8878-4b43-a72a-f0662c292030,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-5390b180-f0a4-43ff-b4fa-51016b151871,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-b3196789-188a-49bf-a8ab-e301cfad86a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-51b9c296-37a1-4719-a3d2-cf25f0c0104f,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-ce9122b6-f54b-47c4-94e8-9996469582ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-ccb87176-1766-4a0f-a869-6a8aebd30b83,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-aeb1d8ea-7123-4a67-ad88-3202bd271da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-bc27f059-0992-4c9a-b14b-7af3d878a798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35917958-172.17.0.12-1597120700350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39721,DS-ce8b9783-d462-4755-b11c-71dc44562a33,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-e6b1341c-2722-49ab-b0cc-502392abe2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-7353f2ed-6c07-4266-86f4-7a10c97e245b,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-776cd953-d680-47a3-a9dd-acdd38fe6493,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-d4711bb3-8afc-41ef-8d7d-69a144937abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-97124757-f6e4-4cae-a37c-4b5817d53dce,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-c2215b77-5409-41b0-93c2-2e421c3d0171,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-a38c1d2a-3e65-4bbb-aead-7cf492a04e52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35917958-172.17.0.12-1597120700350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39721,DS-ce8b9783-d462-4755-b11c-71dc44562a33,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-e6b1341c-2722-49ab-b0cc-502392abe2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37355,DS-7353f2ed-6c07-4266-86f4-7a10c97e245b,DISK], DatanodeInfoWithStorage[127.0.0.1:39556,DS-776cd953-d680-47a3-a9dd-acdd38fe6493,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-d4711bb3-8afc-41ef-8d7d-69a144937abd,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-97124757-f6e4-4cae-a37c-4b5817d53dce,DISK], DatanodeInfoWithStorage[127.0.0.1:45234,DS-c2215b77-5409-41b0-93c2-2e421c3d0171,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-a38c1d2a-3e65-4bbb-aead-7cf492a04e52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418361843-172.17.0.12-1597120813601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37401,DS-bbe73dcf-ee98-40d5-ad16-aa4f13b037c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-885eb7b2-b2c8-4bad-9535-180ebcc53e15,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-6c8f872a-beda-471f-a3f3-14dae6e2bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-769c3bec-6b5d-4417-9f0f-f46ea0985f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-13c1deb1-5eac-4563-bdae-919d048555ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-4c6c33f3-0e8a-488b-8b8e-20cf44333621,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-89877ad3-b60e-43b1-b683-9a7fd498b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-be1c60bb-2c9b-4221-b60d-6cfa64cbca3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418361843-172.17.0.12-1597120813601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37401,DS-bbe73dcf-ee98-40d5-ad16-aa4f13b037c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-885eb7b2-b2c8-4bad-9535-180ebcc53e15,DISK], DatanodeInfoWithStorage[127.0.0.1:34283,DS-6c8f872a-beda-471f-a3f3-14dae6e2bf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-769c3bec-6b5d-4417-9f0f-f46ea0985f24,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-13c1deb1-5eac-4563-bdae-919d048555ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-4c6c33f3-0e8a-488b-8b8e-20cf44333621,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-89877ad3-b60e-43b1-b683-9a7fd498b7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-be1c60bb-2c9b-4221-b60d-6cfa64cbca3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207509750-172.17.0.12-1597120944644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-b913e84d-b0bd-4cb1-9ab7-b941538e68d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-658e37b1-ec80-4691-aaed-acb35495e8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-af82ab04-2b4e-4f13-871f-74c704604776,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-797402ca-23be-4781-a554-84ed6aaf1515,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-660a0595-a4b0-4943-88dc-ab412e5ba0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-c0b01f32-9c82-4ab8-9d2b-d2670bc3a80d,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-56a583c4-b8fd-40a0-825e-dd53e661be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-2f40089b-6ddc-4fb6-b69e-acd0eafd7fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207509750-172.17.0.12-1597120944644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-b913e84d-b0bd-4cb1-9ab7-b941538e68d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-658e37b1-ec80-4691-aaed-acb35495e8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-af82ab04-2b4e-4f13-871f-74c704604776,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-797402ca-23be-4781-a554-84ed6aaf1515,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-660a0595-a4b0-4943-88dc-ab412e5ba0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-c0b01f32-9c82-4ab8-9d2b-d2670bc3a80d,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-56a583c4-b8fd-40a0-825e-dd53e661be1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-2f40089b-6ddc-4fb6-b69e-acd0eafd7fd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max.full.block.report.leases
component: hdfs:NameNode
v1: 6
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124839675-172.17.0.12-1597121079782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-ce7db8f3-5a8f-402b-b9fe-3d7274841e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-c750813a-dbb5-4459-bbc9-586bbd0b20cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-d3a3ed37-4115-46ea-969f-b40687a85ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-d2e0d69b-8b5b-443c-a271-2cbede4ae630,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-dffb1cab-d77a-47d8-9941-e55a4cd910f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-7cf9724d-fe4e-42fb-815b-b5f4d50b3c76,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-f8ccf624-a8eb-41f7-bd6b-946897a5c1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-10a68564-c512-4a1e-b901-8b4e1528207b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124839675-172.17.0.12-1597121079782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35574,DS-ce7db8f3-5a8f-402b-b9fe-3d7274841e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-c750813a-dbb5-4459-bbc9-586bbd0b20cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-d3a3ed37-4115-46ea-969f-b40687a85ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-d2e0d69b-8b5b-443c-a271-2cbede4ae630,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-dffb1cab-d77a-47d8-9941-e55a4cd910f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-7cf9724d-fe4e-42fb-815b-b5f4d50b3c76,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-f8ccf624-a8eb-41f7-bd6b-946897a5c1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-10a68564-c512-4a1e-b901-8b4e1528207b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5229
