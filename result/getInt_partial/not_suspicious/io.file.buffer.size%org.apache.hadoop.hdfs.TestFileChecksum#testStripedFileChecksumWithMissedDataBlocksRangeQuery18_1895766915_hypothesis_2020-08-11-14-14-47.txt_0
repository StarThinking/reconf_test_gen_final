reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098799322-172.17.0.3-1597156327280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46533,DS-7a14370d-86d5-45c6-b432-c9c0d86fed24,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-a6abad9f-74f1-42c6-95f9-623daead24e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-5a2713ea-b859-414a-9e76-5f85c6162895,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-11bcc0c0-171e-4193-97bd-d841e12e467c,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d4ab9c41-5643-43a8-a2d4-0e9b1c2786b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-53d8cba5-272f-4ae4-8338-a449c07d9972,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-178bc81b-da1d-4874-a4fa-0f671ae606bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-073d733b-81ed-4ea3-957d-e95f61aea755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098799322-172.17.0.3-1597156327280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46533,DS-7a14370d-86d5-45c6-b432-c9c0d86fed24,DISK], DatanodeInfoWithStorage[127.0.0.1:43260,DS-a6abad9f-74f1-42c6-95f9-623daead24e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-5a2713ea-b859-414a-9e76-5f85c6162895,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-11bcc0c0-171e-4193-97bd-d841e12e467c,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d4ab9c41-5643-43a8-a2d4-0e9b1c2786b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-53d8cba5-272f-4ae4-8338-a449c07d9972,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-178bc81b-da1d-4874-a4fa-0f671ae606bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-073d733b-81ed-4ea3-957d-e95f61aea755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145266723-172.17.0.3-1597156575304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36922,DS-378171a0-cb3e-4728-9d89-da14aa02cb83,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-72e29022-ec68-44a6-8d86-c10556fb4ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-e40097a5-95d9-4954-a734-dea771843275,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-82927fbc-dff3-48d2-a326-ded425f2129b,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-1e4ec8b6-4cdd-4305-8336-5bbdaef41cac,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-d4ae439d-6742-4679-99e5-2cddbd60a82b,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-158677b3-3e0e-4251-9cd3-5002d387dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-e812df4f-7802-4532-8919-db9c99d380f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145266723-172.17.0.3-1597156575304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36922,DS-378171a0-cb3e-4728-9d89-da14aa02cb83,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-72e29022-ec68-44a6-8d86-c10556fb4ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-e40097a5-95d9-4954-a734-dea771843275,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-82927fbc-dff3-48d2-a326-ded425f2129b,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-1e4ec8b6-4cdd-4305-8336-5bbdaef41cac,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-d4ae439d-6742-4679-99e5-2cddbd60a82b,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-158677b3-3e0e-4251-9cd3-5002d387dbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-e812df4f-7802-4532-8919-db9c99d380f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996808858-172.17.0.3-1597156945261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36373,DS-f0f38868-87ba-40b7-95cc-25fafc605b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-48818442-8a89-49e2-b8dc-7b9b57f25d87,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-1b060468-c646-43c6-a13c-ce42adb82204,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-02fb19dd-cb7b-4b04-b9bb-558f4aa8a4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-4f43dc4c-9b16-4140-ac35-3993aed798d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-01e043f0-7f63-4f13-bded-d90818718db4,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7fe5e7b9-0f67-4cdc-9af5-379361754181,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-da7f3f82-23b8-4e55-bb23-a35cc3321d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-996808858-172.17.0.3-1597156945261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36373,DS-f0f38868-87ba-40b7-95cc-25fafc605b72,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-48818442-8a89-49e2-b8dc-7b9b57f25d87,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-1b060468-c646-43c6-a13c-ce42adb82204,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-02fb19dd-cb7b-4b04-b9bb-558f4aa8a4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-4f43dc4c-9b16-4140-ac35-3993aed798d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-01e043f0-7f63-4f13-bded-d90818718db4,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-7fe5e7b9-0f67-4cdc-9af5-379361754181,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-da7f3f82-23b8-4e55-bb23-a35cc3321d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594782255-172.17.0.3-1597157337623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35405,DS-b43b566c-ffa9-4f83-966e-2639e6fa7ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-4b289fc0-be41-40d8-9f8b-bd9da0394248,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-e86c8812-1fd4-4774-8221-ec43995e4c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-0b3e7b13-ca75-4a42-b06e-1a834e59da44,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-387823d3-8800-4d89-b520-aea56b5b0474,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-8d76c02b-3049-45af-86fa-1c60633afe23,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-35c0249e-f2d8-4e07-b146-05678123c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-67e617de-d5ef-446e-8c50-95fdc62faa52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-594782255-172.17.0.3-1597157337623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35405,DS-b43b566c-ffa9-4f83-966e-2639e6fa7ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-4b289fc0-be41-40d8-9f8b-bd9da0394248,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-e86c8812-1fd4-4774-8221-ec43995e4c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-0b3e7b13-ca75-4a42-b06e-1a834e59da44,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-387823d3-8800-4d89-b520-aea56b5b0474,DISK], DatanodeInfoWithStorage[127.0.0.1:44755,DS-8d76c02b-3049-45af-86fa-1c60633afe23,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-35c0249e-f2d8-4e07-b146-05678123c37b,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-67e617de-d5ef-446e-8c50-95fdc62faa52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095572666-172.17.0.3-1597158085672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33034,DS-2f8b4a06-aa96-4ddf-9868-1f83cb6e0aad,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-753233f6-22b8-4d8a-ab47-c60e40e25d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-30604a06-87b7-4dd7-9bd9-9dabcc202da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-c2042f4e-2a35-4302-a419-2ffaaccf322e,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-45be635a-5f40-4c75-9a73-f17b6499a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-815215a9-9b62-4d15-a61a-a1d458c649f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-1602087a-459f-4075-824b-1f996d0fe2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-7433f2b0-1390-43a0-aa56-88115588e08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1095572666-172.17.0.3-1597158085672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33034,DS-2f8b4a06-aa96-4ddf-9868-1f83cb6e0aad,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-753233f6-22b8-4d8a-ab47-c60e40e25d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-30604a06-87b7-4dd7-9bd9-9dabcc202da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-c2042f4e-2a35-4302-a419-2ffaaccf322e,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-45be635a-5f40-4c75-9a73-f17b6499a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-815215a9-9b62-4d15-a61a-a1d458c649f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-1602087a-459f-4075-824b-1f996d0fe2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-7433f2b0-1390-43a0-aa56-88115588e08f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399190368-172.17.0.3-1597158506411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-b8e50e10-a41d-4eda-ad38-86b7e76748b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-47e00fe1-f4af-4b85-ac84-908c33e71b43,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-6909409f-8d9e-40bf-af8d-7ce0551f83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-d368094e-4ca0-43dd-9229-f535bbd46eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-bdf9e001-4977-4f2e-8b6e-fcb443c19266,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-48734652-e7f3-49e6-8d86-19a88a3b7fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-dd6fd548-acbc-4197-a1f1-0fa494361314,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-98f93d00-16ef-4e06-bce9-e437a2d64c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399190368-172.17.0.3-1597158506411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-b8e50e10-a41d-4eda-ad38-86b7e76748b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-47e00fe1-f4af-4b85-ac84-908c33e71b43,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-6909409f-8d9e-40bf-af8d-7ce0551f83d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35777,DS-d368094e-4ca0-43dd-9229-f535bbd46eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-bdf9e001-4977-4f2e-8b6e-fcb443c19266,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-48734652-e7f3-49e6-8d86-19a88a3b7fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-dd6fd548-acbc-4197-a1f1-0fa494361314,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-98f93d00-16ef-4e06-bce9-e437a2d64c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776171897-172.17.0.3-1597159001412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38216,DS-ab1158b4-0e77-4899-b588-b7678a1e7332,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-6f01a1b0-ca0d-4673-8dec-aa6bcbf31b15,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-78fdfd1c-516e-4dc1-897d-7744dcdf3ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-5247df43-41f8-4b31-a4e8-83ef8fe062a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-71636401-97b0-422d-99ec-23f0592217b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-49e2c84f-7440-4b90-af5e-06f6798feda7,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-519ac312-1b9b-4871-8da9-c77a58b077e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-d4c94eed-5ca5-4e21-bdca-7266d6c16009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1776171897-172.17.0.3-1597159001412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38216,DS-ab1158b4-0e77-4899-b588-b7678a1e7332,DISK], DatanodeInfoWithStorage[127.0.0.1:37951,DS-6f01a1b0-ca0d-4673-8dec-aa6bcbf31b15,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-78fdfd1c-516e-4dc1-897d-7744dcdf3ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-5247df43-41f8-4b31-a4e8-83ef8fe062a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-71636401-97b0-422d-99ec-23f0592217b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-49e2c84f-7440-4b90-af5e-06f6798feda7,DISK], DatanodeInfoWithStorage[127.0.0.1:34445,DS-519ac312-1b9b-4871-8da9-c77a58b077e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-d4c94eed-5ca5-4e21-bdca-7266d6c16009,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413090261-172.17.0.3-1597159442797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-f3eb8174-bbff-4c89-948b-fd50bf06dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-55fb666e-7d71-47a6-9b8c-926c0de027a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-09ebaae6-c651-415d-951a-6c926e34b584,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-abe40553-19c9-4d18-9493-30d82c19f9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-86633183-1666-401f-abf3-08aa28ab7b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-80ca2d07-2fe0-43a2-8293-d6650cff0f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-27f40b94-4053-4fa9-9b61-b1364f16cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-f8407388-fa2d-4f87-bd88-e27cc52b5eb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1413090261-172.17.0.3-1597159442797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-f3eb8174-bbff-4c89-948b-fd50bf06dd85,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-55fb666e-7d71-47a6-9b8c-926c0de027a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-09ebaae6-c651-415d-951a-6c926e34b584,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-abe40553-19c9-4d18-9493-30d82c19f9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-86633183-1666-401f-abf3-08aa28ab7b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-80ca2d07-2fe0-43a2-8293-d6650cff0f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-27f40b94-4053-4fa9-9b61-b1364f16cf92,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-f8407388-fa2d-4f87-bd88-e27cc52b5eb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033456249-172.17.0.3-1597159689090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40411,DS-3a452e9e-429c-47b1-9dbd-4a7b5a41c603,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-51c1ba7d-3c3d-4389-be13-80bce5c44a27,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-a6e1d243-ab6d-46f1-a378-e23b1e2b56c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-453a44e1-3c70-45a4-aa10-1911ed72a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-d5e3135d-8592-43c7-bea0-6128e8d1ad61,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-6c2d9762-0ba2-42c1-9e49-da0fce7a1883,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-da07cdd0-9c19-4ad6-ac2a-14dfb7732032,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-77f88f2f-c3cd-43e3-8aee-c4c95d24eabd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033456249-172.17.0.3-1597159689090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40411,DS-3a452e9e-429c-47b1-9dbd-4a7b5a41c603,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-51c1ba7d-3c3d-4389-be13-80bce5c44a27,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-a6e1d243-ab6d-46f1-a378-e23b1e2b56c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-453a44e1-3c70-45a4-aa10-1911ed72a9f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-d5e3135d-8592-43c7-bea0-6128e8d1ad61,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-6c2d9762-0ba2-42c1-9e49-da0fce7a1883,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-da07cdd0-9c19-4ad6-ac2a-14dfb7732032,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-77f88f2f-c3cd-43e3-8aee-c4c95d24eabd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888254806-172.17.0.3-1597159816757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-a66cec44-5146-4d84-b9e2-4963f2a6a871,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-455b6944-8405-4f60-a7df-043d37367564,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-66447769-ba08-449b-b415-a1e760ff52f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-b4ef639a-b529-488d-9554-3f9c44bbb834,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-8cf13734-10ac-4945-98e7-f06123a44cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-4192b5d2-665b-4bb6-9c1e-47de8bc39154,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-50cf9ab9-a5ec-4d65-a480-3ba4112616e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-ffc76cbc-8aff-42ad-8555-b19ca5eedcf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-888254806-172.17.0.3-1597159816757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44158,DS-a66cec44-5146-4d84-b9e2-4963f2a6a871,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-455b6944-8405-4f60-a7df-043d37367564,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-66447769-ba08-449b-b415-a1e760ff52f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44743,DS-b4ef639a-b529-488d-9554-3f9c44bbb834,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-8cf13734-10ac-4945-98e7-f06123a44cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-4192b5d2-665b-4bb6-9c1e-47de8bc39154,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-50cf9ab9-a5ec-4d65-a480-3ba4112616e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-ffc76cbc-8aff-42ad-8555-b19ca5eedcf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172205507-172.17.0.3-1597159846501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38454,DS-6e5ba2a9-754a-4e8c-b983-7f2b9e4b7e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-b3b05175-2c82-4d93-a3b9-d163956b84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-4d9a88a6-7437-415b-9770-ca08658b9dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-3cbfcd3c-e12f-4bd5-b012-db7b8160b51d,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-2b3b2f71-55bc-4cbc-9959-0d5cb0e4c744,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-3122872e-f72e-4eda-90b3-c9397e2c77ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-4e10fd94-72ac-49a4-9141-f6a0bcc329eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-2ade80fb-febf-40ea-951b-6e10ade8334a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-172205507-172.17.0.3-1597159846501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38454,DS-6e5ba2a9-754a-4e8c-b983-7f2b9e4b7e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-b3b05175-2c82-4d93-a3b9-d163956b84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-4d9a88a6-7437-415b-9770-ca08658b9dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-3cbfcd3c-e12f-4bd5-b012-db7b8160b51d,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-2b3b2f71-55bc-4cbc-9959-0d5cb0e4c744,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-3122872e-f72e-4eda-90b3-c9397e2c77ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-4e10fd94-72ac-49a4-9141-f6a0bcc329eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-2ade80fb-febf-40ea-951b-6e10ade8334a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88997281-172.17.0.3-1597159991989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-80571e5b-32d6-4079-bc0d-3583c8b471b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-409527ae-af73-4484-8b36-15217ab21ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-91b4c8f3-54b6-4166-87ae-201296d04ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-c8532555-9fea-4e4f-a434-efe84fa7320c,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-dfc47083-9bfc-428b-ab7c-63bc496f3267,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-8ec7445a-c676-4a6a-9582-d21bcac9d96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-8d7e6828-9f37-428c-88af-d4809dd003ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-f6779307-9df0-4e86-9f02-c017c6d8068e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88997281-172.17.0.3-1597159991989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-80571e5b-32d6-4079-bc0d-3583c8b471b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-409527ae-af73-4484-8b36-15217ab21ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-91b4c8f3-54b6-4166-87ae-201296d04ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-c8532555-9fea-4e4f-a434-efe84fa7320c,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-dfc47083-9bfc-428b-ab7c-63bc496f3267,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-8ec7445a-c676-4a6a-9582-d21bcac9d96d,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-8d7e6828-9f37-428c-88af-d4809dd003ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-f6779307-9df0-4e86-9f02-c017c6d8068e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: io.file.buffer.size
component: hdfs:DataNode
v1: 64
v2: 4096
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067132752-172.17.0.3-1597160172906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35355,DS-b8921467-311f-4066-b8ad-7ac68ffdc5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-0d15b125-8a1e-478f-8715-ed21d50ecc03,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-bfd6f887-fa85-4ec7-bc88-71dbfa0ea66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-d649f79c-3c60-45d2-bd24-b0748582584d,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-b5128616-7330-4cd6-9f74-0b0766d86dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-5b1abcbb-45cc-4aaf-a3bf-7a4dc96a08df,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-8135c581-c1fb-4b2a-9194-33fd60bd9f44,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-66c2f37f-a919-4da8-b2d4-b4879ea4fb6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067132752-172.17.0.3-1597160172906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35355,DS-b8921467-311f-4066-b8ad-7ac68ffdc5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-0d15b125-8a1e-478f-8715-ed21d50ecc03,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-bfd6f887-fa85-4ec7-bc88-71dbfa0ea66a,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-d649f79c-3c60-45d2-bd24-b0748582584d,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-b5128616-7330-4cd6-9f74-0b0766d86dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-5b1abcbb-45cc-4aaf-a3bf-7a4dc96a08df,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-8135c581-c1fb-4b2a-9194-33fd60bd9f44,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-66c2f37f-a919-4da8-b2d4-b4879ea4fb6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 4935
